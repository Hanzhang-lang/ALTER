{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 5.24早修改table format 空格\\xa\n",
    "- 5.24 下午修改str_normalize \n",
    "- 5.24 晚 72需要复查\n",
    "- 5.25 早list query strip() \n",
    "- 5.27 修改total，尝试disambiguous/  改成PIPE  / 晚上发现列名重复修改的问题， 发现shot来自test的问题\n",
    "- 5.29 在shot中添加extra\n",
    "- 5.31 在选列aug的shot中添加extra\n",
    "- 6.1 some extra infor may be useful\n",
    "- 6.3 添val 101shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import parse_specific_composition, add_row_number, parse_specific_composition_zh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sqlalchemy import create_engine\n",
    "from executor import SQLManager\n",
    "import sqlparse\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "            model_name='BAAI/bge-large-en',\n",
    "            model_kwargs={'device': 'cuda:0', 'trust_remote_code': True},\n",
    "            encode_kwargs={'normalize_embeddings': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "                  \"what was the time difference between the first place finisher and the eighth place finisher?\",\n",
    "                  \"other than william stuart price, which other businessman was born in tulsa?\",\n",
    "                  \"which canadian city had the most passengers traveling from manzanillo international airport in 2013?\"\n",
    "                  ]\n",
    "new_query_examples = [\n",
    "                      \"what was the time for the first place finisher?; what was the time for the eighth place finisher?\",\n",
    "                      \"was william stuart price born in tulsa?; who was born in tulsa?\",\n",
    "                      \"how many passengers do each airline from canadian city have?; which canadian city had the most passengers?\"\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 11, 86]\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True, embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub-queries. Below is a sub-table with rows randomly sampled from the original table. Based on the sub-table, decompose the original query into 2-3 complete sub-queries that can solve the original query.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "# model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.7).bind(logprobs=True)\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "engine = create_engine('sqlite:////media/disk1/chatgpt/zh/tabular_data/db/sqlite/ablquery.db', echo=False)\n",
    "manager = SQLManager(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name=task_name, split='test', use_sample=False, small_test=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [5, 11, 46]\n",
    "num_k = 3\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True,embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\"was the Sandia Peak Tramway before or after the 3S Aerial Tramway in terms of Year_of_inauguration?\",\n",
    "                      \"other than William Stuart Price, which other businessman's was in Tulsa in terms of Hometown?\",\n",
    "                      \"How many players are G\\\\nF in terms of Position?\"]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "disambiguous_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    # prefix=\"\"\"Based on the given table, your task is to rewrite the query to resolve ambiguity and ensure the question is consistent with the table. \n",
    "    # This requires pinpointing elements of the question to table contents and rewriting the question to ensure a consistent, clear interpretation. \"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_answer(k: int=1):\n",
    "#     sqls = [\"SELECT COUNT(*) FROM DF WHERE Outcome = 'Runner-up' AND Opponent = 'Roger Federer';\"\n",
    "#             ]\n",
    "#     thoughts = [\"The SQL query filters the data to only include rows where the outcome is 'Runner-up' and the opponent is 'Roger Federer'. The sub-table shows that Roger Federer was a runner-up 2 times.\"]\n",
    "#     tables = [\"\"\" <table>\n",
    "# <thead>\n",
    "# <tr><th>  COUNT(*)</th></tr>\n",
    "# </thead>\n",
    "# <tbody>\n",
    "# <tr><td>2.0000    </td></tr>\n",
    "# </tbody>\n",
    "# </table>\"\"\"]\n",
    "#     tables_pipe = [\"\"\"/*\n",
    "# table caption : turkish cup\n",
    "# col : MAX(winners_c_from_previous_round)\n",
    "# row 1: 54\n",
    "# */\"\"\"]\n",
    "#     claims = [\"how many times was roger federer a runner-up?\"]\n",
    "        sqls = [\"SELECT DISTINCT Type FROM DF WHERE Type != 'audio';\"\n",
    "                ]\n",
    "        thoughts = [\"Based on the SQL query and the extra information provided, the types include audio or video. Therefore, other than audio, the payload type is video.\"]\n",
    "        tables = ['<table>\\n<thead>\\n<tr><th> Type </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>video   </td></tr>\\n<tr><td>audio/video   </td></tr>\\n</tbody>\\n</table>']\n",
    "        claims = [\"other than audio, what type of payload types are there?\"]\n",
    "        extras = [\"The payload types for audio include audio, video, and audio/video.\"]\n",
    "#     sqls = [\"SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';\"\n",
    "#             ]\n",
    "#     thoughts = [\"Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \"]\n",
    "#     tables = [\"<table>\\n<caption>1972 isle of man tt</caption>\\n<thead>\\n<tr><th>  MIN(points)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>3            </td></tr>\\n</tbody>\\n</table>\"]\n",
    "#     claims = [\"2 be the fewest point that roger dutton / tony wright receive\"]\n",
    "    # inds from test split\n",
    "        examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"information\",  \"claim\", \"thought\", \"output\"], template=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {claim}\n",
    "Thought: {thought}\n",
    "Answer: {output}\n",
    "        \"\"\")\n",
    "        examples_dict = dict(zip([\"SQL\", \"table\", \"information\",  \"claim\", \"thought\", \"output\"], [sqls[0], tables[0], extras[0], claims[0], thoughts[0], 'video']))\n",
    "        prompt_template = FewShotPromptTemplate(\n",
    "                examples=[examples_dict],\n",
    "                example_prompt=examples_prompt,\n",
    "                prefix=\"\"\"Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
    "You should output in the following format:\n",
    "Thought: your step by step thought\n",
    "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "Below is an example.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\"\"\",\n",
    "                input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    "        )\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_aug(k: int=2):\n",
    "    table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "    examples_dict = []\n",
    "    \n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Mesa Trouble\"       </td><td>Sid Marcus </td><td>1974       </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": table_loader.dataset[95]['question'],\n",
    "                                        \"aug\": \"The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year. \\n1. Number: The episode number in the series \\n2. Title: The title of the episode \\n3. Directed_by_: The director of the episode \\n4. Released_: The release year of the episode\",\n",
    "                                        \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "                                        \"output\": \"Released_, Number, Title, Directed_by_\"}])\n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>1943–44 Chicago Black Hawks season</caption>\\n<thead>\\n<tr><th>  num</th><th>       Date</th><th>            Visitor</th><th>  Score</th><th>               Home</th><th>  Record</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>14   </td><td>December 5 </td><td>New York Rangers   </td><td>6–7    </td><td>Chicago Black Hawks</td><td>8–6–0   </td></tr>\\n<tr><td>40   </td><td>February 26</td><td>Chicago Black Hawks</td><td>3–2    </td><td>Toronto Maple Leafs</td><td>18–18–4 </td></tr>\\n<tr><td>31   </td><td>January 29 </td><td>Chicago Black Hawks</td><td>4–3    </td><td>Toronto Maple Leafs</td><td>14–16–1 </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": 'what was the difference in score in the december 19th win?',\n",
    "                                        \"aug\": 'The table contains information about the 1943-44 Chicago Black Hawks season, including the date, visitor, score, home team, record, and points for each game. \\n1. num: The game number in the season \\n2. Date: The date of the game\\n3. Vistor: The visiting team\\n4. Score: The final score, with the visitor score listed first\\n5. Home: The home team\\n6. Record: The team win-loss-overtime loss record at the time of the game',\n",
    "                                        \"linking\": 'difference in score -> Score, december 19th -> Date',\n",
    "                                        \"output\": 'Date, Score'}])\n",
    "    \n",
    "    # \"The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year.\"\n",
    "    # \"№<The episode number in the series>\\nTitle<The title of the episode>\\nDirected_by_<The director of the episode>\\nReleased_<The release year of the episode>\"\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"table\", \"aug\",\"claim\", \"output\", \"linking\"], template=\n",
    "    \"\"\"\n",
    "    Table: {table}\n",
    "    Extra information: {aug}\n",
    "    \n",
    "    Query: {claim}\n",
    "    Column linking: {linking}\n",
    "    Columns: {output}\"\"\")\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples_dict,\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\n",
    "        \"\"\"\n",
    "    Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
    "    Approach this task as follows:\n",
    "    Read the query and extra information thoroughly and list every possible link from query term to column in the Table. \n",
    "    Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "    Table: {table}\n",
    "    Extra information: {aug}\n",
    "    \n",
    "    Query: {claim}\"\"\",\n",
    "        input_variables=[\"table\", \"claim\", \"aug\"],\n",
    ")\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "# def get_k_shot_with_aug(k: int=2):\n",
    "#     table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "#     examples_dict = []\n",
    "#     examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>',\n",
    "#                                         \"claim\": table_loader.dataset[95]['question'],\n",
    "#                                         \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "#                                         \"output\": \"Title, Released_, Number, Directed_by_\"}])\n",
    "#     examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "#     \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking: {linking}\n",
    "#     Columns: {output}\"\"\")\n",
    "#     prompt_template = FewShotPromptTemplate(\n",
    "#         examples=examples_dict,\n",
    "#         example_prompt=examples_prompt,\n",
    "#         prefix=\n",
    "#         \"\"\"\n",
    "#     Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
    "#     Approach this task as follows:\n",
    "#     Read the query thoroughly and list every possible link from query term to column in the Table. \n",
    "#     Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "#     # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "#     # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "#     # Here are some examples:\"\"\",\n",
    "#         suffix=\n",
    "#         \"\"\"\n",
    "#     Table: {table}\n",
    "#     Extra information: {aug}\n",
    "    \n",
    "#     Query: {claim}\"\"\",\n",
    "#         input_variables=[\"table\", \"claim\", \"aug\"],\n",
    "# )\n",
    "#     return prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "# from utils import parse_output\n",
    "# table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "# summary_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "# schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "# composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "\n",
    "\n",
    "# sample = table_loader.normalize_table(table_loader.dataset[110])\n",
    "\n",
    "# # summary_aug, column_aug = summary_information.loc[sample['table']['id']]['summary'], summary_information.loc[sample['table']['id']]['column_description'] \n",
    "# # col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "# # extra_col_info = []\n",
    "# # for i_c in range(len(col_names)):\n",
    "# #     extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "# formatter = TableFormat(format='none', data=sample)\n",
    "\n",
    "\n",
    "\n",
    "# llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=True)\n",
    "# batch_pred = llm_chain.batch([{\n",
    "#     \"claim\": sample['query'],\n",
    "#     'aug':  '',\n",
    "#     # \"query\": \"how many of the seasons games were played in the gold coast convention centre?\",\n",
    "#                             \"table\": TableFormat.format_html(data= formatter.get_sample_data(sample_type='random',k=5, query=sample['query'],),table_caption=sample['table']['caption'])}],)\n",
    "# print(batch_pred[0]['text'])\n",
    "#     #                             \"table\": \"\"\"table caption : 2008 - 09 nbl season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "def scene_A(query, sample, k =3, verbose=True):\n",
    "    # Our ultimate goal is to answer query based on the original table. Below we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "    # Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "#     row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "#                                  template=\"\"\"Our ultimate goal is to answer query based on the original table. Below we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "# sub-table: {table}\n",
    "# Extra information: {aug}\n",
    "\n",
    "# Query: {claim}\n",
    "# SQL: \"\"\")\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                    template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        \n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug +'\\n'+ '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        if verbose:\n",
    "            print(stage_1_batch_pred)\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        try: \n",
    "            # formatter.all_data = formatter.all_data.loc[:, columns]\n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique().astype(str)))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique()[:3].astype(str)))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        extra_information.append('row_number: row index in the original table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data = sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\nColumn information:\\n' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "        if verbose:\n",
    "            print(stage_2_batch_pred)\n",
    "    # stage 3: SQL Excution\n",
    "    try: \n",
    "        execute_data = manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "    except:\n",
    "        execute_data = formatter.all_data\n",
    "        stage_2_batch_pred = 'SELECT * from DF;'\n",
    "    if len(execute_data) == 0:\n",
    "        return query, stage_2_batch_pred, 'No data from database', cb.total_tokens\n",
    "    return query, stage_2_batch_pred, TableFormat.format_html(data=execute_data), cb.total_tokens\n",
    "    # return query, stage_2_batch_pred, execute_data, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)\n",
    "\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整extrainformation的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering and answer the query using the final sub-table. \n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: \n",
    "{table}\n",
    "Query: {claim}\n",
    "Please provide a clear, complete statement in response to the query. If you cannot answer the query based on the sub-table, just say 'Cannot get answer from sub-table'.\n",
    "\"\"\" )\n",
    "def scene_B(query, sample, k=3, verbose=False):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    \n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    # get columns\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n' + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        try: \n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique().astype(str)))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique()[:3].astype(str)))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        #  sample augmentation\n",
    "        # extra_information = (parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        extra_information.append('row_number: row index in the table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "    \n",
    "        \n",
    "        # stage 3: SQL Excution\n",
    "        try: \n",
    "            execute_data= manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "        except:\n",
    "            execute_data = formatter.all_data\n",
    "            stage_2_batch_pred = 'SELECT * from DF;'\n",
    "        llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=verbose)\n",
    "        response = llm_chain.batch([dict({'table': TableFormat.format_html(execute_data),\n",
    "                                                'claim': query,\n",
    "                                                'SQL':  stage_2_batch_pred\n",
    "                                                })], return_only_outputs=True)[0]['text']\n",
    "    # print(\"total_tokens:\", cb.total_tokens)\n",
    "    return response, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2b219db0d2984f9dae28b651ab8ab3d9\"\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://smsh.openai.azure.com/\"\n",
    "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "# os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=0.3,\n",
    "    max_retries=8, request_timeout=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '跑的是加了选列的shot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m跑的是加了选列的shot\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name '跑的是加了选列的shot' is not defined"
     ]
    }
   ],
   "source": [
    "跑的是加了选列的shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff12394f259488591811059289cc6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|                                                                                             …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Process 3031\n",
      " Process 3032\n",
      " Process 3033\n",
      " Process 3034\n",
      " Process 3035\n",
      " Process 3036\n",
      " Process 3037\n",
      " Process 3038\n",
      " Process 3039\n",
      "saving 3039\n",
      " Process 3040\n",
      " Process 3041\n",
      " Process 3042\n",
      " Process 3043\n",
      " Process 3044\n",
      " Process 3045\n",
      " Process 3046\n",
      " Process 3047\n",
      " Process 3048\n",
      " Process 3049\n",
      "saving 3049\n",
      " Process 3050\n",
      " Process 3051\n",
      " Process 3052\n",
      " Process 3053\n",
      " Process 3054\n",
      " Process 3055\n",
      " Process 3056\n",
      " Process 3057\n",
      " Process 3058\n",
      " Process 3059\n",
      "saving 3059\n",
      " Process 3060\n",
      " Process 3061\n",
      " Process 3062\n",
      " Process 3063\n",
      " Process 3064\n",
      " Process 3065\n",
      " Process 3066\n",
      " Process 3067\n",
      " Process 3068\n",
      " Process 3069\n",
      "saving 3069\n",
      " Process 3070\n",
      " Process 3071\n",
      " Process 3072\n",
      " Process 3073\n",
      " Process 3074\n",
      " Process 3075\n",
      " Process 3076\n",
      " Process 3077\n",
      " Process 3078\n",
      " Process 3079\n",
      "saving 3079\n",
      " Process 3080\n",
      " Process 3081\n",
      " Process 3082\n",
      " Process 3083\n",
      " Process 3084\n",
      " Process 3085\n",
      " Process 3086\n",
      " Process 3087\n",
      " Process 3088\n",
      " Process 3089\n",
      "saving 3089\n",
      " Process 3090\n",
      " Process 3091\n",
      " Process 3092\n",
      " Process 3093\n",
      " Process 3094\n",
      " Process 3095\n",
      " Process 3096\n",
      " Process 3097\n",
      " Process 3098\n",
      " Process 3099\n",
      "saving 3099\n",
      " Process 3100\n",
      " Process 3101\n",
      " Process 3102\n",
      " Process 3103\n",
      " Process 3104\n",
      " Process 3105\n",
      " Process 3106\n",
      " Process 3107\n",
      " Process 3108\n",
      " Process 3109\n",
      "saving 3109\n",
      " Process 3110\n",
      " Process 3111\n",
      " Process 3112\n",
      " Process 3113\n",
      " Process 3114\n",
      " Process 3115\n",
      " Process 3116\n",
      " Process 3117\n",
      " Process 3118\n",
      " Process 3119\n",
      "saving 3119\n",
      " Process 3120\n",
      " Process 3121\n",
      " Process 3122\n",
      " Process 3123\n",
      " Process 3124\n",
      " Process 3125\n",
      " Process 3126\n",
      " Process 3127\n",
      " Process 3128\n",
      " Process 3129\n",
      "saving 3129\n",
      " Process 3130\n",
      " Process 3131\n",
      " Process 3132\n",
      " Process 3133\n",
      " Process 3134\n",
      " Process 3135\n",
      " Process 3136\n",
      " Process 3137\n",
      " Process 3138\n",
      " Process 3139\n",
      "saving 3139\n",
      " Process 3140\n",
      " Process 3141\n",
      " Process 3142\n",
      " Process 3143\n",
      " Process 3144\n",
      " Process 3145\n",
      " Process 3146\n",
      " Process 3147\n",
      " Process 3148\n",
      " Process 3149\n",
      "saving 3149\n",
      " Process 3150\n",
      " Process 3151\n",
      " Process 3152\n",
      " Process 3153\n",
      " Process 3154\n",
      " Process 3155\n",
      " Process 3156\n",
      " Process 3157\n",
      " Process 3158\n",
      " Process 3159\n",
      "saving 3159\n",
      " Process 3160\n",
      " Process 3161\n",
      " Process 3162\n",
      " Process 3163\n",
      " Process 3164\n",
      " Process 3165\n",
      " Process 3166\n",
      " Process 3167\n",
      " Process 3168\n",
      " Process 3169\n",
      "saving 3169\n",
      " Process 3170\n",
      " Process 3171\n",
      " Process 3172\n",
      " Process 3173\n",
      " Process 3174\n",
      " Process 3175\n",
      " Process 3176\n",
      " Process 3177\n",
      " Process 3178\n",
      " Process 3179\n",
      "saving 3179\n",
      " Process 3180\n",
      " Process 3181\n",
      " Process 3182\n",
      " Process 3183\n",
      " Process 3184\n",
      " Process 3185\n",
      " Process 3186\n",
      " Process 3187\n",
      " Process 3188\n",
      " Process 3189\n",
      "saving 3189\n",
      " Process 3190\n",
      " Process 3191\n",
      " Process 3192\n",
      " Process 3193\n",
      " Process 3194\n",
      " Process 3195\n",
      " Process 3196\n",
      " Process 3197\n",
      " Process 3198\n",
      " Process 3199\n",
      "saving 3199\n",
      " Process 3200\n",
      " Process 3201\n",
      " Process 3202\n",
      " Process 3203\n",
      " Process 3204\n",
      " Process 3205\n",
      " Process 3206\n",
      " Process 3207\n",
      " Process 3208\n",
      " Process 3209\n",
      "saving 3209\n",
      " Process 3210\n",
      " Process 3211\n",
      " Process 3212\n",
      " Process 3213\n",
      " Process 3214\n",
      " Process 3215\n",
      " Process 3216\n",
      " Process 3217\n",
      " Process 3218\n",
      " Process 3219\n",
      "saving 3219\n",
      " Process 3220\n",
      " Process 3221\n",
      " Process 3222\n",
      " Process 3223\n",
      " Process 3224\n",
      " Process 3225\n",
      " Process 3226\n",
      " Process 3227\n",
      " Process 3228\n",
      " Process 3229\n",
      "saving 3229\n",
      " Process 3230\n",
      " Process 3231\n",
      " Process 3232\n",
      " Process 3233\n",
      " Process 3234\n",
      " Process 3235\n",
      " Process 3236\n",
      " Process 3237\n",
      " Process 3238\n",
      " Process 3239\n",
      "saving 3239\n",
      " Process 3240\n",
      " Process 3241\n",
      " Process 3242\n",
      " Process 3243\n",
      " Process 3244\n",
      " Process 3245\n",
      " Process 3246\n",
      " Process 3247\n",
      " Process 3248\n",
      " Process 3249\n",
      "saving 3249\n",
      " Process 3250\n",
      " Process 3251\n",
      " Process 3252\n",
      " Process 3253\n",
      " Process 3254\n",
      " Process 3255\n",
      " Process 3256\n",
      " Process 3257\n",
      " Process 3258\n",
      " Process 3259\n",
      "saving 3259\n",
      " Process 3260\n",
      " Process 3261\n",
      " Process 3262\n",
      " Process 3263\n",
      " Process 3264\n",
      " Process 3265\n",
      " Process 3266\n",
      " Process 3267\n",
      " Process 3268\n",
      " Process 3269\n",
      "saving 3269\n",
      " Process 3270\n",
      " Process 3271\n",
      " Process 3272\n",
      " Process 3273\n",
      " Process 3274\n",
      " Process 3275\n",
      " Process 3276\n",
      " Process 3277\n",
      " Process 3278\n",
      " Process 3279\n",
      "saving 3279\n",
      " Process 3280\n",
      " Process 3281\n",
      " Process 3282\n",
      " Process 3283\n",
      " Process 3284\n",
      " Process 3285\n",
      " Process 3286\n",
      " Process 3287\n",
      " Process 3288\n",
      " Process 3289\n",
      "saving 3289\n",
      " Process 3290\n",
      " Process 3291\n",
      " Process 3292\n",
      " Process 3293\n",
      " Process 3294\n",
      " Process 3295\n",
      " Process 3296\n",
      " Process 3297\n",
      " Process 3298\n",
      " Process 3299\n",
      "saving 3299\n",
      " Process 3300\n",
      " Process 3301\n",
      " Process 3302\n",
      " Process 3303\n",
      " Process 3304\n",
      " Process 3305\n",
      " Process 3306\n",
      " Process 3307\n",
      " Process 3308\n",
      " Process 3309\n",
      "saving 3309\n",
      " Process 3310\n",
      " Process 3311\n",
      " Process 3312\n",
      " Process 3313\n",
      " Process 3314\n",
      " Process 3315\n",
      " Process 3316\n",
      " Process 3317\n",
      " Process 3318\n",
      " Process 3319\n",
      "saving 3319\n",
      " Process 3320\n",
      " Process 3321\n",
      " Process 3322\n",
      " Process 3323\n",
      " Process 3324\n",
      " Process 3325\n",
      " Process 3326\n",
      " Process 3327\n",
      " Process 3328\n",
      " Process 3329\n",
      "saving 3329\n",
      " Process 3330\n",
      " Process 3331\n",
      " Process 3332\n",
      " Process 3333\n",
      " Process 3334\n",
      " Process 3335\n",
      " Process 3336\n",
      " Process 3337\n",
      " Process 3338\n",
      " Process 3339\n",
      "saving 3339\n",
      " Process 3340\n",
      " Process 3341\n",
      " Process 3342\n",
      " Process 3343\n",
      " Process 3344\n",
      " Process 3345\n",
      " Process 3346\n",
      " Process 3347\n",
      " Process 3348\n",
      " Process 3349\n",
      "saving 3349\n",
      " Process 3350\n",
      " Process 3351\n",
      " Process 3352\n",
      " Process 3353\n",
      " Process 3354\n",
      " Process 3355\n",
      " Process 3356\n",
      " Process 3357\n",
      " Process 3358\n",
      " Process 3359\n",
      "saving 3359\n",
      " Process 3360\n",
      " Process 3361\n",
      " Process 3362\n",
      " Process 3363\n",
      " Process 3364\n",
      " Process 3365\n",
      " Process 3366\n",
      " Process 3367\n",
      " Process 3368\n",
      " Process 3369\n",
      "saving 3369\n",
      " Process 3370\n",
      " Process 3371\n",
      " Process 3372\n",
      " Process 3373\n",
      " Process 3374\n",
      " Process 3375\n",
      " Process 3376\n",
      " Process 3377\n",
      " Process 3378\n",
      " Process 3379\n",
      "saving 3379\n",
      " Process 3380\n",
      " Process 3381\n",
      " Process 3382\n",
      " Process 3383\n",
      " Process 3384\n",
      " Process 3385\n",
      " Process 3386\n",
      " Process 3387\n",
      " Process 3388\n",
      " Process 3389\n",
      "saving 3389\n",
      " Process 3390\n",
      " Process 3391\n",
      " Process 3392\n",
      " Process 3393\n",
      " Process 3394\n",
      " Process 3395\n",
      " Process 3396\n",
      " Process 3397\n",
      " Process 3398\n",
      " Process 3399\n",
      "saving 3399\n",
      " Process 3400\n",
      " Process 3401\n",
      " Process 3402\n",
      " Process 3403\n",
      " Process 3404\n",
      " Process 3405\n",
      " Process 3406\n",
      " Process 3407\n",
      " Process 3408\n",
      " Process 3409\n",
      "saving 3409\n",
      " Process 3410\n",
      " Process 3411\n",
      " Process 3412\n",
      " Process 3413\n",
      " Process 3414\n",
      " Process 3415\n",
      " Process 3416\n",
      " Process 3417\n",
      " Process 3418\n",
      " Process 3419\n",
      "saving 3419\n",
      " Process 3420\n",
      " Process 3421\n",
      " Process 3422\n",
      " Process 3423\n",
      " Process 3424\n",
      " Process 3425\n",
      " Process 3426\n",
      " Process 3427\n",
      " Process 3428\n",
      " Process 3429\n",
      "saving 3429\n",
      " Process 3430\n",
      " Process 3431\n",
      " Process 3432\n",
      " Process 3433\n",
      " Process 3434\n",
      " Process 3435\n",
      " Process 3436\n",
      " Process 3437\n",
      " Process 3438\n",
      " Process 3439\n",
      "saving 3439\n",
      " Process 3440\n",
      " Process 3441\n",
      " Process 3442\n",
      " Process 3443\n",
      " Process 3444\n",
      " Process 3445\n",
      " Process 3446\n",
      " Process 3447\n",
      " Process 3448\n",
      " Process 3449\n",
      "saving 3449\n",
      " Process 3450\n",
      " Process 3451\n",
      " Process 3452\n",
      " Process 3453\n",
      " Process 3454\n",
      " Process 3455\n",
      " Process 3456\n",
      " Process 3457\n",
      " Process 3458\n",
      " Process 3459\n",
      "saving 3459\n",
      " Process 3460\n",
      " Process 3461\n",
      " Process 3462\n",
      " Process 3463\n",
      " Process 3464\n",
      " Process 3465\n",
      " Process 3466\n",
      " Process 3467\n",
      " Process 3468\n",
      " Process 3469\n",
      "saving 3469\n",
      " Process 3470\n",
      " Process 3471\n",
      " Process 3472\n",
      " Process 3473\n",
      " Process 3474\n",
      " Process 3475\n",
      " Process 3476\n",
      " Process 3477\n",
      " Process 3478\n",
      " Process 3479\n",
      "saving 3479\n",
      " Process 3480\n",
      " Process 3481\n",
      " Process 3482\n",
      " Process 3483\n",
      " Process 3484\n",
      " Process 3485\n",
      " Process 3486\n",
      " Process 3487\n",
      " Process 3488\n",
      " Process 3489\n",
      "saving 3489\n",
      " Process 3490\n",
      " Process 3491\n",
      " Process 3492\n",
      " Process 3493\n",
      " Process 3494\n",
      " Process 3495\n",
      " Process 3496\n",
      " Process 3497\n",
      " Process 3498\n",
      " Process 3499\n",
      "saving 3499\n",
      " Process 3500\n",
      " Process 3501\n",
      " Process 3502\n",
      " Process 3503\n",
      " Process 3504\n",
      " Process 3505\n",
      " Process 3506\n",
      " Process 3507\n",
      " Process 3508\n",
      " Process 3509\n",
      "saving 3509\n",
      " Process 3510\n",
      " Process 3511\n",
      " Process 3512\n",
      " Process 3513\n",
      " Process 3514\n",
      " Process 3515\n",
      "******************Value Error 3515****************************\n",
      " Process 3517\n",
      " Process 3518\n",
      " Process 3519\n",
      "saving 3519\n",
      " Process 3520\n",
      " Process 3521\n",
      " Process 3522\n",
      " Process 3523\n",
      " Process 3524\n",
      " Process 3525\n",
      " Process 3526\n",
      " Process 3527\n",
      " Process 3528\n",
      " Process 3529\n",
      "saving 3529\n",
      " Process 3530\n",
      " Process 3531\n",
      " Process 3532\n",
      " Process 3533\n",
      " Process 3534\n",
      " Process 3535\n",
      " Process 3536\n",
      " Process 3537\n",
      " Process 3538\n",
      " Process 3539\n",
      "saving 3539\n",
      " Process 3540\n",
      " Process 3541\n",
      " Process 3542\n",
      " Process 3543\n",
      " Process 3544\n",
      " Process 3545\n",
      " Process 3546\n",
      " Process 3547\n",
      " Process 3548\n",
      " Process 3549\n",
      "saving 3549\n",
      " Process 3550\n",
      " Process 3551\n",
      " Process 3552\n",
      " Process 3553\n",
      " Process 3554\n",
      " Process 3555\n",
      " Process 3556\n",
      " Process 3557\n",
      " Process 3558\n",
      " Process 3559\n",
      "saving 3559\n",
      " Process 3560\n",
      " Process 3561\n",
      " Process 3562\n",
      " Process 3563\n",
      " Process 3564\n",
      " Process 3565\n",
      " Process 3566\n",
      " Process 3567\n",
      " Process 3568\n",
      " Process 3569\n",
      "saving 3569\n",
      " Process 3570\n",
      " Process 3571\n",
      " Process 3572\n",
      " Process 3573\n",
      " Process 3574\n",
      " Process 3575\n",
      " Process 3576\n",
      " Process 3577\n",
      " Process 3578\n",
      " Process 3579\n",
      "saving 3579\n",
      " Process 3580\n",
      " Process 3581\n",
      " Process 3582\n",
      " Process 3583\n",
      " Process 3584\n",
      " Process 3585\n",
      " Process 3586\n",
      " Process 3587\n",
      " Process 3588\n",
      " Process 3589\n",
      "saving 3589\n",
      " Process 3590\n",
      " Process 3591\n",
      " Process 3592\n",
      " Process 3593\n",
      " Process 3594\n",
      " Process 3595\n",
      " Process 3596\n",
      " Process 3597\n",
      " Process 3598\n",
      " Process 3599\n",
      "saving 3599\n",
      " Process 3600\n",
      " Process 3601\n",
      " Process 3602\n",
      " Process 3603\n",
      " Process 3604\n",
      " Process 3605\n",
      " Process 3606\n",
      " Process 3607\n",
      " Process 3608\n",
      " Process 3609\n",
      "saving 3609\n",
      " Process 3610\n",
      " Process 3611\n",
      " Process 3612\n",
      " Process 3613\n",
      " Process 3614\n",
      " Process 3615\n",
      " Process 3616\n",
      " Process 3617\n",
      " Process 3618\n",
      " Process 3619\n",
      "saving 3619\n",
      " Process 3620\n",
      " Process 3621\n",
      " Process 3622\n",
      " Process 3623\n",
      " Process 3624\n",
      " Process 3625\n",
      " Process 3626\n",
      " Process 3627\n",
      " Process 3628\n",
      " Process 3629\n",
      "saving 3629\n",
      " Process 3630\n",
      " Process 3631\n",
      " Process 3632\n",
      " Process 3633\n",
      " Process 3634\n",
      " Process 3635\n",
      " Process 3636\n",
      " Process 3637\n",
      " Process 3638\n",
      " Process 3639\n",
      "saving 3639\n",
      " Process 3640\n",
      " Process 3641\n",
      " Process 3642\n",
      " Process 3643\n",
      " Process 3644\n",
      " Process 3645\n",
      " Process 3646\n",
      " Process 3647\n",
      " Process 3648\n",
      " Process 3649\n",
      "saving 3649\n",
      " Process 3650\n",
      " Process 3651\n",
      " Process 3652\n",
      " Process 3653\n",
      " Process 3654\n",
      " Process 3655\n",
      " Process 3656\n",
      " Process 3657\n",
      " Process 3658\n",
      " Process 3659\n",
      "saving 3659\n",
      " Process 3660\n",
      " Process 3661\n",
      " Process 3662\n",
      " Process 3663\n",
      " Process 3664\n",
      " Process 3665\n",
      " Process 3666\n",
      " Process 3667\n",
      " Process 3668\n",
      " Process 3669\n",
      "saving 3669\n",
      " Process 3670\n",
      " Process 3671\n",
      " Process 3672\n",
      " Process 3673\n",
      " Process 3674\n",
      " Process 3675\n",
      " Process 3676\n",
      " Process 3677\n",
      " Process 3678\n",
      " Process 3679\n",
      "saving 3679\n",
      " Process 3680\n",
      " Process 3681\n",
      " Process 3682\n",
      " Process 3683\n",
      " Process 3684\n",
      " Process 3685\n",
      " Process 3686\n",
      " Process 3687\n",
      " Process 3688\n",
      " Process 3689\n",
      "saving 3689\n",
      " Process 3690\n",
      " Process 3691\n",
      " Process 3692\n",
      " Process 3693\n",
      " Process 3694\n",
      " Process 3695\n",
      " Process 3696\n",
      " Process 3697\n",
      " Process 3698\n",
      " Process 3699\n",
      "saving 3699\n",
      " Process 3700\n",
      " Process 3701\n",
      " Process 3702\n",
      " Process 3703\n",
      " Process 3704\n",
      " Process 3705\n",
      " Process 3706\n",
      " Process 3707\n",
      " Process 3708\n",
      " Process 3709\n",
      "*************************Bad Request**************\n",
      " Process 3711\n",
      " Process 3712\n",
      " Process 3713\n",
      " Process 3714\n",
      " Process 3715\n",
      " Process 3716\n",
      " Process 3717\n",
      " Process 3718\n",
      " Process 3719\n",
      "saving 3719\n",
      " Process 3720\n",
      " Process 3721\n",
      " Process 3722\n",
      " Process 3723\n",
      " Process 3724\n",
      " Process 3725\n",
      " Process 3726\n",
      " Process 3727\n",
      " Process 3728\n",
      " Process 3729\n",
      "saving 3729\n",
      " Process 3730\n",
      " Process 3731\n",
      " Process 3732\n",
      " Process 3733\n",
      " Process 3734\n",
      " Process 3735\n",
      " Process 3736\n",
      " Process 3737\n",
      " Process 3738\n",
      " Process 3739\n",
      "saving 3739\n",
      " Process 3740\n",
      " Process 3741\n",
      " Process 3742\n",
      " Process 3743\n",
      " Process 3744\n",
      " Process 3745\n",
      " Process 3746\n",
      " Process 3747\n",
      " Process 3748\n",
      " Process 3749\n",
      "saving 3749\n",
      " Process 3750\n",
      " Process 3751\n",
      " Process 3752\n",
      " Process 3753\n",
      " Process 3754\n",
      " Process 3755\n",
      " Process 3756\n",
      " Process 3757\n",
      " Process 3758\n",
      " Process 3759\n",
      "saving 3759\n",
      " Process 3760\n",
      " Process 3761\n",
      " Process 3762\n",
      " Process 3763\n",
      " Process 3764\n",
      " Process 3765\n",
      " Process 3766\n",
      " Process 3767\n",
      " Process 3768\n",
      " Process 3769\n",
      "saving 3769\n",
      " Process 3770\n",
      " Process 3771\n",
      " Process 3772\n",
      " Process 3773\n",
      " Process 3774\n",
      " Process 3775\n",
      " Process 3776\n",
      " Process 3777\n",
      " Process 3778\n",
      " Process 3779\n",
      "saving 3779\n",
      " Process 3780\n",
      " Process 3781\n",
      " Process 3782\n",
      " Process 3783\n",
      " Process 3784\n",
      " Process 3785\n",
      " Process 3786\n",
      " Process 3787\n",
      " Process 3788\n",
      " Process 3789\n",
      "saving 3789\n",
      " Process 3790\n",
      " Process 3791\n",
      " Process 3792\n",
      " Process 3793\n",
      " Process 3794\n",
      " Process 3795\n",
      " Process 3796\n",
      " Process 3797\n",
      " Process 3798\n",
      " Process 3799\n",
      "saving 3799\n",
      " Process 3800\n",
      " Process 3801\n",
      " Process 3802\n",
      " Process 3803\n",
      " Process 3804\n",
      " Process 3805\n",
      " Process 3806\n",
      " Process 3807\n",
      " Process 3808\n",
      " Process 3809\n",
      "saving 3809\n",
      " Process 3810\n",
      " Process 3811\n",
      " Process 3812\n",
      " Process 3813\n",
      " Process 3814\n",
      " Process 3815\n",
      " Process 3816\n",
      " Process 3817\n",
      " Process 3818\n",
      " Process 3819\n",
      "saving 3819\n",
      " Process 3820\n",
      " Process 3821\n",
      " Process 3822\n",
      " Process 3823\n",
      " Process 3824\n",
      " Process 3825\n",
      " Process 3826\n",
      " Process 3827\n",
      " Process 3828\n",
      " Process 3829\n",
      "saving 3829\n",
      " Process 3830\n",
      " Process 3831\n",
      " Process 3832\n",
      " Process 3833\n",
      " Process 3834\n",
      " Process 3835\n",
      " Process 3836\n",
      " Process 3837\n",
      " Process 3838\n",
      " Process 3839\n",
      "saving 3839\n",
      " Process 3840\n",
      " Process 3841\n",
      " Process 3842\n",
      " Process 3843\n",
      " Process 3844\n",
      " Process 3845\n",
      " Process 3846\n",
      " Process 3847\n",
      " Process 3848\n",
      " Process 3849\n",
      "saving 3849\n",
      " Process 3850\n",
      " Process 3851\n",
      " Process 3852\n",
      " Process 3853\n",
      " Process 3854\n",
      " Process 3855\n",
      " Process 3856\n",
      " Process 3857\n",
      " Process 3858\n",
      " Process 3859\n",
      "saving 3859\n",
      " Process 3860\n",
      " Process 3861\n",
      " Process 3862\n",
      " Process 3863\n",
      " Process 3864\n",
      " Process 3865\n",
      " Process 3866\n",
      " Process 3867\n",
      " Process 3868\n",
      " Process 3869\n",
      "saving 3869\n",
      " Process 3870\n",
      " Process 3871\n",
      " Process 3872\n",
      " Process 3873\n",
      " Process 3874\n",
      " Process 3875\n",
      " Process 3876\n",
      " Process 3877\n",
      " Process 3878\n",
      " Process 3879\n",
      "saving 3879\n",
      " Process 3880\n",
      " Process 3881\n",
      " Process 3882\n",
      " Process 3883\n",
      " Process 3884\n",
      " Process 3885\n",
      " Process 3886\n",
      " Process 3887\n",
      " Process 3888\n",
      " Process 3889\n",
      "saving 3889\n",
      " Process 3890\n",
      " Process 3891\n",
      " Process 3892\n",
      " Process 3893\n",
      " Process 3894\n",
      " Process 3895\n",
      " Process 3896\n",
      " Process 3897\n",
      " Process 3898\n",
      " Process 3899\n",
      "saving 3899\n",
      " Process 3900\n",
      " Process 3901\n",
      " Process 3902\n",
      " Process 3903\n",
      " Process 3904\n",
      " Process 3905\n",
      " Process 3906\n",
      " Process 3907\n",
      " Process 3908\n",
      " Process 3909\n",
      "saving 3909\n",
      " Process 3910\n",
      " Process 3911\n",
      " Process 3912\n",
      " Process 3913\n",
      " Process 3914\n",
      " Process 3915\n",
      " Process 3916\n",
      " Process 3917\n",
      " Process 3918\n",
      " Process 3919\n",
      "saving 3919\n",
      " Process 3920\n",
      " Process 3921\n",
      " Process 3922\n",
      " Process 3923\n",
      " Process 3924\n",
      " Process 3925\n",
      " Process 3926\n",
      " Process 3927\n",
      " Process 3928\n",
      " Process 3929\n",
      "saving 3929\n",
      " Process 3930\n",
      " Process 3931\n",
      " Process 3932\n",
      " Process 3933\n",
      " Process 3934\n",
      " Process 3935\n",
      " Process 3936\n",
      " Process 3937\n",
      " Process 3938\n",
      " Process 3939\n",
      "saving 3939\n",
      " Process 3940\n",
      " Process 3941\n",
      " Process 3942\n",
      " Process 3943\n",
      " Process 3944\n",
      " Process 3945\n",
      " Process 3946\n",
      " Process 3947\n",
      " Process 3948\n",
      " Process 3949\n",
      "saving 3949\n",
      " Process 3950\n",
      " Process 3951\n",
      " Process 3952\n",
      " Process 3953\n",
      " Process 3954\n",
      " Process 3955\n",
      " Process 3956\n",
      " Process 3957\n",
      " Process 3958\n",
      " Process 3959\n",
      "saving 3959\n",
      " Process 3960\n",
      " Process 3961\n",
      " Process 3962\n",
      " Process 3963\n",
      " Process 3964\n",
      " Process 3965\n",
      " Process 3966\n",
      " Process 3967\n",
      " Process 3968\n",
      " Process 3969\n",
      "saving 3969\n",
      " Process 3970\n",
      " Process 3971\n",
      " Process 3972\n",
      " Process 3973\n",
      " Process 3974\n",
      " Process 3975\n",
      " Process 3976\n",
      " Process 3977\n",
      " Process 3978\n",
      " Process 3979\n",
      "saving 3979\n",
      " Process 3980\n",
      " Process 3981\n",
      " Process 3982\n",
      " Process 3983\n",
      " Process 3984\n",
      " Process 3985\n",
      " Process 3986\n",
      " Process 3987\n",
      " Process 3988\n",
      " Process 3989\n",
      "saving 3989\n",
      " Process 3990\n",
      " Process 3991\n",
      " Process 3992\n",
      " Process 3993\n",
      " Process 3994\n",
      " Process 3995\n",
      " Process 3996\n",
      " Process 3997\n",
      " Process 3998\n",
      " Process 3999\n",
      "saving 3999\n",
      " Process 4000\n",
      " Process 4001\n",
      " Process 4002\n",
      " Process 4003\n",
      " Process 4004\n",
      " Process 4005\n",
      " Process 4006\n",
      " Process 4007\n",
      " Process 4008\n",
      " Process 4009\n",
      "saving 4009\n",
      " Process 4010\n",
      " Process 4011\n",
      " Process 4012\n",
      " Process 4013\n",
      " Process 4014\n",
      " Process 4015\n",
      " Process 4016\n",
      " Process 4017\n",
      " Process 4018\n",
      " Process 4019\n",
      "saving 4019\n",
      " Process 4020\n",
      " Process 4021\n",
      " Process 4022\n",
      " Process 4023\n",
      " Process 4024\n",
      " Process 4025\n",
      " Process 4026\n",
      " Process 4027\n",
      " Process 4028\n",
      " Process 4029\n",
      "saving 4029\n",
      " Process 4030\n",
      " Process 4031\n",
      " Process 4032\n",
      " Process 4033\n",
      " Process 4034\n",
      " Process 4035\n",
      " Process 4036\n",
      " Process 4037\n",
      " Process 4038\n",
      " Process 4039\n",
      "saving 4039\n",
      " Process 4040\n",
      " Process 4041\n",
      " Process 4042\n",
      " Process 4043\n",
      " Process 4044\n",
      " Process 4045\n",
      " Process 4046\n",
      " Process 4047\n",
      " Process 4048\n",
      " Process 4049\n",
      "saving 4049\n",
      " Process 4050\n",
      " Process 4051\n",
      " Process 4052\n",
      " Process 4053\n",
      " Process 4054\n",
      " Process 4055\n",
      " Process 4056\n",
      " Process 4057\n",
      " Process 4058\n",
      " Process 4059\n",
      "saving 4059\n",
      " Process 4060\n",
      " Process 4061\n",
      " Process 4062\n",
      " Process 4063\n",
      " Process 4064\n",
      " Process 4065\n",
      " Process 4066\n",
      " Process 4067\n",
      " Process 4068\n",
      " Process 4069\n",
      "saving 4069\n",
      " Process 4070\n",
      " Process 4071\n",
      " Process 4072\n",
      " Process 4073\n",
      " Process 4074\n",
      " Process 4075\n",
      " Process 4076\n",
      " Process 4077\n",
      " Process 4078\n",
      " Process 4079\n",
      "saving 4079\n",
      " Process 4080\n",
      " Process 4081\n",
      " Process 4082\n",
      " Process 4083\n",
      " Process 4084\n",
      " Process 4085\n",
      " Process 4086\n",
      " Process 4087\n",
      " Process 4088\n",
      " Process 4089\n",
      "******************Value Error 4089****************************\n",
      " Process 4091\n",
      " Process 4092\n",
      " Process 4093\n",
      " Process 4094\n",
      " Process 4095\n",
      " Process 4096\n",
      " Process 4097\n",
      " Process 4098\n",
      " Process 4099\n",
      "saving 4099\n",
      " Process 4100\n",
      " Process 4101\n",
      " Process 4102\n",
      " Process 4103\n",
      " Process 4104\n",
      " Process 4105\n",
      " Process 4106\n",
      " Process 4107\n",
      " Process 4108\n",
      " Process 4109\n",
      "saving 4109\n",
      " Process 4110\n",
      " Process 4111\n",
      " Process 4112\n",
      " Process 4113\n",
      " Process 4114\n",
      " Process 4115\n",
      " Process 4116\n",
      " Process 4117\n",
      " Process 4118\n",
      " Process 4119\n",
      "saving 4119\n",
      " Process 4120\n",
      " Process 4121\n",
      " Process 4122\n",
      " Process 4123\n",
      " Process 4124\n",
      " Process 4125\n",
      " Process 4126\n",
      " Process 4127\n",
      " Process 4128\n",
      " Process 4129\n",
      "saving 4129\n",
      " Process 4130\n",
      " Process 4131\n",
      " Process 4132\n",
      " Process 4133\n",
      " Process 4134\n",
      " Process 4135\n",
      " Process 4136\n",
      " Process 4137\n",
      " Process 4138\n",
      " Process 4139\n",
      "saving 4139\n",
      " Process 4140\n",
      " Process 4141\n",
      " Process 4142\n",
      " Process 4143\n",
      " Process 4144\n",
      "******************Value Error 4144****************************\n",
      " Process 4146\n",
      " Process 4147\n",
      " Process 4148\n",
      " Process 4149\n",
      "saving 4149\n",
      " Process 4150\n",
      " Process 4151\n",
      " Process 4152\n",
      " Process 4153\n",
      " Process 4154\n",
      " Process 4155\n",
      " Process 4156\n",
      " Process 4157\n",
      " Process 4158\n",
      " Process 4159\n",
      "saving 4159\n",
      " Process 4160\n",
      " Process 4161\n",
      " Process 4162\n",
      " Process 4163\n",
      " Process 4164\n",
      " Process 4165\n",
      " Process 4166\n",
      " Process 4167\n",
      " Process 4168\n",
      " Process 4169\n",
      "saving 4169\n",
      " Process 4170\n",
      " Process 4171\n",
      " Process 4172\n",
      " Process 4173\n",
      " Process 4174\n",
      " Process 4175\n",
      " Process 4176\n",
      " Process 4177\n",
      " Process 4178\n",
      " Process 4179\n",
      "saving 4179\n",
      " Process 4180\n",
      " Process 4181\n",
      " Process 4182\n",
      " Process 4183\n",
      " Process 4184\n",
      " Process 4185\n",
      " Process 4186\n",
      " Process 4187\n",
      " Process 4188\n",
      " Process 4189\n",
      "saving 4189\n",
      " Process 4190\n",
      " Process 4191\n",
      " Process 4192\n",
      " Process 4193\n",
      " Process 4194\n",
      " Process 4195\n",
      " Process 4196\n",
      " Process 4197\n",
      " Process 4198\n",
      " Process 4199\n",
      "saving 4199\n",
      " Process 4200\n",
      " Process 4201\n",
      " Process 4202\n",
      " Process 4203\n",
      " Process 4204\n",
      " Process 4205\n",
      " Process 4206\n",
      " Process 4207\n",
      " Process 4208\n",
      " Process 4209\n",
      "saving 4209\n",
      " Process 4210\n",
      " Process 4211\n",
      " Process 4212\n",
      " Process 4213\n",
      " Process 4214\n",
      " Process 4215\n",
      " Process 4216\n",
      " Process 4217\n",
      " Process 4218\n",
      " Process 4219\n",
      "saving 4219\n",
      " Process 4220\n",
      " Process 4221\n",
      " Process 4222\n",
      " Process 4223\n",
      " Process 4224\n",
      " Process 4225\n",
      " Process 4226\n",
      " Process 4227\n",
      " Process 4228\n",
      " Process 4229\n",
      "saving 4229\n",
      " Process 4230\n",
      " Process 4231\n",
      " Process 4232\n",
      " Process 4233\n",
      " Process 4234\n",
      " Process 4235\n",
      " Process 4236\n",
      " Process 4237\n",
      " Process 4238\n",
      " Process 4239\n",
      "saving 4239\n",
      " Process 4240\n",
      " Process 4241\n",
      " Process 4242\n",
      " Process 4243\n",
      " Process 4244\n",
      " Process 4245\n",
      " Process 4246\n",
      " Process 4247\n",
      " Process 4248\n",
      " Process 4249\n",
      "saving 4249\n",
      " Process 4250\n",
      " Process 4251\n",
      " Process 4252\n",
      " Process 4253\n",
      " Process 4254\n",
      " Process 4255\n",
      " Process 4256\n",
      " Process 4257\n",
      " Process 4258\n",
      " Process 4259\n",
      "saving 4259\n",
      " Process 4260\n",
      " Process 4261\n",
      " Process 4262\n",
      " Process 4263\n",
      " Process 4264\n",
      " Process 4265\n",
      " Process 4266\n",
      " Process 4267\n",
      " Process 4268\n",
      " Process 4269\n",
      "saving 4269\n",
      " Process 4270\n",
      " Process 4271\n",
      " Process 4272\n",
      " Process 4273\n",
      " Process 4274\n",
      " Process 4275\n",
      " Process 4276\n",
      " Process 4277\n",
      " Process 4278\n",
      " Process 4279\n",
      "saving 4279\n",
      " Process 4280\n",
      " Process 4281\n",
      " Process 4282\n",
      " Process 4283\n",
      " Process 4284\n",
      " Process 4285\n",
      " Process 4286\n",
      " Process 4287\n",
      " Process 4288\n",
      " Process 4289\n",
      "saving 4289\n",
      " Process 4290\n",
      " Process 4291\n",
      " Process 4292\n",
      " Process 4293\n",
      " Process 4294\n",
      " Process 4295\n",
      " Process 4296\n",
      " Process 4297\n",
      " Process 4298\n",
      " Process 4299\n",
      "saving 4299\n",
      " Process 4300\n",
      " Process 4301\n",
      " Process 4302\n",
      " Process 4303\n",
      " Process 4304\n",
      " Process 4305\n",
      " Process 4306\n",
      " Process 4307\n",
      " Process 4308\n",
      " Process 4309\n",
      "saving 4309\n",
      " Process 4310\n",
      " Process 4311\n",
      " Process 4312\n",
      " Process 4313\n",
      " Process 4314\n",
      " Process 4315\n",
      " Process 4316\n",
      " Process 4317\n",
      " Process 4318\n",
      " Process 4319\n",
      "saving 4319\n",
      " Process 4320\n",
      " Process 4321\n",
      " Process 4322\n",
      " Process 4323\n",
      " Process 4324\n",
      " Process 4325\n",
      " Process 4326\n",
      " Process 4327\n",
      " Process 4328\n",
      " Process 4329\n",
      "saving 4329\n",
      " Process 4330\n",
      " Process 4331\n",
      " Process 4332\n",
      " Process 4333\n",
      " Process 4334\n",
      " Process 4335\n",
      " Process 4336\n",
      " Process 4337\n",
      " Process 4338\n",
      " Process 4339\n",
      "saving 4339\n",
      " Process 4340\n",
      " Process 4341\n",
      " Process 4342\n",
      " Process 4343\n",
      " Process 4344\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError\n",
    "from tqdm.notebook import tqdm\n",
    "# table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.01)\n",
    "# save_path = f\"../result/final_answer/wikitable_abl_step_back_{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.csv\"\n",
    "save_path = f\"../result/final_answer/wikitable_abl_step_back_06-04_15-30-14.csv\"\n",
    "\n",
    "# reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "# template=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "template = \"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Complete task with the help of extra information below.\n",
    "\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table:\n",
    "{table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\n",
    "Think step by step and answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "\"\"\" )\n",
    "sample_k = 3\n",
    "# Task: answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# Task: verify whether the provided claim/query is true or false, return 0 if it's false, or 1 if it's true. Please think step by step and return 0/1 at last.\n",
    "\n",
    "\n",
    "# muilti_answer_instruction = get_k_shot_with_answer()\n",
    "# for sample_n in range(3):\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 3030\n",
    "with tqdm(total=len(table_loader.dataset) - 3030, desc=f\"Processing\",ncols=1500) as pbar:\n",
    "    while i < len(table_loader.dataset):\n",
    "        try:\n",
    "            sample = table_loader.normalize_table(\n",
    "                                table_loader.dataset[i])\n",
    "            all_tokens = 0\n",
    "            all_queries = []\n",
    "            formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "            sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "            with get_openai_callback() as cb:\n",
    "                # llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "                # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                # if batch_pred[0]['text'].strip() != sample['query']:\n",
    "                #     all_queries.append(batch_pred[0]['text'].strip())\n",
    "                # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "                # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                # all_queries.append(batch_pred[0]['text'].strip())\n",
    "                llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "                batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "                # print(all_queries)\n",
    "            all_tokens += cb.total_tokens\n",
    "            all_queries = list(set(all_queries))\n",
    "            args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "            # print(args_list)\n",
    "            ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "            results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "            all_tokens += sum([res[1] for res in ans_from_B])\n",
    "            #With answer\n",
    "            # results= []\n",
    "            with get_openai_callback() as cb:\n",
    "                imp_input = scene_A(sample['query'], sample, sample_k, False)\n",
    "                llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=False)\n",
    "                batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "            # print(batch_pred[0])\n",
    "            all_tokens += cb.total_tokens\n",
    "            # print('ALL TOKENS', all_tokens)\n",
    "            ids.append(sample['id'])\n",
    "            labels.append(sample['query'])\n",
    "            outputs.append(batch_pred[0]['text'])\n",
    "            tokens.append(all_tokens)\n",
    "            extra_quries.append(';'.join(all_queries))\n",
    "            if (i + 1) % 10 == 0:\n",
    "                    print(f'saving {i}')\n",
    "                    save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "                    outputs = []\n",
    "                    labels = []\n",
    "                    ids = []\n",
    "                    tokens = []\n",
    "                    extra_quries = []\n",
    "            i += 1\n",
    "            print(f' Process {i}')\n",
    "            pbar.update(1)\n",
    "        \n",
    "        except BadRequestError as e:\n",
    "            print('*************************Bad Request**************')\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "        except ValueError as e:\n",
    "            print(f'******************Value Error {i}****************************')\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the total number of Škoda cars sold in 2005?',\n",
       " 'what is the number of Škoda Octavia cars sold in 2005?',\n",
       " 'what is the number of Škoda Yeti cars sold in 2005?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thought: The SQL query is filtering the row number 14 from the table, which corresponds to the next driver listed after Scott Dixon, who is Mike Conway.\\nAnswer: Mike Conway']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
      "    Approach this task as follows:\n",
      "    Read the query and extra information thoroughly and list every possible link from query term to column in the Table. \n",
      "    Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>Hoot Kloot</caption>\n",
      "<thead>\n",
      "<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1  </td><td>\"Kloot's Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>6  </td><td>\"Mesa Trouble\"       </td><td>Sid Marcus </td><td>1974       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Extra information: The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year. \n",
      "1. Number: The episode number in the series \n",
      "2. Title: The title of the episode \n",
      "3. Directed_by_: The director of the episode \n",
      "4. Released_: The release year of the episode\n",
      "    \n",
      "    Query: what was the last title that sid marcus directed?\n",
      "    Column linking: the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\n",
      "    Columns: Released_, Number, Title, Directed_by_\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>JumpStart Adventures 3rd Grade: Mystery Mountain</caption>\n",
      "<thead>\n",
      "<tr><th>     Subject</th><th>     Robots_Name</th><th>              Who</th><th>            When</th><th>      Where</th><th>  Occupation</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>Wheel       </td><td>Rollin' Road-Bot</td><td>Sumerians        </td><td>3000000000000.C.</td><td>Middle East</td><td>Race Starter</td></tr>\n",
      "<tr><td>Solar System</td><td>Cosmo-Bot       </td><td>Copernicus       </td><td>1531            </td><td>Poland     </td><td>Cosmonaut   </td></tr>\n",
      "<tr><td>Helicopter  </td><td>Amelia Air-Bot  </td><td>Leonardo da Vinci</td><td>1483            </td><td>Italy      </td><td>Pilot       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Extra information: The table contains information about different subjects, the names of robots associated with each subject, the historical figures or civilizations related to the subject, the time period or date associated with the subject, the location of the subject, and the occupation of the historical figure or civilization.\n",
      "1. Subject: The topic or subject being discussed in the table\n",
      "2. Robots_Name: The name of the robot associated with the subject\n",
      "3. Who: The historical figure or civilization related to the subject\n",
      "4. When: The time period or date associated with the subject\n",
      "5. Where: The location of the subject\n",
      "6. Occupation: The occupation of the historical figure or civilization\n",
      "    \n",
      "    Query: what are the robots in the middle east?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOur ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>JumpStart Adventures 3rd Grade: Mystery Mountain</caption>\n",
      "<thead>\n",
      "<tr><th>  row_number</th><th>     Robots_Name</th><th>     Subject</th><th>      Where</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>19          </td><td>Rollin' Road-Bot</td><td>Wheel       </td><td>Middle East</td></tr>\n",
      "<tr><td>1           </td><td>Cosmo-Bot       </td><td>Solar System</td><td>Poland     </td></tr>\n",
      "<tr><td>6           </td><td>Amelia Air-Bot  </td><td>Helicopter  </td><td>Italy      </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about different subjects, the names of robots associated with each subject, the historical figures or civilizations related to the subject, the time period or date associated with the subject, the location of the subject, and the occupation of the historical figure or civilization.\n",
      " Column information:Subject:Various subjects are listed, such as \"Chewing Gum\", \"Sausage\", \"Solar System\" (Values like Solar System, Olympics, Basketball...)\n",
      "Robots_Name:Names of robots are listed with a common suffix \"-Bot\" (e.g., Bubble-Bot, Sock-Bot, Cosmo-Bot) (Values like Cosmo-Bot, Rhonda Robot, Danny Defrost-Bot...)\n",
      "Where:Different locations are listed, such as \"Mexico\", \"Middle East\", \"Poland\" (Values like Poland, Greece, United States...)\n",
      "row_number: row index in the table\n",
      "\n",
      "Query: what are the robots in the middle east?\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering and answer the query using the final sub-table. \n",
      "SQL Excuted: \n",
      "```SELECT * from DF;```\n",
      "Sub-table: \n",
      "<table>\n",
      "<thead>\n",
      "<tr><th>     Subject</th><th>                  Robots_Name</th><th>                    Who</th><th>                When</th><th>                 Where</th><th>           Occupation</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>Solar System</td><td>Cosmo-Bot                    </td><td>Copernicus             </td><td>1531                </td><td>Poland                </td><td>Cosmonaut            </td></tr>\n",
      "<tr><td>Olympics    </td><td>Rhonda Robot                 </td><td>Greeks                 </td><td>776000000000.C.     </td><td>Greece                </td><td>Beauty queen         </td></tr>\n",
      "<tr><td>Basketball  </td><td>Danny Defrost-Bot            </td><td>James Naismith         </td><td>1891                </td><td>United States         </td><td>Snowman              </td></tr>\n",
      "<tr><td>Nursing     </td><td>Dr. Bug-Bot                  </td><td>Florence Nightengale   </td><td>1860                </td><td>England               </td><td>Doctor               </td></tr>\n",
      "<tr><td>Scuba Gear  </td><td>Flip the High-Diving Robot   </td><td>Jacques Cousteau       </td><td>1946                </td><td>France                </td><td>Diver                </td></tr>\n",
      "<tr><td>Helicopter  </td><td>Amelia Air-Bot               </td><td>Leonardo da Vinci      </td><td>1483                </td><td>Italy                 </td><td>Pilot                </td></tr>\n",
      "<tr><td>Corn Flakes </td><td>Chef Boy-Robot               </td><td>William Kellogg        </td><td>1894                </td><td>Battle Creek, Michigan</td><td>Cook                 </td></tr>\n",
      "<tr><td>Radium      </td><td>Miss Battery-Bot             </td><td>Marie Curie            </td><td>1898                </td><td>France                </td><td>Battery Lady         </td></tr>\n",
      "<tr><td>Chewing Gum </td><td>Bubble-Bot                   </td><td>Mayans                 </td><td>400                 </td><td>Mexico                </td><td>Bubble Man           </td></tr>\n",
      "<tr><td>Painting    </td><td>Pierro-Bot                   </td><td>Stone-Age Humans       </td><td>35000000000000.C.   </td><td>Europe                </td><td>Clown/Artist         </td></tr>\n",
      "<tr><td>Phonograph  </td><td>Slide the Heavy-Metal Robot  </td><td>Thomas Edison          </td><td>1877                </td><td>New Jersey            </td><td>Rock Star            </td></tr>\n",
      "<tr><td>Paper       </td><td>Noshi Origami                </td><td>Ts'ai Lun              </td><td>105                 </td><td>China                 </td><td>Origami Maker        </td></tr>\n",
      "<tr><td>Round Earth </td><td>Vasco da Robot               </td><td>Ferdinand Magellan     </td><td>1522                </td><td>Spain                 </td><td>Early Sailor         </td></tr>\n",
      "<tr><td>Dynamite    </td><td>Robby Robot                  </td><td>Alfred Nobel           </td><td>1866                </td><td>Sweden                </td><td>Prankster            </td></tr>\n",
      "<tr><td>Microscope  </td><td>Slobot                       </td><td>Antonie van Leeuwenhoek</td><td>1674                </td><td>The Netherlands       </td><td>Dirty Person         </td></tr>\n",
      "<tr><td>Writing     </td><td>Eraser-Bot                   </td><td>Sumerians              </td><td>3500000000000.C.    </td><td>Middle East           </td><td>Pencil Man           </td></tr>\n",
      "<tr><td>Sausage     </td><td>Sock-Bot                     </td><td>Babylonians            </td><td>3000000000000.C.    </td><td>Middle East           </td><td>Sock Man             </td></tr>\n",
      "<tr><td>Bicycle     </td><td>Booster-Bot                  </td><td>Karl von Drais         </td><td>1816                </td><td>Germany               </td><td>Rocket Man           </td></tr>\n",
      "<tr><td>Wheel       </td><td>Rollin' Road-Bot             </td><td>Sumerians              </td><td>3000000000000.C.    </td><td>Middle East           </td><td>Race Starter         </td></tr>\n",
      "<tr><td>Germs       </td><td>Roast-Bot                    </td><td>Louis Pasteur          </td><td>1865                </td><td>France                </td><td>Firefighter          </td></tr>\n",
      "<tr><td>Boomerang   </td><td>Oswald the Mailman Robot     </td><td>Aborigines             </td><td>40000 years ago     </td><td>Australia             </td><td>Mailman              </td></tr>\n",
      "<tr><td>Coins       </td><td>Verna the Vend-Bot           </td><td>Lydians                </td><td>600000000000.C.     </td><td>Turkey                </td><td>Vending Machine      </td></tr>\n",
      "<tr><td>Tools       </td><td>Hank the Handyman Robot      </td><td>Stone-Age Humans       </td><td>2½ million years ago</td><td>Africa                </td><td>Mechanic             </td></tr>\n",
      "<tr><td>Saxophone   </td><td>Bongo-Bot the Six-Armed Robot</td><td>Antoine-Joseph Sax     </td><td>1846                </td><td>France                </td><td>Six-Armed Drum Player</td></tr>\n",
      "<tr><td>Toilet      </td><td>Brunwella the Bombshell      </td><td>Minoans                </td><td>2000000000000.C.    </td><td>Crete                 </td><td>Demolisher           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: what are the robots in the middle east?\n",
      "Please provide a clear, complete statement in response to the query. If you cannot answer the query based on the sub-table, just say 'Cannot get answer from sub-table'.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The robots in the Middle East are Rollin' Road-Bot and Sock-Bot.\", 2916)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_B('what are the robots in the middle east?', sample, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'what is the average percentage of each selection in the polls?'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the total number of robots in the middle east?',\n",
       " 'what is the total number of robots in the Middle East?',\n",
       " 'what are the robots in the middle east?']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thought: The BBC Three weekly ranking for episode 9 was 6, which is higher than the ranking for episode 8, which was 5. Therefore, episode 9 had a better BBC Three weekly ranking than episode 8.\\nAnswer: episode 9']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b31b71580a420ea43e2d869cb03c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|                                                                                             …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1352\n",
      "process 1686\n",
      "process 2019\n",
      "process 2825\n",
      "process 3516\n",
      "process 3710\n",
      "process 4090\n",
      "process 4145\n"
     ]
    }
   ],
   "source": [
    "##### add residual \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "# from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError, RateLimitError\n",
    "from tqdm.notebook import tqdm\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.tech/v1\",\n",
    "                       openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.01)\n",
    "save_path = f\"../result/final_answer/wikitable_abl_step_back_06-04_15-30-14.csv\"\n",
    "sample_k = 3\n",
    "data = pd.read_csv(save_path)\n",
    "\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 0\n",
    "with tqdm(total=len(table_loader.dataset), desc=f\"Processing\",ncols=150) as pbar:\n",
    "    while i < len(table_loader.dataset):\n",
    "        if table_loader.dataset[i]['id'] in list(data['ids']):\n",
    "            i += 1\n",
    "        else:\n",
    "            try:\n",
    "                sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "                all_tokens = 0\n",
    "                all_queries = []\n",
    "                formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "                sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "                with get_openai_callback() as cb:\n",
    "                    # llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "                    # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    # if batch_pred[0]['text'].strip() != sample['query']:\n",
    "                    #     all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "                    # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    # all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "                    # print(all_queries)\n",
    "                all_tokens += cb.total_tokens\n",
    "                all_queries = list(set(all_queries))\n",
    "                args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "                # print(args_list)\n",
    "                ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "                results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "                all_tokens += sum([res[1] for res in ans_from_B])\n",
    "                #With answer\n",
    "                # results= []\n",
    "                with get_openai_callback() as cb:\n",
    "                    imp_input = scene_A(sample['query'], sample, sample_k, False)\n",
    "                    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "                # print(batch_pred[0])\n",
    "                all_tokens += cb.total_tokens\n",
    "                # print('ALL TOKENS', all_tokens)\n",
    "                ids.append(sample['id'])\n",
    "                labels.append(sample['query'])\n",
    "                outputs.append(batch_pred[0]['text'])\n",
    "                tokens.append(all_tokens)\n",
    "                extra_quries.append(';'.join(all_queries))\n",
    "                i += 1\n",
    "                pbar.update(1)\n",
    "                print(f'process {i}')\n",
    "            except RateLimitError as e:\n",
    "                print('*************************Rate limit**************')\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nu-401', 'nu-448', 'nu-1351', 'nu-2388', 'nu-2516', 'nu-2824', 'nu-3515']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_extra_info(summary_aug, column_aug, composition_aug, columns):\n",
    "    col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "    items, crackets = parse_output(composition_aug, pattern = r'\\d. (.+?): (.+)')\n",
    "    assert len(items) == len(col_names)\n",
    "    extra_col_info = []\n",
    "    for i_c in range(len(col_names)):\n",
    "        if col_names[i_c] in columns:\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]} {crackets[i_c]}')\n",
    "            \n",
    "    extra_col_info.append('row_number: row number in the original table')\n",
    "    return summary_aug + '\\n'.join(extra_col_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
