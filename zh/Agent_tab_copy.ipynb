{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from utils import parse_specific_composition\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sqlalchemy import create_engine\n",
    "from executor import SQLManager\n",
    "import sqlparse\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "            model_name='BAAI/bge-large-en',\n",
    "            model_kwargs={'device': 'cuda:3', 'trust_remote_code': True},\n",
    "            encode_kwargs={'normalize_embeddings': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "\n",
    "\n",
    "query_instruction = PromptTemplate(input_variables=[ \"claim\"], \n",
    "                                    template=\"\"\"Given the table with rows sampled from the original table and the claim/question, you need to provide one or more questions which can answer the orignal claim/question.\n",
    "                                    \n",
    "The questions should follow the following requirement:\n",
    "1. The questions should not repeat the original claim/question. \n",
    "2. List the questions split by line. \n",
    "3. The generated questions together are sufficient to answer the original claim/question.\n",
    "4. The fewer questions the better.\n",
    "\n",
    "You can think of the following ways:\n",
    "1. decompose original question into complete sub questions which can solve original claim/question.\n",
    "2. step back and paraphrase a question to a more generic step-back question, which is easier to answer.\n",
    "3. Reformulate the question to eliminate ambiguity or providing additional context to guide the interpretation\n",
    "\n",
    "Table: {table}\n",
    "Claim/question: {claim}\n",
    "Output: \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',',\n",
       "       '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F',\n",
       "       'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
       "       'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\\\\\', ']', '^', '_', '`',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
       "       '{', '\\\\p', '}', '~'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4233\n",
    "sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "formatter = TableFormat(format='none', data=sample)\n",
    "pd.unique(formatter.all_data['glyph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "table_loader = TableLoader(table_name='fetaqa', split='test', use_sample=False, small_test=False)\n",
    "i = 39\n",
    "sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample)\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "# os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "# model = AzureChatOpenAI(\n",
    "#     openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "#     temperature=0.01\n",
    "# )\n",
    "# model = ChatOpenAI(model_name='deepseek-chat', openai_api_base=\"https://api.deepseek.com\",\n",
    "#                        openai_api_key=\"sk-0f41fb981d434de08f6bd9712d75bf43\", temperature=0.3)\n",
    "\n",
    "# llm_chain = LLMChain(llm=model, prompt=query_instruction, verbose=True,)\n",
    "# batch_pred = llm_chain.batch([{\n",
    "#     \"claim\": sample['query'],\n",
    "#     # \"query\": \"how many of the seasons games were played in the gold coast convention centre?\",\n",
    "#                                \"table\": TableFormat.format_html(data= formatter.get_sample_data(sample_type='random',k=5, query=sample['query'],),table_caption=sample['table']['caption'])}],)\n",
    "# #                             \"table\": \"\"\"table caption : 2008 - 09 nbl season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Particulars</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total No. of Houses</td>\n",
       "      <td>80</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Population</td>\n",
       "      <td>350</td>\n",
       "      <td>185</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Child (0-6)</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schedule Caste</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schedule Tribe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Literacy</td>\n",
       "      <td>71.88 %</td>\n",
       "      <td>76.33 %</td>\n",
       "      <td>66.89 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total Workers</td>\n",
       "      <td>134</td>\n",
       "      <td>107</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Main Worker</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marginal Worker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Particulars    Total     Male   Female\n",
       "0  Total No. of Houses       80        -        -\n",
       "1           Population      350      185      165\n",
       "2          Child (0-6)       30       16       14\n",
       "3       Schedule Caste       64       32       32\n",
       "4       Schedule Tribe        0        0        0\n",
       "5             Literacy  71.88 %  76.33 %  66.89 %\n",
       "6        Total Workers      134      107       27\n",
       "7          Main Worker      134        0        0\n",
       "8      Marginal Worker        0        0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatter.all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "                  \"what was the time difference between the first place finisher and the eighth place finisher?\",\n",
    "                  # \"compare the chart positions between the us and the uk for the science of selling yourself short, where did it do better?\",\n",
    "                  \"other than william stuart price, which other businessman was born in tulsa?\",\n",
    "                  \"which canadian city had the most passengers traveling from manzanillo international airport in 2013?\"\n",
    "                # \"what is the next most populous district after haridwar?\",(70)\n",
    "                  ]\n",
    "new_query_examples = [\n",
    "  # \"what was the chart position of 'The Science of Selling Yourself Short' in the US?; what was the chart position of 'The Science of Selling Yourself Short' in the UK?;\",\n",
    "                      \"what was the time for the first place finisher?; what was the time for the eighth place finisher?\",\n",
    "                      \"was william stuart price born in tulsa?; who was born in tulsa?\",\n",
    "                      \"how many passengers from each airline from canadian city? which canadian city had the most passengers?\"\n",
    "                    # \"what are the districts after haridwar?; what is the next most populous district after haridwar?\",\n",
    "                    #   \"When did polona hercog partner with alberta brianti?; When did polona hercog partner with stephanie vogt?\",\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 11, 86, 70, 42]\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True, embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub queries. Based on the table, decompose original query into at most 2 complete sub queries which can solve original query. Output new query directly.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "    # \"after 2005 , the winner of the lifetime achievement award be andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle\",\n",
    "                  \"all 12 club play a total of 22 game for the wru division one east\",\n",
    "                #   \"a gamecube game loss the award in each of the first 3 year\",\n",
    "                \"from 1980 to 2011 , apoel bc lose more than 2 time as many game as it win\",\n",
    "                  \"polona hercog 1890partner with alberta brianti after she have stephanie vogt as the partner\",\n",
    "                  ]\n",
    "task_examples = [\"query rewrite\", \"query decompose\", \"query ambiguity resolve\"]\n",
    "new_query_examples = [\n",
    "    # \"Who were the winners of the lifetime achievement award after 2005?;\",\n",
    "                      \"How many clubs play for the wru division one east in total?; How many clubs play 22 game for the wru division one east?;\",\n",
    "                    #   \"a gamecube game loss the award in each of the first 3 year\",\n",
    "                    \"from 1980 to 2011 , how many games did apoel bc lose?; from 1980 to 2011 , how many games did apoel bc win?;\",\n",
    "                      \"When did polona hercog partner with alberta brianti?; When did polona hercog partner with stephanie vogt?\",\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 124, 5]\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub-queries. Based on the table, provide at most 2 sub-queries for knowledge that you need. Output new query directly.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Query: {query}\n",
    "Table: {table}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n",
    "# Sub-questions are separated by semicolons.\n",
    "# answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "#                                     template=\"\"\"\n",
    "# Below is a sub-table generated by excuting the SQL. You need to understand the logic behind the SQL filtering and complete task using the final sub-table. \n",
    "# SQL Excuted: \n",
    "# ```{SQL}```\n",
    "# Sub-table: {table}\n",
    "# Query: {claim}\n",
    "# answer the question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "                       openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.7).bind(logprobs=True)\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name=task_name, split='test', use_sample=False, small_test=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [11,]\n",
    "num_k = 1\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which business man was born in tulsa?\",\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Based on the table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query:\"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [8, 173,]\n",
    "num_k = 2\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which college list be public?\",\n",
    "    \"what was the works number used in 1883?\"\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['statement'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Based on the table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query:\"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are capable of converting complex query into sub queries. Based on the table, decompose original query into at most 2 complete sub queries which can solve original query. Output new query directly.\n",
      "\n",
      "Sub-Table: Athletics at the 2003 Summer Universiade – Women's 800 metres\n",
      "Col :Rank|Athlete|Nationality|Time\n",
      "Row 1 :|Anna Zagórska|Poland|2:00.11\n",
      "Row 2 :8|Sandra Teixeira|Portugal|2:03.01\n",
      "Row 3 :|Irina Vashentseva|Russia|2:00.77\n",
      "Query: what was the time difference between the first place finisher and the eighth place finisher?\n",
      "Decompose query: what was the time for the first place finisher?; what was the time for the eighth place finisher?\n",
      "\n",
      "Sub-Table: Oklahoma State Regents for Higher Education\n",
      "Col :Name|Profession|Hometown|Term_Expires|Office\n",
      "Row 1 :William Stuart Price|Businessman|Tulsa|2013|\n",
      "Row 2 :Joseph L. Parker Jr.|Businessman|Tulsa|2014|Chair\n",
      "Row 3 :Bill W. Burgess Jr.|Attorney|Lawton|2011|\n",
      "Query: other than william stuart price, which other businessman was born in tulsa?\n",
      "Decompose query: was william stuart price born in tulsa?; who was born in tulsa?\n",
      "\n",
      "Sub-Table: Playa de Oro International Airport\n",
      "Col :Rank|City|Passengers|Ranking|Airline\n",
      "Row 1 :7|Canada, Toronto|1,202|1|Air Transat, CanJet\n",
      "Row 2 :3|Canada, Calgary|3,761||Air Transat, WestJet\n",
      "Row 3 :8|Canada, Edmonton|110||\n",
      "Query: which canadian city had the most passengers traveling from manzanillo international airport in 2013?\n",
      "Decompose query: how many passengers from each airline from canadian city? which canadian city had the most passengers?\n",
      "\n",
      "Sub-Table: Sinnamon\n",
      "Col :Year|Name|Label|Hot_Black_Singles|Club_Play_Singles\n",
      "Row 1 :1982|\"He's Gonna Take You Home\"|Becket|―|―\n",
      "Row 2 :1982|\"Thanks to You\"|Becket|#44|#1\n",
      "Row 3 :1986|\"Say It Again\"|Spring|―|―\n",
      "Query: which singles are newer? \"thin line\" or \"say it again\"?\n",
      "Decompose query: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "i = 1106\n",
    "sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample)\n",
    "# llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=True)\n",
    "llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=True,)\n",
    "batch_pred = llm_chain.batch([{\n",
    "    \"query\": sample['query'],\n",
    "    # \"query\": \"how many of the seasons games were played in the gold coast convention centre?\",\n",
    "                               \"table\": TableFormat.format_nl_sep(data= formatter.get_sample_data(),table_caption=sample['table']['caption'])}],)\n",
    "#                             \"table\": \"\"\"table caption : 2008 - 09 nbl season.\n",
    "# col : date | home team | score | away team | venue | crowd | box score | report\n",
    "# row 1 : 31 december | cairns taipans | 105 - 112 | wollongong hawks | cairns convention centre | 3853 | box score | -\n",
    "# row 2 : 31 december | gold coast blaze | 103 - 94 | adelaide 36ers | gold coast convention centre | 2233 | box score | -\"\"\"}],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'which singles are newer? \"thin line\" or \"say it again\"?',\n",
       " 'table': 'Sinnamon\\nCol :Year|Name|Label|Hot_Black_Singles|Club_Play_Singles\\nRow 1 :1982|\"He\\'s Gonna Take You Home\"|Becket|―|―\\nRow 2 :1982|\"Thanks to You\"|Becket|#44|#1\\nRow 3 :1986|\"Say It Again\"|Spring|―|―',\n",
       " 'text': 'what is the year of release for \"thin line\"?; what is the year of release for \"say it again\"?'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_answer(k: int=1):\n",
    "    sqls = [\"SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';\"\n",
    "            ]\n",
    "    thoughts = [\"Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \"]\n",
    "    tables = [\"<table>\\n<caption>1972 isle of man tt</caption>\\n<thead>\\n<tr><th>  MIN(points)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>3            </td></tr>\\n</tbody>\\n</table>\"]\n",
    "    claims = [\"was 2 be the fewest point that roger dutton / tony wright receive?\"]\n",
    "    # inds from test split\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], template=\n",
    "    \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Query: {claim}\n",
    "Thought: {thought}\n",
    "Answer: {output}\n",
    "    \"\"\")\n",
    "    examples_dict = dict(zip([\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], [sqls[0], tables[0], claims[0], thoughts[0], '3']))\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=[examples_dict],\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\"\"\"Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the last question given in the query.\n",
    "You should output in the following format:\n",
    "Thought: your step by step thought\n",
    "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "Below is an example.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\"\"\",\n",
    "        input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    ")\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' who finish in first place and who do not manage to get in the top 3?', 'How many skaters finished in the top 3?', ' Who finished in first place?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th>  №</th><th>                      Title</th><th>  Directed_by_</th><th>  Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_loader_wiki = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "TableFormat(format='none', data=table_loader_wiki.dataset[95], use_sampling=True).format_html(table_loader_wiki.dataset[95]['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_k_shot_with_aug(k: int=2):\n",
    "#     table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "\n",
    "#     inds = [3, 6, 260, 33]\n",
    "#     Output_examples = [\n",
    "#                        'team, goals_for',\n",
    "#                        'year, game, platform_s',\n",
    "#                        'name, population_density_km_2_, population_2011_census_'\n",
    "#                        'leading_scorer, score, date']\n",
    "#     linking_examples = ['the team -> team; the most goal for -> goals_for',\n",
    "#                         'gamecube -> platform_s; gamecube game -> game; the first 3 year -> year;',\n",
    "#                         'alberta -> name; population density -> population_density_km_2_; 4257744 less people -> population_2011_census_; 2011 -> population_2011_census_'\n",
    "#                         'jason richardson -> leading_scorer; leading scorer -> score; month -> date; 23 point per game -> leading_scorer'\n",
    "#     ]\n",
    "#     examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "#     \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking: {linking}\n",
    "#     Columns: {output}\"\"\")\n",
    "#     num_k = 3\n",
    "#     examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_nl_sep(table_loader.dataset[inds[i]]['table']['caption']),\n",
    "#                                         \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "#                                         \"linking\": linking_examples[i],\n",
    "#                                         # \"summary\": summary_examples[i],\n",
    "#                                         \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "#     prompt_template = FewShotPromptTemplate(\n",
    "#         examples=examples_dict,\n",
    "#         example_prompt=examples_prompt,\n",
    "#         prefix=\n",
    "#         \"\"\"\n",
    "#     Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
    "#     Approach this task as follows:\n",
    "#     Read the question thoroughly and list every possible link from query term to column in Table.\n",
    "#     Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "#     # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "#     # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "#     # Here are some examples:\"\"\",\n",
    "#         suffix=\n",
    "#         \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking:\n",
    "#     \"\"\",\n",
    "#         input_variables=[\"table\", \"claim\"],\n",
    "# )\n",
    "#     return prompt_template\n",
    "\n",
    "def get_k_shot_with_aug(k: int=2):\n",
    "    table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "    table_loader_wiki = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "    inds = [3, 6, 260, 33]\n",
    "    Output_examples = [\n",
    "                       'team, goals_for',\n",
    "                       'year, game, platform_s',\n",
    "                       'name, population_density_km_2_, population_2011_census_'\n",
    "                       'leading_scorer, score, date']\n",
    "    linking_examples = ['the team -> team, the most goal for -> goals_for',\n",
    "                        'gamecube -> platform_s, gamecube game -> game, the first 3 year -> year',\n",
    "                        'alberta -> name, population density -> population_density_km_2_, 4257744 less people -> population_2011_census_, 2011 -> population_2011_census_'\n",
    "                        'jason richardson -> leading_scorer, month -> date, 23 point per game -> score'\n",
    "    ]\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "    \"\"\"\n",
    "    Table: {table}\n",
    "    Query: {claim}\n",
    "    Column linking: {linking}\n",
    "    Columns: {output}\"\"\")\n",
    "    num_k = 2\n",
    "    normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "    example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "    examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "    examples_dict = [{\"table\": examples[i],\n",
    "                                        \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                        \"linking\": linking_examples[i],\n",
    "                                        # \"summary\": summary_examples[i],\n",
    "                                        \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": table_loader_wiki.dataset[95]['question'],\n",
    "                                        \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title\",\n",
    "                                        # \"summary\": summary_examples[i],\n",
    "                                        \"output\": \"Title, Released_, Number\"}])\n",
    "#     examples_dict.extend([{\"table\": \"\"\"<table>\n",
    "# <thead>\n",
    "# <tr><th>  Pick</th><th>       Player</th><th>              Team</th><th>  Position</th><th>                    School</th></tr>\n",
    "# </thead>\n",
    "# <tbody>\n",
    "# <tr><td>24    </td><td>Alan Zinter  </td><td>New York Mets     </td><td>C         </td><td>University of Arizona     </td></tr>\n",
    "# <tr><td>18    </td><td>Willie Greene</td><td>Pittsburgh Pirates</td><td>SS        </td><td>Jones County HS (Gray, GA)</td></tr>\n",
    "# <tr><td>23    </td><td>Mo Vaughn    </td><td>Boston Red Sox    </td><td>1B        </td><td>Seton Hall University     </td></tr>\n",
    "# </tbody>\n",
    "# </table>\"\"\",\n",
    "#                                     \"claim\": \"was kiki jones picked before or after greg gohr?\",\n",
    "#                                     \"linking\": \"kiki jones -> Player, picked before -> Pick, after -> Pick, greg gohr -> Player\",\n",
    "#                                     # \"summary\": summary_examples[i],\n",
    "#                                     \"output\": \"Player, Pick\"}])\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples_dict,\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\n",
    "        \"\"\"\n",
    "    Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
    "    Approach this task as follows，read the claim thoroughly and list every possible link from query term to column in Table. Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "    # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "    # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "    # Here are some examples:\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "    Table: {table}\n",
    "    Extra information: {aug}\n",
    "    Query: {claim}\"\"\",\n",
    "        input_variables=[\"table\", \"claim\", \"aug\"],\n",
    ")\n",
    "    return prompt_template\n",
    "\n",
    "pre_instruction_schema = PromptTemplate(input_variables=[\"table\"], template=\"\"\"\n",
    "Instruction: Given the following table, you will add Metadata about the columns in the table.\n",
    "Metadata includes:\n",
    "- Numerical: consist digits and numerical symbols like decimal points or signs.\n",
    "- Char: whether column content is a text or description.\n",
    "- Date: whether the column content is datetime.\n",
    "\n",
    "You need to output all the column names with metadata in angle brackets.\n",
    "Example: name<Char> launched<Date> count<Numerical>\n",
    "\n",
    "Table: {table}\n",
    "Output:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "task\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "summary_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "    summary_aug, column_aug = summary_information.loc[sample['table']['id']]['summary'], summary_information.loc[sample['table']['id']]['column_description'] \n",
    "    if len(summary_aug) ==0 or len(column_aug) == 0:\n",
    "        print(sample['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from utils import parse_output\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "summary_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=0.01\n",
    ")\n",
    "outputs = []\n",
    "for i in range(10):\n",
    "    sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "\n",
    "    summary_aug, column_aug = summary_information.loc[sample['table']['id']]['summary'], summary_information.loc[sample['table']['id']]['column_description'] \n",
    "    col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "    extra_col_info = []\n",
    "    for i_c in range(len(col_names)):\n",
    "        extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "    formatter = TableFormat(format='none', data=sample)\n",
    "\n",
    "\n",
    "\n",
    "    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\n",
    "        \"claim\": sample['query'],\n",
    "        'aug':  summary_aug + '\\n'.join(extra_col_info),\n",
    "        # \"query\": \"how many of the seasons games were played in the gold coast convention centre?\",\n",
    "                                \"table\": TableFormat.format_html(data= formatter.get_sample_data(sample_type='random',k=5, query=sample['query'],),table_caption=sample['table']['caption'])}],)\n",
    "    print(batch_pred[0]['text'])\n",
    "    #                             \"table\": \"\"\"table caption : 2008 - 09 nbl season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
      "    Approach this task as follows，read the claim thoroughly and list every possible link from query term to column in Table. Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>1986 - 87 north west counties football league</caption>\n",
      "<thead>\n",
      "<tr><th>  position</th><th>               team</th><th>  played</th><th>  drawn</th><th>  lost</th><th>  goals_for</th><th>  goals_against</th><th>  goal_difference</th><th>  points_1</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>12        </td><td>ashton town        </td><td>24      </td><td>9      </td><td>11    </td><td>29         </td><td>39             </td><td>10               </td><td>15 2      </td></tr>\n",
      "<tr><td>10        </td><td>padiham            </td><td>24      </td><td>8      </td><td>12    </td><td>35         </td><td>39             </td><td>4                </td><td>16        </td></tr>\n",
      "<tr><td>1         </td><td>atherton collieries</td><td>24      </td><td>4      </td><td>4     </td><td>46         </td><td>22             </td><td>+ 24             </td><td>36        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "    Column linking: the team -> team, the most goal for -> goals_for\n",
      "    Columns: team, goals_for\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<thead>\n",
      "<tr><th>  Pick</th><th>       Player</th><th>              Team</th><th>  Position</th><th>                    School</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>24    </td><td>Alan Zinter  </td><td>New York Mets     </td><td>C         </td><td>University of Arizona     </td></tr>\n",
      "<tr><td>18    </td><td>Willie Greene</td><td>Pittsburgh Pirates</td><td>SS        </td><td>Jones County HS (Gray, GA)</td></tr>\n",
      "<tr><td>23    </td><td>Mo Vaughn    </td><td>Boston Red Sox    </td><td>1B        </td><td>Seton Hall University     </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: was kiki jones picked before or after greg gohr?\n",
      "    Column linking: kiki jones -> Player, picked before -> Pick, after -> Pick, greg gohr -> Player\n",
      "    Columns: Player, Pick\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>Cheltenham Town F.C.</caption>\n",
      "<thead>\n",
      "<tr><th>     Year</th><th>  Kit_Manufacturer</th><th>   Shirt_Sponsor</th><th>  Back_of_Shirt_Sponsor</th><th>  Short_Sponsor</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1977–1978</td><td>                  </td><td>National Express</td><td>                       </td><td>               </td></tr>\n",
      "<tr><td>1982–1985</td><td>Umbro             </td><td>                </td><td>                       </td><td>               </td></tr>\n",
      "<tr><td>1991–1993</td><td>Technik           </td><td>Gulf Oil        </td><td>                       </td><td>               </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Extra information: \n",
      "    Query: which kit manufacturer came next after umbro?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "    Column linking: kit manufacturer -> Kit_Manufacturer, came next after -> Year\n",
      "    Columns: Kit_Manufacturer, Year\n"
     ]
    }
   ],
   "source": [
    "from utils import parse_output\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[1089])\n",
    "k_shot_prompt = get_k_shot_with_aug()\n",
    "formatter = TableFormat(format='none', data=sample)\n",
    "llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=True)\n",
    "summary_information = pd.read_csv(f\"result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "schema_information = pd.read_csv(f\"result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "summary_aug, column_aug = summary_information.loc[sample['table']['id']]['summary'], summary_information.loc[sample['table']['id']]['column_description'] \n",
    "col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "extra_col_info = []\n",
    "for i_c in range(len(col_names)):\n",
    "    extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "stage_1_batch_pred = llm_chain.batch([dict({\n",
    "    'table': TableFormat.format_html(data=formatter.get_sample_data(),table_caption=sample['table']['caption']),\n",
    "                                            # 'claim': sample['query'],\n",
    "                                    'claim': sample['query'],\n",
    "                                    'aug': \"\"\n",
    "                                    # 'aug':  summary_aug + '\\n'.join(extra_col_info),\n",
    "                                    })], return_only_outputs=True)[0]['text']\n",
    "# pred = llm_chain.batch([dict({\"query\": 'Who is one of the three nominees for a Drama Desk Award?'})])\n",
    "# print(pred[0]['text'])\n",
    "print(stage_1_batch_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "def scene_A(query, sample, verbose=True):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    sample_data = formatter.get_sample_data(sample_type='embedding', query=query)\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        if pd.isna(summary_aug):\n",
    "            summary_aug = ''\n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        \n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        \n",
    "        try: \n",
    "            # formatter.all_data = formatter.all_data.loc[:, columns]\n",
    "            sample_data = sample_data.loc[:, columns]\n",
    "            # sample_data = sample_data.reset_index()\n",
    "        except:\n",
    "            pass\n",
    "        extra_information = '\\n'.join(parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data = sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + extra_information\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "    # stage 3: SQL Excution\n",
    "    try: \n",
    "        execute_data = manager.execute_from_df(stage_2_batch_pred, formatter.all_data, table_name='DF')\n",
    "    except:\n",
    "        execute_data = formatter.all_data\n",
    "        stage_2_batch_pred = 'SELECT * from DF;'\n",
    "    if len(execute_data) == 0:\n",
    "        return query, stage_2_batch_pred, 'No data from database', cb.total_tokens\n",
    "    return query, stage_2_batch_pred, TableFormat.format_html(data=execute_data), cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [0,   1,  11,  14,  22,  24,  26,  31,  37,  38,  39,  40,  47,\n",
    "        49,  50,  59,  62,  63,  65,  66,  68,  69,  70,  75,  80,  81,\n",
    "        82,  90,  91,  93,  95,  99, 100, 105, 106, 108, 110, 116, 119,\n",
    "       124, 129, 136, 137, 145, 147, 148, 151, 153, 155, 158, 160, 164,\n",
    "       167, 169, 171, 173, 175, 179, 180, 181, 187, 188, 190, 192, 198,\n",
    "       200, 207, 209, 210, 211, 217, 225, 227, 230, 233, 236, 237, 241,\n",
    "       251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "non_equal = []\n",
    "for ind, (pred, gold) in enumerate(zip(ttt, labels )):\n",
    "            if pred == str(gold):\n",
    "                acc += 1\n",
    "            else:\n",
    "                non_equal.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 11, 14, 22, 26, 29, 37, 38, 40, 47, 49, 50, 56, 57, 59, 63, 65, 66, 68, 72, 76, 78, 82, 84, 87, 88, 90, 95, 96, 99]\n"
     ]
    }
   ],
   "source": [
    "print(non_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 14, 22, 25, 33, 38, 40, 42, 43, 44, 47, 49, 50, 51, 53, 59, 61, 63, 68, 69, 72, 74, 75, 76, 78, 80, 82, 83, 89, 91, 92, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "[0, 1, 3, 14, 22, 38, 40, 42, 43, 44, 47, 49, 50, 51, 53, 59, 61, 63, 68, 69, 72, 74, 75, 76, 78, 80, 82, 83, 89, 91, 92, 98, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 11, 12, 13, 14, 16, 20, 22, 26, 34, 38, 40, 41, 42, 44, 47, 50, 53, 56, 64, 65, 69, 72, 79, 80, 82, 83, 84, 88, 90, 91, 92, 95, 98, 100, 108, 110, 113, 116, 119, 121, 122, 123, 125, 133, 136, 137, 139, 140, 141, 144, 145, 148, 158, 167, 169, 174, 176, 177, 179, 181, 185, 191, 200, 201, 210, 220, 223, 225, 226, 227, 228, 229, 231, 238, 240, 241, 246, 251, 254, 255, 256, 265, 269, 270, 272, 274, 280, 281, 282, 283, 286, 287, 294, 296]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "1, 3, 11, 12, 13, 14, 16, 20, 22, 26, 34, 38, \n",
    "40, 41, 42, 44, 47, 50, 53, 56, 64, 65, 69, 72,\n",
    "79, 80, 82, 83, 84, 88, 90, 91, 92, 95, 98, 100,\n",
    "108, 110, 113, 116, 119, 121, 122, 123, 125, 133, \n",
    "136, 137, 139, 140, 141, 144, 145, 148, 158, 167,\n",
    "169, 174, 176, 177, 179, 181, 185, 191, 200, 201, 210, \n",
    "220, 223, 225, 226, 227, 228, 229, 231, 238, 240, 241, \n",
    "246, 251, 254, 255, 256, 265, 269, 270, 272, 274, 280, \n",
    "281, 282, 283, 286, 287, 294, 296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To verify the claim, we need to look at the sub-table and check if there are at least 3 people who tie for fifth place and are from the United States.\n",
      "\n",
      "Since we do not have access to the sub-table, we cannot directly verify the claim. However, based on the SQL query provided, we can infer that the query is filtering for players who are in fifth place and from the United States. Therefore, if the query returns at least 3 players, then the claim is true.\n",
      "\n",
      "So, based on the logic of the SQL query, if the query returns at least 3 players, the claim is true. If not, the claim is false.\n",
      "\n",
      "Therefore, we cannot definitively determine the truth of the claim without the sub-table.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[25, :]['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>extra_information</th>\n",
       "      <th>preds</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-29063233-1.html.csv</td>\n",
       "      <td>The episode \"The Nightmare Begins\" happened ea...</td>\n",
       "      <td>To verify the claim that the episode \"Sweet Dr...</td>\n",
       "      <td>4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-29063233-1.html.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To verify the claim that \"David Moore directed...</td>\n",
       "      <td>4338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-29063233-1.html.csv</td>\n",
       "      <td>The episode of \"The Lady of the Lake\" with the...</td>\n",
       "      <td>The SQL query is filtering the table DF to onl...</td>\n",
       "      <td>4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-29063233-1.html.csv</td>\n",
       "      <td>Cannot get answer from sub-table.</td>\n",
       "      <td>The SQL query is filtering the table DF to onl...</td>\n",
       "      <td>3912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-29063233-1.html.csv</td>\n",
       "      <td>Beauty and the Beast (part 2) has more UK view...</td>\n",
       "      <td>The SQL query retrieves the titles and UK view...</td>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              table_name                                  extra_information  \\\n",
       "0  1-29063233-1.html.csv  The episode \"The Nightmare Begins\" happened ea...   \n",
       "1  1-29063233-1.html.csv                                                NaN   \n",
       "2  1-29063233-1.html.csv  The episode of \"The Lady of the Lake\" with the...   \n",
       "3  1-29063233-1.html.csv                  Cannot get answer from sub-table.   \n",
       "4  1-29063233-1.html.csv  Beauty and the Beast (part 2) has more UK view...   \n",
       "\n",
       "                                               preds  token  \n",
       "0  To verify the claim that the episode \"Sweet Dr...   4077  \n",
       "1  To verify the claim that \"David Moore directed...   4338  \n",
       "2  The SQL query is filtering the table DF to onl...   4469  \n",
       "3  The SQL query is filtering the table DF to onl...   3912  \n",
       "4  The SQL query retrieves the titles and UK view...   4182  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "data = pd.read_csv('./result/answer/tabfact_zh_04-25_15-42-17.csv')\n",
    "\n",
    "ttt = eval_blury_string(data['preds'])\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "labels = []\n",
    "for i in range(100):\n",
    "    labels.append(table_loader.dataset[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)\n",
    "# args_list = [{\"query\": 'Who took the loss in the game on August 30 and who suffered the loss in the game on August 31?', \"sample\": sample},{\"query\": sample['query'], \"sample\": sample}]\n",
    "# args_list = [{\"query\": q, \"sample\": sample} for q in all_queries]\n",
    "\n",
    "# results = parallel_run_kwargs(scene_A, args_list)\n",
    "# print(results)\n",
    "# print(cb.total_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below are some sub-tables generated by excuting the SQL. You need to understand the logic behind the SQL filtering. Complete task using all information below. \n",
    "{information}\n",
    "Query: {query}\n",
    "verify whether the provided claim/query is true or false, return 0 if it's false, or 1 if it's true. Please think step by step.\n",
    "\"\"\" )\n",
    "temp = [f\"\"\"\n",
    "SQL Excuted: \n",
    "```{res[1]}```\n",
    "Sub-table: {res[2]}\"\"\" for res in results]\n",
    "muilti_answer_instruction = get_k_shot_with_answer()\n",
    "llm_chain = LLMChain(llm=model, prompt=muilti_answer_instruction, verbose=True)\n",
    "batch_pred = llm_chain.batch([{\"query\": sample['query'], \"information\": '\\n'.join(temp)}], return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_B():\n",
    "    agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Based on the history information, your task is to only based on the conversation information to answer the user query.\n",
    "    If you cannot get the answer from past history, reorganize the question and return the question explicitly. If you are confident in the answer, answer it directly.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    ]\n",
    ")\n",
    "    chain = LLMChain(llm=model, prompt=agent_prompt, verbose=True)\n",
    "    return chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": Agent_history.messages,\n",
    "    }\n",
    ")['text']\n",
    "    \n",
    "    #维护一个Agent Memory\n",
    "Agent_history = []\n",
    "agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # (\n",
    "        #     \"system\",\n",
    "        #     \"\"\"\"\"\"\n",
    "            \n",
    "        #     # return 'A' if you think you need more information, else return 'B'. You should only use information during the conversation.,\n",
    "        # ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    ]\n",
    ")\n",
    "system =  PromptTemplate(input_variables=[\"history\"], template=\"\"\"Based on the history information, your task is to only based on the conversation information to answer the user query. \n",
    "Note: Do not use information on your own, only use information from the conversation history!\n",
    "\n",
    "conversation histroy:\n",
    "{history}\n",
    "\n",
    "The output should choose from Choice A and Choice B:\n",
    "Choice A: ###If you cannot get the answer from conversation histroy, reorganize the question and return the question explicitly.\n",
    "Choice B: ###If you are confident in the answer, answer it directly.\"\"\")\n",
    "chain = LLMChain(llm=model, prompt=system, verbose=True)\n",
    "Agent_history.append('Q: Who were the winners of the lifetime achievement award after 2005?')\n",
    "# Agent_history.append('A: the winners are andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle')\n",
    "# Agent_history.append('Q: Are the winners andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    " \n",
    "def outer_task(url):\n",
    "   # 外层任务\n",
    "   print(f\"Processing {url}\")\n",
    "   # 内部再次使用线程池\n",
    "   with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "       # 执行一些依赖于外层任务的结果的并行操作\n",
    "       inner_results = [executor.submit(inner_task, f\"{url}_{i}\") for i in range(2)]\n",
    "       # 等待内部任务完成并收集结果\n",
    "       return [r.result() for r in inner_results]\n",
    " \n",
    "def inner_task(url):\n",
    "   # 内层任务\n",
    "   print(f\"Inner task for {url}\")\n",
    "   # 这里可以执行一些操作，比如I/O密集型的任务\n",
    "   return f\"Result for {url}\"\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "   # 创建线程池\n",
    "   with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "       # 提交外层任务到线程池\n",
    "       outer_results = [executor.submit(outer_task, f\"http://example.com/{i}\") for i in range(2)]\n",
    "       # 等待外层任务完成并收集结果\n",
    "       for future in concurrent.futures.as_completed(outer_results):\n",
    "           print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整extrainformation的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below is a sub-table generated by excuting the SQL. You need to understand the logic behind the SQL filtering and complete task using the final sub-table. \n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: \n",
    "{table}\n",
    "Query: {claim}\n",
    "Please provide a clear, concise statement in response to the question. If you cannot answer the question based on the sub-table, just say 'Cannot get answer from sub-table'\n",
    "\"\"\" )\n",
    "def scene_B(query, sample, verbose=False):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    sample_data = formatter.get_sample_data(sample_type='embedding', query=query)\n",
    "    # get columns\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        # if pd.isna(summary_aug):\n",
    "        #     summary_aug = ''\n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        \n",
    "        try: \n",
    "            sample_data = sample_data.loc[:, columns]\n",
    "        except:\n",
    "            pass\n",
    "        extra_information = '\\n'.join(parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + extra_information\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "    \n",
    "        \n",
    "        # stage 3: SQL Excution\n",
    "        try: \n",
    "            execute_data= manager.execute_from_df(stage_2_batch_pred, formatter.all_data, table_name='DF')\n",
    "        except:\n",
    "            execute_data = formatter.all_data\n",
    "            stage_2_batch_pred = 'SELECT * from DF;'\n",
    "        llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=verbose)\n",
    "        response = llm_chain.batch([dict({'table': TableFormat.format_html(execute_data),\n",
    "                                                'claim': query,\n",
    "                                                'SQL':  stage_2_batch_pred\n",
    "                                                })], return_only_outputs=True)[0]['text']\n",
    "    # print(\"total_tokens:\", cb.total_tokens)\n",
    "    return response, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 4*GPUs----------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
      "    Approach this task as follows，read the claim thoroughly and list every possible link from query term to column in Table. Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>1986 - 87 north west counties football league</caption>\n",
      "<thead>\n",
      "<tr><th>  position</th><th>               team</th><th>  played</th><th>  drawn</th><th>  lost</th><th>  goals_for</th><th>  goals_against</th><th>  goal_difference</th><th>  points_1</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>12        </td><td>ashton town        </td><td>24      </td><td>9      </td><td>11    </td><td>29         </td><td>39             </td><td>10               </td><td>15 2      </td></tr>\n",
      "<tr><td>10        </td><td>padiham            </td><td>24      </td><td>8      </td><td>12    </td><td>35         </td><td>39             </td><td>4                </td><td>16        </td></tr>\n",
      "<tr><td>1         </td><td>atherton collieries</td><td>24      </td><td>4      </td><td>4     </td><td>46         </td><td>22             </td><td>+ 24             </td><td>36        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "    Column linking: the team -> team, the most goal for -> goals_for\n",
      "    Columns: team, goals_for\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>list of game of the year awards</caption>\n",
      "<thead>\n",
      "<tr><th>  year</th><th>                               game</th><th>                                  genre</th><th>                        platform_s</th><th>                 developer_s</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>2011  </td><td>the legend of zelda : skyward sword</td><td>action - adventure                     </td><td>wii                               </td><td>nintendo ead , monolith soft</td></tr>\n",
      "<tr><td>2010  </td><td>mass effect 2                      </td><td>action rpg : ( third - person ) shooter</td><td>xbox 360 , windows , playstation 3</td><td>bioware                     </td></tr>\n",
      "<tr><td>2001  </td><td>super smash bros melee             </td><td>fighting                               </td><td>gamecube                          </td><td>hal laboratory , inc        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: a gamecube game loss the award in each of the first 3 year\n",
      "    Column linking: gamecube -> platform_s, gamecube game -> game, the first 3 year -> year\n",
      "    Columns: year, game, platform_s\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>Hoot Kloot</caption>\n",
      "<thead>\n",
      "<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1  </td><td>\"Kloot's Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: what was the last title that sid marcus directed?\n",
      "    Column linking: the last title -> Released_, the last title-> Number, title -> Title\n",
      "    Columns: Title, Released_, Number\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>2008 Clásica de San Sebastián</caption>\n",
      "<thead>\n",
      "<tr><th>  Rank</th><th>                 Cyclist</th><th>            Team</th><th>      Time</th><th>  UCI_ProTour_nPoints</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>6     </td><td>Denis Menchov (RUS)     </td><td>Rabobank        </td><td>s.t.      </td><td>11                   </td></tr>\n",
      "<tr><td>1     </td><td>Alejandro Valverde (ESP)</td><td>Caisse d'Epargne</td><td>5h 29' 10\"</td><td>40                   </td></tr>\n",
      "<tr><td>10    </td><td>David Moncoutié (FRA)   </td><td>Cofidis         </td><td>+ 2\"      </td><td>1                    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Extra information: The table shows the results of the 2008 Clásica de San Sebastián cycling race.1. Rank: The position in which the cyclist finished in the race\n",
      "2. Cyclist: The name and nationality of the cyclist\n",
      "3. Team: The team to which the cyclist belongs\n",
      "4. Time: The time it took for the cyclist to complete the race\n",
      "5. UCI_ProTour_nPoints: The number of UCI ProTour points earned by the cyclist\n",
      "    Query: which country had the most cyclists finish within the top 10?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>2008 Clásica de San Sebastián</caption>\n",
      "<thead>\n",
      "<tr><th>                 Cyclist</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>Denis Menchov (RUS)     </td></tr>\n",
      "<tr><td>Alejandro Valverde (ESP)</td></tr>\n",
      "<tr><td>David Moncoutié (FRA)   </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: which country had the most cyclists finish within the top 10?\n",
      "Extra information: The table shows the results of the 2008 Clásica de San Sebastián cycling race.\n",
      " Column information:Cyclist:Names of cyclists with their nationality in parentheses\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the last question given in the query.\n",
      "You should output in the following format:\n",
      "Thought: your step by step thought\n",
      "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
      "Below is an example.\n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';```\n",
      "Sub-table: <table>\n",
      "<caption>1972 isle of man tt</caption>\n",
      "<thead>\n",
      "<tr><th>  MIN(points)</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>3            </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: was 2 be the fewest point that roger dutton / tony wright receive?\n",
      "Thought: Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \n",
      "Answer: 3\n",
      "    \n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT * from DF;```\n",
      "Sub-table: <table>\n",
      "<thead>\n",
      "<tr><th>  Rank</th><th>                 Cyclist</th><th>              Team</th><th>      Time</th><th>  UCI_ProTour_nPoints</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1     </td><td>Alejandro Valverde (ESP)</td><td>Caisse d'Epargne  </td><td>5h 29' 10\"</td><td>40                   </td></tr>\n",
      "<tr><td>2     </td><td>Alexandr Kolobnev (RUS) </td><td>Team CSC Saxo Bank</td><td>s.t.      </td><td>30                   </td></tr>\n",
      "<tr><td>3     </td><td>Davide Rebellin (ITA)   </td><td>Gerolsteiner      </td><td>s.t.      </td><td>25                   </td></tr>\n",
      "<tr><td>4     </td><td>Paolo Bettini (ITA)     </td><td>Quick Step        </td><td>s.t.      </td><td>20                   </td></tr>\n",
      "<tr><td>5     </td><td>Franco Pellizotti (ITA) </td><td>Liquigas          </td><td>s.t.      </td><td>15                   </td></tr>\n",
      "<tr><td>6     </td><td>Denis Menchov (RUS)     </td><td>Rabobank          </td><td>s.t.      </td><td>11                   </td></tr>\n",
      "<tr><td>7     </td><td>Samuel Sánchez (ESP)    </td><td>Euskaltel-Euskadi </td><td>s.t.      </td><td>7                    </td></tr>\n",
      "<tr><td>8     </td><td>Stéphane Goubert (FRA)  </td><td>Ag2r-La Mondiale  </td><td>+ 2\"      </td><td>5                    </td></tr>\n",
      "<tr><td>9     </td><td>Haimar Zubeldia (ESP)   </td><td>Euskaltel-Euskadi </td><td>+ 2\"      </td><td>3                    </td></tr>\n",
      "<tr><td>10    </td><td>David Moncoutié (FRA)   </td><td>Cofidis           </td><td>+ 2\"      </td><td>1                    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information:\n",
      "From the sub-table, we can see that there are 3 cyclists from Italy, 2 cyclists from Spain, 2 cyclists from Russia, and 1 cyclist from France who finished within the top 10.\n",
      "\n",
      "Query: which country had the most cyclists finish within the top 10?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text': 'Thought: Based on the sub-table, Italy had the most cyclists finish within the top 10, with 3 cyclists.\\nAnswer: Italy'}\n",
      "ALL TOKENS 3435\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.01)\n",
    "save_path = f\"result/answer/wikitable_zh_{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.csv\"\n",
    "save_path = f\"result/answer/wikitable_zh_05-07_09-21-03.csv\"\n",
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "# template=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "template = \"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Complete task with the help of extra information below.\n",
    "\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table:\n",
    "{table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\n",
    "Think step by step and answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "\"\"\" )\n",
    "# Task: answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# Task: verify whether the provided claim/query is true or false, return 0 if it's false, or 1 if it's true. Please think step by step and return 0/1 at last.\n",
    "\n",
    "\n",
    "# muilti_answer_instruction = get_k_shot_with_answer()\n",
    "# for sample_n in range(3):\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "samplings = []\n",
    "i = 0\n",
    "# while i < len(table_loader.dataset):\n",
    "#     try:\n",
    "sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "all_tokens = 0\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "sample_data = formatter.get_sample_data(sample_type='embedding', query=sample['query'])\n",
    "with get_openai_callback() as cb:\n",
    "    llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    all_queries.append(batch_pred[0]['text'].strip())\n",
    "    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    all_queries.extend(batch_pred[0]['text'].split(';'))\n",
    "    # print(all_queries)\n",
    "all_tokens += cb.total_tokens\n",
    "args_list = [{\"query\": q, \"sample\": sample} for q in all_queries if reranker.compute_score([(q, sample['query'])], normalize=True) < 0.95]\n",
    "# print(len(args_list))\n",
    "ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "results = [res[0] for res in ans_from_B if res[0] != 'Cannot get answer from sub-table']\n",
    "all_tokens += sum([res[1] for res in ans_from_B])\n",
    "#With answer\n",
    "with get_openai_callback() as cb:\n",
    "    imp_input = scene_A(sample['query'], sample, True)\n",
    "    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=True)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "print(batch_pred[0])\n",
    "all_tokens += cb.total_tokens\n",
    "print('ALL TOKENS', all_tokens)\n",
    "ids.append(sample['id'])\n",
    "labels.append(sample['query'])\n",
    "outputs.append(batch_pred[0]['text'])\n",
    "\n",
    "    #     if (i + 1) % 10 == 0:\n",
    "    #         print(f'saving {i}')\n",
    "    #         save_csv([outputs, labels, ids, samplings], ['preds', 'statements','ids', 'sample_n'], file_path=save_path)\n",
    "    #         outputs = []\n",
    "    #         labels = []\n",
    "    #         ids = []\n",
    "    #     i += 1\n",
    "    # except ValueError as e:\n",
    "    #     print(f'******************Value Error {i}****************************')\n",
    "    #     i += 1\n",
    "    # except BadRequestError as e:\n",
    "    #     print('*************************Bad Request**************')\n",
    "    #     i += 1\n",
    "#With no answer\n",
    "# temp = [f\"\"\"\n",
    "# SQL Excuted for extra information: \n",
    "# ```{res[1]}```\n",
    "# Sub-table for extra information: {res[2]}\"\"\" for res in results if res[2] != 'No data from database']\n",
    "# imp_input = scene_A(sample['query'], sample, False)\n",
    "# llm_chain = LLMChain(llm=model, prompt=muilti_answer_instruction, verbose=True)\n",
    "# batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(temp)}], return_only_outputs=True)\n",
    "# print(batch_pred[0])\n",
    "# outputs.append(batch_pred[0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2232"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "46: west berkshire brewery 's maggs magnificent mild be its most decorate beer between 1995 and 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '：' (U+FF1A) (3998830562.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    20 ：Based on the information provided, the SQL query filtered for records where the place starts with 't9' and the country is 'united states'. The result of the query shows that there are 3 people who meet these criteria. However, the extra information states that there were actually 4 people who tied for ninth place, and all of them were from the United States.\\n\\nTherefore, the provided claim/query is false. The correct number of people from the United States who tied for ninth place is 4, not 3. \\n\\nFinal answer: 0\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '：' (U+FF1A)\n"
     ]
    }
   ],
   "source": [
    "20 ：Based on the information provided, the SQL query filtered for records where the place starts with 't9' and the country is 'united states'. The result of the query shows that there are 3 people who meet these criteria. However, the extra information states that there were actually 4 people who tied for ninth place, and all of them were from the United States.\\n\\nTherefore, the provided claim/query is false. The correct number of people from the United States who tied for ninth place is 4, not 3. \\n\\nFinal answer: 0\n",
    "88: To verify whether the term start for Bashkim Fino is after the term start for Vilson Ahmeti, we need to compare the dates mentioned in the sub-table. From the sub-table:\\n- Vilson Ahmeti's term started on December 10, 1991.\\n- Bashkim Fino's term started on March 11, 1997.\\n\\nSince December comes before March in the calendar year, it is evident that Vilson Ahmeti's term started before Bashkim Fino's term. Therefore, the claim that the term start for Bashkim Fino is after the term start for Vilson Ahmeti is FALSE.\\n\\nHence, the answer is 0\n",
    "72:To verify the claim that the gap between the first and last player being a total of 58.04 is true, we need to calculate the difference between the points of the first and last player based on the given information.\\n\\nGiven:\\n- Total gap between the first and last rank is 18.\\n- Rank of the first player is 1.\\n- Rank of the last player is 19.\\n\\nLet's calculate the points difference between the first and last player:\\npoints difference = (points of last player) - (points of first player)\\n\\nSince the total gap between the first and last rank is 18, we can calculate the points difference as follows:\\npoints difference = 18 * (MAX(points) - MIN(points))\\n\\nGiven that the calculated point gap from the sub-table is 58.04, we can substitute this value into the formula:\\n18 * 58.04 = 1044.72\\n\\nTherefore, the claim that the gap between the first and last player being a total of 58.04 is false.\\n\\nFinal answer: 0\n",
    "76:The SQL query filters for competitors from France with a rank less than 5. Since the sub-table generated from the query shows no data, it means that there were no competitors from France who finished better than 5th place. \\n\\nTherefore, the provided claim that France's competitors all finished better than 5th place is TRUE.\\n\\nFinal answer: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1, 3, 11, 12, 13, 14, 16, 20, 22, 26, 34, 38, \n",
    "40, 41, 42, 44, 47, 50, 53, 56, 64, 65, 69, 72,\n",
    "79, 80, 82, 83, 84, 88, 90, 91, 92, 95, 98, 100,\n",
    "108, 110, 113, 116, 119, 121, 122, 123, 125, 133, \n",
    "136, 137, 139, 140, 141, 144, 145, 148, 158, 167,\n",
    "169, 174, 176, 177, 179, 181, 185, 191, 200, 201, 210, \n",
    "220, 223, 225, 226, 227, 228, 229, 231, 238, 240, 241, \n",
    "246, 251, 254, 255, 256, 265, 269, 270, 272, 274, 280, \n",
    "281, 282, 283, 286, 287, 294, 296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To verify whether the term start for Bashkim Fino is after the term start for Vilson Ahmeti, we need to compare the dates mentioned in the sub-table.\n",
      "\n",
      "From the sub-table:\n",
      "- Vilson Ahmeti's term started on 10th December 1991.\n",
      "- Bashkim Fino's term started on 11th March 1997.\n",
      "\n",
      "Since 10th December 1991 comes before 11th March 1997, the claim that the term start for Bashkim Fino is after the term start for Vilson Ahmeti is FALSE.\n",
      "\n",
      "Therefore, the answer is 0.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[88, :]['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "def parse_datetime(date_string):\n",
    "    parsed_date = parser.parse(date_string)\n",
    "    if parsed_date is None or not all([parsed_date.year, parsed_date.month, parsed_date.day]):\n",
    "        return date_string\n",
    "    print(parsed_date)\n",
    "    if parsed_date.year == datetime.datetime.now().year:\n",
    "        normalized_date = datetime.datetime.strftime(parsed_date, \"%m-%d\")\n",
    "    else:\n",
    "        normalized_date = datetime.datetime.strftime(parsed_date, \"%Y-%m-%d\")\n",
    "    return normalized_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [ ]\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    sample = table_loader.normalize_table(table_loader.dataset[i])\n",
    "    llm_chain = LLMChain(llm=model, prompt=stage_0_prompt, verbose=False)\n",
    "    stage_0_batch_pred = llm_chain.batch([{\"query\": sample['query']}], return_only_outputs=True)[0]['text'].split(':')[-1]\n",
    "    print(stage_0_batch_pred)\n",
    "    sub_queries = stage_0_batch_pred.split(';')\n",
    "\n",
    "    from langchain_community.callbacks import get_openai_callback\n",
    "    Agent_history = ChatMessageHistory()\n",
    "    agent_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"Based on the history information, your task is to determine whether the information is enough to answer the user query.\n",
    "                return 'A' if you think you need more information, else return 'B'. You should only use information during the conversation.\"\"\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = LLMChain(llm=model, prompt=agent_prompt, verbose=True)\n",
    "    with get_openai_callback() as cb:\n",
    "        for sub_query in sub_queries:\n",
    "            Agent_history.add_user_message(sub_query)\n",
    "            choice = chain.invoke(\n",
    "            {\n",
    "                \"chat_history\": Agent_history.messages,\n",
    "            }\n",
    "            )['text']\n",
    "            if 'A' in choice:\n",
    "                Agent_history.add_ai_message(scene_A(sub_query, sample))\n",
    "            else:\n",
    "                res = scene_B()\n",
    "                print(res)\n",
    "                result.append(res)\n",
    "                \n",
    "    print(cb.total_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import recognizers_suite\n",
    "from recognizers_text import Culture, ModelResult\n",
    "def str_normalize(user_input, recognition_types=None):\n",
    "    \"\"\"A string normalizer which recognize and normalize value based on recognizers_suite\"\"\"\n",
    "    user_input = str(user_input)\n",
    "    user_input = user_input.replace(\"\\\\n\", \"; \")\n",
    "\n",
    "    def replace_by_idx_pairs(orig_str, strs_to_replace, idx_pairs):\n",
    "        assert len(strs_to_replace) == len(idx_pairs)\n",
    "        last_end = 0\n",
    "        to_concat = []\n",
    "        for idx_pair, str_to_replace in zip(idx_pairs, strs_to_replace):\n",
    "            to_concat.append(orig_str[last_end : idx_pair[0]])\n",
    "            to_concat.append(str_to_replace)\n",
    "            last_end = idx_pair[1]\n",
    "        to_concat.append(orig_str[last_end:])\n",
    "        return ''.join(to_concat)\n",
    "\n",
    "    if recognition_types is None:\n",
    "        recognition_types = [\n",
    "            \"datetime\",\n",
    "            \"number\",\n",
    "            \"ordinal\",\n",
    "            \"percentage\",\n",
    "            \"age\",\n",
    "            \"currency\",\n",
    "            \"dimension\",\n",
    "            \"temperature\",\n",
    "        ]\n",
    "    culture = Culture.English\n",
    "    for recognition_type in recognition_types:\n",
    "        if re.match(\"\\d+/\\d+\", user_input):\n",
    "            # avoid calculating str as 1991/92\n",
    "            continue\n",
    "        recognized_list = getattr(\n",
    "            recognizers_suite, \"recognize_{}\".format(recognition_type)\n",
    "        )(\n",
    "            user_input, culture\n",
    "        )  # may match multiple parts\n",
    "        strs_to_replace = []\n",
    "        idx_pairs = []\n",
    "        for recognized in recognized_list:\n",
    "            if not recognition_type == 'datetime':\n",
    "                recognized_value = recognized.resolution['value']\n",
    "                if str(recognized_value).startswith(\"P\"):\n",
    "                    # if the datetime is a period:\n",
    "                    continue\n",
    "                else:\n",
    "                    strs_to_replace.append(recognized_value)\n",
    "                    idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "            else:\n",
    "                if recognized.resolution:  # in some cases, this variable could be none.\n",
    "                    if len(recognized.resolution['values']) == 1:\n",
    "                        strs_to_replace.append(\n",
    "                            recognized.resolution['values'][0]['timex']\n",
    "                        )  # We use timex as normalization\n",
    "                        idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "\n",
    "        if len(strs_to_replace) > 0:\n",
    "            user_input = replace_by_idx_pairs(user_input, strs_to_replace, idx_pairs)\n",
    "\n",
    "    if re.match(\"(.*)-(.*)-(.*) 00:00:00\", user_input):\n",
    "        user_input = user_input[: -len(\"00:00:00\") - 1]\n",
    "        # '2008-04-13 00:00:00' -> '2008-04-13'\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE), \" \", text)\n",
    "\n",
    "    def whilt_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return whilt_space_fix(remove_articles(remove_punc(lower(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE), \" \", text)\n",
    "\n",
    "    def whilt_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return whilt_space_fix(remove_articles(remove_punc(lower(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cahill' == 'cahill colosimo culina elrich griffiths skoko zdrilic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dmitry Mikhailovich Golitsyn served longer as an ambassador.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize('Dmitry Mikhailovich Golitsyn served longer as an ambassador.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "compute_exact('Cahill', 'Cahill, Colosimo, Culina, Elrich, Griffiths, Skoko, Zdrilic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sopwith triplane sn n5460'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize(normalize_answer('Sopwith Triplane s/n N5460'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cahill, Colosimo, Culina, Elrich, Griffiths, Skoko, Zdrilic'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize('Cahill, Colosimo, Culina, Elrich, Griffiths, Skoko, Zdrilic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
