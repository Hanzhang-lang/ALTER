{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 5.24早修改table format 空格\\xa\n",
    "- 5.24 下午修改str_normalize \n",
    "- 5.24 晚 72需要复查\n",
    "- 5.25 早list query strip() \n",
    "- 5.27 修改total，尝试disambiguous/  改成PIPE  / 晚上发现列名重复修改的问题， 发现shot来自test的问题\n",
    "- 5.29 在shot中添加extra\n",
    "- 5.31 在选列aug的shot中添加extra\n",
    "- 6.1 some extra infor may be useful\n",
    "- 6.3 添val 101shot\n",
    "- 6.5 规范化prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import parse_specific_composition, add_row_number, parse_specific_composition_zh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sqlalchemy import create_engine\n",
    "from executor import SQLManager\n",
    "import sqlparse\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "            model_name='BAAI/bge-large-en',\n",
    "            model_kwargs={'device': 'cuda:0', 'trust_remote_code': True},\n",
    "            encode_kwargs={'normalize_embeddings': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "                  \"what was the time difference between the first place finisher and the eighth place finisher?\",\n",
    "                  \"other than william stuart price, which other businessman was born in tulsa?\",\n",
    "                  \"which canadian city had the most passengers traveling from manzanillo international airport in 2013?\"\n",
    "                  ]\n",
    "new_query_examples = [\n",
    "                      \"what was the time for the first place finisher?; what was the time for the eighth place finisher?\",\n",
    "                      \"was william stuart price born in tulsa?; who was born in tulsa?\",\n",
    "                      \"how many passengers do each airline from canadian city have?; which canadian city had the most passengers?\"\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 11, 86]\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True, embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub-queries. Below is a sub-table with rows randomly sampled from the original table. Based on the sub-table, decompose the original query into 2-3 complete sub-queries that can solve the original query.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "# model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.7).bind(logprobs=True)\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "engine = create_engine('sqlite:////media/disk1/chatgpt/zh/tabular_data/db/sqlite/cell.db', echo=False)\n",
    "manager = SQLManager(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name=task_name, split='test', use_sample=False, small_test=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [5, 11, 46]\n",
    "num_k = 3\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True,embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\"was the Sandia Peak Tramway before or after the 3S Aerial Tramway in terms of Year_of_inauguration?\",\n",
    "                      \"other than William Stuart Price, which other businessman's was in Tulsa in terms of Hometown?\",\n",
    "                      \"How many players are G\\\\nF in terms of Position?\"]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"Sub-table: {table}\n",
    "Query: {query}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "disambiguous_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    # prefix=\"\"\"Based on the given table, your task is to rewrite the query to resolve ambiguity and ensure the question is consistent with the table. \n",
    "    # This requires pinpointing elements of the question to table contents and rewriting the question to ensure a consistent, clear interpretation. \"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-table: {table}\n",
    "Query: {query}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [11, 182, 70]\n",
    "num_k = 2\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True,embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which business man was born in tulsa?\",\n",
    "    \"what is the network owned by national polytechnic institute?\",\n",
    "    \"what districts are more populous than haridwar?\"\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"Sub-table: {table}\n",
    "Query: {query}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Below is a sub-table with rows randomly sampled from the original table. Based on the sub-table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-table: {table}\n",
    "Query: {query}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_answer(k: int=1):\n",
    "#     sqls = [\"SELECT COUNT(*) FROM DF WHERE Outcome = 'Runner-up' AND Opponent = 'Roger Federer';\"\n",
    "#             ]\n",
    "#     thoughts = [\"The SQL query filters the data to only include rows where the outcome is 'Runner-up' and the opponent is 'Roger Federer'. The sub-table shows that Roger Federer was a runner-up 2 times.\"]\n",
    "#     tables = [\"\"\" <table>\n",
    "# <thead>\n",
    "# <tr><th>  COUNT(*)</th></tr>\n",
    "# </thead>\n",
    "# <tbody>\n",
    "# <tr><td>2.0000    </td></tr>\n",
    "# </tbody>\n",
    "# </table>\"\"\"]\n",
    "#     tables_pipe = [\"\"\"/*\n",
    "# table caption : turkish cup\n",
    "# col : MAX(winners_c_from_previous_round)\n",
    "# row 1: 54\n",
    "# */\"\"\"]\n",
    "#     claims = [\"how many times was roger federer a runner-up?\"]\n",
    "        sqls = [\"SELECT DISTINCT Type FROM DF WHERE Type != 'audio';\"\n",
    "                ]\n",
    "        thoughts = [\"Based on the SQL query and the extra information provided, the types include audio or video. Therefore, other than audio, the payload type is video.\"]\n",
    "        tables = ['<table>\\n<thead>\\n<tr><th> Type </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>video   </td></tr>\\n<tr><td>audio/video   </td></tr>\\n</tbody>\\n</table>']\n",
    "        claims = [\"other than audio, what type of payload types are there?\"]\n",
    "        extras = [\"The payload types for audio include audio, video, and audio/video.\"]\n",
    "#     sqls = [\"SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';\"\n",
    "#             ]\n",
    "#     thoughts = [\"Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \"]\n",
    "#     tables = [\"<table>\\n<caption>1972 isle of man tt</caption>\\n<thead>\\n<tr><th>  MIN(points)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>3            </td></tr>\\n</tbody>\\n</table>\"]\n",
    "#     claims = [\"2 be the fewest point that roger dutton / tony wright receive\"]\n",
    "    # inds from test split\n",
    "        examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"information\",  \"claim\", \"thought\", \"output\"], template=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {claim}\n",
    "Thought: {thought}\n",
    "Answer: {output}\n",
    "        \"\"\")\n",
    "        examples_dict = dict(zip([\"SQL\", \"table\", \"information\",  \"claim\", \"thought\", \"output\"], [sqls[0], tables[0], extras[0], claims[0], thoughts[0], 'video']))\n",
    "        prompt_template = FewShotPromptTemplate(\n",
    "                examples=[examples_dict],\n",
    "                example_prompt=examples_prompt,\n",
    "                prefix=\"\"\"Below is a sub-table generated by executing the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
    "You should output in the following format:\n",
    "Thought: your step by step thought\n",
    "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "Below is an example.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "SQL Executed: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\"\"\",\n",
    "                input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    "        )\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_aug(k: int=2):\n",
    "    table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "    examples_dict = []\n",
    "    \n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Mesa Trouble\"       </td><td>Sid Marcus </td><td>1974       </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": table_loader.dataset[95]['question'],\n",
    "                                        \"aug\": \"The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year. \\n1. Number: The episode number in the series \\n2. Title: The title of the episode \\n3. Directed_by_: The director of the episode \\n4. Released_: The release year of the episode\",\n",
    "                                        \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "                                        \"output\": \"Released_, Number, Title, Directed_by_\"}])\n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>1943–44 Chicago Black Hawks season</caption>\\n<thead>\\n<tr><th>  num</th><th>       Date</th><th>            Visitor</th><th>  Score</th><th>               Home</th><th>  Record</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>14   </td><td>December 5 </td><td>New York Rangers   </td><td>6–7    </td><td>Chicago Black Hawks</td><td>8–6–0   </td></tr>\\n<tr><td>40   </td><td>February 26</td><td>Chicago Black Hawks</td><td>3–2    </td><td>Toronto Maple Leafs</td><td>18–18–4 </td></tr>\\n<tr><td>31   </td><td>January 29 </td><td>Chicago Black Hawks</td><td>4–3    </td><td>Toronto Maple Leafs</td><td>14–16–1 </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": 'what was the difference in score in the december 19th win?',\n",
    "                                        \"aug\": 'The table contains information about the 1943-44 Chicago Black Hawks season, including the date, visitor, score, home team, record, and points for each game. \\n1. num: The game number in the season \\n2. Date: The date of the game\\n3. Vistor: The visiting team\\n4. Score: The final score, with the visitor score listed first\\n5. Home: The home team\\n6. Record: The team win-loss-overtime loss record at the time of the game',\n",
    "                                        \"linking\": 'difference in score -> Score, december 19th -> Date',\n",
    "                                        \"output\": 'Date, Score'}])\n",
    "    \n",
    "    # \"The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year.\"\n",
    "    # \"№<The episode number in the series>\\nTitle<The title of the episode>\\nDirected_by_<The director of the episode>\\nReleased_<The release year of the episode>\"\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"table\", \"aug\",\"claim\", \"output\", \"linking\"], template=\n",
    "    \"\"\"\n",
    "Table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "Column linking: {linking}\n",
    "Columns: {output}\"\"\")\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples_dict,\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\n",
    "        \"\"\"\n",
    "Based on the Table below, your task is to accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
    "Approach this task as follows:\n",
    "Read the query and extra information thoroughly and list every possible link from query term to column in the Table. \n",
    "Then based on the column linking, output all useful columns at last. Make sure all columns in the linking step are included and every column is in the Table.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "Table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\"\"\",\n",
    "        input_variables=[\"table\", \"claim\", \"aug\"],\n",
    ")\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "# def get_k_shot_with_aug(k: int=2):\n",
    "#     table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "#     examples_dict = []\n",
    "#     examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>',\n",
    "#                                         \"claim\": table_loader.dataset[95]['question'],\n",
    "#                                         \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "#                                         \"output\": \"Title, Released_, Number, Directed_by_\"}])\n",
    "#     examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "#     \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking: {linking}\n",
    "#     Columns: {output}\"\"\")\n",
    "#     prompt_template = FewShotPromptTemplate(\n",
    "#         examples=examples_dict,\n",
    "#         example_prompt=examples_prompt,\n",
    "#         prefix=\n",
    "#         \"\"\"\n",
    "#     Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
    "#     Approach this task as follows:\n",
    "#     Read the query thoroughly and list every possible link from query term to column in the Table. \n",
    "#     Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "#     # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "#     # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "#     # Here are some examples:\"\"\",\n",
    "#         suffix=\n",
    "#         \"\"\"\n",
    "#     Table: {table}\n",
    "#     Extra information: {aug}\n",
    "    \n",
    "#     Query: {claim}\"\"\",\n",
    "#         input_variables=[\"table\", \"claim\", \"aug\"],\n",
    "# )\n",
    "#     return prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "def scene_A(query, sample, k =3, verbose=True):\n",
    "    # Our ultimate goal is to answer query based on the original table. Below we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "    # Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "#     row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "#                                  template=\"\"\"Our ultimate goal is to answer query based on the original table. Below we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the extra information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "# sub-table: {table}\n",
    "# Extra information: {aug}\n",
    "\n",
    "# Query: {claim}\n",
    "# SQL: \"\"\")\n",
    "\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                    template=\"\"\"Our ultimate goal is to answer the query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table.  Based on the augmentation information, carefully analyze the query and write an SQLITE3 SELECT SQL statement using table DF that completes the query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        \n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug +'\\n'+ '\\n'.join(extra_col_info)\n",
    "                                            # 'aug': ''\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        if verbose:\n",
    "            print(stage_1_batch_pred)\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        try: \n",
    "            # formatter.all_data = formatter.all_data.loc[:, columns]\n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique().astype(str)))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique()[:3].astype(str)))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        extra_information.append('row_number: row index in the original table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data = sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\nColumn information:\\n' + '\\n'.join(extra_information)\n",
    "                                            # 'aug': ''\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "        if verbose:\n",
    "            print(stage_2_batch_pred)\n",
    "    # stage 3: SQL Excution\n",
    "    try: \n",
    "        execute_data = manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "    except:\n",
    "        execute_data = formatter.all_data\n",
    "        stage_2_batch_pred = 'SELECT * from DF;'\n",
    "    if len(execute_data) == 0:\n",
    "        return query, stage_2_batch_pred, 'No data from database', cb.total_tokens\n",
    "    return query, stage_2_batch_pred, TableFormat.format_html(data=execute_data), cb.total_tokens\n",
    "    # return query, stage_2_batch_pred, execute_data, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)\n",
    "\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整extrainformation的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering and answer the query using the final sub-table. \n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: \n",
    "{table}\n",
    "Query: {claim}\n",
    "Please provide a clear, complete statement in response to the query. If you cannot answer the query based on the sub-table, just say 'Cannot get answer from sub-table'.\n",
    "\"\"\" )\n",
    "def scene_B(query, sample, k=3, verbose=False):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer the query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table.  Based on the augmentation information, carefully analyze the query and write an SQLITE3 SELECT SQL statement using table DF that completes the query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    \n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    # get columns\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n' + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        try: \n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique().astype(str)))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(formatter.all_data[col].dropna().unique()[:3].astype(str)))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        #  sample augmentation\n",
    "        # extra_information = (parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        extra_information.append('row_number: row index in the table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "    \n",
    "        \n",
    "        # stage 3: SQL Excution\n",
    "        try: \n",
    "            execute_data= manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "        except:\n",
    "            execute_data = formatter.all_data\n",
    "            stage_2_batch_pred = 'SELECT * from DF;'\n",
    "        llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=verbose)\n",
    "        response = llm_chain.batch([dict({'table': TableFormat.format_html(execute_data),\n",
    "                                                'claim': query,\n",
    "                                                'SQL':  stage_2_batch_pred\n",
    "                                                })], return_only_outputs=True)[0]['text']\n",
    "    # print(\"total_tokens:\", cb.total_tokens)\n",
    "    return response, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2b219db0d2984f9dae28b651ab8ab3d9\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://smsh.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "# os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=0.3,\n",
    "    max_retries=5, request_timeout=600\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '跑的是加了选列的shot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m跑的是加了选列的shot\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name '跑的是加了选列的shot' is not defined"
     ]
    }
   ],
   "source": [
    "跑的是加了选列的shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what was the point difference between the teams in game 33?']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Based on the Table below, your task is to accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
      "Approach this task as follows:\n",
      "Read the query and extra information thoroughly and list every possible link from query term to column in the Table. \n",
      "Then based on the column linking, output all useful columns at last. Make sure all columns in the linking step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>Hoot Kloot</caption>\n",
      "<thead>\n",
      "<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1  </td><td>\"Kloot's Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>6  </td><td>\"Mesa Trouble\"       </td><td>Sid Marcus </td><td>1974       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year. \n",
      "1. Number: The episode number in the series \n",
      "2. Title: The title of the episode \n",
      "3. Directed_by_: The director of the episode \n",
      "4. Released_: The release year of the episode\n",
      "\n",
      "Query: what was the last title that sid marcus directed?\n",
      "Column linking: the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\n",
      "Columns: Released_, Number, Title, Directed_by_\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>1943–44 Chicago Black Hawks season</caption>\n",
      "<thead>\n",
      "<tr><th>  num</th><th>       Date</th><th>            Visitor</th><th>  Score</th><th>               Home</th><th>  Record</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>14   </td><td>December 5 </td><td>New York Rangers   </td><td>6–7    </td><td>Chicago Black Hawks</td><td>8–6–0   </td></tr>\n",
      "<tr><td>40   </td><td>February 26</td><td>Chicago Black Hawks</td><td>3–2    </td><td>Toronto Maple Leafs</td><td>18–18–4 </td></tr>\n",
      "<tr><td>31   </td><td>January 29 </td><td>Chicago Black Hawks</td><td>4–3    </td><td>Toronto Maple Leafs</td><td>14–16–1 </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about the 1943-44 Chicago Black Hawks season, including the date, visitor, score, home team, record, and points for each game. \n",
      "1. num: The game number in the season \n",
      "2. Date: The date of the game\n",
      "3. Vistor: The visiting team\n",
      "4. Score: The final score, with the visitor score listed first\n",
      "5. Home: The home team\n",
      "6. Record: The team win-loss-overtime loss record at the time of the game\n",
      "\n",
      "Query: what was the difference in score in the december 19th win?\n",
      "Column linking: difference in score -> Score, december 19th -> Date\n",
      "Columns: Date, Score\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>2008–09 Sacramento Kings season</caption>\n",
      "<thead>\n",
      "<tr><th>  Game</th><th>      Date</th><th>          Team</th><th>          Score</th><th>      High_points</th><th>       High_rebounds</th><th>                High_assists</th><th>              Location_nAttendance</th><th>  Record</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>33    </td><td>January 2 </td><td>@ Detroit     </td><td>L 92-98        </td><td>Brad Miller (25) </td><td>Brad Miller (16)    </td><td>John Salmons (4)            </td><td>The Palace of Auburn Hills\\n22,076</td><td>8-25    </td></tr>\n",
      "<tr><td>40    </td><td>January 14</td><td>@ Golden State</td><td>W 135-133 (3OT)</td><td>Brad Miller (30) </td><td>Brad Miller (22)    </td><td>John Salmons, Beno Udrih (7)</td><td>Oracle Arena\\n19,122              </td><td>10-30   </td></tr>\n",
      "<tr><td>39    </td><td>January 13</td><td>Orlando       </td><td>L 107-139      </td><td>Kevin Martin (30)</td><td>Francisco García (5)</td><td>Francisco García (5)        </td><td>ARCO Arena\\n11,168                </td><td>9-30    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains data for the 2008-09 Sacramento Kings season, including game number, date, opposing team, score, high points, high rebounds, high assists, location and attendance, and the team's record.\n",
      "1. Game: The number of the game in the season\n",
      "2. Date: The date of the game\n",
      "3. Team: The opposing team\n",
      "4. Score: The final score of the game\n",
      "5. High_points: The player and their number of high points in the game\n",
      "6. High_rebounds: The player and their number of high rebounds in the game\n",
      "7. High_assists: The player and their number of high assists in the game\n",
      "8. Location_nAttendance: The location and attendance of the game\n",
      "9. Record: The team's record after the game\n",
      "\n",
      "Query: what was the point difference between the sacramento and detroit for game 33?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Column linking: point difference -> Score, sacramento -> Team, detroit -> Team, game 33 -> Game\n",
      "Columns: Score, Team, Game\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOur ultimate goal is to answer the query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table.  Based on the augmentation information, carefully analyze the query and write an SQLITE3 SELECT SQL statement using table DF that completes the query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>2008–09 Sacramento Kings season</caption>\n",
      "<thead>\n",
      "<tr><th>  row_number</th><th>          Score</th><th>          Team</th><th>  Game</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1           </td><td>L 92-98        </td><td>@ Detroit     </td><td>33    </td></tr>\n",
      "<tr><td>8           </td><td>W 135-133 (3OT)</td><td>@ Golden State</td><td>40    </td></tr>\n",
      "<tr><td>7           </td><td>L 107-139      </td><td>Orlando       </td><td>39    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains data for the 2008-09 Sacramento Kings season, including game number, date, opposing team, score, high points, high rebounds, high assists, location and attendance, and the team's record.\n",
      "Column information:\n",
      "Game:Sequential numbers indicating the order of the game (Values like 33, 34, 35...)\n",
      "Team:Team names with @ indicating away games (Values like @ Detroit, @ Indiana, @ New Jersey...)\n",
      "Score:Scores in the format W/L followed by points for each team (Values like L 92-98, L 117-122, L 90-98...)\n",
      "row_number: row index in the original table\n",
      "\n",
      "Query: what was the point difference between the sacramento and detroit for game 33?\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "SELECT ABS(SUBSTR(Score, INSTR(Score, '-') + 1) - SUBSTR(Score, INSTR(Score, ' ') + 2)) AS Point_Difference\n",
      "FROM DF\n",
      "WHERE Team = '@ Detroit' AND Game = 33;\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a sub-table generated by executing the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
      "You should output in the following format:\n",
      "Thought: your step by step thought\n",
      "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
      "Below is an example.\n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT DISTINCT Type FROM DF WHERE Type != 'audio';```\n",
      "Sub-table: <table>\n",
      "<thead>\n",
      "<tr><th> Type </th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>video   </td></tr>\n",
      "<tr><td>audio/video   </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information:\n",
      "The payload types for audio include audio, video, and audio/video.\n",
      "\n",
      "Query: other than audio, what type of payload types are there?\n",
      "Thought: Based on the SQL query and the extra information provided, the types include audio or video. Therefore, other than audio, the payload type is video.\n",
      "Answer: video\n",
      "        \n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT ABS(SUBSTR(Score, INSTR(Score, '-') + 1) - SUBSTR(Score, INSTR(Score, ' ') + 2)) AS Point_Difference\n",
      "FROM DF\n",
      "WHERE Team = '@ Detroit' AND Game = 33;```\n",
      "Sub-table: <table>\n",
      "<thead>\n",
      "<tr><th>  Point_Difference</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>96.0000           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information:\n",
      "The point difference between the teams in game 33 was 92.\n",
      "The score for the Detroit game in game 33 was L 92-98.\n",
      "\n",
      "Query: what was the point difference between the sacramento and detroit for game 33?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text': 'Thought: The SQL query calculates the absolute value of the point difference between the two teams in game 33. The point difference is calculated by subtracting the second score from the first score. In this case, the first score is 98 and the second score is 92. Therefore, the point difference is 98 - 92 = 6. The absolute value of 6 is 6, so the point difference is 6.\\nAnswer: 6'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError\n",
    "from tqdm.notebook import tqdm\n",
    "# table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.01)\n",
    "# save_path = f\"../result/final_answer/wikitable_{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.csv\"\n",
    "save_path = f\"../result/final_answer/wikitable_06-06_08-27-00.csv\"\n",
    "\n",
    "# reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "# template=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "template = \"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Complete task with the help of extra information below.\n",
    "\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table:\n",
    "{table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\n",
    "Think step by step and answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "\"\"\" )\n",
    "sample_k = 3\n",
    "# Task: answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# Task: verify whether the provided claim/query is true or false, return 0 if it's false, or 1 if it's true. Please think step by step and return 0/1 at last.\n",
    "\n",
    "\n",
    "# muilti_answer_instruction = get_k_shot_with_answer()\n",
    "# for sample_n in range(3):\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 717\n",
    "# with tqdm(total=len(table_loader.dataset) - 1540, desc=f\"Processing\",ncols=1500) as pbar:\n",
    "#     while i < len(table_loader.dataset):\n",
    "#         try:\n",
    "sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "all_tokens = 0\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "with get_openai_callback() as cb:\n",
    "    llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    if batch_pred[0]['text'].strip() != sample['query']:\n",
    "        all_queries.append(batch_pred[0]['text'].strip())\n",
    "        print(all_queries)\n",
    "    # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "    # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    # all_queries.append(batch_pred[0]['text'].strip())\n",
    "    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "    # print(all_queries)\n",
    "all_tokens += cb.total_tokens\n",
    "all_queries = list(set(all_queries))\n",
    "args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "# print(args_list)\n",
    "ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "all_tokens += sum([res[1] for res in ans_from_B])\n",
    "#With answer\n",
    "# results= []\n",
    "\n",
    "# answer_instruction = PromptTemplate(input_variables=[\"table\", \"claim\"], \n",
    "#                                     template=\"\"\"\n",
    "# Task: Based on the table, think step by step and answer the last question given in the query. \n",
    "# Table: {table}\n",
    "# Query: {claim}\n",
    "# Based on the table, answer the question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# \"\"\" )\n",
    "# with get_openai_callback() as cb:\n",
    "#     # imp_input = scene_A(sample['query'], sample, sample_k, True)\n",
    "#     llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=True)\n",
    "#     batch_pred = llm_chain.batch([{\"claim\": sample['query'], \"table\": TableFormat.format_html(formatter.all_data)}], return_only_outputs=True)\n",
    "    \n",
    "with get_openai_callback() as cb:\n",
    "    imp_input = scene_A(sample['query'], sample, sample_k, True)\n",
    "    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=True)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "print(batch_pred[0])\n",
    "all_tokens += cb.total_tokens\n",
    "# print('ALL TOKENS', all_tokens)\n",
    "ids.append(sample['id'])\n",
    "labels.append(sample['query'])\n",
    "outputs.append(batch_pred[0]['text'])\n",
    "tokens.append(all_tokens)\n",
    "extra_quries.append(';'.join(all_queries))\n",
    "        #     if (i + 1) % 10 == 0:\n",
    "        #             print(f'saving {i}')\n",
    "        #             save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "        #             outputs = []\n",
    "        #             labels = []\n",
    "        #             ids = []\n",
    "        #             tokens = []\n",
    "        #             extra_quries = []\n",
    "        #     i += 1\n",
    "        #     print(f' Process {i}')\n",
    "        #     pbar.update(1)\n",
    "        \n",
    "        # except BadRequestError as e:\n",
    "        #     print('*************************Bad Request**************')\n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "        # except ValueError as e:\n",
    "        #     print(f'******************Value Error {i}****************************')\n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Chevrolet Corvette'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when did rené heitmann start as head coach of boldklubben frem?',\n",
       " 'how long was the head coach of Boldklubben Frem?',\n",
       " 'when did rené heitmann stop being head coach of boldklubben frem?']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thought: The SQL query filters the positions that start with 1, 2, 3, 4, or 5. Based on the extra information provided, Salvatore Bettiol finished in the top five positions a total of 4 times.\\nAnswer: 4']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Based on the Table below, your task is to accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
      "Approach this task as follows:\n",
      "Read the query and extra information thoroughly and list every possible link from query term to column in the Table. \n",
      "Then based on the column linking, output all useful columns at last. Make sure all columns in the linking step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>Hoot Kloot</caption>\n",
      "<thead>\n",
      "<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1  </td><td>\"Kloot's Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>6  </td><td>\"Mesa Trouble\"       </td><td>Sid Marcus </td><td>1974       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about the Hoot Kloot animated series, including the episode number, title, director, and release year. \n",
      "1. Number: The episode number in the series \n",
      "2. Title: The title of the episode \n",
      "3. Directed_by_: The director of the episode \n",
      "4. Released_: The release year of the episode\n",
      "\n",
      "Query: what was the last title that sid marcus directed?\n",
      "Column linking: the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\n",
      "Columns: Released_, Number, Title, Directed_by_\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>1943–44 Chicago Black Hawks season</caption>\n",
      "<thead>\n",
      "<tr><th>  num</th><th>       Date</th><th>            Visitor</th><th>  Score</th><th>               Home</th><th>  Record</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>14   </td><td>December 5 </td><td>New York Rangers   </td><td>6–7    </td><td>Chicago Black Hawks</td><td>8–6–0   </td></tr>\n",
      "<tr><td>40   </td><td>February 26</td><td>Chicago Black Hawks</td><td>3–2    </td><td>Toronto Maple Leafs</td><td>18–18–4 </td></tr>\n",
      "<tr><td>31   </td><td>January 29 </td><td>Chicago Black Hawks</td><td>4–3    </td><td>Toronto Maple Leafs</td><td>14–16–1 </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about the 1943-44 Chicago Black Hawks season, including the date, visitor, score, home team, record, and points for each game. \n",
      "1. num: The game number in the season \n",
      "2. Date: The date of the game\n",
      "3. Vistor: The visiting team\n",
      "4. Score: The final score, with the visitor score listed first\n",
      "5. Home: The home team\n",
      "6. Record: The team win-loss-overtime loss record at the time of the game\n",
      "\n",
      "Query: what was the difference in score in the december 19th win?\n",
      "Column linking: difference in score -> Score, december 19th -> Date\n",
      "Columns: Date, Score\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<caption>Boldklubben Frem</caption>\n",
      "<thead>\n",
      "<tr><th>                   Name</th><th>  Nationality</th><th>      c_From</th><th>       To</th><th>                     Honours</th><th>                         Comments</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>René Heitmann          </td><td>Denmark      </td><td>17 July 2010</td><td>2010-7-27</td><td>                            </td><td>Never coached the team in a match</td></tr>\n",
      "<tr><td>John 'Tune' Kristiansen</td><td>Denmark      </td><td>1996        </td><td>1998-5-4 </td><td>Won promotion to second tier</td><td>                                 </td></tr>\n",
      "<tr><td>John 'Tune' Kristiansen</td><td>Denmark      </td><td>18 June 2012</td><td>2012-6-23</td><td>                            </td><td>Caretaker for one league match   </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about players in Boldklubben Frem, including their names, nationality, start and end dates with the club, any honours they received, and any additional comments.\n",
      "1. Name: The name of the player\n",
      "2. Nationality: The nationality of the player\n",
      "3. From: The date when the player joined the club\n",
      "4. To: The date when the player left the club\n",
      "5. Honours: Any honours or achievements received by the player while at the club\n",
      "6. Comments: Any additional comments or information about the player's time at the club\n",
      "\n",
      "Query: when did rené heitmann start as head coach of boldklubben frem?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOur ultimate goal is to answer the query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table.  Based on the augmentation information, carefully analyze the query and write an SQLITE3 SELECT SQL statement using table DF that completes the query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>Boldklubben Frem</caption>\n",
      "<thead>\n",
      "<tr><th>  row_number</th><th>                   Name</th><th>      c_From</th><th>                         Comments</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>5           </td><td>René Heitmann          </td><td>17 July 2010</td><td>Never coached the team in a match</td></tr>\n",
      "<tr><td>11          </td><td>John 'Tune' Kristiansen</td><td>1996        </td><td>                                 </td></tr>\n",
      "<tr><td>2           </td><td>John 'Tune' Kristiansen</td><td>18 June 2012</td><td>Caretaker for one league match   </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about players in Boldklubben Frem, including their names, nationality, start and end dates with the club, any honours they received, and any additional comments.\n",
      " Column information:Name:Contains the full name of the player (Values like Henrik Jensen, John 'Tune' Kristiansen, Peer F. Hansen...)\n",
      "Comments:Contains any additional comments or information about the player's time at the club (Values like Caretaker for one league match, Originally had contract until summer 2012, Never coached the team in a match...)\n",
      "row_number: row index in the table\n",
      "\n",
      "Query: when did rené heitmann start as head coach of boldklubben frem?\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering and answer the query using the final sub-table. \n",
      "SQL Excuted: \n",
      "```SELECT c_From\n",
      "FROM DF\n",
      "WHERE Name = 'René Heitmann'```\n",
      "Sub-table: \n",
      "<table>\n",
      "<thead>\n",
      "<tr><th>      c_From</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>17 July 2010</td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: when did rené heitmann start as head coach of boldklubben frem?\n",
      "Please provide a clear, complete statement in response to the query. If you cannot answer the query based on the sub-table, just say 'Cannot get answer from sub-table'.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Based on the sub-table provided, René Heitmann started as head coach of Boldklubben Frem on 17 July 2010.',\n",
       " 1892)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_B('when did rené heitmann start as head coach of boldklubben frem?', sample, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter.all_data.to_csv('./result/case616.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the total number of robots in the middle east?',\n",
       " 'what is the total number of robots in the Middle East?',\n",
       " 'what are the robots in the middle east?']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thought: The BBC Three weekly ranking for episode 9 was 6, which is higher than the ranking for episode 8, which was 5. Therefore, episode 9 had a better BBC Three weekly ranking than episode 8.\\nAnswer: episode 9']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c302a1ed0ff43949968405e40497a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|                                                                                             …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2901\n",
      "process 3012\n",
      "process 3516\n",
      "process 3591\n",
      "process 3710\n",
      "process 3745\n",
      "process 4145\n",
      "process 4213\n",
      "process 4341\n",
      "process 4342\n",
      "process 4343\n",
      "process 4344\n"
     ]
    }
   ],
   "source": [
    "##### add residual \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "# from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError, RateLimitError\n",
    "from tqdm.notebook import tqdm\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.tech/v1\",\n",
    "                       openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.3)\n",
    "save_path = f\"../result/final_answer/wikitable_06-06_08-27-00.csv\"\n",
    "sample_k = 3\n",
    "data = pd.read_csv(save_path)\n",
    "\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 0\n",
    "with tqdm(total=len(table_loader.dataset), desc=f\"Processing\",ncols=150) as pbar:\n",
    "    while i < len(table_loader.dataset):\n",
    "        if table_loader.dataset[i]['id'] in list(data['ids']):\n",
    "            i += 1\n",
    "        else:\n",
    "            try:\n",
    "                sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "                all_tokens = 0\n",
    "                all_queries = []\n",
    "                formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "                sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "                with get_openai_callback() as cb:\n",
    "                    llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    if batch_pred[0]['text'].strip() != sample['query']:\n",
    "                        all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "                    # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    # all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "                    all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "                    # print(all_queries)\n",
    "                all_tokens += cb.total_tokens\n",
    "                all_queries = list(set(all_queries))\n",
    "                args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "                # print(args_list)\n",
    "                ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "                results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "                all_tokens += sum([res[1] for res in ans_from_B])\n",
    "                #With answer\n",
    "                # results= []\n",
    "                with get_openai_callback() as cb:\n",
    "                    imp_input = scene_A(sample['query'], sample, sample_k, False)\n",
    "                    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "                # print(batch_pred[0])\n",
    "                all_tokens += cb.total_tokens\n",
    "                # print('ALL TOKENS', all_tokens)\n",
    "                ids.append(sample['id'])\n",
    "                labels.append(sample['query'])\n",
    "                outputs.append(batch_pred[0]['text'])\n",
    "                tokens.append(all_tokens)\n",
    "                extra_quries.append(';'.join(all_queries))\n",
    "                i += 1\n",
    "                pbar.update(1)\n",
    "                print(f'process {i}')\n",
    "            except RateLimitError as e:\n",
    "                print('*************************Rate limit**************')\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2900"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_extra_info(summary_aug, column_aug, composition_aug, columns):\n",
    "    col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "    items, crackets = parse_output(composition_aug, pattern = r'\\d. (.+?): (.+)')\n",
    "    assert len(items) == len(col_names)\n",
    "    extra_col_info = []\n",
    "    for i_c in range(len(col_names)):\n",
    "        if col_names[i_c] in columns:\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]} {crackets[i_c]}')\n",
    "            \n",
    "    extra_col_info.append('row_number: row number in the original table')\n",
    "    return summary_aug + '\\n'.join(extra_col_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
