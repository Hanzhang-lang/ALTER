{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 5.24早修改table format 空格\\xa\n",
    "- 5.24 下午修改str_normalize \n",
    "- 5.24 晚 72需要复查\n",
    "- 5.25 早list query strip() \n",
    "- 5.27 修改total，尝试disambiguous/  改成PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import parse_specific_composition, add_row_number, parse_specific_composition_zh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sqlalchemy import create_engine\n",
    "from executor import SQLManager\n",
    "import sqlparse\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "            model_name='BAAI/bge-large-en',\n",
    "            model_kwargs={'device': 'cuda:2', 'trust_remote_code': True},\n",
    "            encode_kwargs={'normalize_embeddings': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "                  \"what was the time difference between the first place finisher and the eighth place finisher?\",\n",
    "                  \"other than william stuart price, which other businessman was born in tulsa?\",\n",
    "                  \"which canadian city had the most passengers traveling from manzanillo international airport in 2013?\"\n",
    "                # \"what is the next most populous district after haridwar?\",(70)\n",
    "                  ]\n",
    "new_query_examples = [\n",
    "                      \"what was the time for the first place finisher?; what was the time for the eighth place finisher?\",\n",
    "                      \"was william stuart price born in tulsa?; who was born in tulsa?\",\n",
    "                      \"how many passengers do each airline from canadian city have?; which canadian city had the most passengers?\"\n",
    "                    # \"what are the districts after haridwar?; what is the next most populous district after haridwar?\",\n",
    "                    #   \"When did polona hercog partner with alberta brianti?; When did polona hercog partner with stephanie vogt?\",\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 11, 86, 70, 42]\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True, embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_PIPE(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub queries. Based on the table, decompose original query into at most 2 complete sub queries which can solve original query. Output new query directly.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "# model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.7).bind(logprobs=True)\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "engine = create_engine('sqlite:////media/disk1/chatgpt/zh/tabular_data/db/sqlite/wiki_query.db', echo=False)\n",
    "manager = SQLManager(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name=task_name, split='test', use_sample=False, small_test=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [5, 11, 46]\n",
    "num_k = 3\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True,embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_PIPE(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\"was the Sandia Peak Tramway before or after the 3S Aerial Tramway in terms of Year_of_inauguration?\",\n",
    "                      \"other than William Stuart Price, which other businessman's was in Tulsa in terms of Hometown?\",\n",
    "                      \"How many players are G\\\\nF in terms of Position?\"]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "disambiguous_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    # prefix=\"\"\"Based on the given table, your task is to rewrite the query to resolve ambiguity and ensure the question is consistent with the table. \n",
    "    # This requires pinpointing elements of the question to table contents and rewriting the question to ensure a consistent, clear interpretation. \"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [11, 182]\n",
    "num_k = 2\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True,embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_PIPE(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which business man was born in tulsa?\",\n",
    "    \"what is the network owned by national polytechnic institute?\"\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Based on the table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_answer(k: int=1):\n",
    "    sqls = [\"SELECT MAX(winners_c_from_previous_round) FROM DF;\"\n",
    "            ]\n",
    "    thoughts = [\"Based on the the SQL query provided, The sub-table shows that the highest number of winner from a previous round was 54.\"]\n",
    "    tables = [\"\"\"<table>\n",
    "<thead>\n",
    "<tr><th>  MAX(winners_c_from_previous_round)</th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>54                             </td></tr>\n",
    "</tbody>\n",
    "</table>\"\"\"]\n",
    "    tables_pipe = [\"\"\"/*\n",
    "table caption : turkish cup\n",
    "col : MAX(winners_c_from_previous_round)\n",
    "row 1: 54\n",
    "*/\"\"\"]\n",
    "    claims = [\"what is the highest number of winner from a previous round?\"]\n",
    "    # inds from test split\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], template=\n",
    "    \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "\n",
    "Query: {claim}\n",
    "Thought: {thought}\n",
    "Answer: {output}\n",
    "    \"\"\")\n",
    "    examples_dict = dict(zip([\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], [sqls[0], tables_pipe[0], claims[0], thoughts[0], '54']))\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=[examples_dict],\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\"\"\"Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
    "You should output in the following format:\n",
    "Thought: your step by step thought\n",
    "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "Below is an example.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\"\"\",\n",
    "        input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    ")\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "\n",
    "# def get_k_shot_with_answer(k: int=1):\n",
    "#     sqls = [\"SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';\"\n",
    "#             ]\n",
    "#     thoughts = [\"Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \"]\n",
    "#     tables = [\"<table>\\n<caption>1972 isle of man tt</caption>\\n<thead>\\n<tr><th>  MIN(points)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>3            </td></tr>\\n</tbody>\\n</table>\"]\n",
    "#     claims = [\"was 2 be the fewest point that roger dutton / tony wright receive?\"]\n",
    "#     # inds from test split\n",
    "#     examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], template=\n",
    "#     \"\"\"\n",
    "# SQL Excuted: \n",
    "# ```{SQL}```\n",
    "# Sub-table: {table}\n",
    "\n",
    "# Query: {claim}\n",
    "# Thought: {thought}\n",
    "# Answer: {output}\n",
    "#     \"\"\")\n",
    "#     examples_dict = dict(zip([\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], [sqls[0], tables[0], claims[0], thoughts[0], '3']))\n",
    "#     prompt_template = FewShotPromptTemplate(\n",
    "#         examples=[examples_dict],\n",
    "#         example_prompt=examples_prompt,\n",
    "#         prefix=\"\"\"Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
    "# You should output in the following format:\n",
    "# Thought: your step by step thought\n",
    "# Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "# Below is an example.\"\"\",\n",
    "#         suffix=\n",
    "#         \"\"\"\n",
    "# SQL Excuted: \n",
    "# ```{SQL}```\n",
    "# Sub-table: {table}\n",
    "# Extra information:\n",
    "# {information}\n",
    "\n",
    "# Query: {query}\"\"\",\n",
    "#         input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    "# )\n",
    "#     return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_aug(k: int=2):\n",
    "    table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "    examples_dict = []\n",
    "    # examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>',\n",
    "    #                                     \"claim\": table_loader.dataset[95]['question'],\n",
    "    #                                     \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "    #                                     \"output\": \"Title, Released_, Number, Directed_by_\"}])\n",
    "    examples_dict.extend([{\"table\": \"\"\"/*\n",
    "table caption : Hoot Kloot\n",
    "col : Number | Title | Directed_by_ | Released_\n",
    "row 1 : 1 | \"Kloot's Kounty\" | Hawley Pratt | 1973\n",
    "row 2 : 2 | \"Apache on the County Seat\" | Hawley Pratt | 1973\n",
    "row 6 : 6 | \"Stirrups and Hiccups\" | Gerry Chiniquy | 1973\n",
    "*/\"\"\",\n",
    "                                        \"claim\": table_loader.dataset[95]['question'],\n",
    "                                        \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\",\n",
    "                                        \"output\": \"Title, Released_, Number, Directed_by_\"}])\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "    \"\"\"\n",
    "    Table: {table}\n",
    "    Query: {claim}\n",
    "    Column linking: {linking}\n",
    "    Columns: {output}\"\"\")\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples_dict,\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\n",
    "        \"\"\"\n",
    "    Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
    "    Approach this task as follows:\n",
    "    Read the query thoroughly and list every possible link from query term to column in the Table. \n",
    "    Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "    # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "    # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "    # Here are some examples:\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "    Table: {table}\n",
    "    Extra information: {aug}\n",
    "    \n",
    "    Query: {claim}\"\"\",\n",
    "        input_variables=[\"table\", \"claim\", \"aug\"],\n",
    ")\n",
    "    return prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "# from utils import parse_output\n",
    "# table_loader = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "# summary_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "# schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "# composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "\n",
    "\n",
    "# sample = table_loader.normalize_table(table_loader.dataset[110])\n",
    "\n",
    "# # summary_aug, column_aug = summary_information.loc[sample['table']['id']]['summary'], summary_information.loc[sample['table']['id']]['column_description'] \n",
    "# # col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "# # extra_col_info = []\n",
    "# # for i_c in range(len(col_names)):\n",
    "# #     extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "# formatter = TableFormat(format='none', data=sample)\n",
    "\n",
    "\n",
    "\n",
    "# llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=True)\n",
    "# batch_pred = llm_chain.batch([{\n",
    "#     \"claim\": sample['query'],\n",
    "#     'aug':  '',\n",
    "#     # \"query\": \"how many of the seasons games were played in the gold coast convention centre?\",\n",
    "#                             \"table\": TableFormat.format_PIPE(data= formatter.get_sample_data(sample_type='random',k=5, query=sample['query'],),table_caption=sample['table']['caption'])}],)\n",
    "# print(batch_pred[0]['text'])\n",
    "#     #                             \"table\": \"\"\"table caption : 2008 - 09 nbl season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "def scene_A(query, sample, k =3, verbose=True):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        \n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_PIPE(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        if verbose:\n",
    "            print(stage_1_batch_pred)\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        # columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        \n",
    "        try: \n",
    "            # formatter.all_data = formatter.all_data.loc[:, columns]\n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(pd.unique(formatter.all_data[col].astype(str))))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(pd.unique(formatter.all_data[col][:3].astype(str))))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        extra_information.append('row_number: row number in the original table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data = sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\nColumn information:\\n' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "        if verbose:\n",
    "            print(stage_2_batch_pred)\n",
    "    # stage 3: SQL Excution\n",
    "    try: \n",
    "        execute_data = manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "    except:\n",
    "        execute_data = formatter.all_data\n",
    "        stage_2_batch_pred = 'SELECT * from DF;'\n",
    "    if len(execute_data) == 0:\n",
    "        return query, stage_2_batch_pred, 'No data from database', cb.total_tokens\n",
    "    return query, stage_2_batch_pred, TableFormat.format_PIPE(data=execute_data), cb.total_tokens\n",
    "    # return query, stage_2_batch_pred, execute_data, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)\n",
    "\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整extrainformation的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering and answer the query using the final sub-table. \n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: \n",
    "{table}\n",
    "Query: {claim}\n",
    "Please provide a clear, complete statement in response to the query. If you cannot answer the query based on the sub-table, just say 'Cannot get answer from sub-table'.\n",
    "\"\"\" )\n",
    "def scene_B(query, sample, k=3, verbose=False):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    \n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    if k == 0:\n",
    "        sample_data = formatter.get_sample_data(sample_type='head', k=k)\n",
    "    else:\n",
    "        sample_data = formatter.get_sample_data(sample_type='embedding', query=query, k=k)\n",
    "    # get columns\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_aug(), verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_PIPE(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        try: \n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            sample_data = add_row_number(sample_data)\n",
    "        extra_information = []\n",
    "        tuples = parse_specific_composition_zh(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        for col, com in tuples:\n",
    "            if len(pd.unique(formatter.all_data[col])) < 6:\n",
    "                com += f' (Values like {\", \".join(list(pd.unique(formatter.all_data[col].astype(str))))})'\n",
    "                extra_information.append(col + ':' + com)\n",
    "            else:\n",
    "                com += f' (Values like {\", \".join(list(pd.unique(formatter.all_data[col][:3].astype(str))))}...)'\n",
    "                extra_information.append(col + ':' + com)\n",
    "        #  sample augmentation\n",
    "        # extra_information = (parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        extra_information.append('row_number: row number in the table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_PIPE(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "    \n",
    "        \n",
    "        # stage 3: SQL Excution\n",
    "        try: \n",
    "            execute_data= manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "        except:\n",
    "            execute_data = formatter.all_data\n",
    "            stage_2_batch_pred = 'SELECT * from DF;'\n",
    "        llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=verbose)\n",
    "        response = llm_chain.batch([dict({'table': TableFormat.format_PIPE(execute_data),\n",
    "                                                'claim': query,\n",
    "                                                'SQL':  stage_2_batch_pred\n",
    "                                                })], return_only_outputs=True)[0]['text']\n",
    "    # print(\"total_tokens:\", cb.total_tokens)\n",
    "    return response, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2b219db0d2984f9dae28b651ab8ab3d9\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://smsh.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    temperature=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Based on the Table below, your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the Table.\n",
      "    Approach this task as follows:\n",
      "    Read the query thoroughly and list every possible link from query term to column in the Table. \n",
      "    Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "    Table: /*\n",
      "table caption : Hoot Kloot\n",
      "col : Number | Title | Directed_by_ | Released_\n",
      "row 1 : 1 | \"Kloot's Kounty\" | Hawley Pratt | 1973\n",
      "row 2 : 2 | \"Apache on the County Seat\" | Hawley Pratt | 1973\n",
      "row 6 : 6 | \"Stirrups and Hiccups\" | Gerry Chiniquy | 1973\n",
      "*/\n",
      "    Query: what was the last title that sid marcus directed?\n",
      "    Column linking: the last title -> Released_, the last title-> Number, title -> Title, sid marcus -> Directed_by_\n",
      "    Columns: Title, Released_, Number, Directed_by_\n",
      "\n",
      "\n",
      "    Table: /*\n",
      "table caption : 2001 St. Louis Rams season\n",
      "col : Week | Date | Opponent | Result | Record | TV_Time | Attendance\n",
      "row : 13 | 2001-12-9 | San Francisco 49ers | W 27-14 | 10-2 | FOX 12:00pm | 66218\n",
      "row : 1 | 2001-9-9 | at Philadelphia Eagles | W 20-17 (OT) | 1-0 | FOX 3:15pm | 66243\n",
      "row : 2 | 2001-9-23 | at San Francisco 49ers | W 30-26 | 2-0 | FOX 3:15pm | 67536\n",
      "*/\n",
      "\n",
      "    Extra information: This table shows the 2001 St. Louis Rams season with information on the week, date, opponent, result, record, TV time, and attendance for select games.1. Week: The week number of the game\n",
      "2. Date: The date of the game\n",
      "3. Opponent: The opposing team\n",
      "4. Result: The outcome of the game\n",
      "5. Record: The team's win-loss record after the game\n",
      "6. TV_Time: The television broadcast time of the game\n",
      "7. Attendance: The number of spectators present at the game\n",
      "    \n",
      "    Query: what was the rams' largest margin of victory during the season?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "    Column linking: rams' largest margin of victory -> Result, rams' largest margin of victory -> Opponent\n",
      "    Columns: Result, Opponent\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOur ultimate goal is to answer query based on the original table. Now we have a sub-table with rows randomly sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>2001 St. Louis Rams season</caption>\n",
      "<thead>\n",
      "<tr><th>  row_number</th><th>      Result</th><th>              Opponent</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>13          </td><td>W 27-14     </td><td>San Francisco 49ers   </td></tr>\n",
      "<tr><td>1           </td><td>W 20-17 (OT)</td><td>at Philadelphia Eagles</td></tr>\n",
      "<tr><td>2           </td><td>W 30-26     </td><td>at San Francisco 49ers</td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: This table shows the 2001 St. Louis Rams season with information on the week, date, opponent, result, record, TV time, and attendance for select games.\n",
      "Column information:\n",
      "Opponent:Names of the opposing teams (Values like at Philadelphia Eagles, at San Francisco 49ers, Miami Dolphins...)\n",
      "Result:Format of W/L followed by the score, sometimes with additional information like (OT) for overtime (Values like W 20-17 (OT), W 30-26, W 42-10...)\n",
      "row_number: row number in the original table\n",
      "\n",
      "Query: what was the rams' largest margin of victory during the season?\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "SELECT MAX(CAST(SUBSTR(Result, 3, INSTR(Result, '-') - 3) AS INTEGER) - CAST(SUBSTR(Result, INSTR(Result, '-') + 1, INSTR(Result, ' ') - INSTR(Result, '-') - 1) AS INTEGER) AS largest_margin_of_victory\n",
      "FROM DF\n",
      "WHERE Result LIKE 'W%';\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the question given in the query.\n",
      "You should output in the following format:\n",
      "Thought: your step by step thought\n",
      "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
      "Below is an example.\n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT MAX(winners_c_from_previous_round) FROM DF;```\n",
      "Sub-table: /*\n",
      "table caption : turkish cup\n",
      "col : MAX(winners_c_from_previous_round)\n",
      "row 1: 54\n",
      "*/\n",
      "\n",
      "Query: what is the highest number of winner from a previous round?\n",
      "Thought: Based on the the SQL query provided, The sub-table shows that the highest number of winner from a previous round was 54.\n",
      "Answer: 54\n",
      "    \n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT * from DF;```\n",
      "Sub-table: /*\n",
      "col : Week | Date | Opponent | Result | Record | TV_Time | Attendance\n",
      "row : 1 | 2001-9-9 | at Philadelphia Eagles | W 20-17 (OT) | 1-0 | FOX 3:15pm | 66243\n",
      "row : 2 | 2001-9-23 | at San Francisco 49ers | W 30-26 | 2-0 | FOX 3:15pm | 67536\n",
      "row : 3 | 2001-9-30 | Miami Dolphins | W 42-10 | 3-0 | CBS 12:00pm | 66046\n",
      "row : 4 | 2001-10-8 | at Detroit Lions | W 35-0 | 4-0 | ABC 8:00pm | 77765\n",
      "row : 5 | 2001-10-14 | New York Giants | W 15-14 | 5-0 | FOX 12:00pm | 65992\n",
      "row : 6 | 2001-10-21 | at New York Jets | W 34-14 | 6-0 | FOX 12:00pm | 78766\n",
      "row : 7 | 2001-10-28 | New Orleans Saints | L 34-31 | 6-1 | FOX 12:00pm | 66189\n",
      "row : 8 | Bye | Bye | Bye | Bye | Bye | Bye\n",
      "row : 9 | 2001-11-11 | Carolina Panthers | W 48-14 | 7-1 | FOX 12:00pm | 66069\n",
      "row : 10 | 2001-11-18 | at New England Patriots | W 24-17 | 8-1 | ESPN 7:30pm | 60292\n",
      "row : 11 | 2001-11-26 | Tampa Bay Buccaneers | L 24-17 | 8-2 | ABC 8:00pm | 66198\n",
      "row : 12 | 2001-12-2 | at Atlanta Falcons | W 35-6 | 9-2 | FOX 3:15pm | 60787\n",
      "row : 13 | 2001-12-9 | San Francisco 49ers | W 27-14 | 10-2 | FOX 12:00pm | 66218\n",
      "row : 14 | 2001-12-17 | at New Orleans Saints | W 34-21 | 11-2 | ABC 8:00pm | 70332\n",
      "row : 15 | 2001-12-23 | at Carolina Panthers | W 38-32 | 12-2 | FOX 12:00pm | 72438\n",
      "row : 16 | 2001-12-30 | Indianapolis Colts | W 42-17 | 13-2 | CBS 12:00pm | 66084\n",
      "row : 17 | 2002-1-6 | Atlanta Falcons | W 31-13 | 14-2 | FOX 3:15pm | 66033\n",
      "*/\n",
      "\n",
      "Extra information:\n",
      "\n",
      "\n",
      "Query: what was the rams' largest margin of victory during the season?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError\n",
    "from tqdm.notebook import tqdm\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.01)\n",
    "# save_path = f\"../result/answer/wikitable_PIPE_{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.csv\"\n",
    "save_path = f\"../result/answer/wikitable_PIPE_05-28_01-34-01.csv\"\n",
    "\n",
    "# reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "# template=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "template = \"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Complete task with the help of extra information below.\n",
    "\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table:\n",
    "{table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\n",
    "Think step by step and answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "\"\"\" )\n",
    "sample_k = 3\n",
    "# Task: answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# Task: verify whether the provided claim/query is true or false, return 0 if it's false, or 1 if it's true. Please think step by step and return 0/1 at last.\n",
    "\n",
    "\n",
    "# muilti_answer_instruction = get_k_shot_with_answer()\n",
    "# for sample_n in range(3):\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 1142\n",
    "# with tqdm(total=len(table_loader.dataset) , desc=f\"Processing\",ncols=1500) as pbar:\n",
    "#     while i < len(table_loader.dataset):\n",
    "#         try:\n",
    "sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "all_tokens = 0\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "# with get_openai_callback() as cb:\n",
    "#     llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "#     batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "#     all_queries.append(batch_pred[0]['text'].strip())\n",
    "#     # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "#     # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "#     # all_queries.append(batch_pred[0]['text'].strip())\n",
    "#     llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "#     batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "#     all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "#     # print(all_queries)\n",
    "# all_tokens += cb.total_tokens\n",
    "# all_queries = list(set(all_queries))\n",
    "# args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "# # print(args_list)\n",
    "# ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "# results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "# all_tokens += sum([res[1] for res in ans_from_B])\n",
    "#With answer\n",
    "results= []\n",
    "with get_openai_callback() as cb:\n",
    "    imp_input = scene_A(sample['query'], sample, sample_k, True)\n",
    "    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=True)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "# print(batch_pred[0])\n",
    "all_tokens += cb.total_tokens\n",
    "# print('ALL TOKENS', all_tokens)\n",
    "ids.append(sample['id'])\n",
    "labels.append(sample['query'])\n",
    "outputs.append(batch_pred[0]['text'])\n",
    "tokens.append(all_tokens)\n",
    "extra_quries.append(';'.join(all_queries))\n",
    "        #     if (i + 1) % 10 == 0:\n",
    "        #             print(f'saving {i}')\n",
    "        #             save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "        #             outputs = []\n",
    "        #             labels = []\n",
    "        #             ids = []\n",
    "        #             tokens = []\n",
    "        #             extra_quries = []\n",
    "        #     i += 1\n",
    "        #     print(f' Process {i}')\n",
    "        #     pbar.update(1)\n",
    "        # except ValueError as e:\n",
    "        #     print(f'******************Value Error {i}****************************')\n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "        # except BadRequestError as e:\n",
    "        #     print('*************************Bad Request**************')\n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thought: Based on the sub-table provided, I need to look at the \"Result\" column to find the largest margin of victory for the Rams during the season. The largest margin of victory is indicated by the highest number in the \"Result\" column after the \"W\" (win) and before the \"-\" (score separator).\\n\\nAnswer: 35']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what were the results of each game?',\n",
       " 'what was the largest margin of victory for the Rams?',\n",
       " \"what was the rams' largest margin of victory during the season?\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The results of each game were as follows:\\n- W 20-17 (OT)\\n- W 30-26\\n- W 42-10\\n- W 35-0\\n- W 15-14\\n- W 34-14\\n- L 34-31\\n- Bye\\n- W 48-14\\n- W 24-17\\n- L 24-17\\n- W 35-6\\n- W 27-14\\n- W 34-21\\n- W 38-32\\n- W 42-17\\n- W 31-13',\n",
       "  1162),\n",
       " ('The largest margin of victory for the Rams was 35 points, achieved in their game against the Detroit Lions on October 8, 2001, with a final score of 35-0.',\n",
       "  1775),\n",
       " (\"The Rams' largest margin of victory during the season was 44 points.\",\n",
       "  1076)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_from_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552c37a4aea94d08832a259801e2d2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|                                                                                             …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 4343\n",
      "process 4344\n"
     ]
    }
   ],
   "source": [
    "##### add residual \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "# from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError, RateLimitError\n",
    "from tqdm.notebook import tqdm\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.tech/v1\",\n",
    "                       openai_api_key=\"sk-bLZSHx4pKfPRZkYyIyyvUHSEjrlqj5sh2QIsxOM23yJnyoGD\", temperature=0.01)\n",
    "save_path = f\"../result/answer/wikitable_PIPE_05-28_01-34-01.csv\"\n",
    "sample_k = 3\n",
    "data = pd.read_csv(save_path)\n",
    "\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "extra_quries = []\n",
    "i = 0\n",
    "with tqdm(total=len(table_loader.dataset), desc=f\"Processing\",ncols=150) as pbar:\n",
    "    while i < len(table_loader.dataset):\n",
    "        if table_loader.dataset[i]['id'] in list(data['ids']):\n",
    "            i += 1\n",
    "        else:\n",
    "            try:\n",
    "                sample = table_loader.normalize_table(\n",
    "                                    table_loader.dataset[i])\n",
    "                all_tokens = 0\n",
    "                all_queries = []\n",
    "                formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "                sample_data = formatter.get_sample_data(sample_type='random', k=sample_k, query=sample['query'])\n",
    "                with get_openai_callback() as cb:\n",
    "                    llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "                    all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    # llm_chain = LLMChain(llm=model, prompt=disambiguous_prompt_wiki, verbose=False)\n",
    "                    # batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "                    # all_queries.append(batch_pred[0]['text'].strip())\n",
    "                    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_PIPE(sample_data)}], return_only_outputs=True)\n",
    "                    all_queries.extend([q.strip() for q in batch_pred[0]['text'].split(';')])\n",
    "                    # print(all_queries)\n",
    "                all_tokens += cb.total_tokens\n",
    "                all_queries = list(set(all_queries))\n",
    "                args_list = [{\"query\": q, \"sample\": sample, \"k\": sample_k} for q in all_queries]\n",
    "                # print(args_list)\n",
    "                ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "                results = [res[0] for res in ans_from_B if 'Cannot get answer from sub-table' not in res[0] ]\n",
    "                all_tokens += sum([res[1] for res in ans_from_B])\n",
    "                #With answer\n",
    "                # results= []\n",
    "                with get_openai_callback() as cb:\n",
    "                    imp_input = scene_A(sample['query'], sample, sample_k, False)\n",
    "                    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=False)\n",
    "                    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "                # print(batch_pred[0])\n",
    "                all_tokens += cb.total_tokens\n",
    "                # print('ALL TOKENS', all_tokens)\n",
    "                ids.append(sample['id'])\n",
    "                labels.append(sample['query'])\n",
    "                outputs.append(batch_pred[0]['text'])\n",
    "                tokens.append(all_tokens)\n",
    "                extra_quries.append(';'.join(all_queries))\n",
    "                i += 1\n",
    "                print(f'process {i}')\n",
    "            except RateLimitError as e:\n",
    "                print('*************************Rate limit**************')\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv([outputs, labels, ids, tokens, extra_quries], ['preds', 'statements','ids', 'tokens', 'extra'], file_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_extra_info(summary_aug, column_aug, composition_aug, columns):\n",
    "    col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "    items, crackets = parse_output(composition_aug, pattern = r'\\d. (.+?): (.+)')\n",
    "    assert len(items) == len(col_names)\n",
    "    extra_col_info = []\n",
    "    for i_c in range(len(col_names)):\n",
    "        if col_names[i_c] in columns:\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]} {crackets[i_c]}')\n",
    "            \n",
    "    extra_col_info.append('row_number: row number in the original table')\n",
    "    return summary_aug + '\\n'.join(extra_col_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
