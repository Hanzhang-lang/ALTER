{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03aa6018",
   "metadata": {},
   "source": [
    "## Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1aebf6d-8a64-433c-84a0-d38e50c6f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into sqlite database\n",
    "from data_loader import TableLoader\n",
    "\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "511cb4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465bf4dc-f2af-4456-b693-961ed623fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "totto = load_dataset('./data_loader/totto_zh.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")\n",
    "tabfact = load_dataset('./data_loader/tabfact.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")\n",
    "sqa = load_dataset('./data_loader/sqa.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db1b61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1000/1000 [00:00<00:00, 4669.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset = table_loader.dataset.filter(lambda example: example['small_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a91cae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'table', 'statement', 'label', 'hardness', 'small_test'],\n",
       "    num_rows: 147\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d9351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99838a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 996,\n",
       " 'table': {'id': '2-16369528-1.html.csv',\n",
       "  'header': ['year',\n",
       "   'best teenage / young adult',\n",
       "   \"reader 's vote\",\n",
       "   'best non - fiction',\n",
       "   'lifetime achievement'],\n",
       "  'rows': [['1996', 'na', 'na', 'na', 'jon cleary'],\n",
       "   ['1997',\n",
       "    'na',\n",
       "    'na',\n",
       "    'how to write crime edited by marele day',\n",
       "    'alan yates (aka carter brown )'],\n",
       "   ['1998', 'na', 'na', 'na', 'na'],\n",
       "   ['1999', 'na', 'na', 'na', 'peter corris'],\n",
       "   ['2000', 'na', 'na', 'na', 'na'],\n",
       "   ['2001',\n",
       "    'na',\n",
       "    'bleeding hearts by lindy cameron',\n",
       "    'na',\n",
       "    'professor stephen knight'],\n",
       "   ['2002',\n",
       "    'blue murder by ken catran',\n",
       "    'apartment 255 by bunty avieson',\n",
       "    'na',\n",
       "    'patrick gallagher'],\n",
       "   ['2003', 'na', 'na', 'na', 'kerry greenwood'],\n",
       "   ['2004', 'na', 'na', 'na', 'bob bottom'],\n",
       "   ['2005', 'na', 'na', 'na', 'stuart coupe'],\n",
       "   ['2006', 'na', 'na', 'na', 'andrew rule and john silvester'],\n",
       "   ['2007', 'na', 'na', 'na', 'sandra harvey and lindsay simpson'],\n",
       "   ['2008', 'na', 'na', 'na', 'marele day'],\n",
       "   ['2009', 'na', 'na', 'na', 'shane maloney'],\n",
       "   ['2010', 'na', 'na', 'na', 'peter doyle'],\n",
       "   ['2011', 'na', 'na', 'na', 'na']],\n",
       "  'caption': 'ned kelly awards'},\n",
       " 'statement': 'after 2005 , the winner of the lifetime achievement award be andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle',\n",
       " 'label': 1,\n",
       " 'hardness': 'simple',\n",
       " 'small_test': True}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = table_loader.dataset[2]\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188aeba",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入 schema(table measurement) statistical(numerical) enum string(char) date\n",
    "#引入 term explanation（table comment(RAG)）\n",
    "#引入 column summarization\n",
    "#是否需要search engine\n",
    "#table size, statistical features, header hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5734d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema \n",
    "from data_loader import TableFormat\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.tech/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "# formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\"], template=\n",
    "\"\"\"\n",
    "Instruction: Given the following table, you will add Metadata about the columns in the table.\n",
    "Metadata includes:\n",
    "- Numerical: whether the column content is numeric type like int or float.\n",
    "- Char: whether the column content is a text or description.\n",
    "- Date: whether the column content is datetime.\n",
    "\n",
    "You need to output all the column names with metadata in angle brackets.\n",
    "Example: name<Char>, launched<Date>, count<Numerical>\n",
    "\n",
    "Table: {table}\n",
    "Output:\n",
    "\"\"\")\n",
    "# \n",
    "# output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "457207ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 1, 'prompt_tokens': 269, 'total_tokens': 270}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.response_metadata['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24ed8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarization\n",
    "pre_instruction_summary = PromptTemplate(input_variables=['table'], template=\n",
    "\"\"\"\n",
    "Instruction: Given the following table, you need to first summarize the contents of the table, then based on the summay, give a concluded description to each of the column.\n",
    "Table: {table}\n",
    "\n",
    "The output should use the following format: \n",
    "table summary: #summary for table contents\n",
    "column description: You need to output all the column names with description in angle brackets\n",
    "example: launched<The launched date for the competition> date<The date of the match>\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction_summary.format(table=formatter.format_html()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c92ad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table summary: The table shows the performance of a player in different tennis tournaments from 1986 to 1999.\n",
      "\n",
      "column description: \n",
      "tournament<The name of the tennis tournament>\n",
      "1986<The player's performance in the tournament in 1986>\n",
      "1988<The player's performance in the tournament in 1988>\n",
      "1989<The player's performance in the tournament in 1989>\n",
      "1990<The player's performance in the tournament in 1990>\n",
      "1991<The player's performance in the tournament in 1991>\n",
      "1992<The player's performance in the tournament in 1992>\n",
      "1993<The player's performance in the tournament in 1993>\n",
      "1994<The player's performance in the tournament in 1994>\n",
      "1995<The player's performance in the tournament in 1995>\n",
      "1996<The player's performance in the tournament in 1996>\n",
      "1997<The player's performance in the tournament in 1997>\n",
      "1998<The player's performance in the tournament in 1998>\n",
      "1999<The player's performance in the tournament in 1999>\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a1a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799366bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m table_loader\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m formatter \u001b[38;5;241m=\u001b[39m TableFormat(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43maug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_summary_aug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# batch_data = table_loader.dataset[:2]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print([formatter.load_data_from_dic({key: value[i] for key, value in batch_data.items()}).format_html() for i in range(len(batch_data.keys())) ])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print([formatter.load_data_from_dic({key: value[i] for key, value in table_loader.dataset[:2].items()}).format_html() for i in range(2)])\u001b[39;00m\n",
      "File \u001b[0;32m~/zh/tabular_data/data_loader/table_augmentation.py:61\u001b[0m, in \u001b[0;36mTableAug.batch_summary_aug\u001b[0;34m(self, formatter, batch_data, batch_size, output_token)\u001b[0m\n\u001b[1;32m     57\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     58\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mpre_instruction_summary, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# add             \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     batch_pred \u001b[38;5;241m=\u001b[39m llm_chain\u001b[38;5;241m.\u001b[39mbatch([formatter\u001b[38;5;241m.\u001b[39mload_data_from_dic(batch_data[i])\u001b[38;5;241m.\u001b[39mformat_html(batch_data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_pred)):\n\u001b[1;32m     64\u001b[0m     parts \u001b[38;5;241m=\u001b[39m batch_pred[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn description\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/zh/tabular_data/data_loader/table_augmentation.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     58\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mpre_instruction_summary, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# add             \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     batch_pred \u001b[38;5;241m=\u001b[39m llm_chain\u001b[38;5;241m.\u001b[39mbatch([formatter\u001b[38;5;241m.\u001b[39mload_data_from_dic(\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mformat_html(batch_data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_pred)):\n\u001b[1;32m     64\u001b[0m     parts \u001b[38;5;241m=\u001b[39m batch_pred[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn description\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#table_size\n",
    "def get_table_size():\n",
    "    return f'The table has {formatter.data.shape[0]} rows and {formatter.data.shape[1]} columns.'\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\", temperature=0.1)\n",
    "from data_loader import TableAug,TableFormat\n",
    "aug = TableAug(model)\n",
    "# aug.schema_aug(test_sample)\n",
    "test_sample = table_loader.dataset[0]\n",
    "formatter = TableFormat(format='none')\n",
    "output = aug.batch_summary_aug(formatter, table_loader.dataset[:2], batch_size=2, output_token=True)\n",
    "# batch_data = table_loader.dataset[:2]\n",
    "\n",
    "# print([formatter.load_data_from_dic({key: value[i] for key, value in batch_data.items()}).format_html() for i in range(len(batch_data.keys())) ])\n",
    "# print([formatter.load_data_from_dic({key: value[i] for key, value in table_loader.dataset[:2].items()}).format_html() for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d08d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'table summary: The table provides information about different wind farms including their names, scheduled dates, capacity in megawatts, number of turbines, types of turbines, and locations.\\n\\ncolumn description: \\nwind farm<The name of the wind farm>\\nscheduled<The scheduled date for the wind farm>\\ncapacity (mw)<The capacity of the wind farm in megawatts>\\nturbines<The number of turbines at the wind farm>\\ntype<The type of turbines used at the wind farm>\\nlocation<The location of the wind farm>'}\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a66183a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col :Name|Title|Date_c_from|Date_until|Russian_state|Austrian_state\n",
      "Row 1 :Lev Pavlovich Urusov|Ambassador|1905|1910|Russian Empire|Austria-Hungary\n",
      "Row 2 :Konstantin Konstantinovich Yurenev|Plenipotentiary|1 October 1927|24 January 1933|Soviet Union|Federal State of Austria\n",
      "Row 3 :Averky Borisovich Aristov|Ambassador Extraordinary and Plenipotentiary|20 September 1971|11 July 1973|Soviet Union|Republic of Austria\n"
     ]
    }
   ],
   "source": [
    "print(formatter.format_nl_sep())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98301793",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49a3eb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv/204-csv/925.tsv'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['table']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ffaeeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import parse_specific_composition, parse_output\n",
    "sample = table_loader.normalize_table(table_loader.dataset[505])\n",
    "formatter = TableFormat(format='none',data=sample)\n",
    "formatter.all_data\n",
    "row_string = []\n",
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "schema_information = pd.read_csv(f\"result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description']\n",
    "col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "extra_col_info = []\n",
    "for i_c in range(len(col_names)):\n",
    "    extra_col_info.append(f'{col_names[i_c]}: {col_infos[i_c]}')\n",
    "# extra_information = '\\n'.join(parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], formatter.all_data.columns))\n",
    "# for i in range(len(formatter.all_data.columns)):\n",
    "#     row_string.append(formatter.all_data.columns[i])\n",
    "# from langchain_text_splitters import CharacterTextSplitter\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1, chunk_overlap=0, separator='\\n\\n')\n",
    "# texts = text_splitter.split_text('\\n\\n'.join(row_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999286c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_base=\"https://api.chatanywhere.com.cn/v1\", openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b85eb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which team had the first pick this round?'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d9ce77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_texts(extra_col_info, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed509fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"include_metadata\": True, \"score_threshold\": 0.4})\n",
    "result = retriever.invoke(sample['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "94f2ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NHL_team', 'Pick_num', 'a']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.page_content.split(':')[0].strip() for r in result]  + ['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1ba0193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NHL_team</th>\n",
       "      <th>Pick_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winnipeg Jets</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hartford Whalers</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington Capitals</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toronto Maple Leafs</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pittsburgh Penguins</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Edmonton Oilers</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New York Rangers</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vancouver Canucks</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Quebec Nordiques</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chicago Black Hawks</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Minnesota North Stars</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philadelphia Flyers</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Los Angeles Kings</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Montreal Canadiens</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New York Islanders</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NHL_team Pick_num\n",
       "0           Winnipeg Jets      148\n",
       "1       Detroit Red Wings      149\n",
       "2        Colorado Rockies      150\n",
       "3        Hartford Whalers      151\n",
       "4     Washington Capitals      152\n",
       "5     Toronto Maple Leafs      153\n",
       "6     Pittsburgh Penguins      154\n",
       "7         Edmonton Oilers      155\n",
       "8        New York Rangers      156\n",
       "9       Vancouver Canucks      157\n",
       "10       Quebec Nordiques      158\n",
       "11    Chicago Black Hawks      159\n",
       "12  Minnesota North Stars      160\n",
       "13          Boston Bruins      161\n",
       "14         Calgary Flames      162\n",
       "15    Philadelphia Flyers      163\n",
       "16         Buffalo Sabres      164\n",
       "17      Los Angeles Kings      165\n",
       "18     Montreal Canadiens      166\n",
       "19        St. Louis Blues      167\n",
       "20     New York Islanders      168"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatter.all_data[[r.page_content.split(':')[0].strip() for r in result]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10112f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# Row (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rowinds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(pattern\u001b[38;5;241m.\u001b[39msearch(r\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "Cell \u001b[0;32mIn[100], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# Row (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rowinds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(\u001b[43mpattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'# Row (\\d+)')\n",
    "rowinds = [int(pattern.search(r.page_content).group(1)) for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "defcfe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>League</th>\n",
       "      <th>FA_Cup</th>\n",
       "      <th>League_Cup</th>\n",
       "      <th>JP_Trophy</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jamie Cureton</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guillem Bauza</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pat Baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OWN GOALS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name League FA_Cup League_Cup JP_Trophy Total\n",
       "8   Jamie Cureton     20      0          0         0    20\n",
       "5   Guillem Bauza      2      0          0         0     2\n",
       "7     Pat Baldwin      1      0          0         0     1\n",
       "11      OWN GOALS      0      0          0         0     0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatter.all_data.loc[rowinds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe409023",
   "metadata": {},
   "source": [
    "### Few Shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6daf1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Given the following table and claim, let's first summarize the contents of the rows and columns of the table, and then select relevent rows/columns in the given table that support or oppose the statement.\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  wind farm</th><th>  scheduled</th><th>  capacity (mw)</th><th>  turbines</th><th>              type</th><th>      location</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>codling    </td><td>unknown    </td><td>1100           </td><td>220       </td><td>unknown           </td><td>county wicklow</td></tr>\n",
      "<tr><td>carrowleagh</td><td>2012       </td><td>36.8           </td><td>16        </td><td>enercon e - 70 2.3</td><td>county cork   </td></tr>\n",
      "<tr><td>gortahile  </td><td>2010 autumn</td><td>20             </td><td>8         </td><td>nordex n90        </td><td>county laois  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: the scheduled date for the farm with 17 turbine be 2012\n",
      "Summary: The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.\n",
      "Subtable: Columns(wind farm, scheduled, turbines), Rows(12)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  kanji</th><th>             name</th><th>                     builder</th><th>     laid down</th><th>     launched</th><th>      completed</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>望月   </td><td>mochizuki dd - 33</td><td>uraga dock company , japan  </td><td>23 march 1926 </td><td>28 april 1927</td><td>31 october 1927</td></tr>\n",
      "<tr><td>三日月 </td><td>mikazuki dd - 32 </td><td>sasebo naval arsenal , japan</td><td>21 august 1925</td><td>12 july 1926 </td><td>5 may 1927     </td></tr>\n",
      "<tr><td>睦月   </td><td>mutsuki dd - 19  </td><td>sasebo naval arsenal , japan</td><td>21 may 1924   </td><td>23 july 1925 </td><td>25 march 1926  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: uraga dock company produce the most destroyer on the list , at 3\n",
      "Summary: The table provides information about different destroyers, including their kanji (Japanese characters), names, builders, dates when they were laid down, launched, and completed.\n",
      "Subtable: Columns(kanji, builder), Rows(ALL)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>               event name</th><th>  established</th><th>  category</th><th>  sub category</th><th>           main venue</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>the frye festival        </td><td>2000         </td><td>arts      </td><td>literary      </td><td>university of moncton</td></tr>\n",
      "<tr><td>world wine &amp; food expo   </td><td>1990         </td><td>arts      </td><td>food &amp; drink  </td><td>moncton coliseum     </td></tr>\n",
      "<tr><td>dieppe kite international</td><td>2001         </td><td>sporting  </td><td>kite flying   </td><td>dover park           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "summary_examples = ['The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.',\n",
    "                    \"The table provides information about different destroyers, including their kanji (Japanese characters), names, builders, dates when they were laid down, launched, and completed.\"]\n",
    "subtable_examples = ['Columns(wind farm, scheduled, turbines), Rows(12)',\n",
    "                    'Columns(kanji, builder), Rows(ALL)']\n",
    "inds = [0, 100]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"summary\", \"subtable\"], template=\n",
    "\"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "Summary: {summary}\n",
    "Subtable: {subtable}\"\"\")\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "num_k = 2\n",
    "# examples = [examples_prompt.format(**{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]]).format_html(),\n",
    "#                                     \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "#                                     \"summary\": summary_examples[i],\n",
    "#                                     \"subtable\": subtable_examples[i]}) for i in range(num_k)]\n",
    "\n",
    "examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_html(),\n",
    "                                    \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                    \"summary\": summary_examples[i],\n",
    "                                    \"subtable\": subtable_examples[i]} for i in range(num_k)]\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"Instruction: Given the following table and claim, let's first summarize the contents of the rows and columns of the table, and then select relevent rows/columns in the given table that support or oppose the statement.\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "    \"\"\",\n",
    "    input_variables=[\"table\", \"claim\"],\n",
    ")\n",
    "print(prompt.format(table=formatter.format_html(), claim=test_sample['statement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d826faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(2)', response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 931, 'total_tokens': 972}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29768c0b",
   "metadata": {},
   "source": [
    "### Few-shot for operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d644a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
      "Instruction: Given the following table and claim, you will output the operations corresponding to each column which can help us judging the truth or falsity of claim.\n",
      "Operations: DELETE(delete column unrelevant to the claim), KEEP(keep column relevant to the claim), GROUP BY(combine aggregate functions and group the result set by one or more columns), COUNT(returns the number of rows in column), AVG(returns the average value of a numeric column), SUM(returns the sum of a numeric column), MAX(returns the max value of a numeric column), MIN(returns the min value of a numeric column), ORDER BY(sort the value in ascending order)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  wind farm</th><th>  scheduled</th><th>  capacity (mw)</th><th>  turbines</th><th>              type</th><th>      location</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>codling    </td><td>unknown    </td><td>1100           </td><td>220       </td><td>unknown           </td><td>county wicklow</td></tr>\n",
      "<tr><td>carrowleagh</td><td>2012       </td><td>36.8           </td><td>16        </td><td>enercon e - 70 2.3</td><td>county cork   </td></tr>\n",
      "<tr><td>gortahile  </td><td>2010 autumn</td><td>20             </td><td>8         </td><td>nordex n90        </td><td>county laois  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: the scheduled date for the farm with 17 turbine be 2012\n",
      "Output: wind farm<DELETE>, scheduled<KEEP>, capacity (mw)<DELETE>, turbines<KEEP>, type<KEEP>, location<KEEP>\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>               event name</th><th>  established</th><th>  category</th><th>  sub category</th><th>           main venue</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>the frye festival        </td><td>2000         </td><td>arts      </td><td>literary      </td><td>university of moncton</td></tr>\n",
      "<tr><td>world wine &amp; food expo   </td><td>1990         </td><td>arts      </td><td>food &amp; drink  </td><td>moncton coliseum     </td></tr>\n",
      "<tr><td>dieppe kite international</td><td>2001         </td><td>sporting  </td><td>kite flying   </td><td>dover park           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "Output: event name<KEEP> established<KEEP> category<KEEP> sub category<DELETE> main venue<DELETE>\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>            date</th><th>        tournament</th><th>  surface</th><th>        partner</th><th>                                     opponents</th><th>                score</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>11 february 2008</td><td>mallorca 2 , spain</td><td>clay     </td><td>stephanie vogt </td><td>leticia costas - moreira maite gabarrus alonso</td><td>7 - 6 (7 - 2) , 6 - 3</td></tr>\n",
      "<tr><td>8 february 2010 </td><td>cali , colombia   </td><td>clay     </td><td>edina gallovits</td><td>estrella cabeza candella laura pous tió       </td><td>3 - 6 , 6 - 3 ,      </td></tr>\n",
      "<tr><td>28 april 2008   </td><td>makarska , croatia</td><td>clay     </td><td>stephanie vogt </td><td>tadeja majerić maša zec peškirič              </td><td>7 - 5 , 6 - 2        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Thought: your reason here\n",
      "Claim: polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "inds = [0,2]\n",
    "summary_examples = ['The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.',\n",
    "                    \"The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\"]\n",
    "Output_examples = ['wind farm<DELETE>, scheduled<KEEP>, capacity (mw)<DELETE>, turbines<KEEP>, type<KEEP>, location<KEEP>', 'event name<KEEP> established<KEEP> category<KEEP> sub category<DELETE> main venue<DELETE>']\n",
    "examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\"], template=\n",
    "\"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "Output: {output}\"\"\")\n",
    "num_k = 2\n",
    "examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_html(),\n",
    "                                    \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                    # \"summary\": summary_examples[i],\n",
    "                                    \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "Instruction: Given the following table and claim, you will output the operations corresponding to each column which can help us judging the truth or falsity of claim.\n",
    "Operations: DELETE(delete column unrelevant to the claim), KEEP(keep column relevant to the claim), GROUP BY(combine aggregate functions and group the result set by one or more columns), COUNT(returns the number of rows in column), AVG(returns the average value of a numeric column), SUM(returns the sum of a numeric column), MAX(returns the max value of a numeric column), MIN(returns the min value of a numeric column), ORDER BY(sort the value in ascending order)\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Table: {table}\n",
    "Thought: your reason here\n",
    "Claim: {claim}\n",
    "    \"\"\",\n",
    "    input_variables=[\"table\", \"claim\"],\n",
    ")\n",
    "print(prompt.format(table=formatter.format_html(), claim=test_sample['statement']))\n",
    "\n",
    "# output = model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03387f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Output: date<DELETE>, tournament<DELETE>, surface<DELETE>, partner<KEEP>, opponents<KEEP>, score<DELETE>' response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1037, 'total_tokens': 1063}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "output = model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "741b809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------+\n",
      "| date             | tournament                        | surface   | partner             | opponents                                      | score                 |\n",
      "|------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------|\n",
      "| 15 january 2007  | algiers 2 , algeria               | clay      | rushmi chakravarthi | barbora matusova anna savitskaya               | 6 - 2 , 6 - 0         |\n",
      "| 11 february 2008 | mallorca 2 , spain                | clay      | stephanie vogt      | leticia costas - moreira maite gabarrus alonso | 7 - 6 (7 - 2) , 6 - 3 |\n",
      "| 28 april 2008    | makarska , croatia                | clay      | stephanie vogt      | tadeja majerić maša zec peškirič               | 7 - 5 , 6 - 2         |\n",
      "| 8 september 2008 | sarajevo 2 , bosnia - herzegovina | clay      | alberta brianti     | çağla büyükakçay julia glushko                 | 6 - 4 , 7 - 5         |\n",
      "| 8 february 2010  | cali , colombia                   | clay      | edina gallovits     | estrella cabeza candella laura pous tió        | 3 - 6 , 6 - 3 ,       |\n",
      "+------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------+\n",
      "polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(formatter.format_psql())\n",
    "print(test_sample['statement'])\n",
    "print(test_sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e7d96",
   "metadata": {},
   "source": [
    "## Zero-shot learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fa5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uraga dock company produce the most destroyer on the list , at 3\n",
      "+----+---------+-------------------+--------------------------------+------------------+------------------+-------------------+\n",
      "|    | kanji   | name              | builder                        | laid down        | launched         | completed         |\n",
      "|----+---------+-------------------+--------------------------------+------------------+------------------+-------------------|\n",
      "|  0 | 睦月    | mutsuki dd - 19   | sasebo naval arsenal , japan   | 21 may 1924      | 23 july 1925     | 25 march 1926     |\n",
      "|  1 | 如月    | kisaragi dd - 21  | maizuru naval arsenal , japan  | 3 june 1924      | 5 june 1925      | 21 december 1925  |\n",
      "|  2 | 彌生    | yayoi dd - 23     | uraga dock company , japan     | 11 january 1924  | 11 july 1925     | 28 august 1926    |\n",
      "|  3 | 卯月    | uzuki dd - 25     | ishikawajima shipyards , japan | 11 january 1924  | 15 october 1925  | 14 september 1926 |\n",
      "|  4 | 皐月    | satsuki dd - 27   | fujinagata shipyards , japan   | 1 december 1924  | 25 march 1925    | 15 november 1925  |\n",
      "|  5 | 水無月  | minazuki dd - 28  | uraga dock company , japan     | 24 march 1924    | 25 march 1926    | 22 march 1927     |\n",
      "|  6 | 文月    | fumizuki dd - 29  | fujinagata shipyards , japan   | 20 october 1924  | 16 february 1926 | 3 july 1926       |\n",
      "|  7 | 長月    | nagatsuki dd - 30 | ishikawajima shipyards , japan | 16 april 1925    | 6 october 1926   | 30 april 1927     |\n",
      "|  8 | 菊月    | kikuzuki dd - 31  | maizuru naval arsenal , japan  | 15 june 1925     | 15 may 1926      | 20 november 1926  |\n",
      "|  9 | 三日月  | mikazuki dd - 32  | sasebo naval arsenal , japan   | 21 august 1925   | 12 july 1926     | 5 may 1927        |\n",
      "| 10 | 望月    | mochizuki dd - 33 | uraga dock company , japan     | 23 march 1926    | 28 april 1927    | 31 october 1927   |\n",
      "| 11 | 夕月    | yūzuki dd - 34    | fujinagata shipyards , japan   | 27 november 1926 | 4 march 1927     | 25 july 1927      |\n",
      "+----+---------+-------------------+--------------------------------+------------------+------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "formatter = TableFormat(format='none', data=test_sample)\n",
    "print(test_sample['statement'])\n",
    "print(tabulate(formatter.data, headers=formatter.data.columns, tablefmt='psql'))\n",
    "# print('Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e7abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=True, small_test=False)\n",
    "test_sample = table_loader.dataset[40]\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "pre_instruction_schema = PromptTemplate(input_variables=[\"table\"], template=\"\"\"\n",
    "Instruction: Given the following table, you need to summarize the contents of the table and tell what table is about.\n",
    "Table: {table}\n",
    "\n",
    "The output should use the following format: \n",
    "Summary: #summary for table contents\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction_schema.format(table=formatter.format_html(),))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0d8705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about different games played by a football team. It includes details like the week number, date of the game, opponent team, game result, game site, NFL recap, and the attendance for each game.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "650b53bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------------------+---------------+----------------+----------------+--------------------------+\n",
      "|    | event name                                 |   established | category       | sub category   | main venue               |\n",
      "|----+--------------------------------------------+---------------+----------------+----------------+--------------------------|\n",
      "|  0 | dieppe kite international                  |          2001 | sporting       | kite flying    | dover park               |\n",
      "|  1 | the frye festival                          |          2000 | arts           | literary       | university of moncton    |\n",
      "|  2 | hubcap comedy festival                     |          2000 | arts           | comedy         | various                  |\n",
      "|  3 | touchdown atlantic                         |          2010 | sporting       | football       | moncton stadium          |\n",
      "|  4 | atlantic nationals automotive extravaganza |          2000 | transportation | automotive     | moncton coliseum         |\n",
      "|  5 | world wine & food expo                     |          1990 | arts           | food & drink   | moncton coliseum         |\n",
      "|  6 | shediac lobster festival                   |          1950 | arts           | food & drink   | shediac festival grounds |\n",
      "|  7 | mosaã¯q multicultural festival             |          2004 | festival       | multicultural  | moncton city hall plaza  |\n",
      "+----+--------------------------------------------+---------------+----------------+----------------+--------------------------+\n",
      "Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\n",
      "Subtable: Columns(event name, established, category), Rows(touchdown atlantic)\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(formatter.data, headers=formatter.data.columns, tablefmt='psql'))\n",
    "print('Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(touchdown atlantic)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe7ca0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "touchdown atlantic , in the category of sporting , be establish in 2010\n"
     ]
    }
   ],
   "source": [
    "print(test_sample['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0fc7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "class Config:\n",
    "    def __init__(self) -> None:\n",
    "        self.openai_api_key = \"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\"\n",
    "        self.base_url = \"https://api.chatanywhere.cn/v1\"\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "\n",
    "class CallLLM:\n",
    "    \"\"\"Class for calling the OpenAI Language Model API.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.client = OpenAI(api_key=config.openai_api_key,\n",
    "                             base_url=config.base_url)\n",
    "        self.model = config.model\n",
    "        \n",
    "    @retry(wait=wait_random_exponential(min=30, max=60), stop=stop_after_attempt(1000))\n",
    "    def generate_text(self, prompt: List[str]) -> List[str]:\n",
    "        \"\"\"Generate text based on the prompt and instruction.\"\"\"\n",
    "\n",
    "            # batched examples, with xx completions per request\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "            temperature=0,\n",
    "            max_tokens=96,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "        )\n",
    "        # match completions to prompts by index\n",
    "        return response.choices[0].message.content.strip()\n",
    "configs = Config()  \n",
    "llm = CallLLM(config=configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "957617c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_text = \"\\n\".join(input)\n",
    "llm.generate_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0fee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_input(sample, instruction):\n",
    "    df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "    for i, line in enumerate(sample['table']['rows']):\n",
    "        df.loc[i] = line\n",
    "        \n",
    "    texts = [instruction,\n",
    "          \"The database table DF is shown as follows: \\n\",\n",
    "          df.to_html(),\n",
    "          \"query:\",\n",
    "          sample['statement'],\n",
    "           \"Output the code braced by '```'. \\n SQL:\"]\n",
    "    \n",
    "    label = sample['label']\n",
    "    return \"\\n\".join(texts), label \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec355fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtable_instruction = \"\"\"\n",
    "You are a SQLite expert. Given an input query, identify critical values and ranges of the table, then create a syntactically correct SQLite query to create a VIEW. To create a syntactically correct SQL view, the selected data within this view must be helpful in answering the question. During the construction of the view, if column names are confusing, rename the columns accordingly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604321c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nYou are a SQLite expert. Given an input query, identify critical values and ranges of the table, then create a syntactically correct SQLite query to create a VIEW. To create a syntactically correct SQL view, the selected data within this view must be helpful in answering the question. During the construction of the view, if column names are confusing, rename the columns accordingly.\\n\\nThe database table DF is shown as follows: \\n\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>date</th>\\n      <th>result</th>\\n      <th>score</th>\\n      <th>brazil scorers</th>\\n      <th>competition</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>may 11 , 1919</td>\\n      <td>w</td>\\n      <td>6 - 0</td>\\n      <td>friedenreich (3) , neco (2) , haroldo</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>may 18 , 1919</td>\\n      <td>w</td>\\n      <td>3 - 1</td>\\n      <td>heitor , amílcar , millon</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>may 26 , 1919</td>\\n      <td>d</td>\\n      <td>2 - 2</td>\\n      <td>neco (2)</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>may 29 , 1919</td>\\n      <td>w</td>\\n      <td>1 - 0</td>\\n      <td>friedenreich</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>june 1 , 1919</td>\\n      <td>d</td>\\n      <td>3 - 3</td>\\n      <td>haroldo , arlindo (2)</td>\\n      <td>taça roberto cherry</td>\\n    </tr>\\n  </tbody>\\n</table>\\nquery:\\nharoldo be mention as a brazil scorer for 2 different game\\nOutput the code braced by \\'```\\'. \\n SQL:', 1)\n"
     ]
    }
   ],
   "source": [
    "print(process_input(test_sample, subtable_instruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c3210",
   "metadata": {},
   "source": [
    "### Simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4aa5027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db')\n",
    "normalized = table_loader.normalize_table(test_sample)\n",
    "df = pd.DataFrame(columns=normalized['table']['header'])\n",
    "for ind, r in enumerate(normalized['table']['rows']):\n",
    "    df.loc[ind] = r\n",
    "# print(' '.join(normalized['table']['header']) + '*************')\n",
    "df.to_sql(name='ind100', con=engine, if_exists='replace', index=False)\n",
    "# table_loader.table2db(engine, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b84b796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "structured_data_markdown = tabulate(\n",
    "            df, headers=df.columns, tablefmt=\"pipe\", showindex=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea32bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|    | date          | result   | score   | brazil scorers                        | competition                 |\\n|---:|:--------------|:---------|:--------|:--------------------------------------|:----------------------------|\\n|  0 | may 11 , 1919 | w        | 6 - 0   | friedenreich (3) , neco (2) , haroldo | south american championship |\\n|  1 | may 18 , 1919 | w        | 3 - 1   | heitor , amílcar , millon             | south american championship |\\n|  2 | may 26 , 1919 | d        | 2 - 2   | neco (2)                              | south american championship |\\n|  3 | may 29 , 1919 | w        | 1 - 0   | friedenreich                          | south american championship |\\n|  4 | june 1 , 1919 | d        | 3 - 3   | haroldo , arlindo (2)                 | taça roberto cherry         |'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_data_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd90b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "model = ChatOpenAI(model_name=\"gpt-4\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a95af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_yes_no_and_map(text):\n",
    "    # Convert the input text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "\n",
    "    # Define regular expressions for yes/no matching\n",
    "    yes_patterns = [r'\\byes\\b', r'\\btrue\\b']\n",
    "    no_patterns = [r'\\bno\\b', r'\\bfalse\\b']\n",
    "\n",
    "    # Check for \"0\"\n",
    "    if text == \"0\":\n",
    "        return \"0\"\n",
    "\n",
    "    # Check for \"1\"\n",
    "    if text == \"1\":\n",
    "        return \"1\"\n",
    "\n",
    "    # Check for yes\n",
    "    for pattern in yes_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"1\"\n",
    "\n",
    "    # Check for no\n",
    "    for pattern in no_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"0\"\n",
    "\n",
    "    # Return 2 if neither yes nor no is found\n",
    "    return \"2\"\n",
    "\n",
    "def eval_fv_match(pred_list, gold_list):\n",
    "        acc = 0.0\n",
    "        for pred, gold in zip(pred_list, gold_list):\n",
    "            pred, gold = extract_yes_no_and_map(pred), extract_yes_no_and_map(gold)\n",
    "            if pred == gold:\n",
    "                acc += 1\n",
    "        acc = acc / len(pred_list)\n",
    "        return acc\n",
    "    \n",
    "def process_input(sample, instruction):\n",
    "    df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "    for i, line in enumerate(sample['table']['rows']):\n",
    "        df.loc[i] = line\n",
    "    texts = [instruction,\n",
    "          \"the table needed to be answered: \\n\",\n",
    "          df.to_html(),\n",
    "          \"query:\",\n",
    "          sample['statement'],\n",
    "           \"answer is: \\n\"]\n",
    "    \n",
    "    label = sample['label']\n",
    "    return \"\\n\".join(texts), label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "367a8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "#简易版本的pipeline\n",
    "instruction = \"Read the table below to verify whether the provided claim/query are true or false. Return 0 if it's false, or 1 if it's true. Only return 0 or 1 without any other information. \\n\"\n",
    "num_samples = 32\n",
    "batch_size = 32\n",
    "num_batches = num_samples // batch_size\n",
    "batches = []\n",
    "for batch_num in range(num_batches):\n",
    "    batch_prompt, ground = [], []\n",
    "    start = batch_num * batch_size\n",
    "    batch_data = tabfact['validation'][start: start+batch_size]\n",
    "    for i in range(batch_size):\n",
    "        prompt, label = process_input(sample=dict({key: value[i] for key, value in batch_data.items()}), instruction=instruction)\n",
    "        batch_prompt.append(prompt)\n",
    "        ground.append(str(label))\n",
    "        # call llm\n",
    "    batch_pred = list(map(lambda x: x.content, model.batch(batch_prompt)))\n",
    "        \n",
    "        #do evaluation\n",
    "    accuracy = eval_fv_match(batch_pred, ground)\n",
    "    print(accuracy)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e917216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "süper lig be the most common league to win a round in the turkish cup 1\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "there be new entry for the 1st 4 round of the turkish cup 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "2 be the lowest number of new entry conclude a round in the turkish cup 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "from round 1 to the final round , there be 4 club remain to complete the round 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "5 of the cultural interest fraternity and sorority be 2 sorority while 3 be a fraternity 0\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "|    | letters   | organization             | nickname         | founding date   | founding university              | type       |\n",
      "|----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------|\n",
      "|  0 | αεπ       | alpha epsilon pi 1       | aepi             | 1913 - 11 - 07  | new york university              | fraternity |\n",
      "|  1 | αεφ       | alpha epsilon phi 2      | aephi            | 1909 - 10 - 24  | barnard college                  | sorority   |\n",
      "|  2 | σαεπ      | sigma alpha epsilon pi 3 | sigma            | 1998 - 10 - 01  | university of california , davis | sorority   |\n",
      "|  3 | σαμ       | sigma alpha mu 1         | sammy            | 1909 - 11 - 26  | city college of new york         | fraternity |\n",
      "|  4 | σδτ       | sigma delta tau 2        | sdt or sig delts | 1917 - 03 - 25  | cornell university               | sorority   |\n",
      "|  5 | τεφ       | tau epsilon phi 1        | tep , tau boys   | 1910 - 10 - 10  | columbia university              | fraternity |\n",
      "|  6 | ζβτ       | zeta beta tau 1          | zbt              | 1898 - 12 - 29  | city college of new york         | fraternity |\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "7 of the cultural interest fraternity and sorority be found before the year 1921 0\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "|    | letters   | organization             | nickname         | founding date   | founding university              | type       |\n",
      "|----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------|\n",
      "|  0 | αεπ       | alpha epsilon pi 1       | aepi             | 1913 - 11 - 07  | new york university              | fraternity |\n",
      "|  1 | αεφ       | alpha epsilon phi 2      | aephi            | 1909 - 10 - 24  | barnard college                  | sorority   |\n",
      "|  2 | σαεπ      | sigma alpha epsilon pi 3 | sigma            | 1998 - 10 - 01  | university of california , davis | sorority   |\n",
      "|  3 | σαμ       | sigma alpha mu 1         | sammy            | 1909 - 11 - 26  | city college of new york         | fraternity |\n",
      "|  4 | σδτ       | sigma delta tau 2        | sdt or sig delts | 1917 - 03 - 25  | cornell university               | sorority   |\n",
      "|  5 | τεφ       | tau epsilon phi 1        | tep , tau boys   | 1910 - 10 - 10  | columbia university              | fraternity |\n",
      "|  6 | ζβτ       | zeta beta tau 1          | zbt              | 1898 - 12 - 29  | city college of new york         | fraternity |\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "goal 2 - 5 be all consider friendly competition 1\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "goal 2 be the first of 3 game with a score of 2 - 0 0\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "the game in pueblo nuevo be 1 of 6 game play in venezuela 0\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "in the 2008 manx grand prix the same team do not have more than 1 rider 1\n",
      "+----+--------+----------------------+---------------------+-------------+------------+\n",
      "|    |   rank | rider                | team                | speed       | time       |\n",
      "|----+--------+----------------------+---------------------+-------------+------------|\n",
      "|  0 |      1 | ryan farquhar        | 498cc bic paton     | 102.385 mph | 1:06.19.90 |\n",
      "|  1 |      2 | alan oversby         | 500cc norton manx   | 101.863 mph | 1:06.40.30 |\n",
      "|  2 |      3 | alan brew            | seeley g50 496cc    | 99.367 mph  | 1:08.20.78 |\n",
      "|  3 |      4 | wattie brown         | 500cc petty manx    | 98.118 mph  | 1:09.12.98 |\n",
      "|  4 |      5 | andy reynolds        | 499cc bic paton     | 97.152 mph  | 1:09.54.28 |\n",
      "|  5 |      6 | bob price            | 500cc seeley g50    | 96.890 mph  | 1:10.05.64 |\n",
      "|  6 |      7 | ken davis            | 500cc norton manx   | 95.948 mph  | 1:10.46.92 |\n",
      "|  7 |      8 | chris swallow        | 476cc ducati        | 95.664 mph  | 1:10.59.52 |\n",
      "|  8 |      9 | mark herbertson      | 499cc matchless g50 | 95.272 mph  | 1:11.17.05 |\n",
      "|  9 |     10 | dave madsen - mygdal | 499cc honda         | 92.209 mph  | 1:11.19.89 |\n",
      "+----+--------+----------------------+---------------------+-------------+------------+\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def display_wrong_result(pred_list, gold_list, dataset):\n",
    "    for ind, (pred, gold) in enumerate(zip(pred_list, gold_list)):\n",
    "        pred, gold = extract_yes_no_and_map(pred), extract_yes_no_and_map(gold)\n",
    "        if pred != gold:\n",
    "            sample= dataset[ind]\n",
    "            df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "            for i, line in enumerate(sample['table']['rows']):\n",
    "                df.loc[i] = line\n",
    "            print(sample['statement'], sample['label'])\n",
    "            print(tabulate(df, headers=df.columns, tablefmt='psql'))\n",
    "        \n",
    "print(display_wrong_result(batch_pred, ground, tabfact['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40664801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('1', '1')\n",
      "1 ('1', '1')\n",
      "2 ('1', '1')\n",
      "3 ('1', '1')\n",
      "4 ('1', '1')\n",
      "5 ('1', '0')\n",
      "6 ('0', '0')\n",
      "7 ('0', '0')\n",
      "8 ('0', '0')\n",
      "9 ('0', '0')\n",
      "10 ('1', '1')\n",
      "11 ('0', '1')\n",
      "12 ('1', '1')\n",
      "13 ('1', '1')\n",
      "14 ('0', '1')\n",
      "15 ('0', '0')\n",
      "16 ('0', '0')\n",
      "17 ('0', '0')\n",
      "18 ('1', '0')\n",
      "19 ('1', '0')\n",
      "20 ('The answer is 1.', '1')\n",
      "21 ('0', '1')\n",
      "22 ('1', '1')\n",
      "23 ('0', '1')\n",
      "24 ('1', '1')\n",
      "25 ('0', '0')\n",
      "26 ('0', '0')\n",
      "27 ('1', '0')\n",
      "28 ('0', '0')\n",
      "29 ('0', '0')\n",
      "30 ('1', '1')\n",
      "31 ('1', '1')\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(zip(batch_pred, ground)):\n",
    "    print(ind, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadec37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9490d54f",
   "metadata": {},
   "source": [
    "## Answer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b300498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data_loader import TableFormat\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from data_loader import TableLoader\n",
    "\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "from utils import normalize_schema\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.tech/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "normalized_sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[3])\n",
    "formatter = TableFormat(format='none', data=normalized_sample)\n",
    "# schema_information = pd.read_csv(f\"result/aug/tabfact_test_schema.csv\", index_col='table_id')\n",
    "# formatter.data = normalize_schema(formatter.data, schema_information.loc[normalized_sample['id']]['schema'])\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\"], template=\n",
    "\"\"\"\n",
    "Below is a subtable with rows sampled, you are required to infer the data distribution and format from the sample data.\n",
    "Refine commonalities about the structure within each table column.\n",
    "You need to output in the following format: \n",
    "number. Column_name: Commonalities\n",
    "#example format\n",
    "1. championship: Names of golf tournaments are listed with some additional information (e.g., 's open, classic)\n",
    "\n",
    "sub-table: {table}\n",
    "\"\"\")\n",
    "# \n",
    "output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html()) )])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf55a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. position: Integer values representing the team's position in the table\n",
      "2. team: Names of football teams\n",
      "3. played: Number of games played by each team\n",
      "4. drawn: Number of games drawn by each team\n",
      "5. lost: Number of games lost by each team\n",
      "6. goals_for: Number of goals scored by each team\n",
      "7. goals_against: Number of goals conceded by each team\n",
      "8. goal_difference: Goal difference calculated as goals_for - goals_against\n",
      "9. points_1: Total points earned by each team in the league\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f79c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. game column: It appears to represent the game number, with each entry being a numerical value.\n",
      "2. date column: It represents the date of the game, with each entry being in a specific date format (e.g., \"month day\").\n",
      "3. team column: It represents the name of the team, with each entry being a text string.\n",
      "4. score column: It represents the game score, with each entry showing the score in a specific format (e.g., \"l 90 - 115 (ot)\").\n",
      "5. high_points column: It represents the player with the highest points in the game, with each entry showing the player's name and the number of points.\n",
      "6. high_rebounds column: It represents the player with the highest rebounds in the game, with each entry showing the player's name and the number of rebounds.\n",
      "7. high_assists column: It represents the player with the highest assists in the game, with each entry showing the player's name and the number of assists.\n",
      "8. location_attendance column: It represents the location of the game and the attendance, with each entry showing the location and the number of attendees.\n",
      "9. record column: It represents the team's record, with each entry showing the number of wins and losses.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query.\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        # 'claim':\"who is the winner of the lifetime achievement award after 2005?\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a285a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that provide clues for query.\n",
    "sub-table: {table}\n",
    "Query: verify whether the provided claim/query are true or false. {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        # 'claim':\"who is the winner of the lifetime achievement award after 2005?\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))\n",
    "# verify whether the provided claim/query are true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c50a649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information and data in subtable, write 3 SELECT SQL statements using table DF that complete or related to query.\n",
    "The SQL may select different useful parts for the query.\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'] + \". The query is about 2005 Milwaukee Brewers season red uniforms vs Padres schedule\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9224bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query.\n",
      "sub-table: <table>\n",
      "<caption>1986 - 87 north west counties football league</caption>\n",
      "<thead>\n",
      "<tr><th>  position</th><th>               team</th><th>  played</th><th>  drawn</th><th>  lost</th><th>  goals_for</th><th>  goals_against</th><th>  goal_difference</th><th>  points_1</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>12        </td><td>ashton town        </td><td>24      </td><td>9      </td><td>11    </td><td>29         </td><td>39             </td><td>10               </td><td>15 2      </td></tr>\n",
      "<tr><td>10        </td><td>padiham            </td><td>24      </td><td>8      </td><td>12    </td><td>35         </td><td>39             </td><td>4                </td><td>16        </td></tr>\n",
      "<tr><td>1         </td><td>atherton collieries</td><td>24      </td><td>4      </td><td>4     </td><td>46         </td><td>22             </td><td>+ 24             </td><td>36        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "Extra information: 1. position: Integer values representing the team's position in the table\n",
      "2. team: Names of football teams\n",
      "3. played: Number of games played by each team\n",
      "4. drawn: Number of games drawn by each team\n",
      "5. lost: Number of games lost by each team\n",
      "6. goals_for: Number of goals scored by each team\n",
      "7. goals_against: Number of goals conceded by each team\n",
      "8. goal_difference: Goal difference calculated as goals_for - goals_against\n",
      "9. points_1: Total points earned by each team in the league\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.tech/v1\",\n",
    "                       openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\", temperature=0.1)\n",
    "llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=True)\n",
    "batch_pred = llm_chain.batch(inputs, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c819dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT team\n",
      "FROM DF\n",
      "WHERE goals_for = (SELECT MAX(goals_for) FROM DF)\n",
      "AND caption = '1986 - 87 north west counties football league'\n",
      "AND team = 'flixton';\n"
     ]
    }
   ],
   "source": [
    "print(batch_pred[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d2022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is relevant information regrading the table stucture. Carefully analyze the query, based on the augmentation information you are required to infer the data distribution and format. Write an SELECT SQL statement using table DF that is most likely to provide useful information to the query.\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3acaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is an initial SQL statement about the query. Now you can see some smaple rows from the table, improve the sql statement so that the SQL can answer the query.\n",
    "initial SQL: {initial}\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({\"initial\" : initial[0]['text'],\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ff859ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 31997 mintage be release in 2001\n",
      "<table>\n",
      "<thead>\n",
      "<tr><th>  year</th><th>                  mintage</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>2003  </td><td>included in hmcs bras dor</td></tr>\n",
      "<tr><td>2003  </td><td>31997                    </td></tr>\n",
      "<tr><td>2000  </td><td>44367                    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "+--------+----------------------------+-------------------+-----------------------------+---------------+\n",
      "|   year | theme                      | artist            | mintage                     |   issue price |\n",
      "|--------+----------------------------+-------------------+-----------------------------+---------------|\n",
      "|   2000 | steam buggy                | john mardon       | 44367                       |         59.95 |\n",
      "|   2000 | the bluenose               | j franklin wright | included in steam buggy     |         59.95 |\n",
      "|   2000 | the toronto                | john mardon       | included in steam buggy     |         59.95 |\n",
      "|   2001 | the russell light four     | john mardon       | 41828                       |         59.95 |\n",
      "|   2001 | the marco polo             | j franklin wright | included in the russell     |         59.95 |\n",
      "|   2001 | the scotia                 | don curley        | included in the russell     |         59.95 |\n",
      "|   2002 | the gray - dort            | john mardon       | 35944                       |         59.95 |\n",
      "|   2002 | the william lawrence       | bonnie ross       | included in the gray - dort |         59.95 |\n",
      "|   2002 | d - 10 locomotive          | dan fell          | included in the gray - dort |         59.95 |\n",
      "|   2003 | hmcs bras dor              | don curley        | 31997                       |         59.95 |\n",
      "|   2003 | cnr fa - 1 diesel electric | john mardon       | included in hmcs bras dor   |         59.95 |\n",
      "|   2003 | bricklin sv - 1            | brian hughes      | included in hmcs bras dor   |         59.95 |\n",
      "+--------+----------------------------+-------------------+-----------------------------+---------------+\n",
      "0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "i = 0\n",
    "# SQL = manager.format_sql(preds[i]['pred'].split(':')[1])\n",
    "\n",
    "\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    columns = [c.strip() for c in preds[i]['pred'].split(',')]\n",
    "    print(data['statement'])\n",
    "    formatter.data = formatter.data.loc[:, columns]\n",
    "    \n",
    "    print(formatter.format_html())\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # data.columns = [manager.normalize_col_name(c) for c in formatter.all_data.columns]\n",
    "    # data.to_sql('DF', manager.engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # subtable = pd.read_sql(command, self.engine)\n",
    "    # test_df = manager.execute_from_df(SQL, formatter.all_data)\n",
    "    # return test_df\n",
    "test_df = show_table(table_loader.dataset[i])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b05ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer output\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\", \"claim\"], template=\n",
    "\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a SQL statement which reports error or returns no result. You need to understand the logic behind the SQL filtering and rewrite SQL to guarantee the SQL return useful information. \n",
    "sub-table: {table}\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Query: {claim}\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html(), claim=test_sample['statement']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3084f1",
   "metadata": {},
   "source": [
    "## Evaluat from local result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e12f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from data_loader import TableLoader\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', small_test=True, use_sample=False)\n",
    "preds = []\n",
    "with open('./result/answer/tabfact_test_04-20_02-06-16.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        preds.append(json.loads(l)['pred'])\n",
    "\n",
    "print(len(preds))\n",
    "SQLs = []\n",
    "with open('./result/SQL/tabfact_test_04-20_02-04-20.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        SQLs.append(json.loads(l)['pred'])\n",
    "print(len(SQLs))\n",
    "# do evaluation\n",
    "# accuracy = eval_fv_match(pred_label, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0423d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0']\n",
      "['1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0']\n",
      "(array([  0,   1,  11,  14,  22,  24,  26,  31,  37,  38,  39,  40,  47,\n",
      "        49,  50,  59,  62,  63,  65,  66,  68,  69,  70,  75,  80,  81,\n",
      "        82,  90,  91,  93,  95,  99, 100, 105, 106, 108, 110, 116, 119,\n",
      "       124, 129, 136, 137, 145, 147, 148, 151, 153, 155, 158, 160, 164,\n",
      "       167, 169, 171, 173, 175, 179, 180, 181, 187, 188, 190, 192, 198,\n",
      "       200, 207, 209, 210, 211, 217, 225, 227, 230, 233, 236, 237, 241,\n",
      "       251]),)\n",
      "0.6901960784313725\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_tabfact\n",
    "import json\n",
    "from data_loader import TableLoader\n",
    "import numpy as np\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "labels = [table_loader.normalize_table(line)['label'] for line in table_loader.dataset][:255]\n",
    "answers = eval_tabfact('./result/answer/tabfact_test_04-20_02-06-16.json', labels, verbose=True)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c40a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0']\n",
      "(array([ 2,  3, 14, 21, 25, 27, 32, 35]),)\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_tabfact\n",
    "import json\n",
    "from data_loader import TableLoader\n",
    "import numpy as np\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=True, small_test=True)\n",
    "labels = [table_loader.normalize_table(line)['label'] for line in table_loader.dataset]\n",
    "answers = eval_tabfact('./result/answer/tabfact_test_04-18_15-20-27.json', labels, verbose=True)\n",
    "print(np.where(np.array(labels) != np.array(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1931fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = table_loader.dataset[i]\n",
    "df = pd.DataFrame(columns=data[\"table\"][\"header\"])\n",
    "for i, line in enumerate(data['table']['rows']):\n",
    "    df.loc[i] = line\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75469cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = TableFormat(format='none', data=table_loader.dataset[i])\n",
    "from functools import partial\n",
    "data_func = partial(pd.to_datetime, dayfirst=True, format='mixed')\n",
    "formatter.all_data['date'] = data_func(formatter.all_data['date'])\n",
    "formatter.all_data['date'] = pd.to_datetime(formatter.all_data['date'], format='%Y-%m')\n",
    "formatter.all_data['date'] = formatter.all_data['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b96e507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "formatter = TableFormat(format='none', data=table_loader.dataset[i])\n",
    "schema_information = pd.read_csv(f\"result/aug/tabfact_test_schema.csv\", index_col='table_id')\n",
    "formatter.normalize_schema(schema_information.loc[table_loader.dataset[i]['table']['id']]['schema'])\n",
    "formatter.all_data.to_sql('DF', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69292e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = [0,   1,  11,  14,  22,  24,  26,  31,  37,  38,  39,  40,  47,\n",
    "       49,  50,  59,  62,  63,  65,  66,  68,  69,  70,  75,  80,  81,\n",
    "       82,  90,  91,  93,  95,  99, 100, 105, 106, 108, 110, 116, 119,\n",
    "124, 129, 136, 137, 145, 147, 148, 151, 153, 155, 158, 160, 164,\n",
    "167, 169, 171, 173, 175, 179, 180, 181, 187, 188, 190, 192, 198,\n",
    "200, 207, 209, 210, 211, 217, 225, 227, 230, 233, 236, 237, 241,\n",
    "251]\n",
    "len(inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d3562",
   "metadata": {},
   "source": [
    "#### show tabfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a8012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9457145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 7 11 19 21 22 24 30 32 37 38 41 42 43 45 58 59 63 64 73 74 76 79 80 83 84 85 89 93 99'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "********210***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, Lleyton Hewitt was a runner-up 5 times. The total number of times he was a runner-up is 5, and the total number of times he participated is not given. \n",
    "Answer: 0\n",
    "['how many times was Lleyton Hewitt a runner-up in total?', ' How many times did Lleyton Hewitt be a runner-up?', 'How many times did Lleyton Hewitt win a championship?']\n",
    "********213***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, there were no instances of a master series final where one side finished with 4 points. \n",
    "Answer: 1\n",
    "[\"How many of Lleyton Hewitt's master series final have one side finishing with 4 points?\", \"How many of Lleyton Hewitt's master series finals ended with one side finishing with 4 points?\", \" How many of Lleyton Hewitt's master series final have the other side finishing with 4 points?\"]\n",
    "********225***************\n",
    "0 1\n",
    "Thought: Based on the sub-table, it appears that no team scored in the first game of the World Cup in France on June 19, 1998.\n",
    "Answer: 1\n",
    "['What was the score for the first game of the world cup in France?', 'which team did not score in the first game of the world cup in France?', ' Did any team score for the first game of the world cup in France?']\n",
    "********227***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the Solheim Cup was hosted in the US 7 times from 1990 through 2013, as indicated by the sub-table.\n",
    "Answer: 1\n",
    "[' When was the Solheim Cup hosted in the US from 1990 through 2013?', 'How many times was the Solheim Cup hosted in the US from 1990 through 2013?', 'how many times was the Solheim Cup hosted in the US from 1990 through 2013?']\n",
    "********228***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the United States team won 8 Solheim Cup tournaments between 1990 and 2009. The last win for the United States team before 2009 was in 2007.\n",
    "Answer: 0\n",
    "['How many Solheim Cup tournaments did the United States team win from 1990 to 2009?', 'how many Solheim Cup tournaments did the United States team win between 1990 and 2009?', ' When was the last Solheim Cup win for the United States team before 2009?']\n",
    "********229***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the captains who have won the cup multiple times are Mickey Walker and Kathy Whitworth. Patty Sheehan, Judy Rankin, and Kathy Whitworth are not the only captains who have won the cup 2 times.\n",
    "Answer: 0\n",
    "['How many times did Patty Sheehan win the cup as captain?', ' How many times did Judy Rankin win the cup as captain?', ' How many times did Kathy Whitworth win the cup as captain?', 'which captains have won the cup multiple times?']\n",
    "********234***************\n",
    "0 1\n",
    "Thought: Based on the sub-table, Patty Sheehan, Judy Rankin, and Kathy Whitworth all captained a winning team in the Solheim Cup 1 time.\n",
    "Answer: 1\n",
    "['How many times did Patty Sheehan captain a winning team in the Solheim Cup?', 'how many times did each captain win the solheim cup?', ' How many times did Judy Rankin captain a winning team in the Solheim Cup?', ' How many times did Kathy Whitworth captain a winning team in the Solheim Cup?']\n",
    "********239***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the attendance on August 26 was 48063 and the attendance on August 27 was 48032.\n",
    "Answer: 0\n",
    "[' What was the attendance on August 27?', 'What was the attendance on August 26?', 'what was the attendance on August 26 and August 27?']\n",
    "********240***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, when the score was 10 - 4 in a game against the Athletics, the Colorado Rockies' record was 68 - 70.\n",
    "Answer: 0\n",
    "[\"When the score be 10 - 4 , what was the Colorado Rockies' record in a game against the athletics?\", \"what is the Colorado Rockies' record after each game?\"]\n",
    "********254***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the smallest attendance was at the game against the Baltimore Colts, with an attendance of 50451. \n",
    "Answer: 1\n",
    "['which game had the smallest attendance?', 'What was the attendance at the game against the New England Patriots?', ' What was the attendance at the game against the Baltimore Colts?']\n",
    "********255***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the attendance in week 12 was 66875, which is higher than the attendance in week 6 (71009) and week 13 (43475). \n",
    "Answer: 1\n",
    "[' What was the attendance in week 6?', 'what is the attendance for each week?', 'What was the attendance in week 12?', ' What was the attendance in week 13?']\n",
    "********259***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the Yugoslavian national team lost the Balkan Cup against Romania with an aggregate score of 3:4. The aggregate score of the Yugoslavian national team against Romania in the Balkan Cup was 7, not 3:4.\n",
    "Answer: 0\n",
    "['what were the results of the games played by the Yugoslavian national team in the Balkan Cup?', 'When did the Yugoslavian national team lose the Balkan Cup?', ' What was the aggregate score of the Yugoslavian national team against Romania in the Balkan Cup?']\n",
    "********265***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the Yugoslavian national team failed to score in world cup qualifying matches 1 time, and dropped a world cup qualify match 2:1 against Denmark.\n",
    "Answer: 1\n",
    "['how many times did the yugoslavian national team fail to score in world cup qualifying matches?', ' Against which team did the Yugoslavian national team drop a world cup qualify match 2:1?', 'When did the Yugoslavian national team fail to score?']\n",
    "********266***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the Yugoslavian national team scored 7 goals and allowed 3 goals in the 1982 World Cup qualifiers.\n",
    "Answer: 1\n",
    "['How many goals did the Yugoslavian national team score in the 1982 world cup qualify?', ' How many goals did the Yugoslavian national team allow in the 1982 world cup qualify?', 'How many goals did the Yugoslavian national team score and allow in the 1982 World Cup qualifiers?']\n",
    "********272***************\n",
    "0 1\n",
    "Thought: Based on the sub-table, March had the most games played with 7, while April had the fewest games played with 3. Therefore, the claim that March is featured more often as a month in the date than any other month, followed by the 4 games in April is true.\n",
    "Answer: 1\n",
    "['how many games were played in each month?', 'How many games were played in March?', ' How many games were played in April?']\n",
    "********287***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, there is 1 translator in the frequency MHz in the 100's and 3 translators in the frequency range of 90.0 to 99.9 MHz.\n",
    "Answer: 0\n",
    "[\"How many translators are there in the frequency mhz in the 100's?\", 'how many translators are there in each frequency range?', \" How many translators are there in the frequency mhz in the 90's?\"]\n",
    "********290***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the station w293al has an ERP W of 80, which is higher than the ERP W of w264bf, which is 2. However, the frequency_mhz of w293al is 106.5, and the frequency_mhz of w264bf is 100.7. The claim that w293al has the highest ERP W and w264bf has the lowest ERP W is false.\n",
    "Answer: 0\n",
    "[' What is the frequency_mhz of w264bf?', 'What is the frequency_mhz of w293al?', 'which station has the highest and lowest erp w?']\n",
    "********291***************\n",
    "1 0\n",
    "Thought: Based on the SQL query provided, the cities of Illinois and Indiana each have 3 translators. However, the sub-table does not contain any data from the database, so we cannot verify the claim based on the provided information.\n",
    "Answer: 0\n",
    "[' How many translators does Indiana have?', 'How many translators does Illinois have?', 'how many translators are there in Illinois and Indiana combined?']\n",
    "********292***************\n",
    "0 1\n",
    "Thought: Based on the sub-table, the query can be answered. There are 6 call signs that have a frequency change range of 5 MHz.\n",
    "Answer: 1\n",
    "['what is the frequency range for the radio stations listed?', ' How many call signs have a frequency change range of 5 MHz?', 'What are the frequency ranges for the call signs?']\n",
    "********294***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the ERP_W value of 2 is the only value that appears in the table.\n",
    "Answer: 1\n",
    "['which call sign has an ERP of 2 W?', 'What is the frequency_mhz for the call_sign w264bf?', ' What is the city_of_license for the call_sign w264bf?']\n",
    "********300***************\n",
    "0 1\n",
    "Thought: Based on the SQL query provided, the tournament that had the same result in the year 1990 and 1999 was the grand slam tournaments.\n",
    "Answer: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a26b900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = []\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    if table_loader.dataset[i]['table']['id'] not in table_name:\n",
    "        table_name.append(table_loader.dataset[i]['table']['id'])\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "695c61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solheim cup\n",
      "2-1546813-1.html.csv\n",
      "patty sheehan , judy rankin and kathy whitworth be all captain that win the solheim cup 1 time\n",
      "+--------+-----------------------------------------------+----------------+-----------+-----------------+-------------------+\n",
      "|   year | venue                                         | winning_team   | score     | usa_captain     | europe_captain    |\n",
      "|--------+-----------------------------------------------+----------------+-----------+-----------------+-------------------|\n",
      "|   2013 | colorado golf club , colorado , usa           | europe         | 18 - 10   | meg mallon      | liselotte neumann |\n",
      "|   2011 | killeen castle golf resort , ireland          | europe         | 15 - 13   | rosie jones     | alison nicholas   |\n",
      "|   2009 | rich harvest farms , illinois , usa           | united states  | 16 - 12   | beth daniel     | alison nicholas   |\n",
      "|   2007 | halmstad gk , sweden                          | united states  | 16 - 12   | betsy king      | helen alfredsson  |\n",
      "|   2005 | crooked stick golf club , indiana , usa       | united states  | 15½ - 12½ | nancy lopez     | catrin nilsmark   |\n",
      "|   2003 | barsebäck golf & country club , sweden        | europe         | 17½ - 10½ | patty sheehan   | catrin nilsmark   |\n",
      "|   2002 | interlachen country club , minnesota , usa    | united states  | 15½ - 12½ | patty sheehan   | dale reid         |\n",
      "|   2000 | loch lomond golf club , scotland              | europe         | 14½ - 11½ | pat bradley     | dale reid         |\n",
      "|   1998 | muirfield village , ohio , usa                | united states  | 16 - 12   | judy rankin     | pia nilsson       |\n",
      "|   1996 | st pierre golf & country club , wales         | united states  | 17 - 11   | judy rankin     | mickey walker     |\n",
      "|   1994 | the greenbrier , west virginia , usa          | united states  | 13 - 7    | joanne carner   | mickey walker     |\n",
      "|   1992 | dalmahoy country club , scotland              | europe         | 11½ - 6½  | kathy whitworth | mickey walker     |\n",
      "|   1990 | lake nona golf & country club , florida , usa | united states  | 11½ - 4½  | kathy whitworth | mickey walker     |\n",
      "+--------+-----------------------------------------------+----------------+-----------+-----------------+-------------------+\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "# table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "i = 234\n",
    "\n",
    "def show_table(data, execute=False):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['table']['id'])\n",
    "    print(data['statement'])\n",
    "    print(formatter.format_psql())\n",
    "    # print(preds[i])\n",
    "    # print(SQLs[i])\n",
    "    # test_df = manager.execute_from_df(SQLs[i], formatter.all_data)\n",
    "    # print(test_df)\n",
    "    print(data['label'])\n",
    "print(table_loader.dataset[i]['table']['caption'])\n",
    "show_table(table_loader.dataset[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c422a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 the scheduled date for the farm with 17 turbine be 2012\n",
      "1 all 12 club play a total of 22 game for the wru division one east\n",
      "2 touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "3 the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "4 in 1980 , 1981 and 1985 pat bradley (golfer) not have the average of 278 win score\n",
      "5 polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "6 a gamecube game loss the award in each of the first 3 year\n",
      "7 scotland be the country with the least point\n",
      "8 only 1 of the college list be public , and it be in new orleans\n",
      "9 19.30 million viewer watch the season finale on march 12 , 1979\n",
      "10 the player garrett sutherland who be in lb position have a pick of 22\n",
      "11 st joseph 's catholic school be a state integrated school in te kuiti for year 1 - 8\n",
      "12 when north melbourne be the home team , they face away team footscray who score 8.9 (57)\n",
      "13 gene donaldson from purdue be pick in the third round\n",
      "14 the away team at prince park have a score of 13.12 (90)\n",
      "15 during the 1926 - 27 new york ranger season , game 26 , 29 , 30 , and 34 be all score in overtime\n",
      "16 a show with airdate 2 january 2010 and 4 couple have 3.87 million viewer\n",
      "17 the most total point score by the knicks in a single game be 126\n",
      "18 the show , my thursday night movie , be on at 9:00 when it be also on at 8:30\n",
      "19 jean behra be not 1 of the driver who have ferrari as their constructor\n",
      "20 the most recent locomotive to be manufacture be make more 10 year after the first to be manufacture\n",
      "21 the largest attendance for a new jersey home game in december be against the ny ranger\n",
      "22 nova scotia and prince edward island have the earliest effective date with indiana have the second early effective date\n",
      "23 during the 1987 master tournament , both tommy aaron and billy casper have a total of 305\n",
      "24 during all competition they have at least 1 draw each time\n",
      "25 when there be 161 receiving yard , there be 22 reception\n",
      "26 gene hartley finish in the same position in 1952 and 1953\n",
      "27 argentinos junior be the home team for the 2nd leg of the match with an aggregate of 2 - 3\n",
      "28 kelly jones and david pate win the match they play\n",
      "29 kim fogh replace the previous manager on 1 january 2011\n",
      "30 on october 2 when the royal be the opponent the score be 5 - 1\n",
      "31 the lowest score reach be 109 score in both game 22 and 23\n",
      "32 the montreal maroon play in 9 overtime game during the 1925 - 26 season\n",
      "33 jason richardson be their leading scorer 4 time that month , with at least 23 point per game\n",
      "34 ghatge 's most recent film be in hindi\n",
      "35 katie taylor win 2 event in the same city between 2005 and 2013\n",
      "36 the xiao hong crater be 0 , 7 km larger in diameter than the ximena crater\n",
      "37 the garden of evil and mission to venus both do not have ibsn number list for the us\n",
      "38 the episdode , live and let doyle air on january 12 , 2011 , be the most viewed episode\n",
      "39 there be more than 2 driver with 23 lap\n",
      "40 on game 45 , jr smith have the most point with the score of 97 - 92\n",
      "41 michael j maker be the trainer in the year 2012\n",
      "42 the difference between the highest number of high point and the lowest number of high point be 22\n",
      "43 calgary unite fc never play any game in 2009\n",
      "44 the only south african player take the fifth position\n",
      "45 the most laps any driver complete during the race be 75\n",
      "46 chick harbert , who lead with 68 before round 1 , finish round 2 with 73 and go down to third with ted kroll\n",
      "47 during the 1996 men 's world ice hockey championship , there be 1 more 1 loss than 4 loss\n",
      "48 the original round 5 game against read have to be replay on february 27\n",
      "49 curtis galick be from harvard college\n",
      "50 raymond sommer be the winner on 4 occasion in the 1946 season\n",
      "51 on 2013 - 05 - 26 molina have the lowest total goal during the k league classic\n",
      "52 the difference in area between the province west cape and gauteng is129462\n",
      "53 8 different bird be feature on the loonie between 2002 and 2012\n",
      "54 the award that ronnie mitchell have be nominate for most often be sexy female\n",
      "55 danny webb be 1 of 2 people to have have an accident during the race\n",
      "56 when the double (aids related) number be 41000 , and the paternal (total) be larger than 442000 then there be 24.6% orphan\n",
      "57 division 2 did not qualify for playoff after year 1993\n",
      "58 the aggregate when the third leg be 1 - 3 be 4 - 2\n",
      "59 in 2008 , the school with the nickname eagle join the mac\n",
      "60 during the 1948 vfl season , lake oral venue record the lowest crowd participation\n",
      "61 : clyde be the opponent for 2 game\n",
      "62 sergey gorovoy be the second youngest player in the team\n",
      "63 ricky newman retire from aldershot town fc on before may of 2009\n",
      "64 the march 86c chassis be use by 2 different team in the same year\n",
      "65 monta elli and matt barnes be lead scorer the most time\n",
      "66 3 of the 8 be radio station cover news in fargo - moorhead\n",
      "67 woman from 5 different country take part in this round of the 2008 woman 's british open\n",
      "68 the highest car number in the 2008 nascar craftsman truck series be 74\n",
      "69 charles martin and brian noble have 3.0 sack each , but neither 1 have any yard or interception\n",
      "70 when she be a runner - up the score be 6 - 4 , 6 - 3\n",
      "71 randall zisk direct 2 episode in all of season 4 , the least of the season\n",
      "72 the number of career cap for a full back be 0 when tour apps be smaller than 29\n",
      "73 the lowest attendance figure for a game be 37230\n",
      "74 the most point score by a celtic player in a game be 35\n",
      "75 the name of the visiting team who play home team chicago black hawk on march 20 be the boston bruin\n",
      "76 marco ravaioli , michael ranseder , takaaki nakagami , and esteve rabat all have to end the race early due to accident\n",
      "77 best new actor be the least common category that he be nominate for\n",
      "78 western oval have carlton as the home team\n",
      "79 douglas vandor cameron sylvester finish before any other team of rower\n",
      "80 panther have only 2 location\n",
      "81 stirling moss win the xiii barc aintree 200 on 20 july 1958\n",
      "82 mexico win the highest number of medal with fifty 7\n",
      "83 april 20 , 2009 be when episode 3 air\n",
      "84 tich freeman be on the record list 3 time , while colin blythe be only on the list 1 time\n",
      "85 52500 be the prize money for texas\n",
      "86 frederick fane be feature as an away captain at more venue than arthur jones\n",
      "87 the trojan be the mascot for the team that join the conference immediately after south newton\n",
      "88 there be a low attendance of 14007 against the devil ray on may 13\n",
      "89 mike eruzione score 92 goal from 1973 - 77\n",
      "90 both the tiger and the ranger be the 2 team that they play 3 time each\n",
      "91 there be only 2 people name sara / sarah show as centerfold\n",
      "92 the washington redskins lose a total of 8 game during their 1952 season\n",
      "93 robert wickens accumulate 4 more point than johnathan bomarito\n",
      "94 the team that earn the highest number of point for and point against be the team that win the most game\n",
      "95 vitória play after river plate\n",
      "96 there be 1 more team classification of euskaltel - euskadi than there be of caisse d'epargne\n",
      "97 freddie jackson 's status be advanced\n",
      "98 the league conference north happen 3 time\n",
      "99 the label before 1969 be columbia\n",
      "100 uraga dock company produce the most destroyer on the list , at 3\n",
      "101 peter mikkelsen only win the men 's single 1 time in 2007\n",
      "102 Örgryte be have the fewest allsvenskan title among the club list in the chart\n",
      "103 gloria moon be on the 2002 and 1999 commission\n",
      "104 multiple volleyball club be establish in st petersburg prior to 1940\n",
      "105 the queen 's birthday clash with the lowest attendance be in 2007\n",
      "106 al bridge in maryland be in the washington county\n",
      "107 5 player end their career in 2009\n",
      "108 the 14th game be the first game play at the summit and result in a 110 - 100 score\n",
      "109 for konstantopoulos , the loan club be coventry city and the start source be cardiff city\n",
      "110 the player of united state nationality be draft after john westin\n",
      "111 phil mickelson and mike weir in 2003 and 2004 be able to interrupt tiger wood streak\n",
      "112 davíd garza pérez participate in more race during the 2006 season than any other year\n",
      "113 northern ireland do not score more than 1 goal in any of the match list\n",
      "114 there be 2 player with the last name of elli on the roster\n",
      "115 22210 attend the tie between sheffield united and middlesbrough\n",
      "116 luigi riva be 1 of 3 people in 18th place\n",
      "117 when the week 15 result be michigan (7 - 2) the week 10 result be washington (7 - 1)\n",
      "118 in 1989 , boris becker be champion with alexander volkov as runner - up , and in 1989 , boris becker be the champion with alexander volkov as runner - up\n",
      "119 0 total win be associate with event with 2 top - 5s\n",
      "120 the united state be home to the most player with 9\n",
      "121 alfa romeo flat - 12 engine race in 1974 by martini racing\n",
      "122 darren kotania be the director and the episode for episode 1 of be you afraid of the dark season 3 be 1\n",
      "123 cristina teuscher be 1 of 2 american swimmer in the 200 meter event medley\n",
      "124 from 1980 to 2011 , apoel bc lose more than 2 time as many game as it win\n",
      "125 of the 14 game play during the month of january , exactly half be home game for the cavalier\n",
      "126 only 4 of the fight go the full 12 round\n",
      "127 sorana cîrstea have a 1r in all the tournament in 2012\n",
      "128 there be 4 win as result , while there be only 2 loss\n",
      "129 chauncey billups (8) have the high assist on april 17 , but share the high assist with anthony carter on april 23\n",
      "130 the country of ecuador be the only country that use the us dollar (usd) as its currency , and the central bank be the federal reserve\n",
      "131 both paraguay and peru use the us dollar\n",
      "132 only 1 player be in the pg position\n",
      "133 on october 4 the record be 90 - 68 when the royal be the opponent\n",
      "134 the episode title hare - abian night be 1 of 10 episode in the mm series\n",
      "135 wesley person lead in rebound on may 1\n",
      "136 1 more season premièred on september 20 than on september 21\n",
      "137 3 player have a - 2 to par and they be jack nicklaus , arnold palmer , and lee trevino\n",
      "138 cartagena fc and real oviedo have a draw of 14 with 44 game play\n",
      "139 the stadium for both of the game of the host team baltimore raven be the m&t bank stadium\n",
      "140 the mcg venue home team be richmond\n",
      "141 the 2006 connecticut sun lose their first 5 game int he month of june\n",
      "142 tumble rfc have win 20 out of 22 of the game they have play\n",
      "143 the entire kawasaki racing team be able to race in all of the round\n",
      "144 carpet be the surface for 16 april 2007\n",
      "145 the only 3 right hand batter be bear within 21 month of each other\n",
      "146 in 2008 , the chunnam dragon beat chonburi 1 - 0\n",
      "147 mauna kea be the summit in the rank 1 , and have a col (m) of 0\n",
      "148 the highest score achieve be 109 score in both game 22 and 23\n",
      "149 the shortest time be 11:44 when jbl be eliminate by jericho\n",
      "150 4 of the segment c show feature foodstuff : plantain chip , soda cracker , sugar , and goat cheese\n",
      "151 all but 1 game in the season have 53 game\n",
      "152 the hmjs surrey have a length of 42.8 m , and its max speed be faster than the hmjs fort charles (p 7) max speed\n",
      "153 the hispanic sounding character mimi be primarily cast by dutch woman\n",
      "154 there be 2 event at donington park in 1994\n",
      "155 brazil 's gold and silver medal be down a total of 10\n",
      "156 jack nicklaus have less than double the win of the rank 2 player\n",
      "157 the least amount of point the fire score in a game be 1\n",
      "158 the match between cowdenbeath and the ranger have a higher attendance than the game between ross county and the ranger\n",
      "159 the senate have an election in 1977 , 1978 and 1979\n",
      "160 since 2000 , there have be 4 match rank in the top 42 for attendance\n",
      "161 the result of the election , in which the incumbent be denver s church , be re - elect\n",
      "162 happy howl - o - ween 4 episode after freaky day / dog tire\n",
      "163 at the weightlifting at the 2008 summer olympics - men 's 105 kg , dmitry berestov snatch more weigth than marcin dołęga\n",
      "164 7 of the 10 bike be manufacture by zabel\n",
      "165 2 team score exactly 139 point during round 20 of the 1978 vfl season\n",
      "166 in april 1992 , ryan stile be the performer 2 time\n",
      "167 craig miller be the youngest water polo player list\n",
      "168 mapiu school have the highest roll in the state authority\n",
      "169 heikki kovalainen earn one lose in his formula one racing career\n",
      "170 the central bank for guyana and argentina be call the federal reserve\n",
      "171 on the earliest date , the score be 6 - 4 , 6 - 4\n",
      "172 john waite won series 3 , while miranda gore browne be 1 runner - up in series 1\n",
      "173 like like a dog / cold fish be list as have the highest number of us viewer\n",
      "174 slovan bratislava be the opponent the year brfore the fight against eintracht frankfurt\n",
      "175 the record in the 100 m freestyle event be set in 2007\n",
      "176 the ireland in the eurovision song contest in 1989 have the real me place 1 rank higher than easy\n",
      "177 dean semmens be not 1 of the 3 player bear after 1981\n",
      "178 on entertainment tonight , diresta be on at 7:30 , follow by cosby at 8:00\n",
      "179 in 1983 , aberdeen win\n",
      "180 mark fellow write 3 big time rush episode\n",
      "181 nick faldo be 1 of 2 player that finish in first place\n",
      "182 the penrith panther have a score of 60 - 17 at sydney football stadium in 2006\n",
      "183 the lowest attendance be 13831\n",
      "184 the team rusport have a 1:25.361 in qual 2\n",
      "185 the new york jet score more point against the houston oiler than the new orleans saint\n",
      "186 catawba and oneota both have the name change 1 time the canonicus - class monitor\n",
      "187 all of the ship in the bolitho novel be classify as frigate\n",
      "188 sam mcgregor be the youngest water polo player list\n",
      "189 d a weibring have less to par point than seve ballesteros\n",
      "190 only 1 of the top 3 winner be a group act\n",
      "191 gracia baylor 's term of office end after that of the member for higinbotham\n",
      "192 the team pacific coast motorsports have a 1:26.582 best record\n",
      "193 the tarija department have 12755 small (100ha) and 17101 medium (500ha)\n",
      "194 incumbent del latta be from district ohio 5\n",
      "195 fm 100.5 , which the note state be license to hope , play child 's music\n",
      "196 jens hammer sørensen leave by mutual consent and be replace by jakob michelsen\n",
      "197 seve ballesteros finish ahead of mike reid by 1 shot , and make 4400 more than him\n",
      "198 singer elvis costello cover a song from the alum the hissing of summer lawn\n",
      "199 only 1 role be the leading role\n",
      "200 the september 17 1997 match against košice have the lowest attendance rate of the season\n",
      "201 the rating (kansai) for the original air date may 25 , 2010 be 15.5\n",
      "202 the maserati win the 1946 grand prix season on 9 occasion\n",
      "203 there be 7 unspecified specie and 5 unspecified strain\n",
      "204 cuba have the second highest number of total medal among all nation\n",
      "205 the railway with a loco name of the pyramus and a build of 1912 be smr\n",
      "206 ted kroll lead lew warsham by 3 stroke at the end of round 2 in the 1953 master tournament\n",
      "207 college / junior / club team kitchener ranger (omjhl) make the 22 pick for the centre position\n",
      "208 finland be the country with the least point\n",
      "209 there be a total of 10267578 gaelic speaker in all council area\n",
      "210 wang xiaoli yu yang win womens double after 2010\n",
      "211 the game on 12 october 2012 , 10 september 2013 , and 19 november 2008 have a result of 1 - 0\n",
      "212 kaitlyn lawes be the skip and liz peter be the lead for canada\n",
      "213 the general classification be silvano contini only 1 time and that be stage 18\n",
      "214 irving romaine have over 1 hundred run more than david hemp\n",
      "215 the only game in manchester , england have a record of 5 - 2\n",
      "216 the average attendance for the series be 52424.40 crowd\n",
      "217 6 driver complete 75 lap , while only 1 driver complete 74 lap\n",
      "218 the attendance for all of the home game be over 77000 at each game\n",
      "219 bagnères - de - bigorre be a leader in 1948 with a stage number 18.0\n",
      "220 kansa city lose all 7 game with attendance of 47310 or greater during the 1978 season\n",
      "221 the spelling of יְהוֹשָפָט in english would be jehoshaphat\n",
      "222 the festival of pacific art be hold at a different location in the pacific every time\n",
      "223 toronto win all 7 of their home game in december of their 2007 - 2008 season\n",
      "224 erkranas and hjk helsinki have the highest agg score during the qualifying round\n",
      "225 the total number of run for and against for april be 173\n",
      "226 the eagle have 2 game where they score 0 point total\n",
      "227 12 - 26 - 1 be the record for detroit and decision of denis on december 30\n",
      "228 the venue mcg be home to the melbourne team\n",
      "229 there be no school that aren't coed and not under the authority of state integrate in the hawke 's bay region\n",
      "230 there be 1 round hold in nevada , united state with a time of 1:55\n",
      "231 the attendance on december 16 at washington redskin be 49484\n",
      "232 opponent albert montañés santiago ventura score 1 - 6 , 2 - 6 in the final\n",
      "233 during the supplemental first round selection , more than 6 people be select in the position rhp\n",
      "234 at the world mind sport game , japan 1 more bronze than israel have\n",
      "235 in international friendly , england always score at least 2 goal\n",
      "236 trina feature more than 3 release on the kontor house of house vol 13 (compilation album)\n",
      "237 bernard mceveety be a director on season 3\n",
      "238 the sum roll of karaka area be 442\n",
      "239 there be 5 game with the goal against over 44 and a goal difference of 11\n",
      "240 on 6 may 1917 , the aircraft locate at s of avion be the sopwith 1 1 / 2 strutter (a1010)\n",
      "241 in the pga championship greg norman be 5 top 5 finish and 6 top 10 finish\n",
      "242 the lowest decile be 1\n",
      "243 limpopo have a population with fewer people than eastern cape\n",
      "244 lord 's be the venue when the result be eng by wkt and the date be 10 , 12 , 13 aug 1902 with joe darling as the home captain\n",
      "245 °56′52″ be the declination ( j2000 ) for constellation of ophiuchus and have an apparent magnitude less than 8.6 with a right ascension ( j2000 ) of 16h47 m14.5s\n",
      "246 the minardi team spa use the minardi m187 chassis 5 out of the 8 time they enter between 1985 and 1987\n",
      "247 tim duncan be the lead athlete when the spur play the king\n",
      "248 more game start at 1:00 pm than at any other time\n",
      "249 the original air date of the episode with a production code of 3x6316 be february 21 , 2011\n",
      "250 iran end up in the top 5 in 7 of the 13 year they participate in the game\n",
      "251 jimmy robertson have a higher number of a (not participating in a tournament) in 2003 / 04 than in 2010 / 11\n",
      "252 3 of the musical guest song have the word the in its name\n",
      "253 mike miller score the highest assist and highest rebound 1 time each in november , but never have the highest point\n",
      "254 dieter kindlmann play as a partner in the tournament in rimini , italy\n",
      "255 maria kirilenko nadia petrova win both 2012 and 2013 french open competition\n",
      "256 pick 27 have a name of jaimie thomas who have a round of 7\n",
      "257 the toronto blue jay do not win the first or last game of the season\n",
      "258 the match in australia on 5 september 1998 , the score be 4 - 1\n",
      "259 when the 1st round be 2 - 0 and when team 2 be stade brestois (d1) the score be 5 - 3\n",
      "260 alberta have a more population density even though it have 4257744 less people in 2011\n",
      "261 adriano buzaid have the fastest lap when dean stoneman be the winning driver and alexander sims have the pole position\n",
      "262 there be 8 country that win their first french open men 's double championship before the year 1950\n",
      "263 the ottawa senator boston bruins be the only 2 team the maroon play in back - to - back game against\n",
      "264 colin montgomerie finish with the same score as tom kite\n",
      "265 when the cycle be less than 2 , the premiere date be april 6 , 2008\n",
      "266 detroit red wing be the only team beat with the least record\n",
      "267 jarno trulli be 1 of 2 driver to retire due to collision damage , after only 2 lap\n",
      "268 the hornet start march with more loss than win on their record\n",
      "269 the hawthorn team score the lowest of any of the home team in 1982 while play at prince park\n",
      "270 tim duncan have the highest number of high assist with 12 , and michael finley alone have the lowest number of high assist with 4\n",
      "271 juan manuel fangio be the sole driver who have maserati as their constructor\n",
      "272 when the place be 9th the date be 28 feb 1987 with location furano , japan and when the place be 5th the location be kitzbühel , austria with a date of 17 jan 1986\n",
      "273 the lowest value of paraguayan guaraní issue be 100000\n",
      "274 tony parker have the highest high point (30) and the lowest number of high point (19)\n",
      "275 the most amount of bronze a team with more than 2 silver have be more than 6.0\n",
      "276 sol de américa have 5 loss and be in last place\n",
      "277 the charger end the regular season with a 4 - 12 record in 2003\n",
      "278 in 1981 the yamaha team have 20 point\n",
      "279 the tenth wicket partnership have more than 59 run in the list\n",
      "280 the highest attendance be 2973 on 29 march 2008 and the lowest be 545 on 19 april 2008\n",
      "281 the first leg list for river plate be 0 - 2\n",
      "282 there be 6 stadium that have a limited capacity of 1000 and 2 with a capacity over 10000\n",
      "283 the lowest attendance show in the 2008 afl season be 18875\n",
      "284 south melbourne and essendon tie for the highest score of all team\n",
      "285 the lowest roll in the list of school be the kotemaori school with 6 , follow by mohaka school with 36\n",
      "286 yang (9:43) be first in front of sato (8:32)\n",
      "287 dominik meffert win all of the match list\n",
      "288 3 player be from russia , 2 from czechoslovakia , 4 from canada , and 1 each from sweden and latvia\n",
      "289 most of the people who play for the 1987 master tournament be from united state\n",
      "290 out of 5 game that boston play in 1975 - 1976 , paul west paul score the highest number of point in 3 of the game\n",
      "291 round larger than 2 and a position of guard involve george college\n",
      "292 on september 13 , september 15 , and september 29 the attendance be exactly the same with 50315 crowd\n",
      "293 goal 2 - 5 be all consider 2007 copa américa competition\n",
      "294 the nomad miss the quarter - final in 2010 and 2011\n",
      "295 the shark be pick second for all 6 year\n",
      "296 in the best families be the title when the season be less than 1.8 and first broadcast be march 6 , 1981\n",
      "297 episode 2 , dennis get divorce , be direct by randall einhorn\n",
      "298 india 's rank be tie with england 's\n",
      "299 in the benin and morocco match the final score be 8 - 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(table_loader.dataset)):\n",
    "    print(i, table_loader.dataset[i]['statement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213ddfe",
   "metadata": {},
   "source": [
    "#### show wikitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be89456",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu-3901 Al Unser, Jr. [S['rick mears']]\n",
    "3898 nu-3905 Ludwig Wolf from Germany (GER) [S['ludwig wolf']]\n",
    "3899 nu-3906 2 [N(10.000000)['10']]\n",
    "3903 nu-3910 3 [N(7.000000)['7']]\n",
    "3906 nu-3913 Survey USA [D(2007,12,17)['dec. 17, 2007']]\n",
    "3915 nu-3922 2010 [N(2012.000000)['2012']]\n",
    "3920 nu-3927 N/A [S['l 29-21']]\n",
    "3922 nu-3929 Apollo [S['achilles']]\n",
    "3923 nu-3930 Die heilige Linde [S['walamund']] 下一行存在空行，格式不规范\n",
    "3924 nu-3931 Mr George Hartigan, R West [S['mr brough scott'], S['pat taaffe'], S['beltran osorio'], S['tommy carberry'], S['stan mellor']]\n",
    "3929 nu-3936 0 [N(14.000000)['14 years']]\n",
    "3932 nu-3939 Total number of pasurams [S['thiruvay mozhi']]\n",
    "3934 nu-3941 11 [N(16.000000)['16']]               给的三行有问题，导致sql有问题\n",
    "3937 nu-3944 No data available [S['16:14.1']]\n",
    "3938 nu-3945 Cincinnati, Hamilton [S['cincinnati']]\n",
    "3942 nu-3949 7DY [S['ulverstone']]\n",
    "3944 nu-3951 September 29 at #20 Nebraska [D(-1,9,29)['september 29']]\n",
    "3946 nu-3953 Giuseppe Aquaro [S['rumen trifonov']]\n",
    "3948 nu-3955 Goodbye City...Hello Country [N(1.000000)['1']]\n",
    "3952 nu-3959 3 [N(5.000000)['5']]\n",
    "3956 nu-3963 Above [S['below']]\n",
    "3962 nu-3969 128 [S['decimal128']]\n",
    "3968 nu-3975 2 [N(5.000000)['5']]\n",
    "3970 nu-3977 -18 [N(18.000000)['18']]\n",
    "3977 nu-3984 38 [N(17.000000)['17']]\n",
    "3978 nu-3985 Bob Anderson, Chris Amon [S['dan gurney']]\n",
    "3982 nu-3989 No data from database [S['essentials']]\n",
    "3984 nu-3991 6 [N(5.000000)['5']]\n",
    "3985 nu-3992 John Lenthall [S['laramie']]\n",
    "3990 nu-3997 71,886.6 [N(43674.000000)['43674']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7ea0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5e849345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu-1441\n",
      "who was the first mayor to be inaugurated in witswaterand?\n",
      "+---------+-------------------+----------+--------------------+----------+---------------------+\n",
      "| Year    | Name              | Year_1   | Name_1             | Year_2   | Name_2              |\n",
      "|---------+-------------------+----------+--------------------+----------+---------------------|\n",
      "| 1903-04 | Mr B. Owen- Jones | 1935-36  | Mr W.Pearce        | 1967-68  | Mr J.F.Serfontein   |\n",
      "| 1904-05 | Mr B. Owen- Jones | 1936-37  | Mr W.Pearce        | 1968-69  | Mr Ben Steyn        |\n",
      "| 1905-06 | Mr G. Constable   | 1937 -38 |                    | 1969-70  |                     |\n",
      "| 1907-08 | Mr T.R.Ziervogel  | 1939 -40 | Mr W.E.Vickers     | 1971-72  | Mr Chris Smith      |\n",
      "| 1908-09 | Mr T.R.Ziervogel  | 1940-41  | Mr P.Venter        | 1972-73  | Mr Ben Steyn        |\n",
      "| 1909-10 | Mr J.Morris       | 1941-42  | Mr P.Venter        | 1973-74  | Mr Issy Kramer      |\n",
      "| 1910-11 |                   | 1942-43  | Mr P.Venter        | 1974-75  |                     |\n",
      "| 1911-12 | Mr B.Owen- Jones  | 1943-44  | Mr P.Venter        | 1975-76  | Mr Sakkie Blanche   |\n",
      "| 1912-13 | Mr J.Johnston     | 1944-45  | Mrs E.Myer         | 1977-78  | Mr Sakkie Blanche   |\n",
      "| 1913-14 | Mr J.Cook         | 1945-46  | Mrs E.Myer         | 1978-79  |                     |\n",
      "| 1914-15 | Mr J.Cook         | 1946-47  | Mrs E.Myer         | 1979 -80 | Mr Kobus Durand     |\n",
      "| 1915-16 | Mr R.Champion     | 1947-48  | Mr C.Chambers      | 1980-81  | Mr Meyer            |\n",
      "| 1916-17 | Mr R.Champion     | 1948-49  | Mrs S.Von Wielligh | 1981-82  | Mr Wiek Steyn       |\n",
      "| 1917-18 | Mr A.Ruffels      | 1949-50  | Mr A.J.Law         | 1982-83  | Mr Andrew Wheeler   |\n",
      "| 1918-19 | Mr J.Campbell     | 1950-51  | Mr P.Venter        | 1983-84  |                     |\n",
      "| 1919-20 | Mr B.Melman       | 1951-52  | Mr P.Venter        | 1984-85  |                     |\n",
      "| 1920-21 | Mr B.Melman       | 1952-53  | Mr Vic Pretorius   | 1985-86  | Mr J.Prins          |\n",
      "| 1921-21 | Mr B.Melman       | 1953-54  | Mr Vic Pretorius   | 1986-87  |                     |\n",
      "| 1922-23 | Mr J.Campbell     | 1954-55  |                    | 1987-88  |                     |\n",
      "| 1923-24 |                   | 1954-56  | Mr J.H.A.Roets     | 1988-89  | Mr Beyers De Klerk  |\n",
      "| 1924-25 | Mr E.Murton       | 1956-57  | Mr P.H.Tredoux     | 1989-90  | Mr Gerrie Wolmarans |\n",
      "| 1925-26 | Mr S.Steenberg    | 1957- 58 |                    | 1990-91  | Mr Gerrie Wolmarans |\n",
      "| 1926-27 |                   | 1958-59  | Mr J.M.Cawood      | 1991-92  | Mr TJ Ferreira      |\n",
      "| 1927-28 | Mr J.Stanbury     | 1959-60  | Mr A.P.Scribante   | 1992-93  | Mr Gerrie Wolmarans |\n",
      "| 1928-29 | Mr E.Murton       | 1960-61  | Mr J.L.Viljoen     | 1993-94  | Mr TJ Ferreira      |\n",
      "| 1929-30 | Mr K.Turner       | 1961-62  | Mr J.L.Viljoen     |          |                     |\n",
      "| 1930-31 | Mr J.E.Bigwood    | 1962-63  | Mrs S.Von Wielligh |          |                     |\n",
      "| 1931-32 | Mr A.Zaretsky     | 1963-64  | Mr F.J.Van Heerden |          |                     |\n",
      "| 1932-33 | Mr G.J.Malan      | 1964-65  |                    |          |                     |\n",
      "| 1933-34 |                   | 1965-66  |                    |          |                     |\n",
      "| 1934-34 |                   | 1966-67  | Mr H.McLennan      |          |                     |\n",
      "+---------+-------------------+----------+--------------------+----------+---------------------+\n",
      "['Mr B. Owen- Jones']\n"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "i = 1441\n",
    "def show_table(data, execute=False):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['id'])\n",
    "    print(data['query'])\n",
    "    print(formatter.format_psql())\n",
    "    # print(preds[i])\n",
    "    # print(SQLs[i])\n",
    "    # test_df = manager.execute_from_df(SQLs[i], formatter.all_data)\n",
    "    # print(test_df)\n",
    "    print(data['label'])\n",
    "\n",
    "show_table(table_loader.normalize_table(table_loader.dataset[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b60ca2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = []\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    if table_loader.dataset[i]['table']['name'] not in table_name:\n",
    "        table_name.append(table_loader.dataset[i]['table']['name'])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0f19b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 how many total orbit pairs are there?\n",
      "1 the two level 6 seasons were 2012/13 and what other season?\n",
      "2 which year had an average population of less than 38?\n",
      "3 how many awards were handed out in 2004?\n",
      "4 what was the most consecutive losses for the mercury in this season?\n",
      "5 which year had less votes,1994 or 2009?\n",
      "6 when was the first season that the team was in tier 6?\n",
      "7 how many songs were juried about eight?\n",
      "8 how many games were played in the month of november\n",
      "9 how many encodings have a decimal above 200 for the capital letter em?\n",
      "10 what municipality is on average 25 km away?\n",
      "11 to which team did charleston southern give up at most 40 points?\n",
      "12 what was the first year that the romanian population was less than 51,000?\n",
      "13 the films beladingala baale and sparsha have which award in common?\n",
      "14 how many stations opened before 1926?\n",
      "15 what was the date of the only match to occur in sapporo, japan?\n",
      "16 how many parties had more than 50 seats in the third duma?\n",
      "17 which country won the gold medal?\n",
      "18 what is the number of plants in ohio?\n",
      "19 how many days did ultimo gladiador and ultimo vampiro hold the title?\n",
      "20 what is the number of losses for dinamo tiranë\n",
      "21 how many times was the venue vasil levski national stadium used?\n",
      "22 what was the number of competitors during the 1995 finals?\n",
      "23 who received more points, alex debon or toni elias?\n",
      "24 how many games went into ot or overtime?\n",
      "25 how many countries appear more than once on the chart?\n",
      "26 how many times after the year 1989 did she come in 1st position?\n",
      "27 how many 'choice tv sidekick' award categories was scrubs nominated for?\n",
      "28 four corners has 13 premierships listed, what was their nickname?\n",
      "29 in what season did they finish in first place?\n",
      "30 what sport has more silver medals: wrestling or rowing\n",
      "31 which category does each train have in common?\n",
      "32 which games had an attendance of below 14,000?\n",
      "33 what were the most points scored by the losing team?\n",
      "34 what was the game next after birmingham city on november 6th?\n",
      "35 how many delegates are under the democratic party who represented the frederick county?\n",
      "36 which two buildings have the same number of floors as bsnl tower and som business square?\n",
      "37 lucy millard and lynsey harley were both from which nation?\n",
      "38 how many athletes had times that were at least 8 minutes?\n",
      "39 what group has under 40 members but at least 2 caucusing?\n",
      "40 how many total assists per game did 2013 eurobasket have?\n",
      "41 what is the number of countries listed in the table\n",
      "42 who had the least amount of attendees?\n",
      "43 which player competed in women's singles and won a silver medal?\n",
      "44 how many awards did kang ji-hwan win after 2010?\n",
      "45 which defendant received the same sentence as reginald shaffer?\n",
      "46 the date previous to june 14th 1993\n",
      "47 what was the largest prize awarded to soviet song in 2004?\n",
      "48 which team scored the highest number of ranking points in games that were won on penalties?\n",
      "49 what is the number of riders listed?\n",
      "50 did austria win more games in 1992 or 1996?\n",
      "51 what km comes after 8.25, but before\n",
      "52 which institutions have more than 2,000 enrollment?\n",
      "53 did the wycombe wanderers have more or less points than the plymouth argyle?\n",
      "54 what year did usl a-league finish 1st?\n",
      "55 how many division 1 teams were founded before 1950?\n",
      "56 what is the season listed after 2002?\n",
      "57 which artist was first in point after nunzio gallo?\n",
      "58 how many presidents were part of the whig party?\n",
      "59 how many songs sung were by cláudio zoli?\n",
      "60 who was the opponent previous to the south georgia wildcats?\n",
      "61 what is he largest points scored in one game?\n",
      "62 what country had the top number of silver medals?\n",
      "63 how long does this table cover in years?\n",
      "64 did she get the same award in 2005, as she did in 2006?\n",
      "65 how many gold and silver medals in total did china receive?\n",
      "66 what was the last team to win in the first round proper?\n",
      "67 in total, how many athlete medal leaders are from the united states?\n",
      "68 which country has had the most men's winners?\n",
      "69 which game had only the driving genre?\n",
      "70 where was the match held immediately before 2014's at guizhou olympic stadium?\n",
      "71 how many times is in service listed as the status?\n",
      "72 what was the last bridge built?\n",
      "73 what is the difference in win pct under fred jordan and chal port?\n",
      "74 how many songs are longer than 3:00?\n",
      "75 on which date did the bombers score the least points?\n",
      "76 which rifle has the longest barrel?\n",
      "77 who is the top in giant slalom\n",
      "78 which terminal had more quay cranes than terminal 6?\n",
      "79 how many priests were in service between 1845 and 1912?\n",
      "80 how many consecutive games were released in 2006?\n",
      "81 how long did it take the german team to finish the race?\n",
      "82 name two people whose height is at least 174 cm\n",
      "83 what amount of people, at most, can begin arena hold?\n",
      "84 what was the score of the first game blackpool played in?\n",
      "85 who shot the highest single round?\n",
      "86 kazakhstan had a position of 23rd in 1999 world championships and what other competition?\n",
      "87 how many airlines have at least three service dates?\n",
      "88 what is the difference between the number of onthophagus obliquus species released and the number of sisyphus rubrus paschalidis released?\n",
      "89 what movie was the highest grossing film the most consecutive weekends?\n",
      "90 what was the most goals scored in one game?\n",
      "91 which year(s) saw the greatest average audience share?\n",
      "92 how many cyclists withdrew before stage 6?\n",
      "93 what is the number of tracks that have no songwriters?\n",
      "94 what was the first game which was won with a score over 70 points?\n",
      "95 what was the last title that sid marcus directed?\n",
      "96 number of wins in the season.\n",
      "97 which party had the most candidates win in this election?\n",
      "98 who produced the track \"no main topic\"?\n",
      "99 what is the number of flag bearers?\n",
      "100 what is the total number of players listed in the table?\n",
      "101 which album did not have more than one song reach the charts?\n",
      "102 which countries each won 3 gold medals?\n",
      "103 which duke has the same date of creation as the duke of coimbra?\n",
      "104 what is the next destination after limestone road north?\n",
      "105 which player is listed first in the table?\n",
      "106 which original work from gaetano donizetti did liszt adapt after adapting opera lucrezia borgia?\n",
      "107 what the number of seats that are in fairfax park?\n",
      "108 which other athlete from the us ahs the same amount of gold medals as seth wescott?\n",
      "109 who was the last team to win?\n",
      "110 in which year was only top ten ranking in monetary earnings recorded?\n",
      "111 what is the number of silver medals won by italy?\n",
      "112 what is the total number of years ele opeloge was the samoa flag bearer at the olympics?\n",
      "113 what is the number of shows on the list?\n",
      "114 which party won the top place in the election?\n",
      "115 what was the name of the ship that was built after the jule in this yard?\n",
      "116 which country has the highest total in the miss supranational pagent?\n",
      "117 who had the next highest number of gold medals after the unites states?\n",
      "118 who won the race in 2014?\n",
      "119 how many assists did the top three have in total?\n",
      "120 did elvir rhimic score more goals during his time in the anxhi makhachkala club or the cska moscow club?\n",
      "121 which is the first latin name on the chart\n",
      "122 how many rankings are there?\n",
      "123 did china or north korea obtain 5 silver medals?\n",
      "124 how many losses from 1984 to 1988\n",
      "125 how many goals did olle ahlund score?\n",
      "126 what kind of power has the least amount of capacity in 2007?\n",
      "127 what was the total prize money earned by contestants?\n",
      "128 what was the only album she produced with the slow motion orchestra?\n",
      "129 which high school left the same year as fenton high school?\n",
      "130 who has competed more years, cuba or canada?\n",
      "131 how long was charlton athletic in administration?\n",
      "132 the most number of days an australian prime minister was in office was how many days?\n",
      "133 other than 1977, what year had 53 maps?\n",
      "134 was the white spruce used in 1985 from michigan or minnesota?\n",
      "135 which player got the most yards?\n",
      "136 which artist has the least highest position?\n",
      "137 name the device above intel x25-e\n",
      "138 who was in the last position?\n",
      "139 how long in years total have they played level tier 4?\n",
      "140 what was the number of awards received by nancy cartwright for her voice work on the simpsons between 1992 and 2011.\n",
      "141 what country finished after the netherlands?\n",
      "142 how many students are enrolled at navy?\n",
      "143 the average silver medal count of the first five ranked nations?\n",
      "144 how many communities are based in africa?\n",
      "145 which festival participated for three consecutive awards?\n",
      "146 how many independent candidates were on the ballot for alderman in 1919?\n",
      "147 what is the only department witj 5 total deputies\n",
      "148 what team comes before hank stein?\n",
      "149 tell me a scorer that had at least 3 scores in cfu club championships.\n",
      "150 how many locations were listed in total?\n",
      "151 what is the difference of points in the game between birmingham city and wrexham?\n",
      "152 the team with the most international caps\n",
      "153 which party received the least votes?\n",
      "154 how many people at most are american?\n",
      "155 what club is after the sevilla fc?\n",
      "156 did tianjin teda or qingdao jonoon have a higher average attendance?\n",
      "157 what company has the top revenue?\n",
      "158 how many films were made by 20th century fox studios?\n",
      "159 how many club presidents held their position in the 19th century?\n",
      "160 which was built at the same time as the lou higgens center?\n",
      "161 how many athletes were faster than bill chisholm?\n",
      "162 how many wrestlers do not have any notes?\n",
      "163 which product as rdf for input or output\n",
      "164 how many landmarks are in the hannover square historic district?\n",
      "165 what is the last recorded ship sunk on august 25?\n",
      "166 how many nations scored more total medals than brazil?\n",
      "167 what is the number of times belgrade is listed as the city?\n",
      "168 sir john a. macdonald and pierre trudeau both held what job in canada?\n",
      "169 other new replacement chosen in april 2009 besides kij meesrisuk\n",
      "170 name the species that has the longest years since divergence from human.\n",
      "171 who lived longer evelyn irons or arturo islas?\n",
      "172 how many teams earned winnings above $100,000 between 1986-1996?\n",
      "173 name a racer that was the winning rider in two consecutive races.\n",
      "174 what nation did the competitor represent?\n",
      "175 which county did mccain have the least amount of votes?\n",
      "176 what is the greatest number of points this team has won by?\n",
      "177 how many places have no zip code listed?\n",
      "178 based on the table of brazil's results at the fifa world cup between 1930 and 2010, in which listed year did brazil play on average only a single match in round 1?\n",
      "179 who was the last deputy judge with finland nationality?\n",
      "180 which country is last on the table?\n",
      "181 which township has the least water area in miles?\n",
      "182 who won the highest amount of rugby matches between new zealand and wales for the last 100 years?\n",
      "183 at least how many parties have won?\n",
      "184 the first car that murphy used in the new zealand v8 supercar\n",
      "185 what model is listed next after tr-2?\n",
      "186 what is the total number of divisions on the chart?\n",
      "187 which year had more deaths, 1998 or 2006?\n",
      "188 what year were prose accessits awarded to the largest number of people?\n",
      "189 how many times out of the 8 matches did the home team win?\n",
      "190 what was the total attendance for the september 19th, 1984 game?\n",
      "191 which party obtained the largest percentage of votes in the 1996 forum?\n",
      "192 list the first year more than 2000 jamaicans were granted british citizenship.\n",
      "193 how many trains are demu category?\n",
      "194 how many points did portugal score in the 1994 europeans men's handball championship preliminary round?\n",
      "195 which united states president appointed the most ambassador's to mexico\n",
      "196 what wrestler held the title the longest?\n",
      "197 how many goals were scored against spain on november 2005?\n",
      "198 how many gold's has brazil won?\n",
      "199 other nation to earn no bronze medals besides peru\n",
      "200 how many consecutive companies had no notes listed?\n",
      "201 what was the first year in which the result was 1st place?\n",
      "202 who is the only wrestler to have only 1 combined day?\n",
      "203 how many riders scored at least 10 final points?\n",
      "204 how many times did this player play in lionel roberts park?\n",
      "205 what are the number of times taito is listed as the manufacturer?\n",
      "206 which player was not a free agent?\n",
      "207 which timberline lodge lift other than the magic mile express has a slope of 20% or greater?\n",
      "208 which results were listed the most under the playoffs column?\n",
      "209 what is the difference in number between the uninominal deputies from potosí and beni?\n",
      "210 how much longer has the north carolina wolfpack been around compared to the tar heels?\n",
      "211 what is the number of awards that arisan won in 2004?\n",
      "212 in which venue was the next performance after the one at verdun auditorium?\n",
      "213 what is the total number of yachts launched in 2001?\n",
      "214 how many times was skrein listed as an artist on a song?\n",
      "215 how many shows won drama desk awards?\n",
      "216 how many different chokes are there that start with an s\n",
      "217 how many years are listed in this competition record chart?\n",
      "218 how many total managers has there been?\n",
      "219 what livery is listed previous to blackpool tramway green and cream?\n",
      "220 how many concerts in washington state?\n",
      "221 which church is listed below christ the king?\n",
      "222 what type of show is running man?\n",
      "223 what is the number of awards she won total for the album whitney?\n",
      "224 how many canadian drivers finished in at least 10th position or better?\n",
      "225 where did they play after the april 5, 2005 game in reading?\n",
      "226 after 'lejila' what was malberg's next film?\n",
      "227 what year what his busiest year with the most roles?\n",
      "228 the artist with the first letter k\n",
      "229 how many relegations did andrea costa imola undergo?\n",
      "230 where was the last match played?\n",
      "231 on what date did the eagles score the least points?\n",
      "232 what party was the last provincial representative of gilbert plains?\n",
      "233 how many locomotives are on display at the narrow gauge railway museum?\n",
      "234 which athlete from poland had the lowest time?\n",
      "235 before rudhra gangadharan, how many directors were before him?\n",
      "236 how many total wins did the team have in 1949?\n",
      "237 was the wang xin ranked above or below qiu lianhai?\n",
      "238 what club is listed next to june 4, 1972?\n",
      "239 how many individual stations are at the times square station complex?\n",
      "240 which buildings have the same number of floors as at least two others?\n",
      "241 which player was the only one drafted from finland?\n",
      "242 what team is first on the list?\n",
      "243 how long was arthur berry in officer for?\n",
      "244 which date has the most attendance?\n",
      "245 which year's were the most japanese titles produced?\n",
      "246 what song got the same points as straatdeuntje?\n",
      "247 which record on the chart was set earlier, the 200 or 400 m?\n",
      "248 on what date did they play the broncos but end up losing the game?\n",
      "249 when was his last match?\n",
      "250 how many competitors did not start the race at all?\n",
      "251 what was the total number of destroyers completed in august 1939?\n",
      "252 what is the number of world championships?\n",
      "253 which driver scored the most points?\n",
      "254 how many medals did france and cuba win?\n",
      "255 tell me the number of times they qualified for the playoffs.\n",
      "256 which team finished last in this conference this season?\n",
      "257 which episode aired in the same month as \"antarctica\"?\n",
      "258 how many summer flag bearers have there been?\n",
      "259 who was the only titleholder to reach the top 15 at miss world?\n",
      "260 how many years after sir carne rasch's election was john macnamara elected?\n",
      "261 what is the top company that has the most employees?\n",
      "262 which country comes in first place?\n",
      "263 who was the first president in the 1900's?\n",
      "264 name a country that only had one of each kind of medal.\n",
      "265 what is the total number of awards that he has won?\n",
      "266 what paul nix or hal baird coach in 1986?\n",
      "267 which country took the least amount of time?\n",
      "268 what is the number of networks accounted for in this chart?\n",
      "269 how many creatures are on page 40?\n",
      "270 name the male/female winners in the 1996 budapest half marathon.\n",
      "271 what was the total number of points for the medal winners?\n",
      "272 how many guards were picked?\n",
      "273 did he score more tds with the los angeles rams or with indianapolis colts?\n",
      "274 tell me the number of trains headed for jolarpet junction.\n",
      "275 name a team that scored more than 8 points.\n",
      "276 who is the last athlete?\n",
      "277 how many honda motorcycles completed the race?\n",
      "278 how many games has chorrillo f.c. won?\n",
      "279 how many championships had at most 900 previous points.\n",
      "280 which year did dickerson earn the most rushing yards?\n",
      "281 how many crayons in crayola's crayons with glitter set include twinkling turquoise glitter?\n",
      "282 how many teams won at most 50% of their games?\n",
      "283 how many total laps did alex figge complete?\n",
      "284 what was the total number of countries that the england women's rfu played against?\n",
      "285 what month would someone attend a game if they wanted to celebrate his/her birthday close to christmas?\n",
      "286 how many draws did ibv have?\n",
      "287 what was the first gain on may 30th, 1963?\n",
      "288 how many teams won by a margin of two or more points?\n",
      "289 how many consecutive games did jay mills lose to fbs opponents?\n",
      "290 which airliner attack on the list had the most dead?\n",
      "291 how many games were played in the regular season?\n",
      "292 which year saw the largest population of tower division during this time?\n",
      "293 which author wrote \"two loves i have, of comfort and despair\", and \"on a day (alack the day)\"?\n",
      "294 was kiki jones picked before or after greg gohr?\n",
      "295 before the jackson state loss, when was their last loss?\n",
      "296 which game did illinois score more points, the first or last?\n",
      "297 who is listed previous to prue watt?\n",
      "298 what country has the least number of rifles in service?\n",
      "299 what is the total number of games played in november?\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(table_loader.dataset['question']):\n",
    "    print(ind, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1301213",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 1014 is out of bounds for size 300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# sum, ope = split_answer(data[ind]['predict'])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print(ope)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(manager.format_sql(ope, table_name='DF'))\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m show_table(table_loader\u001b[38;5;241m.\u001b[39mnormalize_table(\u001b[43mtable_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)) \n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_sql[i])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_data[i])\n",
      "File \u001b[0;32m~/.conda/envs/sqlboy/lib/python3.10/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sqlboy/lib/python3.10/site-packages/datasets/arrow_dataset.py:2787\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2786\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2787\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2788\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2789\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2790\u001b[0m )\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.conda/envs/sqlboy/lib/python3.10/site-packages/datasets/formatting/formatting.py:583\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 583\u001b[0m     \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/sqlboy/lib/python3.10/site-packages/datasets/formatting/formatting.py:526\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size):\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 1014 is out of bounds for size 300"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "table_loader = TableLoader(table_name='sqa', split='test', use_sample=True)\n",
    "i = 1014\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['id'])\n",
    "    print(data['query'])\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # sum, ope = split_answer(data[ind]['predict'])\n",
    "    # print(ope)\n",
    "    # print(manager.format_sql(ope, table_name='DF'))\n",
    "show_table(table_loader.normalize_table(table_loader.dataset[i])) \n",
    "print(all_sql[i])\n",
    "print(all_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860f3ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7e1daa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# show table query\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#debugger\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableFormat, TableLoader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexecutor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLManager\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'"
     ]
    }
   ],
   "source": [
    "# show table query\n",
    "#debugger\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True)\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['statement'])\n",
    "    print(data['table']['caption'])\n",
    "    # print(formatter.format_html())\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # data.columns = [manager.normalize_col_name(c) for c in formatter.all_data.columns]\n",
    "    # data.to_sql('DF', manager.engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # subtable = pd.read_sql(command, self.engine)\n",
    "    # test_df = manager.execute_from_df(SQL, formatter.all_data)\n",
    "    # return test_df\n",
    "# test_df = show_table(table_loader.dataset[i])\n",
    "show_table(table_loader.dataset[130])\n",
    "for ind, i in enumerate(table_loader.dataset['statement']):\n",
    "    print(ind, i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769844d",
   "metadata": {},
   "source": [
    "### Evaluate Tabfact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e93c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_yes_no_and_map(text):\n",
    "    # Convert the input text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "\n",
    "    # Define regular expressions for yes/no matching\n",
    "    yes_patterns = [r'\\byes\\b', r'\\btrue\\b']\n",
    "    no_patterns = [r'\\bno\\b', r'\\bfalse\\b']\n",
    "\n",
    "    # Check for \"0\"\n",
    "    if text == \"0\":\n",
    "        return \"0\"\n",
    "\n",
    "    # Check for \"1\"\n",
    "    if text == \"1\":\n",
    "        return \"1\"\n",
    "\n",
    "    # Check for yes\n",
    "    for pattern in yes_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"1\"\n",
    "\n",
    "    # Check for no\n",
    "    for pattern in no_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"0\"\n",
    "\n",
    "    # Return 2 if neither yes nor no is found\n",
    "    return \"2\"\n",
    "\n",
    "def eval_fv_match(pred_list, gold_list):\n",
    "        acc = 0.0\n",
    "        for pred, gold in zip(pred_list, gold_list):\n",
    "            pred, gold = extract_yes_no_and_map(pred), extract_yes_no_and_map(gold)\n",
    "            if pred == gold:\n",
    "                acc += 1\n",
    "        acc = acc / len(pred_list)\n",
    "        return acc\n",
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beb5558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TableLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m table_loader \u001b[38;5;241m=\u001b[39m \u001b[43mTableLoader\u001b[49m(table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtabfact\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, use_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, small_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(table_loader\u001b[38;5;241m.\u001b[39mdataset)):\n\u001b[1;32m      4\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(table_loader\u001b[38;5;241m.\u001b[39mnormalize_table(table_loader\u001b[38;5;241m.\u001b[39mdataset[i])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TableLoader' is not defined"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    labels.append(table_loader.normalize_table(table_loader.dataset[i])['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73609ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadb87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fbec8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('./result/answer/tabfact_05-15_10-56-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2517a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.concat([data3, data4]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "438ab99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>statements</th>\n",
       "      <th>ids</th>\n",
       "      <th>tokens</th>\n",
       "      <th>extra</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To verify whether the claim is true or false, ...</td>\n",
       "      <td>the sweet dream episode happen later in the se...</td>\n",
       "      <td>0</td>\n",
       "      <td>8860</td>\n",
       "      <td>When did the sweet dream episode happen in the...</td>\n",
       "      <td>To verify whether the claim is true or false, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The SQL query is filtering the table DF for ro...</td>\n",
       "      <td>david moore direct 3 episode of series 2 of me...</td>\n",
       "      <td>1</td>\n",
       "      <td>8064</td>\n",
       "      <td>How many episodes of series 2 of Merlin did Da...</td>\n",
       "      <td>The SQL query is filtering the table DF for ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The SQL query is filtering the data from the t...</td>\n",
       "      <td>the lady of the lake episode have the most uk ...</td>\n",
       "      <td>2</td>\n",
       "      <td>7948</td>\n",
       "      <td>Which episode has the most UK viewers?;What i...</td>\n",
       "      <td>The SQL query is filtering the data from the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To verify the claim, we need to check the \"DF\"...</td>\n",
       "      <td>lucy watkins only write 1 episode of series 2</td>\n",
       "      <td>3</td>\n",
       "      <td>7887</td>\n",
       "      <td>How many episodes did lucy watkins write for s...</td>\n",
       "      <td>To verify the claim, we need to check the \"DF\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The SQL query is filtering the dataframe DF to...</td>\n",
       "      <td>beauty and the beast (part 2) have more uk vie...</td>\n",
       "      <td>4</td>\n",
       "      <td>8096</td>\n",
       "      <td>how many UK viewers did each part of Beauty an...</td>\n",
       "      <td>The SQL query is filtering the dataframe DF to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               preds  \\\n",
       "0  To verify whether the claim is true or false, ...   \n",
       "1  The SQL query is filtering the table DF for ro...   \n",
       "2  The SQL query is filtering the data from the t...   \n",
       "3  To verify the claim, we need to check the \"DF\"...   \n",
       "4  The SQL query is filtering the dataframe DF to...   \n",
       "\n",
       "                                          statements  ids  tokens  \\\n",
       "0  the sweet dream episode happen later in the se...    0    8860   \n",
       "1  david moore direct 3 episode of series 2 of me...    1    8064   \n",
       "2  the lady of the lake episode have the most uk ...    2    7948   \n",
       "3      lucy watkins only write 1 episode of series 2    3    7887   \n",
       "4  beauty and the beast (part 2) have more uk vie...    4    8096   \n",
       "\n",
       "                                               extra  \\\n",
       "0  When did the sweet dream episode happen in the...   \n",
       "1  How many episodes of series 2 of Merlin did Da...   \n",
       "2   Which episode has the most UK viewers?;What i...   \n",
       "3  How many episodes did lucy watkins write for s...   \n",
       "4  how many UK viewers did each part of Beauty an...   \n",
       "\n",
       "                                        final_answer  \n",
       "0  To verify whether the claim is true or false, ...  \n",
       "1  The SQL query is filtering the table DF for ro...  \n",
       "2  The SQL query is filtering the data from the t...  \n",
       "3  To verify the claim, we need to check the \"DF\"...  \n",
       "4  The SQL query is filtering the dataframe DF to...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3fb0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../result/answer/tabfact_zh_04-25_15-42-17.csv')\n",
    "data2 = pd.read_csv('../result/answer/tabfact_05-13_08-47-41.csv')\n",
    "data3 = pd.read_csv('./result/answer/tabfact_05-16_02-20-54.csv')\n",
    "data['final_answer'] = data['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n",
    "data2['final_answer'] = data2['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n",
    "data3['final_answer'] = data3['preds'].apply(lambda x: x.split('Answer:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d9fbf22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds = []\n",
    "ids = []\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "for i, row in data3.iterrows():\n",
    "    ids.append(row['ids'])\n",
    "    labels.append(table_loader.normalize_table(table_loader.dataset[int(row['ids'])])['label'])\n",
    "    preds.append(row['final_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a00b6f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The SQL query is filtering the data from the table DF to only include the episode titled \"the lady of the lake\" and then finding the maximum number of UK viewers for that episode.\\n\\nBased on the sub-table generated by the SQL, it shows that the episode \"the lady of the lake\" indeed has the maximum UK viewers of 6.3 million.\\n\\nTherefore, the provided claim/query is true.\\n\\nReturn: 1'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a6447fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367139959432048"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_fv_match(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8de58485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********1***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, it appears that David Moore did not direct any episodes of series 2 of Merlin. Therefore, the answer to the query is 0 episodes.\n",
      "Answer: 0\n",
      "[' Which episodes did David Moore direct for series 2 of Merlin?', 'How many episodes did David Moore direct for series 2 of Merlin?', 'how many episodes of series 2 of Merlin did David Moore direct?']\n",
      "********3***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Lucy Watkins wrote 0 episodes for series 2. \n",
      "Answer: 0\n",
      "[' Which episode did Lucy Watkins write for series 2?', 'how many episodes of series 2 did lucy watkins write?', 'How many episodes did Lucy Watkins write for series 2?']\n",
      "********8***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the condition of Lucy Watkins writing 6 episodes of series 2. \n",
      "Answer: 1\n",
      "['how many episodes did lucy watkins write for series 2?', 'How many episodes did Lucy Watkins write for series 2?', ' Which episodes did Lucy Watkins write for series 2?']\n",
      "********11***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the player who scored 4 more goals than Matías Suárez in the Belgian First Division A league and also played in the Belgian Cup is the next highest rank player in the league.\n",
      "Answer: 0\n",
      "['How many goals did Jonathan Legear and Matías Suárez score in the Belgian First Division A league and the Belgian Cup?', 'How many goals did Jonathan Legear score in the Belgian First Division A league?', ' How many goals did Matías Suárez score in the Belgian First Division A league?']\n",
      "********12***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Jonathan Legear scored 7 goals, and the other players combined to score a total of 68 goals. Therefore, Jonathan Legear scored more goals than the other players combined.\n",
      "Answer: 1\n",
      "[' How many goals did Jonathan Legear score?', 'which player scored the most goals in the Belgian cup?', 'How many players are there who play in the Belgian cup?', ' How many goals did the other players combine to score?']\n",
      "********13***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Guillaume Gillet scored 9 goals, Thomas Chatelle scored 4 goals, and Jelle Van Damme scored 3 goals in the UEFA Champion League tournament. Guillaume Gillet scored 3 times as much as Thomas Chatelle and 3 times as much as Jelle Van Damme.\n",
      "Answer: 1\n",
      "['How many goals did Guillaume Gillet score in the UEFA Champion League tournament compared to the other two players?', ' How many goals did each of the other 2 players score in the UEFA Champion League tournament?', 'How many goals did Guillaume Gillet score in the UEFA Champion League tournament?']\n",
      "********14***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the top scorer in the Belgian first division is Mbark Boussoufa with 11 goals, and Matias Suarez scored 3 goals. Therefore, the claim that the top scorer (Matias Suarez) has 8 fewer goals than Mbark Boussoufa is false.\n",
      "Answer: 0\n",
      "['', ' How many goals did Matias Suarez score in the Belgian first division?', 'Who is the top scorer in the Belgian first division?', 'who is the top scorer in the Belgian first division and how many goals did they score?']\n",
      "********19***************\n",
      "0 1\n",
      "Thought: The SQL query provided filters the players from the Belgian first division who have either 11 or 3 goals. The players are Mbark Boussoufa, Matías Suárez, and Bart Goor. The extra information states that Mbark Boussoufa has 11 goals, Matías Suárez has 3 goals, and Bart Goor has 1 goal. The top scorer in the Belgian first division is Mbark Boussoufa with 11 goals. Matías Suárez has 5 fewer goals than Bart Goor.\n",
      "Answer: 1\n",
      "[' How many goals does Bart Goor have?', ' How many goals does Matias Suarez have?', 'Who is the top scorer in the Belgian first division?', 'who are the top scorers in the Belgian first division and how many goals did they score?']\n",
      "********20***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, 3 people tied for ninth place in the United States. However, based on the sub-table, there were actually 4 people who tied for ninth place, not 3.\n",
      "Answer: 0\n",
      "[' How many people from the United States tied for ninth place?', 'which players tied for ninth place?', 'How many people tied for ninth place?']\n",
      "********21***************\n",
      "1 0\n",
      "Thought: The sub-table only provides the count of people who scored under par from the United States. It does not provide the count of people who scored under par from other countries. Therefore, the query cannot be answered based on the given sub-table.\n",
      "Answer: 0\n",
      "['which players scored under par and what country are they from?', 'How many people who scored under par were from the United States?', ' How many people who scored over par were from the United States?']\n",
      "********22***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the average score for players from Japan is 70. The average score for players from Japan is 70, not 281.\n",
      "Answer: 0\n",
      "[' What is the average to_par for players from Japan?', 'What is the average score for players from Japan?', 'What is the average score for players from each country?']\n",
      "********24***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the maximum amount of money won by someone from Wales was 67823. However, the winner received 200,000 units of money, and the player who won the most amount of money is Curtis Strange, not someone from Wales.\n",
      "Answer: 0\n",
      "[' How much money did the winner receive?', 'how much money did the player from wale win?', 'Who won the most amount of money?']\n",
      "********37***************\n",
      "1 0\n",
      "Thought: The SQL query filters the data to show players who come from either a college program or a junior/club team. The sub-table shows that there is no data from the database. \n",
      "Answer: 0\n",
      "[' What is the college, junior, or club team for Rob Bellamy?', 'where do the players come from?', 'What is the college, junior, or club team for Ladislav Scurko?']\n",
      "********41***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the West Berkshire Brewery's Dr Hexter Healer beer won a total of 4 gold medals between 1995 and 2009. Therefore, the claim that it won 3 gold medals is false.\n",
      "Answer: 0\n",
      "[\"how many gold medals did west berkshire brewery's dr hexter healer beer win between 1995 and 2009?\", \" How many gold medals did west berkshire brewery's dr hexter healer beer win between 1995 and 2009?\", \"How many gold medals did west berkshire brewery's dr hexter healer beer win between 1995 and 2009?\"]\n",
      "********43***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, 3 of West Berkshire Brewery's beers each won a single award between 1995 and 2009. The beers are \"Dr Hexter's Wedding Ale,\" \"Mash Tun,\" and \"Old Father Thames.\" Each of these beers won a single award during this time period.\n",
      "Answer: 1\n",
      "[\"What awards did west berkshire brewery's beer win between 1995 and 2009?\", \" How many awards did west berkshire brewery's beer win between 1995 and 2009?\", 'Which beers from West Berkshire Brewery won awards between 1995 and 2009?']\n",
      "********49***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that only 1 game was played at the US Airways Center with the same attendance. Therefore, the claim that 3 of the games at the US Airways Center have the same attendance is false.\n",
      "Answer: 0\n",
      "['how many games at the us airways center have the same attendance?', 'Which games were played at the US Airways Center?', ' How many games were played at the US Airways Center?']\n",
      "********61***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Linda Fratianne was ranked in first place and Anett Pötzsch was ranked in second place in the 1979 world figure skate championship.\n",
      "Answer: 0\n",
      "['Who won the 1979 world figure skate championship and who was ranked in second place?', ' Who was ranked in second place in the 1979 world figure skate championship?', 'Who won the 1979 world figure skate championship?']\n",
      "********64***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Emi Watanabe was ranked third in the 1979 world figure skate championship. This is 1 place higher than Dagmar Lurz, who was ranked 4th.\n",
      "Answer: 1\n",
      "['Who was ranked third in the 1979 world figure skate championship?', ' Who was ranked fifth in the 1979 world figure skate championship?', 'what is the ranking of emi watanabe and dagmar lurz in the 1979 world figure skate championship?']\n",
      "********66***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Linda Fratianne finished in first place, and Anett Pötzsch did not manage to get in the top 3.\n",
      "Answer: 1\n",
      "[' Who did not manage to get in the top 3?', 'Who finished in first place?', 'Which skater finished in first place and which skater did not manage to get in the top 3?']\n",
      "********80***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the highest score of the season for Detroit was 5, achieved on January 22nd. The claim that the highest score of the season for Detroit was on January 5th with 6 points is false.\n",
      "Answer: 0\n",
      "[' When did Detroit score the highest in the season?', 'What was the highest score of the season for Detroit?', 'what was the highest score of the season and which team achieved it?']\n",
      "********84***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Detroit tied for the highest home team score 2 times. The highest home team score in the game is 4. The team that tied for the highest score in a game is \"detroit\". Therefore, the claim is true.\n",
      "Answer: 1\n",
      "[' How many times did Detroit tie for the highest home team score?', 'What is the highest home team score in the game?', 'which team tied for the highest score in a game?']\n",
      "********85***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the minimum score for Detroit in January was 1 - 2. This is the lowest score for Detroit in January.\n",
      "Answer: 1\n",
      "[' What is the score of the game between Detroit and Dallas on January 26?', 'What is the score of the game between Detroit and Los Angeles on January 22?', 'which team had the lowest score by late January?']\n",
      "********87***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the query filters the data to only show scores that contain a hyphen, which indicates a tie. The sub-table shows that there are two instances where there is a tie in the score. \n",
      "Answer: 1\n",
      "['How many times was there a tie for the largest point gap during the season?', 'how many times was there a tie for the largest point gap during the season?']\n",
      "********89***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the names Ilir Meta, Bashkim Fino, and Pandeli Majko (1st time) are all members of the socialist party of Albania political party. Ylli Bufi is not included in the sub-table.\n",
      "Answer: 0\n",
      "[' Was Bashkim Fino a member of the socialist party of albania political party?', 'which members were part of the socialist party of albania political party?', 'Was Ilir Meta a member of the socialist party of albania political party?']\n",
      "********101***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the player James Donaldson had 1 stint on the Jazz's roster. \n",
      "Answer: 0\n",
      "[' How many years did Adrian Dantley play for the Jazz?', \"how many stints did each player have on the jazz's roster?\", 'How many years did James Donaldson play for the Jazz?']\n",
      "********121***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the count of viral families with a helical virion shape is 7. \n",
      "Answer: 1\n",
      "['how many viral families have a helical virion shape?', 'Which viral families have a helical virion shape?']\n",
      "********129***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there are 7 viral families that have a helical virion shape. \n",
      "Answer: 1\n",
      "['Which viral families have a helical virion shape?']\n",
      "********133***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the table shows the different virion shapes of viral diseases. The table does not include any viral diseases with a spherical virion shape.\n",
      "Answer: 1\n",
      "['what are the different virion shapes of the viral diseases listed?', 'Which viral diseases have a spherical virion shape?']\n",
      "********135***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the viral disease in Baltimore group iii is reoviridae. \n",
      "Answer: 1\n",
      "['Which viral diseases are in Baltimore group iii?', 'Which viral diseases are in baltimore group iii?']\n",
      "********139***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, Galina Voskoboeva's win rate on clay and hard court surfaces is 0.5 for both surfaces. The winrate of Galina Voskoboeva on hard court is 0.333333, as calculated from the sub-table provided. Therefore, the claim that Galina Voskoboeva has an equal win rate between both clay and hard court is false.\n",
      "Answer: 0\n",
      "['What is the winrate of Galina Voskoboeva on clay court?', \"What is Galina Voskoboeva's win rate on clay and hard court surfaces?\", ' What is the winrate of Galina Voskoboeva on hard court?']\n",
      "********140***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the opponent 'galina voskoboeva' played the same opponent more than once, as the count of the opponent is greater than 1.\n",
      "Answer: 0\n",
      "['How many times did Galina Voskoboeva play the same opponent?', ' Did Galina Voskoboeva play the same opponent more than once?', 'how many times has Galina Voskoboeva played the same opponent?']\n",
      "********148***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Alfredo Binda won 6 races in the 1933 Giro d'Italia, and he was the race leader for 13 races. \n",
      "Answer: 0\n",
      "[\" How many races was Alfredo Binda the race leader for in the 1933 Giro d'Italia?\", \"how many races did Alfredo Binda win in the 1933 Giro d'Italia and how many races was he the race leader for?\", \"How many races did Alfredo Binda win in the 1933 Giro d'Italia?\"]\n",
      "********149***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the winner of the 1933 Giro d'Italia race on May 26 was not Gerard Loncke, it was Learco Guerra. Additionally, the race leader was Alfredo Binda, not Gerard Loncke. \n",
      "Answer: 0\n",
      "[\"who won the 1933 Giro d'Italia race on May 26?\", \"When did Gerard Loncke win the race in the 1933 Giro d'Italia?\", \" Who was the race leader in the 1933 Giro d'Italia?\"]\n",
      "********163***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Wes Roberts and Ed Whitley were both picked in the 3rd round.\n",
      "Answer: 1\n",
      "[' When was Ed Whitley picked?', 'When was Wes Robert picked?', 'were Wes Robert and Ed Whitley both picked in the 3rd round?']\n",
      "********169***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, only one country received 6 bronze medals, which is East Germany (GDR). The extra information states that Finland and the United States received the same number of bronze medals, which is 2, not 6. \n",
      "Answer: 0\n",
      "['Which countries received the same number of bronze medals?', 'Which 6 countries received the same number of bronze medals?']\n",
      "********170***************\n",
      "1 0\n",
      "Thought: Based on the sub-table provided, the query cannot be answered as there is no data to determine which countries received medals in all categories.\n",
      "Answer: 0\n",
      "['Which countries on the table did not receive a medal in one of the categories?', 'Which countries received medals in all categories?', ' Which countries did not receive a medal in one of the categories?']\n",
      "********180***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria. Therefore, it is not possible to verify the claim. \n",
      "Answer: 0\n",
      "[' What is the declination of ngc 1947?', 'What is the declination of ngc 2082?', 'what is the declination of each galaxy in the dorado group?']\n",
      "********181***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the celestial object with the lowest right ascension is ngc 1533 with a right ascension of 4 hours 9 minutes and 51.8 seconds.\n",
      "Answer: 1\n",
      "[' What is the right ascension of ngc 2082?', 'What is the right ascension of ngc 1533?', 'What is the right ascension for each of the listed celestial objects?']\n",
      "********188***************\n",
      "1 0\n",
      "Thought: The sub-table provided does not contain the necessary information to answer the query. \n",
      "Answer: 0\n",
      "['What is the earliest date for volleyball?', ' What is the second earliest date for volleyball?', 'Which sport had the second earliest date?']\n",
      "********193***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the earliest date for volleyball in the table is 2007-09-08. This is the earliest date for volleyball in the table.\n",
      "Answer: 1\n",
      "['which sport has the earliest date?', 'What is the earliest date for volleyball in the table?']\n",
      "********210***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Lleyton Hewitt was a runner-up 5 times. The total number of times he was a runner-up is 5, and the total number of times he participated is not given. \n",
      "Answer: 0\n",
      "['how many times was Lleyton Hewitt a runner-up in total?', ' How many times did Lleyton Hewitt be a runner-up?', 'How many times did Lleyton Hewitt win a championship?']\n",
      "********213***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there were no instances of a master series final where one side finished with 4 points. \n",
      "Answer: 1\n",
      "[\"How many of Lleyton Hewitt's master series final have one side finishing with 4 points?\", \"How many of Lleyton Hewitt's master series finals ended with one side finishing with 4 points?\", \" How many of Lleyton Hewitt's master series final have the other side finishing with 4 points?\"]\n",
      "********225***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, it appears that no team scored in the first game of the World Cup in France on June 19, 1998.\n",
      "Answer: 1\n",
      "['What was the score for the first game of the world cup in France?', 'which team did not score in the first game of the world cup in France?', ' Did any team score for the first game of the world cup in France?']\n",
      "********227***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Solheim Cup was hosted in the US 7 times from 1990 through 2013, as indicated by the sub-table.\n",
      "Answer: 1\n",
      "[' When was the Solheim Cup hosted in the US from 1990 through 2013?', 'How many times was the Solheim Cup hosted in the US from 1990 through 2013?', 'how many times was the Solheim Cup hosted in the US from 1990 through 2013?']\n",
      "********228***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the United States team won 8 Solheim Cup tournaments between 1990 and 2009. The last win for the United States team before 2009 was in 2007.\n",
      "Answer: 0\n",
      "['How many Solheim Cup tournaments did the United States team win from 1990 to 2009?', 'how many Solheim Cup tournaments did the United States team win between 1990 and 2009?', ' When was the last Solheim Cup win for the United States team before 2009?']\n",
      "********229***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the captains who have won the cup multiple times are Mickey Walker and Kathy Whitworth. Patty Sheehan, Judy Rankin, and Kathy Whitworth are not the only captains who have won the cup 2 times.\n",
      "Answer: 0\n",
      "['How many times did Patty Sheehan win the cup as captain?', ' How many times did Judy Rankin win the cup as captain?', ' How many times did Kathy Whitworth win the cup as captain?', 'which captains have won the cup multiple times?']\n",
      "********234***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, Patty Sheehan, Judy Rankin, and Kathy Whitworth all captained a winning team in the Solheim Cup 1 time.\n",
      "Answer: 1\n",
      "['How many times did Patty Sheehan captain a winning team in the Solheim Cup?', 'how many times did each captain win the solheim cup?', ' How many times did Judy Rankin captain a winning team in the Solheim Cup?', ' How many times did Kathy Whitworth captain a winning team in the Solheim Cup?']\n",
      "********239***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the attendance on August 26 was 48063 and the attendance on August 27 was 48032.\n",
      "Answer: 0\n",
      "[' What was the attendance on August 27?', 'What was the attendance on August 26?', 'what was the attendance on August 26 and August 27?']\n",
      "********240***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, when the score was 10 - 4 in a game against the Athletics, the Colorado Rockies' record was 68 - 70.\n",
      "Answer: 0\n",
      "[\"When the score be 10 - 4 , what was the Colorado Rockies' record in a game against the athletics?\", \"what is the Colorado Rockies' record after each game?\"]\n",
      "********254***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the smallest attendance was at the game against the Baltimore Colts, with an attendance of 50451. \n",
      "Answer: 1\n",
      "['which game had the smallest attendance?', 'What was the attendance at the game against the New England Patriots?', ' What was the attendance at the game against the Baltimore Colts?']\n",
      "********255***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the attendance in week 12 was 66875, which is higher than the attendance in week 6 (71009) and week 13 (43475). \n",
      "Answer: 1\n",
      "[' What was the attendance in week 6?', 'what is the attendance for each week?', 'What was the attendance in week 12?', ' What was the attendance in week 13?']\n",
      "********259***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Yugoslavian national team lost the Balkan Cup against Romania with an aggregate score of 3:4. The aggregate score of the Yugoslavian national team against Romania in the Balkan Cup was 7, not 3:4.\n",
      "Answer: 0\n",
      "['what were the results of the games played by the Yugoslavian national team in the Balkan Cup?', 'When did the Yugoslavian national team lose the Balkan Cup?', ' What was the aggregate score of the Yugoslavian national team against Romania in the Balkan Cup?']\n",
      "********265***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Yugoslavian national team failed to score in world cup qualifying matches 1 time, and dropped a world cup qualify match 2:1 against Denmark.\n",
      "Answer: 1\n",
      "['how many times did the yugoslavian national team fail to score in world cup qualifying matches?', ' Against which team did the Yugoslavian national team drop a world cup qualify match 2:1?', 'When did the Yugoslavian national team fail to score?']\n",
      "********266***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Yugoslavian national team scored 7 goals and allowed 3 goals in the 1982 World Cup qualifiers.\n",
      "Answer: 1\n",
      "['How many goals did the Yugoslavian national team score in the 1982 world cup qualify?', ' How many goals did the Yugoslavian national team allow in the 1982 world cup qualify?', 'How many goals did the Yugoslavian national team score and allow in the 1982 World Cup qualifiers?']\n",
      "********272***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, March had the most games played with 7, while April had the fewest games played with 3. Therefore, the claim that March is featured more often as a month in the date than any other month, followed by the 4 games in April is true.\n",
      "Answer: 1\n",
      "['how many games were played in each month?', 'How many games were played in March?', ' How many games were played in April?']\n",
      "********287***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is 1 translator in the frequency MHz in the 100's and 3 translators in the frequency range of 90.0 to 99.9 MHz.\n",
      "Answer: 0\n",
      "[\"How many translators are there in the frequency mhz in the 100's?\", 'how many translators are there in each frequency range?', \" How many translators are there in the frequency mhz in the 90's?\"]\n",
      "********290***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the station w293al has an ERP W of 80, which is higher than the ERP W of w264bf, which is 2. However, the frequency_mhz of w293al is 106.5, and the frequency_mhz of w264bf is 100.7. The claim that w293al has the highest ERP W and w264bf has the lowest ERP W is false.\n",
      "Answer: 0\n",
      "[' What is the frequency_mhz of w264bf?', 'What is the frequency_mhz of w293al?', 'which station has the highest and lowest erp w?']\n",
      "********291***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the cities of Illinois and Indiana each have 3 translators. However, the sub-table does not contain any data from the database, so we cannot verify the claim based on the provided information.\n",
      "Answer: 0\n",
      "[' How many translators does Indiana have?', 'How many translators does Illinois have?', 'how many translators are there in Illinois and Indiana combined?']\n",
      "********292***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, the query can be answered. There are 6 call signs that have a frequency change range of 5 MHz.\n",
      "Answer: 1\n",
      "['what is the frequency range for the radio stations listed?', ' How many call signs have a frequency change range of 5 MHz?', 'What are the frequency ranges for the call signs?']\n",
      "********294***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the ERP_W value of 2 is the only value that appears in the table.\n",
      "Answer: 1\n",
      "['which call sign has an ERP of 2 W?', 'What is the frequency_mhz for the call_sign w264bf?', ' What is the city_of_license for the call_sign w264bf?']\n",
      "********300***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the tournament that had the same result in the year 1990 and 1999 was the grand slam tournaments.\n",
      "Answer: 1\n",
      "['What are the results for each tournament in the year 1990?', 'What were the results for each tournament in the year 1990 and 1999?', ' What are the results for each tournament in the year 1999?']\n",
      "********301***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Australian Open had 1 result with the value 'a' in the c_1991 column, and Wimbledon had 1 result with the value 'a' in the c_1991 column. \n",
      "Answer: 0\n",
      "['how many a results did each tournament have?', ' How many a results did Wimbledon have?', 'How many a results did the Australian Open have?']\n",
      "********309***************\n",
      "1 0\n",
      "Thought: The SQL query filters the data to find the maximum crowd size for the matches between South Melbourne and Richmond, and between Hawthorn and North Melbourne. The maximum crowd size for the match between South Melbourne and Richmond was 17,000. The maximum crowd size for the match between Hawthorn and North Melbourne is not provided in the sub-table. However, the extra information states that the match with the biggest crowd was held at the MCG, with a crowd of 48,952, which is not the match between South Melbourne and Richmond. Therefore, the claim that the match between South Melbourne and Richmond drew a bigger crowd than the game between Hawthorn and North Melbourne is false.\n",
      "Answer: 0\n",
      "[' How many people attended the game between Hawthorn and North Melbourne?', 'How many people attended the match between South Melbourne and Richmond?', 'which match draw the biggest crowd?']\n",
      "********315***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table is empty, which means that there is no data to support the claim that Collingwood scored more points than Hawthorn in the 1962 VFL match.\n",
      "Answer: 0\n",
      "['How many points did Collingwood score in the 1962 VFL match?', 'which team scored more points in the 1962 VFL match, Collingwood or Hawthorn?', ' How many points did Hawthorn score in the 1962 VFL match?']\n",
      "********336***************\n",
      "1 0\n",
      "Thought: The SQL query is filtering for players who have taken 13 wickets and appeared in more matches than the player who took 11 wickets. The sub-table shows that Keith Miller is the player who took 13 wickets, and he appeared in 1 match. The player who took 11 wickets also appeared in 1 match. Therefore, the claim that the bowler with 13 wickets appeared in more matches than the bowler with 11 wickets is false.\n",
      "Answer: 0\n",
      "['which bowler appeared in the most matches?', 'How many wickets did the bowler with 13 wickets appear in?', ' How many wickets did the bowler with 11 wickets appear in?']\n",
      "********349***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only player who doesn't have 0 FA Cup goals is Peter Hart. The player who has scored in the FA Cup is Peter Hart.\n",
      "Answer: 1\n",
      "[' What is the number of fa cup goals for Peter Hart?', \"Who is the only player that doesn't have 0 fa cup goal?\", 'which player has scored in the fa cup?']\n",
      "********350***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Dave Sutton has the most league goals in the df position with 6 goals. The list of league goals in the df position is 0, 2, 2, 0, 1, 6, 0. \n",
      "Answer: 1\n",
      "['Who has the most league goals in the df position?', ' What is the list of league goals in the df position?', 'which player has the least league goals in the df position?']\n",
      "********355***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Toronto Blue Jays played 27 games with an attendance greater than 5000 in May of the 1991 season. The query is false because the Toronto Blue Jays played 27 games with an attendance greater than 5000 in May of the 1991 season, not 8 games.\n",
      "Answer: 0\n",
      "['how many games did the Toronto Blue Jays play in May of the 1991 season with an attendance greater than 5000?', 'How many games did the Toronto Blue Jays play in May of the 1991 season?', ' How many games did the Toronto Blue Jays play with an attendance greater than 5000 in May of the 1991 season?']\n",
      "********357***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Toronto Blue Jays won 2 of the last 3 games they played in May 1991. \n",
      "Answer: 0\n",
      "['how many games did the Toronto Blue Jays win in May 1991?', ' How many games did the Toronto Blue Jays lose in May 1991?', 'How many games did the Toronto Blue Jays win in May 1991?']\n",
      "********358***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the game with the lowest attendance in May of the 1991 Toronto Blue Jays season was played against the Royals. \n",
      "Answer: 1\n",
      "['What was the attendance for the game with the lowest attendance in May of the 1991 Toronto Blue Jay season?', 'which game in May of the 1991 Toronto Blue Jays season had the lowest attendance?']\n",
      "********359***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Toronto Blue Jays lost 3 consecutive games between May 25th and May 28th, 1991.\n",
      "Answer: 1\n",
      "[' How many consecutive games did the Toronto Blue Jays lose between the 25th and the 28th of May 1991?', 'how many consecutive games did the Toronto Blue Jays lose between May 25th and May 28th, 1991?', 'When did the Toronto Blue Jays lose 3 consecutive games?']\n",
      "********362***************\n",
      "0 1\n",
      "Thought: The SQL query filters the data to show the Toronto Blue Jays' games in May 1991 where they lost with a score of 2. The sub-table shows the last 3 games in May 1991 where the Toronto Blue Jays lost with a score of 2. \n",
      "Answer: 1\n",
      "[' How many games did the Toronto Blue Jays lose in May 1991?', 'how many games did the Toronto Blue Jays lose in May 1991?', 'When did the Toronto Blue Jays lose in May 1991?']\n",
      "********364***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Toronto Blue Jays lost a game on May 28, 1991, and the loss was consecutive. \n",
      "Answer: 1\n",
      "[' How many consecutive games did the Toronto Blue Jays lose between the 25th and the 28th of May 1991?', 'When did the Toronto Blue Jays lose a game between the 25th and the 28th of May 1991?', 'how many consecutive games did the Toronto Blue Jays lose between May 25th and May 28th, 1991?']\n",
      "********372***************\n",
      "0 1\n",
      "Thought: Based on the sub-table provided, Alex Bogdanovic has not played against Wesley Moodie. \n",
      "Answer: 1\n",
      "['Has Alex Bogdanovic ever played against Wesley Moodie?', 'When did Alex Bogdanovic play against Wesley Moodie?', ' Has Alex Bogdanovic ever played against Wesley Moodie?']\n",
      "********387***************\n",
      "1 0\n",
      "Thought: The SQL query filters the table to show the vctp and vca_155 values where vctp is '24hp / t (23hp / ton)', vca_155 is '18hp / t ( 16.5hp / ton)', and vca_155 is not '55 km / h (34 mph)'. The sub-table shows that the vctp 24hp / t (23hp / ton) has a vca_155 of 18hp / t ( 16.5hp / ton). However, the sub-table does not provide information about vca_155 being not '55 km / h (34 mph)'. \n",
      "Answer: 0\n",
      "['What is the vctp 24hp / t (23hp / ton)?', 'What are the specifications of the vctp 24hp / t (23hp / ton)?', ' What is the vca 155 of 18hp / t ( 16.5hp / ton)?']\n",
      "********390***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the vctp 20 mm (79in) rh - 202 autocannon does not have the 7.62 mm (0.3in) fn mag 60 - 20 machine gun as the vcrt.\n",
      "Answer: 1\n",
      "['What does the vctp 20 mm (79in) rh - 202 autocannon have as the vcrt?', 'which weapon does the vctp 20 mm (79in) rh - 202 autocannon have as the vcrt?', ' What does the vctp 20 mm (79in) rh - 202 autocannon not have as the vcrt?']\n",
      "********392***************\n",
      "0 1\n",
      "Thought: The vctp 24hp / t (23hp / ton) have a vca 155 of 155 mm (6.1in) l / 41 howitzer, and not 55 km / h (34 mph).\n",
      "Answer: 1\n",
      "['What is the vctp 24hp / t (23hp / ton) vca_155?', ' What is the speed of vctp 24hp / t (23hp / ton)?', 'What are the specifications of vctp 24hp / t (23hp / ton)?']\n",
      "********398***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the sub-table shows that Amy Sherman-Palladino and Daniel Palladino directed a total of 2 episodes together, \"ballrooms and biscotti\" and \"tick , tick , tick , boom!\"\n",
      "Answer: 1\n",
      "['how many episodes did amy sherman - palladino and daniel palladino direct together?', ' Which episodes did amy sherman - palladino and daniel palladino direct together?', 'How many episodes did amy sherman - palladino and daniel palladino direct together?']\n",
      "********422***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the nations of Singapore, Mongolia, and Myanmar have all won 0 gold medals for wushu at the Asian Games. \n",
      "Answer: 1\n",
      "[' How many gold medals has Myanmar won for wushu at the Asian Games?', 'Which countries have won a gold medal for wushu at the Asian Games?', 'How many gold medals has Singapore won for wushu at the Asian Games?']\n",
      "********427***************\n",
      "1 0\n",
      "Thought: The SQL query filters for games where the Detroit Pistons won by over 10 points during the 2010-2011 season. However, the sub-table shows that there is no data from the database, so we cannot verify the claim.\n",
      "Answer: 0\n",
      "['how many games did the Detroit Pistons win by over 10 points during the 2010-2011 season?', ' Which games did the Detroit Pistons win by over 10 points during the 2010-2011 season?', 'How many games did the Detroit Pistons win by over 10 points during the 2010-2011 season?']\n",
      "********429***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there were 0 instances where there was a tie for the most rebounds by a Detroit Pistons player during the 2010-2011 season. \n",
      "Answer: 0\n",
      "['How many instances were there where there was a tie for most rebounds by a Detroit Pistons player during the 2010-2011 season?', 'how many instances were there where there was a tie for the most rebounds by a Detroit Pistons player during the 2010-2011 season?', ' How many instances were there where there was a tie for most assists by a Detroit Pistons player during the 2010-2011 season?']\n",
      "********430***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Rodney Stuckey did not lead the Detroit Pistons in point score in any game during the period of the 2010-2011 season.\n",
      "Answer: 1\n",
      "['When did Rodney Stuckey lead the Detroit Pistons in point score?', ' How many games did Rodney Stuckey lead the Detroit Pistons in point score during the 2010-2011 season?', 'In how many games did Rodney Stuckey lead the Detroit Pistons in point score during the 2010-2011 season?']\n",
      "********431***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Detroit Pistons did not lose any games during this period of their 2010-2011 season. \n",
      "Answer: 1\n",
      "['how many games did the Detroit Pistons lose during the 2010-2011 season?', 'How many games did the Detroit Pistons lose during the 2010-2011 season?', ' How many games did the Detroit Pistons win during the 2010-2011 season?']\n",
      "********438***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the number of episodes in the third season of Dexter is 1.\n",
      "Answer: 0\n",
      "[\" What is the title of the 11th episode in the TV series Dexter's third season?\", 'How many episodes does the TV series Dexter have in its third season?', 'how many episodes does the TV series Dexter have in each season?']\n",
      "********441***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, Keith Gordon wrote 2 episodes in season 3 of Dexter. \n",
      "Answer: 1\n",
      "[' How many episodes did Keith Gordon write for Dexter in season 3?', 'how many episodes of Dexter did Keith Gordon write in season 3?', 'What episodes did Keith Gordon write for Dexter in season 3?']\n",
      "********442***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the earliest episode in season 3 of Dexter aired after October 2008 is \"Finding Freebo,\" which aired on October 5, 2008.\n",
      "Answer: 1\n",
      "['when did season 3 of dexter begin airing?', 'When did season 3 of Dexter begin airing?', ' What is the title of episode 2 in season 3 of Dexter?']\n",
      "********449***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the constituency number for Datia is 22 and the constituency number for Gohad is 13. Therefore, the claim that Datia's constituency number is higher than Gohad's by 9 is false.\n",
      "Answer: 0\n",
      "[\"which constituency number is higher, Datia's or Gohad's?\", 'What is the constituency number for datia?', ' What is the constituency number for gohad?']\n",
      "********455***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that 1 game was played on 12 - 13 July 2003 and 1 game was played on 25 - 26 January 2003. Therefore, the claim that these were the only games played in 2003 is false.\n",
      "Answer: 0\n",
      "[' How many games were played on 12 - 13 july 2003?', 'How many games were played on 25 - 26 january 2003?', 'how many games were played in 2003?']\n",
      "********457***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the seasons 2001-02, 2002-03, and 2003-04 were in the standard format. This is confirmed by the sub-table generated by the SQL query.\n",
      "Answer: 1\n",
      "['What seasons were in the standard format?', 'In which seasons was the standard format used?', ' Which seasons were in the standard format?']\n",
      "********463***************\n",
      "0 1\n",
      "Thought: The SQL query filters the data to show the last 4 games in season 5 that were held in Los Angeles and London. The sub-table shows that the last 4 games in season 5 were held in London and Los Angeles, so the claim is true.\n",
      "Answer: 1\n",
      "['where were the last 4 games in season 5 held?', 'What are the last 4 games in season 5?', ' Where were the last 4 games in season 5 held?']\n",
      "********473***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the directors who directed more than one episode are Mike Clattenburg, Robert Lieberman, and Steve Dimarco. The sub-table shows the directors who directed only one episode. \n",
      "Answer: 1\n",
      "['Who directed \"the pen is mightier than the doyle\"?', ' Who directed \"the return of the grievous angel\"?', 'which directors directed more than one episode?']\n",
      "********475***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Carlos Cuéllar has a transfer fee of 7.8 million. The player with the highest transfer fee is Jean-Claude Darcheville. The player from Spain (ESP) has the highest transfer fee of 7.8 million.\n",
      "Answer: 0\n",
      "[' What is the transfer fee for Carlos Cuéllar?', 'which player has the highest transfer fee?', 'Who has the highest transfer fee of any player?']\n",
      "********476***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the total amount of transfer for sco is 0, and the total amount of transfer for all other teams combined is 12.3. Therefore, the claim that sco has the highest amount of transfer at 22, more than every other team combined is false.\n",
      "Answer: 0\n",
      "['which team has the highest amount of transfers?', 'What is the total amount of transfer for sco?', ' What is the total amount of transfer for all other teams combined?']\n",
      "********477***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that Jeroen van den Broeck was transferred at the end of his contract, but it does not provide information about the total number of players transferred at the end of their contract. \n",
      "Answer: 0\n",
      "[' How many players were not transferred at the end of their contract?', 'how many players were transferred at the end of their contract?', 'How many players were transferred at the end of their contract?']\n",
      "********478***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only player with a free transfer fee is Chris Burke.\n",
      "Answer: 1\n",
      "['Who is the only player to have a free transfer fee?', 'which player have a free transfer fee?']\n",
      "********483***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, Chris Burke is one of the 5 players with a free transfer fee.\n",
      "Answer: 1\n",
      "[' How many players have a free transfer fee?', 'how many players have a free transfer fee?', 'Who are the 5 players with a free transfer fee?']\n",
      "********488***************\n",
      "1 0\n",
      "Thought: The SQL query calculates the average of the home team scores by extracting the score from the \"home_team_score\" column and converting it to a real number. The average of all the home team scores is 15.6717, not 15.67.\n",
      "Answer: 0\n",
      "['What is the average score of the home teams in the games listed?', 'What is the average of all the home team scores?', ' What is the average of all the away team scores?']\n",
      "********489***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the count of away teams with a score greater than 10 is 0. The percentage of away teams with a score greater than 10 is 0%. Therefore, the claim that 1/3 of the away teams have a score greater than 10 is false.\n",
      "Answer: 0\n",
      "['How many away teams have a score greater than 10?', 'what is the percentage of away teams that have a score greater than 10?', ' How many away teams have a score less than or equal to 10?']\n",
      "********493***************\n",
      "0 1\n",
      "Thought: The average of all the home team scores is 15.6717. The average of all the home team scores is less than 12, with an average of 10.13.\n",
      "Answer: 1\n",
      "['what is the average score of the home teams?', 'What is the average of all the home team scores?', ' Is the average of all the home team scores less than 12?']\n",
      "********494***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, there are 2 games where the away team scored more than 10 points, and a total of 6 games. Therefore, more than half of the away teams have a score greater than 10.\n",
      "Answer: 1\n",
      "[' How many games have the away team scored more than 10 points?', 'What is the score of the away team for each game?', 'what is the score of the away team in each game?']\n",
      "********495***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the agricultural panel has 6 members and the labour panel has 17 members. Therefore, the claim that both panels have 11 total members is false.\n",
      "Answer: 0\n",
      "['How many total members are there in the agricultural panel?', ' How many total members are there in the labour panel?', 'how many members are in the agricultural and labour panels?']\n",
      "********498***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the party with the most members nominated by the taoiseach is \"total\". However, from the extra information provided, the party with the most members nominated by the taoiseach is actually Fianna Fáil with 7 members. \n",
      "Answer: 0\n",
      "['Which party has the most members nominated by the taoiseach?', 'which party has the most members nominated by the taoiseach?', ' How many members nominated by the taoiseach are from each party?']\n",
      "********499***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the industrial and commercial panel has 16 members, while the cultural and educational panel has 9 members. The industrial and commercial panel has 7 more members than the cultural and educational panel, not 4.\n",
      "Answer: 0\n",
      "['How many members are in the industrial and commercial panel compared to the cultural and educational panel?', ' How many members are in the cultural and educational panel?', 'How many members are in the industrial and commercial panel?']\n",
      "********503***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the party with the most members in the agricultural panel is \"total\". \n",
      "Answer: 1\n",
      "['which panel has the most members from one party?', ' How many members does the agricultural panel have from the party with the most members?', 'Which party has the most members in the agricultural panel?']\n",
      "********509***************\n",
      "1 0\n",
      "Thought: The query is false. Canon Yaoundé scored 5 more points than their opponent.\n",
      "Answer: 0\n",
      "['What is the total score of canon yaoundé?', 'What was the point difference between Canon Yaoundé and their opponent?', ' What is the total score of as solidarité?']\n",
      "********510***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, asc diaraf won against stade malien in the 1971 African Cup of Champion Clubs. They won with an aggregate score of 3 - 4, and also won the first leg of the match with a score of 3 - 0.\n",
      "Answer: 1\n",
      "['Did asc diaraf win any matches in the 1971 African Cup of Champion Clubs?', 'When did asc diaraf win against stade malien?']\n",
      "********511***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Young Africans scored 0 points in the 1971 African Cup of Champion Clubs.\n",
      "Answer: 1\n",
      "['What was the score of the young african in the 1971 african cup of champion club?', 'How many points did the young african score in the 1971 African Cup of Champion Club?']\n",
      "********520***************\n",
      "1 0\n",
      "Thought: The average number of crowd in the game during the 2008 Arizona Diamondback season is 35751.8, not 31,521.\n",
      "Answer: 0\n",
      "['What is the average number of crowd in the game during the 2008 Arizona Diamondback season?', 'what was the average attendance at Arizona Diamondbacks games during the 2008 season?']\n",
      "********532***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there were 2 games and legs that had a score of 0 - 0.\n",
      "Answer: 1\n",
      "[' How many games have a score of 0 - 0?', 'How many games have a total of 2 legs?', 'how many games and legs had a score of 0 - 0?']\n",
      "********534***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the sub-table shows that there were 6 teams that had the same score during the 1st leg. This means that there were more than 2 teams that had the same score during the 1st leg.\n",
      "Answer: 1\n",
      "[' How many teams had the same score during the 1st leg?', 'Which teams had the same score during the 1st leg?', 'how many teams had the same score during the 1st leg?']\n",
      "********536***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, Lukáš Melich placed third or higher in 3 competitions, not 1.\n",
      "Answer: 0\n",
      "['In which competition did Lukáš Melich place third or higher?', 'In which competitions did Lukáš Melich place third or higher?']\n",
      "********538***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the competition is filtered to only show 'world championships' and the LIMIT and OFFSET are used to show the 10th to 13th entries. Since there is no data from the database, we cannot verify if 4 of the competitions out of 10 are world wide championships.\n",
      "Answer: 0\n",
      "['Which competitions are world wide championships?', 'How many of the competitions are world wide championships out of the total 10?', ' How many competitions out of 10 are world wide championships?']\n",
      "********539***************\n",
      "1 0\n",
      "Thought: The SQL query calculates the average distance thrown by Lukáš Melich in his last 2 competitions. The result of the query is 77 meters, which is less than 78.27 meters.\n",
      "Answer: 0\n",
      "[\"in lukáš melich 's last 2 competition, what was the average distance he threw?\", 'What is the average throwing distance for Lukáš Melich in his last 2 competitions?']\n",
      "********542***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the highest finish of Lukáš Melich as a junior was 6th place, as indicated by the sub-table.\n",
      "Answer: 1\n",
      "['What is the highest finish of Lukáš Melich as a junior?', \"What is Lukáš Melich's highest finish in each competition?\"]\n",
      "********546***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that there are two home teams, \"Footscray\" and \"North Melbourne,\" that scored less than 11. The lowest score for a home team is 11.23. Therefore, the claim that there are no home teams that scored less than 11 is false.\n",
      "Answer: 0\n",
      "[' How many home teams scored less than 11?', 'Which home team scored less than 11?', 'What is the lowest score for a home team?']\n",
      "********547***************\n",
      "1 0\n",
      "Thought: The highest scoring team for the game that happened on the 18th of June was Fitzroy, not Carlton.\n",
      "Answer: 0\n",
      "['What was the score of the game on the 18th of June?', ' Which team scored the most points in the game on the 18th of June?', 'which team scored the highest in the game that happened on the 18th of June?']\n",
      "********549***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, 4 home teams had a higher score than the away team in the game they played. The home teams that had a higher score than the away team in the game they played are Geelong, Fitzroy, St Kilda, Richmond, Footscray, and North Melbourne.\n",
      "Answer: 0\n",
      "['Which home team had a higher score than the away team?', ' How many home teams had a higher score than the away team?', 'Which home teams had a higher score than the away team in the game they played?']\n",
      "********555***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the table does not contain any data. Therefore, we cannot verify whether Alberto Pagani won with two teams. \n",
      "Answer: 0\n",
      "['with how many teams did alberto pagani win?', ' How many teams did Alberto Pagani win with?', 'Which team did Alberto Pagani win with?']\n",
      "********569***************\n",
      "1 0\n",
      "Thought: The SQL query calculates the difference in attendance between the New York Jets' second game against the Miami Dolphins and their first game against the Miami Dolphins during the 1993 season. The attendance difference is calculated by subtracting the attendance in the first game from the attendance in the second game. \n",
      "Answer: 0\n",
      "['how many people attended each game for the New York Jets during the 1993 season?', ' How many crowd attendance did the New York Jets have in their first game against the Miami Dolphins during the 1993 season?', 'How many crowd attendance did the New York Jets have in their second game against the Miami Dolphins during the 1993 season?']\n",
      "********570***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the New York Jets played 8 games at the Robert F Kennedy Memorial Stadium during the 1993 season.\n",
      "Answer: 1\n",
      "['How many games did the New York Jets play during the 1993 season?', 'how many games did the New York Jets play at the game site named the Robert F. Kennedy Memorial Stadium during the 1993 season?', ' How many games did the New York Jets win during the 1993 season?']\n",
      "********578***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the query cannot be answered as it does not contain information about the Cleveland Brown's quarterbacks. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "[\"how many Cleveland Brown's quarterbacks have won more than 10 games?\", \"How many Cleveland Brown's quarterbacks have won more than 10 games?\", \" How many Cleveland Brown's quarterbacks have started more than 10 games?\"]\n",
      "********584***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Otto Graham won 57 games, while Brady Quinn won 3 games. The claim that Otto Graham won 44 more games than Brady Quinn is true because 57 - 3 = 54, which is greater than 44.\n",
      "Answer: 1\n",
      "['How many games did Otto Graham win?', ' How many games did Brady Quinn win?', 'How many games did Otto Graham win compared to Brady Quinn?']\n",
      "********588***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, it appears that 2 players tied for the win score in the 1981 Open Championship, and the winning score was 72.\n",
      "Answer: 1\n",
      "['what was the winning score in the 1981 Open Championship and how many players tied for that score?', 'What was the win score in the 1981 open championship?', ' How many players tied for the win score in the 1981 open championship?']\n",
      "********594***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only player who achieved the position of t1 in the 1981 Open Championship was Nick Job from England. The claim that no 1 player achieved their position alone, except Argentina, is true.\n",
      "Answer: 1\n",
      "['Who achieved the top position in the 1981 open championship?', ' Did any player achieve the top position alone in the 1981 open championship?', 'which players achieved their position alone in the 1981 Open Championship?']\n",
      "********595***************\n",
      "1 0\n",
      "Thought: The SQL query provided filters the data to count the number of times the Padres played against the Milwaukee Brewers in the 2005 season. However, the sub-table does not contain any data for the Padres playing against the Milwaukee Brewers in 2005, so I cannot determine the number of times they were opponents from the sub-table.\n",
      "Answer: 0\n",
      "[' Who were the opponents of the Padres in the 2005 season?', 'how many times did the Padres play against the Milwaukee Brewers in the 2005 season?', 'How many times did the Padres play against the Milwaukee Brewers in the 2005 season?']\n",
      "********598***************\n",
      "1 0\n",
      "Thought: The Milwaukee Brewers played the Cardinals on September 23, 2005, and the Reds on September 26, 2005. Therefore, the Milwaukee Brewers played the Cardinals 3 days before the Reds, not 1 day before the Reds.\n",
      "Answer: 0\n",
      "['which team did the Milwaukee Brewers play in the 2005 season?', ' When did the Milwaukee Brewers play the Reds in the 2005 season?', 'When did the Milwaukee Brewers play the Cardinals in the 2005 season?']\n",
      "********609***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the game with the highest attendance at the Prudential Center was 18711, and it was not against Miami. \n",
      "Answer: 0\n",
      "['which game had the highest attendance at the Prudential Center?', ' Which game had the highest attendance?', 'What was the attendance for the game against Miami at the Prudential Center?']\n",
      "********616***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the players who tied for the lowest to par are Steve Elkington and Tommy Tolles, not Mark Brooks and Kenny Perry. \n",
      "Answer: 0\n",
      "[' Who tied with Kenny Perry for the lowest to par?', 'Who tied with Mark Brooks for the lowest to par?', 'which players tied for the lowest to par?']\n",
      "********621***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the players Steve Elkington and Tommy Tolles tied with Kenny Perry for the lowest to par. Mark Brooks and Kenny Perry did not tie for the lowest to par.\n",
      "Answer: 0\n",
      "[' Who tied with Kenny Perry for the lowest to par?', 'Who tied with Mark Brooks for the lowest to par?', 'which players tied for the lowest to par?']\n",
      "********622***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Phil Mickelson is the only player from the United States. \n",
      "Answer: 1\n",
      "['which players are from the United States?', 'Who are the players from the United States?', ' How many players are from the United States?']\n",
      "********627***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the number of Zakspeed chassis made in the year 1987 is 1, not 2.\n",
      "Answer: 0\n",
      "['how many zakspeed chassis were made in each year?', ' What are the zakspeed chassis made in the year 1987?', 'How many zakspeed chassis were made in the year 1987?']\n",
      "********637***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there are 3 teams that have the same number of goals scored against them, not 2. \n",
      "Answer: 0\n",
      "['which teams have the same number of goals scored against them?', ' How many teams have the same number of goals scored against them?', 'Which teams have the same number of goals scored against them?']\n",
      "********640***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the second team has fewer points than the first team and is separated by a 2 goal difference.\n",
      "Answer: 1\n",
      "['What is the position of the first team?', 'how do the points and goal difference of the second team compare to the first team?', ' What is the position of the second team?']\n",
      "********643***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the teams with 13 points are Flamengo and Fluminense, and their goal difference is more than 1. The claim is true.\n",
      "Answer: 1\n",
      "[' Which team has the lowest point total?', 'Which team has the highest point total?', 'which teams have a goal difference of more than 1?']\n",
      "********644***************\n",
      "1 0\n",
      "Thought: The SQL query is filtering for the home team score for Collingwood and checking if it is higher than that of Geelong. The query is using the CAST function to convert the home team score to an integer and then comparing the scores. The query is also using the SUBSTR function to extract the scores from the home team score column. However, the query has a logical error in the comparison of the scores, which may result in incorrect filtering.\n",
      "Answer: 0\n",
      "['What is the home team score for collingwood?', ' What is the home team score for geelong?', 'which team has the highest home team score?']\n",
      "********645***************\n",
      "1 0\n",
      "Thought: The SQL query is filtering for the home team and the maximum away team score. The sub-table does not show the specific values for the home team and the maximum away team score. \n",
      "Answer: 0\n",
      "[' What is the highest away team score?', 'which team has the highest away team score?', 'What team has the highest away team score?']\n",
      "********661***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the relative value of 斤 is 1, and the relative value of 担 / 擔 is also 1. Therefore, 斤 and 担 / 擔 both have the same relative value.\n",
      "Answer: 1\n",
      "['What is the relative value of 斤?', ' What is the relative value of 担 / 擔?', 'What is the relative value of 斤 and 担 / 擔?']\n",
      "********663***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the characters 錢 and 斤 are the only characters that have metric values measured in grams.\n",
      "Answer: 1\n",
      "['Which characters have metric value measured in g?', ' Are 錢 and 斤 the only characters with metric value measured in g?', 'which characters have metric value measured in grams?']\n",
      "********664***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, Manchester United was in the 2nd league position on multiple dates after November 17, 2005. Therefore, the claim that Manchester United has been in 2nd league position since November 17, 2005 is true.\n",
      "Answer: 1\n",
      "[' How long was Manchester United in 2nd league position?', \"What is Manchester United's league position since November 17, 2005?\", 'When was Manchester United in 2nd league position?']\n",
      "********665***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Manchester United has beaten Portsmouth 2 times since August 13, 2005. \n",
      "Answer: 0\n",
      "[' How many times did Manchester United beat Portsmouth since 13 August 2005?', 'When did Manchester United beat Portsmouth?', 'how many times has Manchester United beaten Portsmouth since August 13, 2005?']\n",
      "********669***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the count of matches where Manchester United lost 0-3 to Portsmouth and the row number is less than or equal to 3 is 0. This means that Manchester United did not lose 3 out of 3 times to Portsmouth since September 10, 2005.\n",
      "Answer: 1\n",
      "['When did Manchester United lose to Portsmouth?', ' How many times did Manchester United lose to Portsmouth since 10 September 2005?', 'how many times has Manchester United lost to Portsmouth since September 10, 2005?']\n",
      "********670***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Manchester United has drawn with Blackburn Rovers 2 times since August 13, 2005. \n",
      "Answer: 1\n",
      "['When did Manchester United draw with Blackburn Rovers?', ' How many times did Manchester United draw with Blackburn Rovers since 13 August 2005?', 'how many times has Manchester United drawn with Blackburn Rovers since August 13, 2005?']\n",
      "********674***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the sub-table shows all the games played in the month of September in the 2006 season. There were 26 games played in September 2006. \n",
      "Answer: 1\n",
      "['What is the date of all the games played in the 2006 season?', 'In which month were all the games played in the 2006 season?', ' How many games were played in the month of September in the 2006 season?']\n",
      "********687***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there were no new episodes of Gary Unmarried in December 2009. \n",
      "Answer: 1\n",
      "[' Were there any new episodes of Gary Unmarried in December 2009?', 'How many new episodes of Gary Unmarried were there in December 2009?', 'how many new episodes of Gary Unmarried were there in December 2009?']\n",
      "********691***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the episode titles that mention both Gary and Allison are \"gary and allison's restaurant\", \"gary and allison brooks\", \"gary hooks up allison\", and \"gary fixes allison's garbage disposal\".\n",
      "Answer: 1\n",
      "['What is the title of the first episode in season 1?', ' What is the title of the second episode in season 1?', 'what is the title of every episode in season 1?']\n",
      "********693***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Boston Celtics only lost 6 games in the 1984-85 season. \n",
      "Answer: 0\n",
      "[' What was the record of the Boston Celtics in the 1984-85 season?', 'How many games did the Boston Celtics lose in the 1984-85 season?', 'how many games did the Boston Celtics lose in the 1984-85 season?']\n",
      "********694***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the New York Knicks won a game against the Boston Celtics at the Boston Garden on January 4th, 1985. Therefore, the claim that the New York Knicks did not win a game against the Boston Celtics in the 1984-85 season is false.\n",
      "Answer: 0\n",
      "['how many games did the New York Knicks win against the Boston Celtics in the 1984-85 season?', ' Did the New York Knicks win any games against the Boston Celtics in the 1984-85 season?', 'When did the New York Knicks play against the Boston Celtics in the 1984-85 season?']\n",
      "********696***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the maximum score achieved by the Boston Celtics against the Detroit Pistons is not available in the sub-table. \n",
      "Answer: 0\n",
      "[' Against which team did the Boston Celtics achieve their highest score in the 1984-85 season?', 'What was the highest score achieved by the Boston Celtics in the 1984-85 season?', 'what was the highest score achieved by the Boston Celtics in the 1984-85 season?']\n",
      "********698***************\n",
      "0 1\n",
      "Thought: The SQL query filters the records where the number of wins is less than the number of losses. If there is no data from the database, it means that there are no records where the Boston Celtics lost more games than they won in the 1984-1985 season.\n",
      "Answer: 1\n",
      "['How many games did the Boston Celtic lose in the 1984-1985 season?', ' How many games did the Boston Celtic win in the 1984-1985 season?', 'what was the win-loss record for the Boston Celtics in the 1984-1985 season?']\n",
      "********700***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the number of games played in the Boston Garden during the 1984-1985 season is less than half of the total number of games played during the season.\n",
      "Answer: 1\n",
      "['In which locations were the games played during the 1984-1985 season?', 'How many games were played in the Boston Garden during the 1984-1985 season?', ' How many games were played outside of the Boston Garden during the 1984-1985 season?']\n",
      "********704***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the schools Georgia and Penn State contribute players in different positions, and the query is looking for positions where both schools contribute players. The schools contribute players in 3 different positions, and 2 of the positions are the same. \n",
      "Answer: 1\n",
      "['which schools contribute players in different positions?', 'Which player played for Georgia?', ' Which player played for Penn State?']\n",
      "********707***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, it can be determined that 1 player from the United States has contributed to the team after 1985. Louis Amundson is the most recent player contributed by the United States.\n",
      "Answer: 0\n",
      "['When did the United States contribute 4 players?', ' Who is the most recent player contributed by the United States?', 'how many players from the United States have contributed to the team after 1985?']\n",
      "********709***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria of school_club_team being 'georgia' or 'penn state' and position being 'center' or 'guard'. Therefore, the claim is false.\n",
      "Answer: 0\n",
      "['Which player from the table played for Georgia?', ' Which player from the table played for Penn State?', 'Which schools contribute a center and a guard to the 3 different positions?']\n",
      "********710***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, after 2000, only Brazil and England contributed 1 player each to the Utah Jazz.\n",
      "Answer: 1\n",
      "['Which countries contributed players to the Utah Jazz after 2000?', ' After 2000, how many players did England contribute to the Utah Jazz?', 'After 2000, how many players did Brazil contribute to the Utah Jazz?']\n",
      "********713***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the episode title \"ありえないキス\" was broadcast 7 days after the title with the earliest broadcast date.\n",
      "Answer: 0\n",
      "['When was the title \"おまえが欲しい\" broadcast?', ' When was the title \"ありえないキス\" broadcast?', 'which episode title was broadcasted 7 days after the title with the earliest broadcast date?']\n",
      "********714***************\n",
      "1 0\n",
      "Thought: The episode \"ありえないキス\" has a rating of 19.2%, and the title with the earliest broadcast date has a rating of 22.4%. To find out if \"ありえないキス\" has 3.2% less rating than the title with the earliest broadcast date, we need to calculate the difference between the two ratings.\n",
      "Answer: 0\n",
      "['What is the rating for the title with the earliest broadcast date?', 'which episode has the highest rating?', ' What is the rating for arienai kisu?']\n",
      "********722***************\n",
      "0 1\n",
      "Thought: The SQL query is filtering for episode titles and ratings where the ratings are greater than 5.8% higher than the lowest rating. The lowest rating is 13.4%, so the episode title \"suki to ietara iinoni\" should have a rating of 19.2% or higher to satisfy the condition.\n",
      "Answer: 1\n",
      "['What is the rating for the title \"suki to ietara iinoni\"?', ' What is the rating for the title with the lowest rating?', 'which episode has the highest rating?']\n",
      "********726***************\n",
      "1 0\n",
      "Thought: Based on the sub-table and extra information provided, the Gold Coast Blaze has a record of 22 losses in the season, with a last 5 record of 3 wins and 2 losses. They have won 3 consecutive games, with a home record of 6 wins and 9 losses, and an away record of 2 wins and 13 losses. Their percentage of points is 93.45, and their percentage of games won is 26.67. However, without data on other teams in the season, it is not possible to compare the Gold Coast Blaze to other teams. Therefore, I cannot get an answer from the sub-table.\n",
      "Answer: 0\n",
      "[' How does gold coast blaze compare to other teams in the season?', 'What is the record of gold coast blaze in the season?', 'which team has the worst record in the season?']\n",
      "********733***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the attendance for the match on 7 March 2001 was 20503, and the attendance for the match on 21 February 2001 was 23266.\n",
      "Answer: 0\n",
      "[' What was the attendance for the match on 21 february 2001?', 'What was the attendance for the match on 7 march 2001?', 'What were the attendance figures for the matches on 7 March 2001 and 21 February 2001?']\n",
      "********737***************\n",
      "1 0\n",
      "Thought: Based on the sub-table provided, the shortest time between two consecutive matches is 3 days, which occurred between the matches on 2000-12-26 and 2000-12-30.\n",
      "Answer: 0\n",
      "[' What is the result of the match on 30 December 2000?', 'What is the shortest time between two consecutive matches?', 'What is the shortest time between 2 consecutive matches?']\n",
      "********744***************\n",
      "1 0\n",
      "Thought: The SQL query filters the data to only show tournaments where Olga Govortsova advanced to the third round or further in a grand slam tournament. However, based on the sub-table provided, there is no data from the database that matches this criteria. \n",
      "Answer: 0\n",
      "['what is the furthest Olga Govortsova has ever advanced in a grand slam tournament?', 'What is the furthest Olga Govortsova has ever advanced in a grand slam tournament?', ' What is the furthest Olga Govortsova has ever advanced in a year-end championship tournament?']\n",
      "********745***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Olga Govortsova has won at least 1 grand slam tournament match in any given year from 2007 - 2011. The query filters for rows where at least one of the columns from c_2007 to c_2011 contains 'grand slam tournaments', and the row number is 1. The sub-table shows that the row number is 1 and all the columns from c_2007 to c_2011 contain 'grand slam tournaments', so the claim is true.\n",
      "Answer: 1\n",
      "['How many grand slam tournaments did Olga Govortsova win in any given year from 2007 - 2011?', ' Did Olga Govortsova win at least 1 grand slam tournament match in any given year from 2007 - 2011?', 'how many grand slam tournament matches did Olga Govortsova win in each year from 2007-2011?']\n",
      "********747***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Olga Govortsova advanced to the third round in the French Open in 2007, but there is no data to confirm whether she advanced to the third round in 2008. \n",
      "Answer: 0\n",
      "['When did Olga Govortsova advance to the third round in the French Open?', 'how did olga govortsova perform in the French Open in consecutive years?']\n",
      "********750***************\n",
      "0 1\n",
      "Thought: The SQL query is counting the number of matches won by Olga Govortsova in the Grand Slam tournaments from 2007 to 2011. The total count of matches won is 5.\n",
      "Answer: 1\n",
      "['how many grand slam tournament matches did Olga Govortsova win in each year from 2007-2011?', 'How many grand slam tournaments did Olga Govortsova win in 2007?', ' How many grand slam tournaments did Olga Govortsova win in 2008?']\n",
      "********763***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Carmelo Anthony was the leading scorer for the Nuggets in 12 out of the 13 games played in November.\n",
      "Answer: 0\n",
      "['who was the leading scorer for the Nuggets in each of the 13 games played in November?', 'How many games did Carmelo Anthony lead in scoring for the Nuggets in November?', ' How many games did the Nuggets play in November?']\n",
      "********764***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data in the sub-table, so we cannot verify whether the Nuggets won all 6 games played at the Pepsi Center during this span.\n",
      "Answer: 0\n",
      "['How many games did the Nuggets win at the Pepsi Center during this span?', ' Did the Nuggets win all 6 games played at the Pepsi Center during this span?', 'how many games did the Nuggets win at the Pepsi Center during this span?']\n",
      "********765***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the attendance of all games at the Pepsi Center was not over 15000. \n",
      "Answer: 0\n",
      "['what was the attendance at each game at the pepsi center?', ' How many games at the Pepsi Center had an attendance over 15000?', 'What is the attendance of all games at the Pepsi Center?']\n",
      "********766***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table does not contain any data from the database. Therefore, it is not possible to verify the claim that Denver did not lose more than 1 game in a row during November.\n",
      "Answer: 0\n",
      "['How many games did Denver lose in a row during November?', 'How many games did Denver lose in November?', ' How many games did Denver win in November?']\n",
      "********767***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Chauncey Billups led or was tied for the lead in assists in 10 games. This means that he did not lead or be tied for the lead in assists in 3 games. \n",
      "Answer: 0\n",
      "['how many games did chauncey billups lead or be tied for the lead in assists?', 'How many games did chauncey billups lead or be tied for the lead in assists?', ' How many games did chauncey billups not lead or be tied for the lead in assists?']\n",
      "********768***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Carmelo Anthony was the leading scorer for the Nuggets in 12 games in November. This is more than 10 games, so the claim is true.\n",
      "Answer: 1\n",
      "[' How many games did Carmelo Anthony not lead in scoring for the Nuggets in November?', 'How many games did Carmelo Anthony lead in scoring for the Nuggets in November?', 'who was the leading scorer for the Nuggets in each game played in November?']\n",
      "********770***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the attendance of all games at the Pepsi Center was not over 19000. The attendance of the games was 19141, 19359, and 19155, which are over 19000.\n",
      "Answer: 1\n",
      "['what was the attendance at each game at the Pepsi Center?', ' How many games at the pepsi center had an attendance over 19000?', 'What is the attendance of all games at the pepsi center?']\n",
      "********773***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that has an attendance figure lower than 12376. The lowest attendance figure for a game is 19911, not 12376.\n",
      "Answer: 0\n",
      "['what is the lowest attendance figure for a game?', ' What is the highest attendance figure for a game?', 'What is the lowest attendance figure for a game?']\n",
      "********777***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data in the database for the Charlotte Bobcats with a record of 3 wins and 7 losses.\n",
      "Answer: 0\n",
      "[' How many losses do the bobcats have?', 'How many wins do the bobcats have?', 'what is the record of the bobcat?']\n",
      "********783***************\n",
      "1 0\n",
      "Thought: The SQL query is filtering for the 2007 season, where the wins are greater than 90% of the total games played and the notes contain the word \"promoted\". The sub-table does not contain any data, so it is not possible to verify the claim based on the provided information.\n",
      "Answer: 0\n",
      "[' What percentage of games did the hurricane win in 2007?', 'what was the win percentage for the hurricane in 2007?', 'How many games did the hurricane win in 2007?']\n",
      "********784***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Dundee Hurricane had 7 losing seasons, not 2. The losing seasons were in the years 2003, 2004, 2005, 2006, 2007, 2008, and 2009.\n",
      "Answer: 0\n",
      "['how many losing seasons did the dundee hurricane have?', 'When did the Dundee Hurricane have a losing season?', ' How many losing seasons did the Dundee Hurricane have?']\n",
      "********787***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the 2009 hurricane season resulted in a final position of 5 out of 7, which is not the lowest final position. \n",
      "Answer: 0\n",
      "['which season resulted in the lowest final position?', ' What was the final position for the 2009 hurricane season?', 'What was the final position for the 2009 hurricane season?']\n",
      "********789***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Dundee Hurricane had losing seasons in the years 2003, 2005, 2007, and 2008. This matches the claim that the Dundee Hurricane had 4 losing seasons in those specific years.\n",
      "Answer: 1\n",
      "['how many losing seasons did the dundee hurricane have?', ' In which years did the dundee hurricane have losing seasons?', 'How many losing seasons did the dundee hurricane have?']\n",
      "********790***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the highest number of ties in a season by the hurricane was 0 in the 2003 season. \n",
      "Answer: 1\n",
      "['how many ties did the hurricane have in each season?', 'What is the highest number of ties in a season by the hurricane?', ' In which season did the hurricane have the highest number of ties?']\n",
      "********793***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table is empty, so we cannot verify the claim.\n",
      "Answer: 0\n",
      "['Which projects were proposed but never listed or completed?', ' Which projects were proposed but never completed?', 'Which projects were proposed but never listed?']\n",
      "********797***************\n",
      "0 1\n",
      "Thought: The SQL query filters the table to show only the rows where the construction was completed between 01/01/1993 and 12/31/1997. The sub-table shows that there are 3 projects that meet this criteria. \n",
      "Answer: 1\n",
      "[' When was the Chemfax, Inc project completed?', 'when were the complete projects completed?', 'When was the Sonford Products project completed?']\n",
      "********810***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the match against London Counties took place on October 28, 1978, which is after the 25th of the month. The other matches took place on October 18, 1978, October 21, 1978, and October 31, 1978, which are also after the 25th of the month. \n",
      "Answer: 1\n",
      "['when did the matches in October 1978 take place?', 'When did the match against Cambridge University take place?', ' When did the match against Cardiff take place?']\n",
      "********812***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, 23,380 people attended the game on September 22, and the score was 8 - 1. \n",
      "Answer: 1\n",
      "['What was the attendance on September 22nd and 23rd?', ' What was the score of the game on September 22nd and 23rd?', 'How many people attended the game on September 22-23 and what was the score?']\n",
      "********817***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Blue Jays' record after their loss to the Red Sox on September 28 was 76 - 86.\n",
      "Answer: 1\n",
      "[\"What was the score of the blue jay's loss to the red sox on September 28?\", 'what is the current record of the blue jays?', \" What was the blue jay's record after their loss to the red sox on September 28?\"]\n",
      "********818***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Blue Jays scored 12 runs once during the month of September. \n",
      "Answer: 1\n",
      "[' What was the highest number of runs scored by the blue jays during the month?', 'how many times did the Blue Jays score 12 runs during the month?', 'How many times did the blue jays score 12 runs during the month?']\n",
      "********819***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Mike Mussina did not get the win in the September 25 game against the Orioles. \n",
      "Answer: 0\n",
      "[' Did Mike Mussina get the win in the September 25 game against the Orioles?', 'Who got the win in the September 25 game against the Orioles?', 'Did Mike Mussina get the win in any game against the Orioles?']\n",
      "********828***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Glasgow Govan is one of the four constituencies with the result as SNP gain. \n",
      "Answer: 1\n",
      "['Which constituency is Glasgow Govan in?', 'which constituencies had a result as snp gain?', ' How many constituencies had SNP gain as the result?']\n",
      "********833***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the maximum score for Steve Stricker from the United States is 139. This means that Steve Stricker has the best score out of all the players from the United States.\n",
      "Answer: 1\n",
      "['which player from the United States had the best score?', 'What is the score of Steve Stricker?', ' Who has the best score out of all the players from the United States?']\n",
      "********837***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the only player from Australia who scored a +1 to par was Geoff Ogilvy. Kenneth Ferrie is not from Australia, so the claim is false.\n",
      "Answer: 0\n",
      "['which players scored a +1 to par?', 'Who are the only players to score a +1 to par?']\n",
      "********851***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the average finish for Shane Hall between 1995 and 2008 is 31.3923, not 31.39.\n",
      "Answer: 0\n",
      "[\"What is Shane Hall's average finish between 1995 and 2008?\", 'What is the average finish of Shane Hall between 1995 - 2008?']\n",
      "********852***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the maximum number of races that Shane Hall ran on the Stegell Motorsports team was 31. However, based on the extra information provided, Shane Hall ran 133 races on his other teams. Therefore, the claim that Shane Hall ran more races on the Stegell Motorsports team than any of his other teams is false.\n",
      "Answer: 0\n",
      "['How many races did Shane Hall run on the stegell motorsports team?', 'how many races did Shane Hall run on each of his teams?', ' How many races did Shane Hall run on his other teams?']\n",
      "********854***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, Shane Hall DNF in 1 race in the year 2000. This is not half of the races he participated in that year.\n",
      "Answer: 0\n",
      "['How many races did Shane Hall DNF in the year 2000?', 'How many races did Shane Hall DNF in each year?', ' How many races did Shane Hall finish in the year 2000?']\n",
      "********855***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Shane Hall ran a total of 198 races between the years 1996 and 2008. Adding up the races from each year, the total is 198.\n",
      "Answer: 1\n",
      "[\" What was Shane Hall's season rank in 2004?\", 'How many races did Shane Hall run between the year of 1996 - 2008?', 'How many races did Shane Hall run each year between 1996 and 2008?']\n",
      "********869***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the spiral galaxy with the second highest declination (J2000) in the list is NGC 5457 with a declination of degree20′53″. \n",
      "Answer: 1\n",
      "[' What is the declination (j2000) of the object with the second highest declination in the list?', 'What is the declination (J2000) of the spiral galaxy in the list?', 'What is the declination (j2000) of the spiral galaxy?']\n",
      "********876***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Kardinia Park was one of the 4 venues that were put to use on 3 June 1961. \n",
      "Answer: 1\n",
      "[' Was Kardinia Park one of the 4 venues that were put to use on 3 June 1961?', 'which venues were put to use on 3 June 1961?', 'What are the 4 venues that were put to use on 3 June 1961?']\n",
      "********879***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Glenferrie Oval venue record 5000 more crowd participants than that of the Arden Street Oval venue. The crowd size at the Glenferrie Oval venue is 15000, and the crowd size at the Arden Street Oval venue is 13000. Therefore, the claim is true.\n",
      "Answer: 1\n",
      "['What is the crowd size at the glenferrie oval venue?', 'how many crowd participants were there at each venue?', ' What is the crowd size at the arden street oval venue?']\n",
      "********880***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the table is being filtered to show only the highest rank and the count of each highest rank. The HAVING clause is then used to filter the results to only show the highest ranks that have a count of 2. However, based on the extra information provided, there are 12 sumo wrestlers with the highest rank listed in the table, not just 2. \n",
      "Answer: 0\n",
      "['What are the names of the sumo wrestlers with the highest rank in the table?', ' How many sumo wrestlers have the highest rank listed in the table?', 'how many wrestlers are listed in the table and what are their highest ranks?']\n",
      "********881***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the time range between the first and last record for Takamiyama is 4687 days, not 13 years. \n",
      "Answer: 0\n",
      "['What is the time range between the first and last record for takamiyama?', ' How many years is the time range between the first and last record for takamiyama?', 'What is the time range between the first and last record for each sumo wrestler?']\n",
      "********882***************\n",
      "1 0\n",
      "Thought: The sub-table provided does not contain the necessary data to answer the query. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['which sum of total appears more than twice?', 'What is the total for the only name that appears more than 2 times?', ' What is the first appearance for the only name that appears more than 2 times?']\n",
      "********888***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the first record in the table is for the wrestler named \"kotonishiki\" with a first date of 1990-09-14, which is after November 1965. The first record for the name \"daikirin\" is on November 14, 1966, which is also after November 1965. The first record for the name \"tochiazuma ii\" was on September 14, 1990, which is also after November 1965. Therefore, the claim is true.\n",
      "Answer: 1\n",
      "['What is the first record in the table?', ' When was the first record for the name \"daikirin\"?', 'When was the first record for the name \"tochiazuma ii\"?']\n",
      "********894***************\n",
      "1 0\n",
      "Thought: The SQL query is looking for the count of rows where the location is either 'seoul' or 'doha' and the location is 'incheon' and 'south korea'. The count returned is 1. Based on the sub-table, we cannot get an answer to the query as the sub-table does not contain the necessary information to verify the claim. \n",
      "Answer: 0\n",
      "[' In which years did South Korea host equestrian at the Asian Games?', 'which country has hosted equestrian at the Asian Games more than once?', 'How many times has South Korea hosted equestrian at the Asian Games?']\n",
      "********895***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the equestrian events at the Asian Games occurred every 4 years from 1982 to 2010, as the years selected are all divisible by 4 and within the specified range.\n",
      "Answer: 1\n",
      "[' How often does the equestrian event at the Asian Games occur?', 'What year did the equestrian event at the Asian Games take place?', 'how often do equestrian events occur at the Asian Games?']\n",
      "********896***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the equestrian event at the Asian Games was located in a different city every year that it occurred, except for 1994 and 1998. The location of the equestrian event at the Asian Games in 1982 was New Delhi, in 1986 was Seoul, in 2002 was Busan, in 2006 was Doha, and in 2010 was Guangzhou.\n",
      "Answer: 1\n",
      "['In which years did the equestrian event at the Asian Games take place in a different city?', ' What is the location of the equestrian event at the Asian Games in 1986?', 'What is the location of the equestrian event at the Asian Games in 1982?']\n",
      "********898***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the gold medalists for equestrian at the Asian Games have been different in every year they have occurred except for 1994 and 1998. This is because the query is selecting distinct years and gold medalists from the table, excluding the years 1994 and 1998.\n",
      "Answer: 1\n",
      "['Who were the gold medalists for equestrian at the Asian Games in 1994 and 1998?', 'who were the gold medalists for equestrian at the Asian Games in each year they have occurred?', ' Who were the gold medalists for equestrian at the Asian Games in 1982, 1986, and 2006?']\n",
      "********899***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, South Korea is the only country to have hosted equestrian at the Asian Games more than once, with Seoul hosting the event twice in 1986 and 1988.\n",
      "Answer: 1\n",
      "[' In which year did South Korea host equestrian at the Asian Games?', 'which countries have hosted equestrian at the Asian Games and how many times?', 'How many times has South Korea hosted equestrian at the Asian Games?']\n",
      "********910***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the lowest number of strokes that Annika Sörenstam and Yani Tseng won with is 272. However, the lowest number of strokes that Annika Sörenstam and Yani Tseng won with is not the lowest. The golfer who won with the lowest number of strokes is Karen Stupples.\n",
      "Answer: 0\n",
      "[' How many strokes did Annika Sörenstam and Yani Tseng win with?', 'What is the lowest number of strokes that Annika Sörenstam and Yani Tseng won with?', 'Which golfers won with the lowest number of strokes?']\n",
      "********913***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Jiyai Shin was the champion by beating Inbee Park in the 2012 open with a margin of victory of 9 strokes. However, the extra information states that the margin of victory for the champion in the 2012 open was 2 strokes, not 9 strokes. \n",
      "Answer: 0\n",
      "[' Who did Jiyai Shin beat in the 2012 open?', 'what was the margin of victory for the champion in the 2012 open?', 'Who was the champion in the 2012 open?']\n",
      "********915***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the lowest number of strokes that Annika Sörenstam and Catriona Matthew won with is 278. \n",
      "Answer: 1\n",
      "['which golfers won with the lowest number of strokes?', 'What is the lowest number of strokes that Annika Sörenstam and Catriona Matthew won with?', ' How many strokes did Annika Sörenstam and Catriona Matthew win with?']\n",
      "********933***************\n",
      "0 1\n",
      "Thought: The SQL query is checking if the count of the decision \"Backstrom\" is 11 times more than the count of the decision \"Harding\" during the 2007-08 Minnesota Wild season. The count of \"Backstrom\" is 11 and the count of \"Harding\" is 3, so the claim is true.\n",
      "Answer: 1\n",
      "[' During the 2007 - 08 minnesota wild season, how many times was the decision Harding?', 'During the 2007 - 08 minnesota wild season, how many times was the decision Backstrom?', 'how many times did the decision be Backstrom during the 2007-08 Minnesota Wild season compared to Harding?']\n",
      "********939***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the lion's win-loss record was 3 wins and 6 losses. The sub-table shows the results of the games where the result starts with 'w' or 'l' and the week is less than or equal to 14. The lion's win-loss record is not 6 wins and 8 losses.\n",
      "Answer: 0\n",
      "[\"what was the lion's win-loss record?\", 'How many wins did the lion finish with?', ' How many losses did the lion finish with?']\n",
      "********941***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Minnesota Vikings defeated the Detroit Lions in both games they played.\n",
      "Answer: 0\n",
      "['how many games did the Minnesota Vikings win against the Lions?', ' How many games did the Minnesota Vikings win against the Lions?', 'How many games did the Minnesota Vikings play against the Lions?']\n",
      "********943***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the minimum score that the Packers received in a game versus the Lions was 24, not 6. \n",
      "Answer: 0\n",
      "[' What was the result of the game between the Packers and the Lions?', 'How many points did the Packers score in the game versus the Lions?', 'how many points did the Packers score in a game versus the Lions?']\n",
      "********951***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Wildcats lost 1 game in September and 3 games in November. \n",
      "Answer: 0\n",
      "[' How many games did the wildcats lose in November?', 'how many games did the wildcats lose in September and November?', 'How many games did the wildcats lose in September?']\n",
      "********955***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the wildcats scored 7 points in a game they won. The query is true.\n",
      "Answer: 1\n",
      "['What is the highest number of points the wildcats have scored in a game they won?', 'what is the highest number of points the wildcats have scored in a game they won?', ' What is the lowest number of points the wildcats have scored in a game they won?']\n",
      "********959***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the constructor \"march - ford\" had the most laps completed with 79 laps, and the constructor \"mclaren - ford\" had the least laps completed with 5 laps. The Ford driver completed 881 laps. The Alfa Romeo and Matra drivers completed a total of 78 + 75 = 153 laps. Since the Ford drivers completed more laps than the Alfa Romeo and Matra drivers combined, there were more Fords than any other constructor, and Alfa Romeo and Matra tied for the least.\n",
      "Answer: 1\n",
      "['Which constructor had the most laps completed and which had the least?', 'How many laps did the Ford driver complete?', ' How many laps did the Alfa Romeo and Matra drivers complete?']\n",
      "********960***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the most common issue affecting the race was engine trouble, which occurred 4 times. The query is false.\n",
      "Answer: 0\n",
      "['What is the most common issue affecting the race?', ' What is the most common issue affecting the time of retirement for drivers?', 'What is the most common issue affecting the time of retirement for drivers?']\n",
      "********961***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide enough information to determine who has the highest position at 25 on the grid. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['What are the grid positions of Alex Soler-Roig, Howden Ganley, and Jackie Stewart?', 'Who has the highest position at 25 on the grid?', ' Who has the position at 24 on the grid?']\n",
      "********968***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only driver who completed more than 75 laps and did not have a time listed as retired is Mario Andretti. All other drivers who completed more than 75 laps had some kind of trouble during the race and did not finish. \n",
      "Answer: 1\n",
      "['Which drivers had trouble during the race and did not finish?', ' How many laps did each driver complete?', 'Which drivers had trouble during the race?']\n",
      "********969***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, we cannot definitively determine if Team Brazil is the only football club located on the South American continent. The sub-table only shows that there is at least one football club that meets the criteria specified in the SQL query, but it does not provide enough information to determine if there are other football clubs located on the continent.\n",
      "Answer: 0\n",
      "['which football clubs are located on the South American continent?', 'Which football club is located on the South American continent?', ' Is Team Brazil the only football club located on the South American continent?']\n",
      "********1004***************\n",
      "0 1\n",
      "Thought: The SQL query is filtering for the episode that aired on December 17 with a higher production number than the Ray J episode and with the title '702'. The production number of the Ray J episode is 351, and the production number of the episode that aired on December 17 is 343, so the claim is true.\n",
      "Answer: 1\n",
      "[' What is the production number of the Ray J episode?', 'which episode has the highest production number?', \" What is the production number of the episode titled '702'?\", 'What is the production number of the episode that aired on December 17?']\n",
      "********1007***************\n",
      "0 1\n",
      "Thought: The SQL query is filtering for all episode titles that contain any letter of the alphabet. The episode title for season 2 is \"montell jordan\", which contains the letter \"a\", so the claim is true.\n",
      "Answer: 1\n",
      "['what is a common characteristic of the episode titles?', 'What are the episode titles for season 1?', ' What are the episode titles for season 2?']\n",
      "********1010***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the team classification wins for caisse d'epargne in the sub-table are 6, not 11. The team with the most team classification wins is caisse d'epargne with 11 wins.\n",
      "Answer: 0\n",
      "[\"How many team classification wins does caisse d'epargne have?\", 'which team has the most team classification wins?', ' Which team has the most team classification wins?']\n",
      "********1022***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows all the rows where the number of wins is 0. The sub-table does not show any rows where the name is Casey Martin, so we cannot determine whether Casey Martin has never won a tournament based on this sub-table.\n",
      "Answer: 0\n",
      "['How many tournaments did Casey Martin win?', ' How many tournaments did Casey Martin win?', 'When did Casey Martin win a tournament?']\n",
      "********1029***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the record for the discus throw was set on the 5th of September 1986 by Bulgaria. The record is 69.84 meters.\n",
      "Answer: 0\n",
      "['When was the record for the discus throw set?', 'What is the record for the discus throw and who set it?', ' By whom was the record for the discus throw set?']\n",
      "********1034***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the pole vault event occurred before August 26, 2005. \n",
      "Answer: 1\n",
      "['Which event occurred before August 26, 2005?', 'When was the pole vault event before August 26, 2005?']\n",
      "********1044***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only year that \"Reason to be Pretty\" had a nominee at the Drama Desk Award ceremony was 2009. \n",
      "Answer: 1\n",
      "[' What category was \"Reason to be Pretty\" nominated for at the Drama Desk Award ceremony?', 'What year was the only year that \"Reason to be Pretty\" had a nominee at the Drama Desk Award ceremony?', 'In which years did \"reason to be pretty\" have a nominee at the drama desk award ceremony?']\n",
      "********1046***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the query cannot be answered as there is no data present in the sub-table. Therefore, the answer cannot be obtained from the sub-table.\n",
      "Answer: 0\n",
      "['where did louisville play on november 14?', ' What was the result of the game on November 14?', 'Where did Louisville play on November 14?']\n",
      "********1053***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, UAB was the opponent when they played at the Legion Field Birmingham, AL site.\n",
      "Answer: 1\n",
      "['which team played at the legion field birmingham, al site?', ' Who was the opponent when UAB played at the Legion Field in Birmingham, AL?', 'When did UAB play at the Legion Field in Birmingham, AL?']\n",
      "********1067***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria of a field goal percentage of 594 and 2.4 blocks per game. \n",
      "Answer: 0\n",
      "['How many blocks per game were there during the season where the field goal percentage was 594 (2nd)?', 'how many blocks per game were there during the season with a field goal percentage of 594 (2nd)?', ' What was the field goal percentage during the season where there were 2.4 blocks per game?']\n",
      "********1070***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the screenings that started on or after March 29, 2006, and were completed on or before May 3, 2006, are rows 5 and 15.\n",
      "Answer: 0\n",
      "[' When did the screening that started on March 29, 2006, be completed?', 'When did the screening that started on March 29, 2006, be completed?', 'when were the screenings started and completed?']\n",
      "********1071***************\n",
      "0 1\n",
      "Thought: The query is looking for screenings that started on May 3rd, 2006 and ended on March 29th, 2006. This is logically impossible as the end date cannot be before the start date. Therefore, there should be no data returned from the database.\n",
      "Answer: 1\n",
      "['When did the screening that started on May 3rd, 2006 end?', ' When did the screening that started on May 3rd, 2006 start?']\n",
      "********1082***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the scores for the Air Force - Navy games up until 2018 are listed. The scores are already decided and are not pending. \n",
      "Answer: 1\n",
      "['what are the scores for air force - navy games up until 2018?', ' What was the score for air force - navy in 2017?', 'What was the score for air force - navy in 2018?']\n",
      "********1084***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the seasons that had an army - navy game in Baltimore, MD (M&T Bank Stadium) are 2014 and 2016. The season that did not have an army-navy game in Baltimore, MD is 2013. Therefore, all but 1 season had or is about to have an army - navy game in Baltimore, MD (M&T Bank Stadium).\n",
      "Answer: 1\n",
      "[' Which seasons had an army - navy game in Baltimore, MD?', 'Which season did not have an army - navy game in Baltimore, MD?', 'In which season did the army - navy game take place in Baltimore, MD (M&T Bank Stadium)?']\n",
      "********1090***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the boy double in 2010 was Jones Ralfy Jansen and Dandi Prabudita, and the girl double in 2010 was Ayu Pratiwi Anggi Widia. \n",
      "Answer: 1\n",
      "['Which players were in the girl doubles and boy doubles in 2010?', ' Who were the boy double in 2010?', 'Who were the girl double in 2010?']\n",
      "********1099***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, Richmond hosted a team at Punt Road Oval, but the specific team is not provided in the sub-table. Therefore, the answer to the query \"which team did Richmond host at Punt Road Oval?\" cannot be determined from the sub-table.\n",
      "Answer: 0\n",
      "[' Where did Richmond host Fitzroy?', 'When did Richmond host Fitzroy at Punt Road Oval?', 'which team did richmond host at punt road oval?']\n",
      "********1111***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the computer does not have AMT 3.0 when the value of \"amt_30_desktop\" is 'no' in the sub-table. \n",
      "Answer: 1\n",
      "['what features does the computer have for the intel amt network interface?', 'When does the computer have the feature of VLAN setting for Intel AMT network interface?', ' When does the computer not have AMT 3.0?']\n",
      "********1112***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the districts that had someone first elected in the 1980s are Pennsylvania7 and Pennsylvania17. The claim that Pennsylvania17 is the only district that had someone first elected in the 1980s is false.\n",
      "Answer: 0\n",
      "['which district had someone first elected in the 1980s?', 'Which district is the only one to have someone first elected in the 1980s?', ' Which district has someone first elected in the 1980s?']\n",
      "********1113***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the number of republican incumbents who were first elected in 1974 is greater than the number of democratic incumbents who were first elected in 1974.\n",
      "Answer: 0\n",
      "[' How many democratic incumbents were first elected in 1974?', 'How many republican incumbents were first elected in 1974?', 'how many republican and democratic incumbents were first elected in 1974?']\n",
      "********1114***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the count of republican incumbents re-elected is 1. The sub-table does not provide information about the total number of republican incumbents re-elected, so it is not possible to determine if William F. Goodling is 1 of 6 republican incumbents to be re-elected.\n",
      "Answer: 0\n",
      "['how many republican incumbents were re-elected?', 'How many republican incumbents were re-elected?', ' How many democratic incumbents were re-elected?']\n",
      "********1119***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the game \"Spy vs Spy\" is in the arcade genre and is available on the Amstrad CPC platform.\n",
      "Answer: 0\n",
      "['What is the genre of Spy v Spy?', 'What genre is Spy v Spy in and with which platform?', ' What format is Spy v Spy available in?']\n",
      "********1132***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the series \"interior loft\" was directed by Ken Wiederhorn and originally aired on January 22, 1990. However, the sub-table does not provide the director of the series and the original airdate. Therefore, I cannot verify the claim based on the sub-table.\n",
      "Answer: 0\n",
      "['who directed the series \"interior loft\" and when did it originally air?', ' When did the series \"interior loft later\" originally air?', 'Who directed the series \"interior loft later\"?']\n",
      "********1142***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Newell's Old Boys scored 136 points in the 1987-88 season, not 55 points.\n",
      "Answer: 0\n",
      "[' How many points did Racing de Córdoba score in the 1987-88 season?', \"how many points did newell's old boy score in the 1987-88 season?\", 'How many points did Independiente score in the 1987-88 season?']\n",
      "********1145***************\n",
      "0 1\n",
      "Thought: The SQL query is filtering for the time for Wallace Spearmon of the United States to be more than the time for Rondell Sorillo of Trinidad and Tobago. The time for Wallace Spearmon is 20.39 seconds and the time for Rondell Sorillo is 20.63 seconds. Based on the query, the time for Wallace Spearmon is more than the time for Rondell Sorillo.\n",
      "Answer: 1\n",
      "['how do the times for Wallace Spearmon and Rondell Sorillo compare?', 'What is the time for Wallace Spearmon of the United States?', ' What is the time for Rondell Sorillo of Trinidad and Tobago?']\n",
      "********1148***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the information about the team that lost at Texas Stadium on December 10 to the New Orleans Saints. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['which team lost at Texas Stadium on December 10 to the New Orleans Saints?', ' When did the New Orleans Saints win at Texas Stadium?', 'When did the Dallas Cowboys lose at Texas Stadium?']\n",
      "********1174***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the claim is that Greg Monroe scored the highest number of rebounds and Rodney Stuckey scored the highest number of points in the game. However, the SQL query does not return any data from the database, so we cannot verify the claim.\n",
      "Answer: 0\n",
      "['Which players scored the highest number of rebounds and points in each game?', ' Who scored the highest number of points in the game?', 'Who scored the highest number of rebounds in the game?']\n",
      "********1175***************\n",
      "1 0\n",
      "Thought: The sub-table shows that Austin Daye scored 16 points in the game, and the team was Dallas. However, the sub-table does not provide information about whether Austin Daye scored the highest number of points in the game. \n",
      "Answer: 0\n",
      "['which player scored the highest number of points in the game and for which team?', ' What was the score of the game where player Austin Daye scored the highest number of points and the team was Dallas?', 'Who scored the highest number of points in the game where the team was Dallas?']\n",
      "********1176***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Will Bynum scored the highest number of assists in the game with 5 assists, and the attendance at the Carrier Dome was 11747. However, the actual player who scored the highest number of assists in the game was Rodney Stuckey with 5 assists, not Will Bynum. Therefore, the claim is false.\n",
      "Answer: 0\n",
      "['Which player scored the highest number of assists in the game and what was the attendance at the Carrier Dome?', ' What was the attendance at the carrier dome?', 'Who scored the highest number of assists in the game?']\n",
      "********1179***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the team Dallas was the opponent in the game in which Austin Daye scored the lowest points. \n",
      "Answer: 1\n",
      "[' Who was the opponent in the game where Austin Daye scored the lowest points?', 'In which game did Austin Daye score the lowest number of points?', 'In which game did Austin Daye score the lowest points?']\n",
      "********1196***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the claim that on 7 May 1960, a crowd of 9000 watched the away team, Richmond, score 3.8 (26) is false. The sub-table shows that there were 110,637 people in the crowd on that date.\n",
      "Answer: 0\n",
      "[' What was the score of the away team, Richmond, on 7 may 1960?', 'how many people were in the crowd on 7 may 1960?', 'How many people were in the crowd on 7 may 1960?']\n",
      "********1198***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the claim is true. The crowd size on May 7, 1960 was larger than 23135, and the away team score was 3.8 (26) and the home team score was 5.12 (42).\n",
      "Answer: 1\n",
      "['How many people were in the crowd on May 7, 1960 for each game?', 'What was the crowd size on May 7, 1960?', ' What was the away team score on May 7, 1960?']\n",
      "********1206***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the necessary information to answer the query. Therefore, I cannot get an answer from the sub-table.\n",
      "Answer: 0\n",
      "['When the record is 11 - 32 - 11, what is the score?', 'What was the score when the record was 11 - 32 - 11?']\n",
      "********1221***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the table shows buildings with a height of at least 196 feet. The building with the least number of feet is \"union buildings\" with a height of 196 feet. Therefore, the claim that there is no building with less than 196 feet is false.\n",
      "Answer: 0\n",
      "[' What is the name of the building with the least number of feet?', 'What is the height of the building with the least number of feet?', 'Which buildings have a height of at least 196 feet?']\n",
      "********1235***************\n",
      "1 0\n",
      "Thought: The SQL query is filtering for the brazil_100percent_percent_of_the_population for the age group 15 - 17. The result returned is 10357874. The total Brazilian population for the age group 15 - 17 is 10,357,900. The result returned by the SQL query is greater than the total population for the age group 15 - 17, so the claim is false.\n",
      "Answer: 0\n",
      "['What is the total Brazilian population for the age group 0 - 4?', ' What is the total Brazilian population for the age group 15 - 17?', 'what is the total population for each age group in Brazil?']\n",
      "********1237***************\n",
      "1 0\n",
      "Thought: The Coquitlam Adanacs made a total of 1129 points over 44 seasons. The claim that they made 1177 points over 45 seasons is false.\n",
      "Answer: 0\n",
      "[' How many seasons did the coquitlam adanacs play in total?', 'how many points did the coquitlam adanacs make each season?', 'How many points did the coquitlam adanacs make in total?']\n",
      "********1239***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the team called the Coquitlam Adanacs has been called the Coquitlam Adanacs throughout all 45 seasons since 1965. \n",
      "Answer: 1\n",
      "['what is the name of the team throughout all 45 seasons since 1965?', ' How many losses did the team called the coquitlam adanacs have throughout all 45 seasons since 1965?', 'How many games did the team called the coquitlam adanacs play throughout all 45 seasons since 1965?']\n",
      "********1262***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the information needed to answer the query. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['Who wrote episode 149?', 'Which episode did Bob Sand write?', ' What is the title of episode 149?']\n",
      "********1269***************\n",
      "1 0\n",
      "Thought: The sub-table shows that Daniel Uberti was sacked on December 29, 2008. However, it does not provide the date when Nelson Ancheta was appointed as manager. Nelson Ancheta was appointed manager on January 1, 2009, not the same day as Daniel Uberti's departure.\n",
      "Answer: 0\n",
      "['when was daniel uberti sacked and when was nelson ancheta appointed as manager?', 'When was Daniel Uberti sacked?', ' When was Nelson Ancheta appointed manager?']\n",
      "********1275***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the information needed to answer the query \"When was Melbourne the away team?\" Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "[' When was St Kilda the home team?', 'which team was the away team when the home team was St Kilda?', 'When was Melbourne the away team?']\n",
      "********1288***************\n",
      "0 1\n",
      "Thought: Based on the sub-table provided, the episode titled \"the expulsion\" is the one that meets the criteria specified in the SQL query. Therefore, the episode titled \"the expulsion\" is the one being referred to in the query.\n",
      "Answer: 1\n",
      "[' What is the title of the 35th episode?', 'What is the title of the 1st episode?', 'which episode is titled \"the expulsion\"?']\n",
      "********1296***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria of 12 t - 260 eu aircraft currently in service.\n",
      "Answer: 0\n",
      "['how many t - 260 eu aircraft are currently in service?', ' What is the total number of t-260 eu aircraft in service?', 'How many t-260 eu aircraft are currently in service?']\n",
      "********1297***************\n",
      "1 0\n",
      "Thought: Based on the sub-table provided, we cannot get an answer to the query \"Are there any c - 95 aircraft of Brazilian origin currently in service?\" as the sub-table is empty.\n",
      "Answer: 0\n",
      "['How many c - 95 aircraft of brazilian origin are currently in service?', 'how many c - 95 aircraft of Brazilian origin are currently in service?', ' Are there any c - 95 aircraft of brazilian origin currently in service?']\n",
      "********1298***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria of 12 t - 260 eu aircraft currently in service.\n",
      "Answer: 0\n",
      "['how many t - 260 eu aircraft are currently in service?', 'How many t-260 eu aircraft are currently in service?', ' How many t-260 eu aircraft have been delivered?']\n",
      "********1299***************\n",
      "1 0\n",
      "Thought: The SQL query filters for aircraft with the designation \"C-95 Brazilian\" and with a value of \"in_service\" equal to 3. Based on the sub-table generated, there are 0 aircraft that meet these criteria, so the claim that there are 3 C-95 Brazilian aircraft currently in service is false.\n",
      "Answer: 0\n",
      "['How many C-95 Brazilian aircraft are currently in service?', ' Are there any C-95 Brazilian aircraft currently in service?', 'how many Brazilian aircraft are currently in service?']\n",
      "********1329***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the total number of goals scored by players during the years 1950 through 1965 is 157. The query is asking for the goal score to be less than 160, which is true based on the total number of goals scored. \n",
      "Answer: 1\n",
      "['How many goals were scored by players during the years 1950 through 1965?', ' During the year of 1950 through 1965, how many goals did Florea Dumitrache score?', 'During the year of 1950 through 1965, how many goals did Mihai Adam score?']\n",
      "********1341***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the total medal for the nation with 1 silver and 0 gold is 4, which is more than 2.\n",
      "Answer: 1\n",
      "['which nation has the most total medals?', 'What is the total medal for the nation with 1 silver and 0 gold?', ' What is the total medal for the nation with 0 silver and 1 gold?']\n",
      "********1342***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the necessary information to answer the query. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['Which episode did Katie Kansa coach?', 'which episode did katie kansa coach?']\n",
      "********1350***************\n",
      "1 0\n",
      "Thought: The SQL query provided is looking for a candidate with 57.6% of the votes and another candidate with 42.4% of the votes. The query is looking for the candidate John J Phillips (R) and N.E. West (D).\n",
      "Answer: 0\n",
      "['Who is the candidate with 57.6% of the votes?', 'What are the results of the election for the candidate John J. Phillips (R) and N.E. West (D)?', ' Who is the candidate with 42.4% of the votes?']\n",
      "********1359***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Republican party had their first election in 1940.\n",
      "Answer: 1\n",
      "['When was the first election for the Republican party?', ' Which party had the first election in 1940?']\n",
      "********1384***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the last appearance of paddock was in the episode \"blood is thicker than water (2x12)\" and the last appearance of red squirrels was in the episode \"a hero's welcome (2x01)\". \n",
      "Answer: 0\n",
      "['What are the last appearances of the animals in the table?', ' When was the last appearance of red squirrel?', 'When was the last appearance of paddock?']\n",
      "********1386***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the specified conditions. However, based on the extra information provided, the playing surface at Auckland, New Zealand on October 10, 2004, was hard.\n",
      "Answer: 0\n",
      "['What was the playing surface at Auckland, New Zealand on January 14, 1996?', 'what was the playing surface at each tournament?', ' What was the playing surface at Auckland, New Zealand on November 1, 1998?']\n",
      "********1396***************\n",
      "1 0\n",
      "Thought: Based on the provided sub-table, Jeremy Summers directed the episode \"The Maze\" on 1966-12-14, which was written by Tony O'Grady (pseudonym of Brian Clemens). \n",
      "Answer: 0\n",
      "[' Who wrote the episode directed by Jeremy Summers?', 'Which episode was directed by Jeremy Summers?', 'When did Jeremy Summers direct an episode?']\n",
      "********1402***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, episodes 15 and 16 of the series \"The Avengers\" were filmed in July/August 1966. The episodes \"Storm Warning (Part One)\" and \"The Island (Part Two)\" were filmed in Jul / Aug 1966. Therefore, the claim that \"There's Somebody Close Behind You\" was filmed in Jul / Aug 1966 is true.\n",
      "Answer: 1\n",
      "['On jul / aug 1966 , what episode of the series \"The Avengers\" was filmed?', 'what episodes were filmed in jul / aug 1966?']\n",
      "********1409***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the total fertility rate (TFR) in the period 2000 - 2005 was 2.25, and the natural change (NC) was 13.4. \n",
      "Answer: 0\n",
      "['What were the total fertility rate and natural change during the period 2000 - 2005?', 'In the period 2000 - 2005, what was the total fertility rate (TFR)?', ' In the period 2000 - 2005, what was the natural change (NC)?']\n",
      "********1418***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there is no data from the database that matches the criteria of Jose Ortiz being the center in the Oregon State Jazz club from 1988 - 90. \n",
      "Answer: 0\n",
      "['When did Jose Ortiz play for the Oregon State Jazz club?', ' What position did Jose Ortiz play for the Oregon State Jazz club?', 'Which players were centers for the Utah Jazz and which years did they play for the team?']\n",
      "********1427***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, Dan O'Sullivan went to Kansas and played the center position.\n",
      "Answer: 1\n",
      "['Which player went to Kansas and played the center position?', \" What position did Dan O'Sullivan play for Kansas?\", \"When did Dan O'Sullivan play for Kansas?\"]\n",
      "********1429***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the average win percentage of a season with a gb of 5 is 53.5%. 53.5% is the average win percentage of a season with a gb of 5.\n",
      "Answer: 0\n",
      "['What is the average win percentage of a season with a gb of 5?']\n",
      "********1430***************\n",
      "1 0\n",
      "Thought: The average win percentage of a season with a gb of 5 is 535, not 0.535. The decimal point is not in the correct place.\n",
      "Answer: 0\n",
      "['What is the average win percentage of a season with a gb of 5?']\n",
      "********1432***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the average win percentage of a season with a gb of 5 in 2011 was 0.535.\n",
      "Answer: 1\n",
      "['what is the average win percentage of a season with a gb of 5?', 'What is the average win percentage of a season with a gb of 5 in 2011?']\n",
      "********1447***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the region 1 episode that aired in September aired in region 2 earlier. The region 1 episode that aired in September 2006 aired earlier than the region 2 episode that aired in September 2007.\n",
      "Answer: 1\n",
      "['which region aired the episodes first?', 'When did the region 1 episode air?', ' When did the region 2 episode air?']\n",
      "********1452***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the southwest region won 1 game in 2011. The southwest region won and lost a total of 5 games in 2011. The record of 28 - 12 does not match the results from the sub-table.\n",
      "Answer: 0\n",
      "['How many games did the southwest region win in 2011?', 'how many games did the southwest region win and lose in 2011?', ' How many games did the southwest region lose in 2011?']\n",
      "********1456***************\n",
      "0 1\n",
      "Thought: The SQL query is filtering for results that match specific criteria and a record of 27 - 9. However, based on the extra information provided, the record for the year 2013 is 27 - 9, which matches the query. \n",
      "Answer: 1\n",
      "[' What is the seed for the w 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 62 - 70 result?', 'What is the record for the w 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 62 - 70 result?', 'what is the record for each year?']\n",
      "********1462***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the earliest year when the result was nominated and the role/episode was Fox Mulder is 1996.\n",
      "Answer: 1\n",
      "['what is the earliest year when the result was a nomination and the role/episode was Fox Mulder?', 'What is the earliest year when the result was nominated?', ' What is the earliest year when the role/episode was Fox Mulder?']\n",
      "********1470***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the first elected date for Goodloe Byron is not available. Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['which election did Goodloe Byron win with 73.7% of the vote?', 'When was Goodloe Byron first elected?', ' What was the result of the election with Goodloe Byron as the incumbent politician?']\n",
      "********1484***************\n",
      "0 1\n",
      "Thought: Based on the sub-table provided, we can see that the query filters for the event \"paris - bourges\" on October 9 and the winner being \"jérôme pineau\". Therefore, based on the sub-table, we can conclude that jérôme pineau was indeed the winner for the event on October 9.\n",
      "Answer: 1\n",
      "['Who was the winner for the event on October 9?', ' Was jérôme pineau the winner for the event on October 9?', 'who won the event on October 9th?']\n",
      "********1485***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the first leg score for the match with a team 1 of Panathinaikos was 1 - 3.\n",
      "Answer: 0\n",
      "['What was the first leg score for the match with a team 1 of panathinaikos?', 'what was the first leg score for each match?']\n",
      "********1504***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Iran has the lowest Mideast rank. \n",
      "Answer: 1\n",
      "['What is the rank of Iran in the Mideast?', ' Which country has the lowest Mideast rank?', 'which country has the lowest mideast rank?']\n",
      "********1508***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the countries that have won bronze medals are Netherlands, Germany, South Korea, Soviet Union, and Great Britain. None of these countries have 4 bronze medals. \n",
      "Answer: 1\n",
      "['which countries have won bronze medals?', ' Which country has no bronze medals?', 'Which country has 4 bronze medals?']\n",
      "********1517***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the total rebound for each player is listed in the extra information. The sub-table shows that no player has a total rebound greater than 1048. \n",
      "Answer: 1\n",
      "['What is the total rebound for each player?', 'What is the total rebound for herb estes?', ' What is the total rebound for kenny sanders?']\n",
      "********1518***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there are no records in the database that match the criteria of George Evans having zero rebounds and a rank greater than 8.\n",
      "Answer: 1\n",
      "['Which players have a rank larger than 8 and zero rebounds?', ' How many games did the player with zero rebounds and named George Evans play?', 'What is the rank of the player with zero rebounds and named George Evans?']\n",
      "********1525***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the score in the final of Katerina Maleeva's match against her opponent was 6 - 2, 7 - 6 (3). \n",
      "Answer: 0\n",
      "['Who was the opponent of Katerina Maleeva in the final?', \"what were the scores in the finals of Katerina Maleeva's matches against her opponents?\", \" What was the score in the final of Katerina Maleeva's match?\"]\n",
      "********1537***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, there are 2 wins when the top 25 is less than 4, and there are 4 wins when the top 10 is less than 4. Therefore, the claim that there are no wins when the top 25 and even the top 10 are less than 4 is false.\n",
      "Answer: 0\n",
      "['How many wins are there when the top 25 is less than 4?', ' How many wins are there when the top 10 is less than 4?', 'How many wins are there when the top 25 and top 10 are less than 4?']\n",
      "********1538***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the PGA Championship had 0 wins when the top-25 was less than 4, cuts made was 6, and top-5 was greater than 0.\n",
      "Answer: 1\n",
      "['When did the PGA Championship have 0 wins?', 'how many wins does the player have in tournaments where the top-25 is less than 4, cuts made is 6, and top-5 is greater than 0?', ' When did the PGA Championship have 6 cuts made?']\n",
      "********1540***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the size of the crowd when Essendon was the away team was 25158.\n",
      "Answer: 1\n",
      "[' What was the size of the crowd when collingwood was the home team?', 'how many people were in the crowd when essendon was the away team?', 'What was the size of the crowd when essendon was the away team?']\n",
      "********1544***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, the query can be answered. There are 9 teams that have a total number of scores higher than 10. The total number of teams with a position higher than 10 is 0.\n",
      "Answer: 1\n",
      "['how many teams have a total number of scores higher than 10?', ' How many teams have a score of zero?', 'What is the total number of teams with a position higher than 10?']\n",
      "********1548***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Australia received 0 gold medals and more than 1 bronze medal.\n",
      "Answer: 1\n",
      "['How many gold medals did Australia receive?', 'How many gold medals did Australia receive and how many bronze medals did they receive?', ' How many bronze medals did Australia receive?']\n",
      "********1550***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the least watched episode number with an original airdate of 8 June 2008 is 4. \n",
      "Answer: 1\n",
      "['What is the least watched episode number?', ' What is the original airdate of the least watched episode?', 'which episode had the least viewers?']\n",
      "********1554***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, the query can be answered. The sub-table shows the weeks and dates where the week is 9 and the date is before October 30, 1983. Therefore, based on the sub-table, the answer to the query is \"Yes, week 9 is before October 30, 1983.\"\n",
      "Answer: 1\n",
      "[' Is week 9 before October 30, 1983?', 'What date is week 9 before?', 'which weeks were before October 30, 1983?']\n",
      "********1563***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the attendance at the New Orleans Saints game with a record of 6 - 1 was 66,189. \n",
      "Answer: 0\n",
      "[' What was the result of the New Orleans Saints game with a record of 6 - 1?', 'how many people attended the New Orleans Saints game with a record of 6 - 1?', 'What was the attendance at the New Orleans Saints game with a record of 6 - 1?']\n",
      "********1574***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the Shanghai Pudong International Airport is ranked 3rd with a total cargo load of 2,939,157 metric tonnes.\n",
      "Answer: 0\n",
      "['What is the total cargo load and rank of Shanghai Pudong International Airport?', ' What is the total cargo load of shanghai pudong international airport?', 'What is the rank of shanghai pudong international airport in terms of total cargo load?']\n",
      "********1581***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, Brian Finch's rank is 7, which is not greater than 3. Therefore, the claim is false.\n",
      "Answer: 0\n",
      "[\"What is Brian Finch's rank?\", \" What is Brian Finch's time?\", \"What is Brian Finch's rank and finishing time?\"]\n",
      "********1589***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that 0 years have \"na\" for the reader's vote and \"na\" for the lifetime achievement. Therefore, the claim that there are 3 years where the reader's vote is \"na\" and the lifetime achievement is \"na\" is false.\n",
      "Answer: 0\n",
      "[' How many years show \"na\" for the reader\\'s vote and \"na\" for the lifetime achievement?', 'how many years have \"na\" for both the reader\\'s vote and lifetime achievement?', 'What are the years when the reader\\'s vote is \"na\" and the lifetime achievement is \"na\"?']\n",
      "********1593***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the lifetime achievement award winners after the year 1998 are Peter Corris, Professor Stephen Knight, Patrick Gallagher, Kerry Greenwood, Bob Bottom, Stuart Coupe, Andrew Rule and John Silvester, Sandra Harvey and Lindsay Simpson, Marele Day, Shane Maloney, and Peter Doyle. \n",
      "Answer: 1\n",
      "['who won the lifetime achievement award before the year 1998?', ' After which year did na win the lifetime achievement award?', 'When did na win the lifetime achievement award?']\n",
      "********1594***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the only individuals who won the lifetime achievement award after 2005 and did not win the best non-fiction or reader's vote are Andrew Rule, John Silvester, Sandra Harvey, Lindsay Simpson, and Marele Day. \n",
      "Answer: 1\n",
      "['Who won the lifetime achievement award after the year 2005?', ' Who won the best non-fiction award after the year 2005?', 'Which authors have won the lifetime achievement award after 2005?']\n",
      "********1600***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the home media center has no OS X and Windows.\n",
      "Answer: 1\n",
      "['Which home media center has no OS X and Windows?', 'Which home media center has no support for OS X and Windows?']\n",
      "********1601***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the name of the software when the windows and web interface are partial is \"coherence\".\n",
      "Answer: 1\n",
      "[' What is the name of the software when the windows and web interface are partial?', 'What is the name of the software with a partial web interface for Windows?', 'What is the name of the software when the windows and web interface are partial?']\n",
      "********1617***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the away team when Richmond played against Melbourne at Punt Road Oval was Melbourne. \n",
      "Answer: 0\n",
      "['When did Richmond play against Melbourne at Punt Road Oval?', \"which team is Melbourne's home team opponent at Punt Road Oval?\", \" Who was Melbourne's home team opponent at Punt Road Oval?\"]\n",
      "********1633***************\n",
      "0 1\n",
      "Thought: The SQL query is looking for the opponent at the home game against the Wightlink Raiders. The query is true because the opponent at the home game against the Wightlink Raiders was 'wightlink raiders'.\n",
      "Answer: 1\n",
      "['which opponent did the team play at the home game?', 'Who was the opponent at the home game against the Wightlink Raiders?', ' What was the result of the home game against the Wightlink Raiders?']\n",
      "********1646***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the Proteus mirabilis does not have a positive Voges-Proskauer reading. \n",
      "Answer: 1\n",
      "['Does Escherichia coli have a positive indole reading?', 'Which species have a positive voges-proskauer reading?', ' Does Shigella spp have a positive methyl red reading?']\n",
      "********1653***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, no games were played on November 27. However, the extra information states that the game played on November 27 was game 5. Therefore, the claim that only 1 game was played on November 27 is false.\n",
      "Answer: 0\n",
      "[' What game was played on November 27?', 'how many games were played on November 27?', 'How many games were played on November 27?']\n",
      "********1665***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the event \"pride bushido 10\" did not have a KO (knee) method. \n",
      "Answer: 1\n",
      "[' What is the record of the fight at pride bushido 10?', 'Which events in the table did not have a KO (knee) method?', 'What is the method used in the fight at pride bushido 10?']\n",
      "********1670***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there are no tournaments after 2012 with a winner's share of less than 15400 and a purse of 0. \n",
      "Answer: 1\n",
      "[\"what is the minimum winner's share for the purse after 2012?\", \"What is the purse for the tournament that has a winner's share of less than 15400?\", \" What is the year of the tournament that has a winner's share of less than 15400?\"]\n",
      "********1675***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the competition that was won on June 2, 2007 was \"friendly\".\n",
      "Answer: 1\n",
      "[' Was the competition he won on June 2, 2007 a friendly?', 'what competition did he win on June 2, 2007?', 'What competition did he win on June 2, 2007?']\n",
      "********1684***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the least amount of money requested for gaming alerts is $200,000.\n",
      "Answer: 1\n",
      "[' What is the least amount of money invested on game alert?', 'Which entrepreneur asked for the least amount of money?', 'What is the least amount of money requested on game alert?']\n",
      "********1688***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the claim is true. The sub-table does not provide information about the average for the teams in 1993-94, so we cannot get the answer from the sub-table. However, the SQL query filters the data to show only the records where the points in 1991-92 are 36 and the points in 1993-94 are less than 34 for the team \"estudiantes de la plata\". \n",
      "Answer: 1\n",
      "['Which team had a smaller average in 1993-94 than 34?', ' How many points did estudiantes de la plata have in 1993-94?', 'What is the average points for the team in 1991-92?']\n",
      "********1711***************\n",
      "0 1\n",
      "Thought: Based on the sub-table, the query can be answered as: 1 game had an attendance of 73263. The attendance for the game on October 17, 2004 was 73263.\n",
      "Answer: 1\n",
      "[' Who was the opponent for the game on October 17, 2004?', 'how many games had an attendance of 73263?', 'What was the attendance for the game on October 17, 2004?']\n",
      "********1717***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the season that had the season premiere on September 26, 2007 is season 4, not 2007 - 2008.\n",
      "Answer: 0\n",
      "['What season did the show have a season premiere on September 26, 2007?', ' What season was 2007 - 2008 for the show?', 'which season had the season premiere on September 26, 2007?']\n",
      "********1730***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the drop height of 272 feet was opened on March 22, 2003. \n",
      "Answer: 1\n",
      "['What is the drop height of the park that opened before March 22, 2003?', ' When was the park with a drop height of 272 feet opened?', \"which park's drop height was open before March 22, 2003?\"]\n",
      "********1736***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the model number 'pentium dual - core sla4h (m0)' does not have any data with a release date of 'q2 2008'. The release date of the slaec (m0) model is Q4 2007.\n",
      "Answer: 0\n",
      "[' What is the release date of the slavg (m0) model?', 'what is the release date of the sla4h (m0) model?', 'What is the release date of the slaec (m0) model?']\n",
      "********1739***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the part number lf80537 gf0411 m with a release price of 90 does have an FSB of 667 mt/s.\n",
      "Answer: 1\n",
      "['What is the part number of the processor with a release price of 90?', 'What is the fsb for part number lf80537 gf0411 m?', ' What is the FSB of the processor with part number lf80537 gf0411 m?']\n",
      "********1755***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Calvin O'Neal was picked in the 6th round, and the players selected in rounds larger than 6 with an overall pick number are Blanchard Carter, Ken Helms, Glenn Capriola, Ron Baker, Brian Ruff, and Bill Deutsch. The overall pick for Calvin O'Neal is 163, which is not larger than 6. Therefore, there are no players with the name of Calvin O'Neal and a round larger than 6.\n",
      "Answer: 1\n",
      "[\" In which round was Calvin O'Neal picked?\", 'which players were selected in rounds larger than 6 and have an overall pick number?', \"What is the overall pick for Calvin O'Neal?\"]\n",
      "********1784***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the team \"atlético ciudad\" had no match with an average higher than 0.61. Álvaro Campos is the goalkeeper for the team \"atlético ciudad.\" Therefore, the claim is true.\n",
      "Answer: 1\n",
      "[' Which team had no match with an average higher than 0.61?', 'Which team did Álvaro Campos play as a goalkeeper for?', 'Which team does Álvaro Campos play as a goalkeeper for?']\n",
      "********1786***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Atlético Ciudad played 28 matches with an average of less than 0.61 goals scored against them. \n",
      "Answer: 1\n",
      "['What is the average number of goals scored against Atlético Ciudad in their matches?', 'How many matches did atlético ciudad play?', ' What is the average for atlético ciudad?']\n",
      "********1791***************\n",
      "1 0\n",
      "Thought: Based on the sub-table, the claim is false. The mountain classification was given to \"no award\" and the team classification was given to \"ind ant - idea - fla - lot de medellín\".\n",
      "Answer: 0\n",
      "[' Who was given the mountain classification?', 'Which stage did Jaime Vergara win and which team and individual classifications were awarded?', 'Who won in the 11th stage?', ' Which team was given the team classification?']\n",
      "********1794***************\n",
      "1 0\n",
      "Thought: Based on the sub-table provided, we cannot get an answer to the query \"When did Orlando win game 65?\" The score of game 65 for Orlando was 79 - 92 (ot), indicating that the team with 92 points won the game.\n",
      "Answer: 0\n",
      "['When did Orlando win game 65?', ' What was the score of game 65 for Orlando?', 'What was the score of game 65 and who won?']\n",
      "********1814***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, there is no data in the database that shows Diego Milito scored 0 goals in his debut year before 2008.\n",
      "Answer: 1\n",
      "['How many goals did Diego Milito score in his debut year before 2008?', ' How many goals did Antonio Di Natale score in his debut year?', 'How many goals did Sergio Pellissier score in his debut year?']\n",
      "********1816***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the query is looking for data where the name is 'mirko vučinić', the debut year is after January 1, 2008, and the number of goals is 0. However, the extra information provided states that Mirko Vučinić debuted on May 14, 2000, and scored 95 goals in his debut year. Therefore, the query is true.\n",
      "Answer: 1\n",
      "['In which year did Mirko Vučinić score his first goal?', 'When did mirko vučinić debut?', ' How many goals did mirko vučinić score in his debut year?']\n",
      "********1826***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Paul Holahan directed episodes for seasons 1 and 2. The query is true.\n",
      "Answer: 1\n",
      "['which episodes did paul holahan direct?', ' Which seasons did Paul Holahan direct episodes for?', 'Which episodes did Paul Holahan direct?']\n",
      "********1841***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, when the away team scored 16.22 (118), the highest home team score was 20.20 (140). \n",
      "Answer: 1\n",
      "['which game had the highest home team score when the away team scored 16.22 (118)?', 'When was the highest home team score?', ' When was the away team score 16.22 (118)?']\n",
      "********1853***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the settlement of Lok is a village.\n",
      "Answer: 0\n",
      "[' What is the population of Lok in 2011?', 'What type of settlement is Lok?', 'what type of settlement is the settlement of lok?']\n",
      "********1854***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the settlements Titel and Lok differ only in population. \n",
      "Answer: 1\n",
      "['what are the differences between the settlements titel and lok?', ' What is the population of the settlement Lok?', 'What is the population of the settlement Titel?']\n",
      "********1857***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the sub-table shows that Phil Crane was first elected in 1969. \n",
      "Answer: 0\n",
      "['When was Republican Phil Crane first elected?', ' What party was Phil Crane affiliated with when he was first elected?', 'When was Phil Crane first elected?']\n",
      "********1859***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, Paul Findley was first elected after Henry Hyde in Illinois 6, and the first elected representative after Henry Hyde in Illinois 6 was Tom Corcoran. Therefore, the claim is true.\n",
      "Answer: 1\n",
      "['When was Paul Findley first elected?', 'who was the first elected representative after Henry Hyde in Illinois?', ' Who was the incumbent in district Illinois 20 after Henry Hyde in district Illinois 6?']\n",
      "********1864***************\n",
      "1 0\n",
      "Thought: The sub-table does not contain the 47th season detail. The title of the season 2010 - 11 detail is \"47th\" and the runner-up was Waseda.\n",
      "Answer: 0\n",
      "[' Who was the runner-up in the season 2010 - 11 detail?', 'which season detail has a title of 47th and who was the runner-up?', 'What is the title of the season 2010 - 11 detail?']\n",
      "********1870***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the New Orleans Saints played against a team for the first time in the 11th week. However, based on the provided sub-table, we cannot determine the specific team they played against.\n",
      "Answer: 0\n",
      "[' Who did the New Orleans Saints play against for the first time in the 11th week?', 'when did the New Orleans Saints play against the opponent for the first time?', 'When did the New Orleans Saints first play against the opponent?']\n",
      "********1872***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the New Orleans Saints had the least attendance against the opponent \"new orleans saints\" in November 1997. \n",
      "Answer: 1\n",
      "['which opponent had the least attendance during the 1997 season when the New Orleans Saints played?', \" On November, 1997, what was the attendance for the New Orleans Saints' game?\", 'On November, 1997, which opponent did the New Orleans Saints have the least attendance against?']\n",
      "********1874***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the information needed to answer the query \"Who was fourth when anders martinson usa was second?\" Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['Who was fourth when anders martinson usa was second?', 'who were the top four finishers in the race where Anders Martinson from the USA finished second?', ' Who was second when jean - françois bouvery france was fourth?']\n",
      "********1882***************\n",
      "0 1\n",
      "Thought: Based on the sub-table provided, the artist with a mintage of 41828 is Bonnie Ross. Therefore, the answer to the query is \"Yes, the artist with a mintage of 41828 is Bonnie Ross.\"\n",
      "Answer: 1\n",
      "['Who is the artist with a mintage of 41828?', ' Is the artist with a mintage of 41828 Bonnie Ross?', 'which artist has a mintage of 41828?']\n",
      "********1906***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the geo id for Janke township in Logan county is 3.80474e+09. \n",
      "Answer: 0\n",
      "[' What is the geo id for johnstown township in grand forks county?', 'what is the geo id for janke township in logan county?', 'What is the geo id for janke township in logan county?']\n",
      "********1915***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, James Hill has the least amount of land (sqmi) at 31.82.\n",
      "Answer: 1\n",
      "['What is the amount of land (sqmi) for James Hill?', ' Which township has the least amount of land (sqmi)?', 'Which township has the least amount of land (sqmi)?']\n",
      "********1921***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, 15 eagles were made and 0 eagles were preserved. \n",
      "Answer: 1\n",
      "['How many of the eagle class were made?', ' How many of the eagle class were preserved?', 'How many of the eagle class were made and preserved?']\n",
      "********1931***************\n",
      "1 0\n",
      "Thought: The sub-table does not provide the information needed to answer the query \"What teams played on March 19, 1984?\" Therefore, I cannot get the answer from the sub-table.\n",
      "Answer: 0\n",
      "['did plymouth argyle play derby county on march 19, 1984?', 'What teams played on March 19, 1984?']\n",
      "********1942***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the position of the player born on 2 November 1987 is fly-half and there is only 1 player from Sale with the position of fly-half.\n",
      "Answer: 1\n",
      "[' How many players from Sale are there with the position of fly-half?', 'What is the position of the player born on 2 November 1987?']\n",
      "********1944***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the runner up of the miyagi tv cup dunlop ladies open was Shiho Oyama. The winner of the miyagi tv cup dunlop ladies open was Shiho Oyama. The winning score for the miyagi tv cup dunlop ladies open was 214, which was calculated as 70 + 73 + 71. The winning score for the winner of the miyagi tv cup dunlop ladies open was 214, which is not 2 points under par.\n",
      "Answer: 0\n",
      "['Who won the miyagi tv cup dunlop ladies open?', ' What was the winning score for the miyagi tv cup dunlop ladies open?', 'What was the winning score for the winner of the miyagi tv cup dunlop ladies open?']\n",
      "********1946***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the winner of the miyagi tv cup dunlop ladies open had a 3-stroke margin of victory.\n",
      "Answer: 1\n",
      "['what was the margin of victory for each winner of the tournaments listed?', 'Who won the miyagi tv cup dunlop ladies open?', ' What was the margin of victory for the winner of the miyagi tv cup dunlop ladies open?']\n",
      "********1952***************\n",
      "1 0\n",
      "Thought: Based on the SQL query provided, the home team score for Carlton when they played Richmond at Prince Park was 20.7. \n",
      "Answer: 0\n",
      "['What was the score when Carlton played Richmond at Prince Park?']\n",
      "********1964***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the US viewers for the episode titled \"Rabid\" was 2.3 million.\n",
      "Answer: 1\n",
      "['How many people in Africa saw the episode titled \"rabid\"?', ' How many people in Africa saw the episode titled \"rabid\"?', 'How many people in Africa saw each episode?']\n",
      "********1979***************\n",
      "1 0\n",
      "Thought: The SQL query filters the table to find the call sign for Bell Media on the frequency 99.9 FM. The result of the query is \"CHSU - FM\". However, the extra information states that the call sign for Bell Media on the frequency 99.9 FM is \"CHSU-FM\". \n",
      "Answer: 0\n",
      "['What is the call sign for bell media on the frequency 99.9 fm?', ' What is the branding for bell media on the frequency 99.9 fm?', 'what is the call sign for bell media on the frequency 99.9 fm?']\n",
      "********1987***************\n",
      "0 1\n",
      "Thought: Based on the SQL query provided, the owner of the radio station that plays adult hits is Bell Media.\n",
      "Answer: 1\n",
      "['What is the owner of the radio station that plays adult hits?', 'which radio station is owned by Bell Media?', ' Who owns the radio station that plays adult hits?']\n"
     ]
    }
   ],
   "source": [
    "for i, row in data.iterrows():\n",
    "    \n",
    "    label = extract_yes_no_and_map(table_loader.normalize_table(table_loader.dataset[int(row['ids'])])['label'])\n",
    "    pred3 = extract_yes_no_and_map(row['final_answer'])\n",
    "    if label != pred3:\n",
    "        id = row['ids']\n",
    "        print(f'********{id}***************')\n",
    "        \n",
    "        print(label, pred3)\n",
    "        print(row['preds'])\n",
    "        print(row['extra'].split(';'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2cd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8241256969082615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eval_fv_match(preds, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b99bb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d349fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds_1</th>\n",
       "      <th>statements_1</th>\n",
       "      <th>final_answer_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>statements_2</th>\n",
       "      <th>final_answer_2</th>\n",
       "      <th>preds</th>\n",
       "      <th>statements</th>\n",
       "      <th>tokens</th>\n",
       "      <th>extra</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>the sweet dream episode happen later in the se...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: The \"Sweet Dreams\" episode happened o...</td>\n",
       "      <td>the sweet dream episode happen later in the se...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>the sweet dream episode happen later in the se...</td>\n",
       "      <td>7622</td>\n",
       "      <td>What was the air date of the episode \"The Witc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thought: Based on the SQL query provided, ther...</td>\n",
       "      <td>david moore direct 3 episode of series 2 of me...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought: Based on the SQL query provided, ther...</td>\n",
       "      <td>david moore direct 3 episode of series 2 of me...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought: Based on the SQL query provided, ther...</td>\n",
       "      <td>david moore direct 3 episode of series 2 of me...</td>\n",
       "      <td>5548</td>\n",
       "      <td>How many episodes did David Moore direct in se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>the lady of the lake episode have the most uk ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>the lady of the lake episode have the most uk ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>the lady of the lake episode have the most uk ...</td>\n",
       "      <td>5608</td>\n",
       "      <td>What was the title of the episode with the hig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thought: Based on the SQL query provided, ther...</td>\n",
       "      <td>lucy watkins only write 1 episode of series 2</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought: Based on the SQL query provided, Lucy...</td>\n",
       "      <td>lucy watkins only write 1 episode of series 2</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought: Based on the SQL query provided, ther...</td>\n",
       "      <td>lucy watkins only write 1 episode of series 2</td>\n",
       "      <td>5484</td>\n",
       "      <td>How many episodes did Lucy Watkins write for s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>beauty and the beast (part 2) have more uk vie...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>beauty and the beast (part 2) have more uk vie...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>beauty and the beast (part 2) have more uk vie...</td>\n",
       "      <td>7682</td>\n",
       "      <td>What was the original air date of \"the curse o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               preds_1  \\\n",
       "ids                                                      \n",
       "0    Thought: Based on the SQL query provided, the ...   \n",
       "1    Thought: Based on the SQL query provided, ther...   \n",
       "2    Thought: Based on the SQL query provided, the ...   \n",
       "3    Thought: Based on the SQL query provided, ther...   \n",
       "4    Thought: Based on the SQL query provided, the ...   \n",
       "\n",
       "                                          statements_1 final_answer_1  \\\n",
       "ids                                                                     \n",
       "0    the sweet dream episode happen later in the se...              1   \n",
       "1    david moore direct 3 episode of series 2 of me...              0   \n",
       "2    the lady of the lake episode have the most uk ...              1   \n",
       "3        lucy watkins only write 1 episode of series 2              0   \n",
       "4    beauty and the beast (part 2) have more uk vie...              1   \n",
       "\n",
       "                                               preds_2  \\\n",
       "ids                                                      \n",
       "0    Thought: The \"Sweet Dreams\" episode happened o...   \n",
       "1    Thought: Based on the SQL query provided, ther...   \n",
       "2    Thought: Based on the SQL query provided, the ...   \n",
       "3    Thought: Based on the SQL query provided, Lucy...   \n",
       "4    Thought: Based on the SQL query provided, the ...   \n",
       "\n",
       "                                          statements_2 final_answer_2  \\\n",
       "ids                                                                     \n",
       "0    the sweet dream episode happen later in the se...              1   \n",
       "1    david moore direct 3 episode of series 2 of me...              0   \n",
       "2    the lady of the lake episode have the most uk ...              1   \n",
       "3        lucy watkins only write 1 episode of series 2              0   \n",
       "4    beauty and the beast (part 2) have more uk vie...              1   \n",
       "\n",
       "                                                 preds  \\\n",
       "ids                                                      \n",
       "0    Thought: Based on the SQL query provided, the ...   \n",
       "1    Thought: Based on the SQL query provided, ther...   \n",
       "2    Thought: Based on the SQL query provided, the ...   \n",
       "3    Thought: Based on the SQL query provided, ther...   \n",
       "4    Thought: Based on the SQL query provided, the ...   \n",
       "\n",
       "                                            statements  tokens  \\\n",
       "ids                                                              \n",
       "0    the sweet dream episode happen later in the se...    7622   \n",
       "1    david moore direct 3 episode of series 2 of me...    5548   \n",
       "2    the lady of the lake episode have the most uk ...    5608   \n",
       "3        lucy watkins only write 1 episode of series 2    5484   \n",
       "4    beauty and the beast (part 2) have more uk vie...    7682   \n",
       "\n",
       "                                                 extra final_answer  \n",
       "ids                                                                  \n",
       "0    What was the air date of the episode \"The Witc...            1  \n",
       "1    How many episodes did David Moore direct in se...            0  \n",
       "2    What was the title of the episode with the hig...            1  \n",
       "3    How many episodes did Lucy Watkins write for s...            0  \n",
       "4    What was the original air date of \"the curse o...            1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c85aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data.set_index(keys='ids').join(data2.set_index(keys='ids'), how='inner',lsuffix='_1', rsuffix='_2').join(data3.set_index(keys='ids'), how='inner',lsuffix='_1', rsuffix='_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "41f0620c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16a22515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0855e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('2', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('2', 1), ('1', 1), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('2', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('2', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('2', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('2', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('2', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('2', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('2', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('2', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('2', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('2', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('0', 2), ('1', 1)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('1', 3)]\n",
      "[('1', 3)]\n",
      "[('1', 2), ('0', 1)]\n",
      "[('0', 3)]\n",
      "[('1', 3)]\n",
      "[('0', 3)]\n",
      "[('0', 3)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labels = []\n",
    "preds = []\n",
    "ids = []\n",
    "acc = 0\n",
    "err = 0\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "for i, row in all_data.iterrows():\n",
    "    label = extract_yes_no_and_map(table_loader.normalize_table(table_loader.dataset[int(i)])['label'])\n",
    "    pred1 = extract_yes_no_and_map(row['final_answer_1'])\n",
    "    pred2 = extract_yes_no_and_map(row['final_answer_2'])\n",
    "    pred3 = extract_yes_no_and_map(row['final_answer'])\n",
    "    print(Counter([pred1,pred2,pred3]).most_common())\n",
    "    if Counter([pred1,pred2,pred3]).most_common()[0][0] == label:\n",
    "        acc += 1\n",
    "    else:\n",
    "        print\n",
    "    if pred1 != label and pred2 != label and pred3 != label:\n",
    "        # print(label, pred1, pred2)\n",
    "        err += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "140c1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1\n",
      "3 0 1\n",
      "7 1 0\n",
      "11 0 1\n",
      "14 0 1\n",
      "16 1 0\n",
      "17 1 0\n",
      "21 0 1\n",
      "22 0 1\n",
      "26 0 1\n",
      "32 0 1\n",
      "37 0 1\n",
      "39 1 0\n",
      "42 0 1\n",
      "43 1 0\n",
      "46 1 0\n",
      "47 1 0\n",
      "51 0 1\n",
      "58 1 0\n",
      "59 0 1\n",
      "62 0 1\n",
      "63 1 0\n",
      "64 1 0\n",
      "66 1 0\n",
      "69 0 1\n",
      "72 0 1\n",
      "73 1 0\n",
      "76 1 0\n",
      "79 0 1\n",
      "80 0 1\n",
      "82 0 1\n",
      "84 1 0\n",
      "87 1 0\n",
      "91 0 1\n",
      "100 0 1\n",
      "101 0 1\n",
      "103 1 0\n",
      "106 1 0\n",
      "107 1 0\n",
      "108 0 1\n",
      "115 2 0\n",
      "121 1 0\n",
      "126 1 0\n",
      "133 1 0\n",
      "135 1 0\n",
      "138 1 0\n",
      "140 0 1\n",
      "148 0 1\n",
      "151 0 1\n",
      "160 0 1\n",
      "169 0 1\n",
      "180 0 1\n",
      "181 1 0\n",
      "184 1 0\n",
      "188 0 1\n",
      "192 1 0\n",
      "196 1 0\n",
      "199 0 1\n",
      "210 0 1\n",
      "211 0 1\n",
      "213 1 0\n",
      "216 2 0\n",
      "225 1 0\n",
      "227 1 0\n",
      "236 1 0\n",
      "240 0 1\n",
      "241 0 1\n",
      "249 0 1\n",
      "254 1 0\n",
      "259 0 1\n",
      "261 0 1\n",
      "265 1 0\n",
      "268 0 1\n",
      "276 1 0\n",
      "277 1 0\n",
      "281 0 1\n",
      "291 0 1\n",
      "292 1 0\n",
      "296 1 0\n",
      "300 1 0\n",
      "301 0 1\n",
      "309 0 1\n",
      "315 0 1\n",
      "341 1 0\n",
      "349 1 0\n",
      "350 1 0\n",
      "355 0 1\n",
      "362 1 0\n",
      "375 0 1\n",
      "390 1 0\n",
      "392 1 0\n",
      "393 1 0\n",
      "396 1 0\n",
      "397 1 0\n",
      "398 1 0\n",
      "408 0 1\n",
      "422 1 0\n",
      "425 0 1\n",
      "426 1 0\n",
      "430 1 0\n",
      "431 1 0\n",
      "432 1 0\n",
      "435 0 1\n",
      "436 0 1\n",
      "438 0 1\n",
      "439 0 1\n",
      "441 1 0\n",
      "442 1 0\n",
      "444 1 0\n",
      "457 1 0\n",
      "463 1 0\n",
      "473 1 0\n",
      "475 0 1\n",
      "476 0 1\n",
      "488 0 1\n",
      "489 0 1\n",
      "491 1 0\n",
      "493 1 0\n",
      "495 0 1\n",
      "499 0 1\n",
      "502 1 0\n",
      "503 1 0\n",
      "504 0 1\n",
      "510 1 0\n",
      "511 1 0\n",
      "517 0 1\n",
      "520 0 1\n",
      "522 1 0\n",
      "534 1 0\n",
      "538 0 1\n",
      "539 0 1\n",
      "542 1 0\n",
      "544 1 0\n",
      "545 0 1\n",
      "546 0 1\n",
      "547 0 1\n",
      "555 0 1\n",
      "557 0 1\n",
      "566 2 0\n",
      "567 0 1\n",
      "569 0 1\n",
      "573 1 0\n",
      "576 0 1\n",
      "590 1 0\n",
      "591 1 0\n",
      "594 1 0\n",
      "595 0 1\n",
      "596 0 1\n",
      "599 0 1\n",
      "601 0 1\n",
      "607 0 1\n",
      "616 0 1\n",
      "619 0 1\n",
      "621 0 1\n",
      "622 1 0\n",
      "627 0 1\n",
      "628 0 1\n",
      "635 0 1\n",
      "636 0 1\n",
      "638 0 1\n",
      "643 1 0\n",
      "645 0 1\n",
      "656 0 1\n",
      "661 1 0\n",
      "663 1 0\n",
      "668 0 1\n",
      "670 1 0\n",
      "674 1 0\n",
      "677 0 1\n",
      "683 0 1\n",
      "684 0 1\n",
      "691 1 0\n",
      "692 0 1\n",
      "693 0 1\n",
      "698 1 0\n",
      "700 1 0\n",
      "701 1 0\n",
      "709 0 1\n",
      "730 1 0\n",
      "737 0 1\n",
      "739 1 0\n",
      "744 0 1\n",
      "746 1 0\n",
      "749 1 0\n",
      "763 0 1\n",
      "764 0 1\n",
      "766 0 1\n",
      "770 1 0\n",
      "773 0 1\n",
      "775 0 1\n",
      "777 0 1\n",
      "779 1 0\n",
      "781 1 0\n",
      "789 1 0\n",
      "791 1 0\n",
      "793 0 1\n",
      "795 0 1\n",
      "796 0 1\n",
      "808 1 0\n",
      "809 1 0\n",
      "810 1 0\n",
      "812 1 0\n",
      "813 0 1\n",
      "817 1 0\n",
      "823 0 1\n",
      "824 0 1\n",
      "827 1 0\n",
      "829 1 0\n",
      "837 0 1\n",
      "847 1 0\n",
      "852 0 1\n",
      "853 0 1\n",
      "854 0 1\n",
      "861 0 1\n",
      "864 0 1\n",
      "868 1 0\n",
      "869 1 0\n",
      "871 0 1\n",
      "875 1 0\n",
      "881 0 1\n",
      "886 1 0\n",
      "888 1 0\n",
      "894 0 1\n",
      "896 1 0\n",
      "898 1 0\n",
      "910 0 1\n",
      "912 0 1\n",
      "914 0 1\n",
      "917 0 1\n",
      "920 0 1\n",
      "923 0 1\n",
      "926 1 0\n",
      "928 1 0\n",
      "933 1 0\n",
      "939 0 1\n",
      "941 0 1\n",
      "943 0 1\n",
      "945 1 0\n",
      "951 0 1\n",
      "967 1 0\n",
      "968 1 0\n",
      "982 0 1\n",
      "1001 0 1\n",
      "1007 1 0\n",
      "1010 0 1\n",
      "1022 0 1\n",
      "1067 0 1\n",
      "1070 0 1\n",
      "1076 0 1\n",
      "1077 1 0\n",
      "1082 1 0\n",
      "1100 0 1\n",
      "1111 1 0\n",
      "1112 0 1\n",
      "1113 0 1\n",
      "1114 0 1\n",
      "1119 0 1\n",
      "1148 0 1\n",
      "1162 0 1\n",
      "1171 1 0\n",
      "1174 0 1\n",
      "1175 0 1\n",
      "1176 0 1\n",
      "1179 1 0\n",
      "1185 1 0\n",
      "1190 1 0\n",
      "1215 1 0\n",
      "1237 0 1\n",
      "1239 1 0\n",
      "1245 1 0\n",
      "1248 0 1\n",
      "1252 0 1\n",
      "1269 0 1\n",
      "1281 1 0\n",
      "1285 0 1\n",
      "1296 0 1\n",
      "1297 0 1\n",
      "1298 0 1\n",
      "1299 0 1\n",
      "1300 0 1\n",
      "1316 1 0\n",
      "1342 0 1\n",
      "1346 1 0\n",
      "1358 1 0\n",
      "1361 0 1\n",
      "1363 1 0\n",
      "1386 0 1\n",
      "1398 0 1\n",
      "1399 1 0\n",
      "1403 0 1\n",
      "1405 0 1\n",
      "1418 0 1\n",
      "1427 2 0\n",
      "1430 0 1\n",
      "1444 0 1\n",
      "1447 1 0\n",
      "1451 0 1\n",
      "1462 1 0\n",
      "1466 0 1\n",
      "1480 1 0\n",
      "1481 0 1\n",
      "1498 0 1\n",
      "1504 1 0\n",
      "1505 1 0\n",
      "1506 0 1\n",
      "1514 0 1\n",
      "1544 1 0\n",
      "1550 1 0\n",
      "1590 0 1\n",
      "1593 1 0\n",
      "1598 2 1\n",
      "1609 1 0\n",
      "1617 0 1\n",
      "1620 1 0\n",
      "1625 1 0\n",
      "1630 0 1\n",
      "1638 0 1\n",
      "1641 0 1\n",
      "1666 0 1\n",
      "1670 1 0\n",
      "1704 1 0\n",
      "1709 0 1\n",
      "1748 1 0\n",
      "1754 1 0\n",
      "1757 1 0\n",
      "1774 1 0\n",
      "1784 1 0\n",
      "1790 0 1\n",
      "1794 0 1\n",
      "1814 1 0\n",
      "1822 0 1\n",
      "1825 0 1\n",
      "1831 1 0\n",
      "1833 1 0\n",
      "1841 1 0\n",
      "1845 0 1\n",
      "1853 0 1\n",
      "1857 0 1\n",
      "1859 1 0\n",
      "1872 1 0\n",
      "1875 1 0\n",
      "1906 0 1\n",
      "1915 1 0\n",
      "1931 0 1\n",
      "1938 0 1\n",
      "1942 1 0\n",
      "1946 1 0\n",
      "1979 0 1\n",
      "1981 0 1\n",
      "1982 0 1\n",
      "1985 1 0\n",
      "1987 1 0\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "errors = []\n",
    "for i in range(len(preds)):\n",
    "    pred, gold = extract_yes_no_and_map(preds[i]), extract_yes_no_and_map(labels[i])\n",
    "    if pred != gold:\n",
    "        print(ids[i], pred, gold)\n",
    "        errors.append(i)\n",
    "    else:\n",
    "        acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./result/answer/tabfact_05-10_07-12-50.csv')\n",
    "data['final_answer'] = data['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n",
    "\n",
    "if len(predict_ans) == 0:\n",
    "    predict_ans = json.loads(l)['pred'][-3:]\n",
    "    if '0' in predict_ans:\n",
    "        predict_ans = '0'\n",
    "    elif '1' in predict_ans:\n",
    "        predict_ans = '1'\n",
    "    else:\n",
    "        predict_ans = '2'\n",
    "    pred_label.append(predict_ans)\n",
    "if verbose:\n",
    "    print(pred_label)\n",
    "    print(gold_list)\n",
    "    print(np.where(np.array(pred_label) != np.array(gold_list)))\n",
    "return eval_fv_match(pred_label, gold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6bf99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c9aa0e9",
   "metadata": {},
   "source": [
    "### Evaluate WikiTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59c33ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import recognizers_suite\n",
    "import recognizers_suite as Recognizers\n",
    "from recognizers_text import Culture, ModelResult\n",
    "def str_normalize(user_input, recognition_types=None):\n",
    "    \"\"\"A string normalizer which recognize and normalize value based on recognizers_suite\"\"\"\n",
    "    user_input = str(user_input)\n",
    "    user_input = user_input.replace(\"\\\\n\", \"; \")\n",
    "\n",
    "    def replace_by_idx_pairs(orig_str, strs_to_replace, idx_pairs):\n",
    "        assert len(strs_to_replace) == len(idx_pairs)\n",
    "        last_end = 0\n",
    "        to_concat = []\n",
    "        for idx_pair, str_to_replace in zip(idx_pairs, strs_to_replace):\n",
    "            to_concat.append(orig_str[last_end : idx_pair[0]])\n",
    "            to_concat.append(str_to_replace)\n",
    "            last_end = idx_pair[1]\n",
    "        to_concat.append(orig_str[last_end:])\n",
    "        return ''.join(to_concat)\n",
    "\n",
    "    if recognition_types is None:\n",
    "        recognition_types = [\n",
    "            \"datetime\",\n",
    "            \"number\",\n",
    "            \"ordinal\",\n",
    "            \"percentage\",\n",
    "            \"age\",\n",
    "            \"currency\",\n",
    "            \"dimension\",\n",
    "            \"temperature\",\n",
    "        ]\n",
    "    culture = Culture.English\n",
    "    for recognition_type in recognition_types:\n",
    "        if re.match(\"\\d+/\\d+\", user_input):\n",
    "            # avoid calculating str as 1991/92\n",
    "            continue\n",
    "        recognized_list = getattr(\n",
    "            recognizers_suite, \"recognize_{}\".format(recognition_type)\n",
    "        )(\n",
    "            user_input, culture\n",
    "        )  # may match multiple parts\n",
    "        strs_to_replace = []\n",
    "        idx_pairs = []\n",
    "        for recognized in recognized_list:\n",
    "            if not recognition_type == 'datetime':\n",
    "                recognized_value = recognized.resolution['value']\n",
    "                if str(recognized_value).startswith(\"P\"):\n",
    "                    # if the datetime is a period:\n",
    "                    continue\n",
    "                else:\n",
    "                    strs_to_replace.append(recognized_value)\n",
    "                    idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "            else:\n",
    "                if recognized.resolution:  # in some cases, this variable could be none.\n",
    "                    if len(recognized.resolution['values']) == 1:\n",
    "                        strs_to_replace.append(\n",
    "                            recognized.resolution['values'][0]['timex']\n",
    "                        )  # We use timex as normalization\n",
    "                        idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "\n",
    "        if len(strs_to_replace) > 0:\n",
    "            user_input = replace_by_idx_pairs(user_input, strs_to_replace, idx_pairs)\n",
    "\n",
    "    if re.match(\"(.*)-(.*)-(.*) 00:00:00\", user_input):\n",
    "        user_input = user_input[: -len(\"00:00:00\") - 1]\n",
    "        # '2008-04-13 00:00:00' -> '2008-04-13'\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE), \" \", text)\n",
    "\n",
    "    def whilt_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return whilt_space_fix(remove_articles(remove_punc(lower(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f55ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, re, argparse\n",
    "import unicodedata\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "################ String Normalization ################\n",
    "\n",
    "def normalize(x):\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "    while True:\n",
    "        old_x = x\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        if x == old_x:\n",
    "            break\n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "################ Value Types ################\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "################ Value Instantiation ################\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "################ Check the Predicted Denotations ################\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    return True\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91b7d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from ../result/data/wikitable/tagged/data/training.tagged\n",
      "Reading dataset from ../result/data/wikitable/tagged/data/pristine-unseen-tables.tagged\n",
      "Reading dataset from ../result/data/wikitable/tagged/data/pristine-seen-tables.tagged\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tagged_dataset_path = '../result/data/wikitable/tagged/data'\n",
    "target_values_map = {}\n",
    "for filename in os.listdir(tagged_dataset_path):\n",
    "    if filename[0]=='.':\n",
    "        continue\n",
    "    filename = os.path.join(tagged_dataset_path, filename)\n",
    "    print('Reading dataset from', filename)\n",
    "    with open(filename, 'r') as fin:\n",
    "        header = fin.readline().rstrip('\\n').split('\\t')\n",
    "        for line in fin:\n",
    "            stuff = dict(zip(header, line.rstrip('\\n').split('\\t')))\n",
    "            ex_id = stuff['id']\n",
    "            original_strings = tsv_unescape_list(stuff['targetValue'])\n",
    "            canon_strings = tsv_unescape_list(stuff['targetCanon'])\n",
    "\n",
    "            target_values_map[ex_id] = to_value_list(\n",
    "                original_strings, canon_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d269de",
   "metadata": {},
   "outputs": [],
   "source": [
    "st2id = {}\n",
    "with open(os.path.join('../../datasets/wtq','valid_lower.jsonl')) as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        dic = json.loads(l)\n",
    "        st = dic['statement']\n",
    "        ids = dic['ids']\n",
    "        st2id[st] = ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb2ff2",
   "metadata": {},
   "source": [
    "##### read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1b921332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data1 = pd.read_csv('./result/answer/wikitable_zh_05-03_15-27-43.csv', encoding='utf-8') \n",
    "# data2 = pd.read_csv('./result/answer/wikitable_zh_05-03_15-46-07.csv', encoding='utf-8') \n",
    "data = pd.read_csv('../result/answer/wikitable_05-12_14-25-15.csv')\n",
    "data2 = pd.read_csv('../result/answer/wikitable_05-14_08-17-04.csv')\n",
    "data3 = pd.read_csv('../result/answer/wikitable_05-15_12-49-12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ce12b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3d1bfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final_answer'] = data['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n",
    "data2['final_answer'] = data2['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n",
    "data3['final_answer'] = data3['preds'].apply(lambda x: x.split('Answer:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "787f2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data2.set_index('ids').join(data3.set_index('ids'), how='inner', lsuffix='_1', rsuffix='_2').join(data.set_index('ids'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "61651d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds_1</th>\n",
       "      <th>statements_1</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>extra_1</th>\n",
       "      <th>final_answer_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>statements_2</th>\n",
       "      <th>tokens_2</th>\n",
       "      <th>extra_2</th>\n",
       "      <th>final_answer_2</th>\n",
       "      <th>preds</th>\n",
       "      <th>statements</th>\n",
       "      <th>sample_n</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nu-0</th>\n",
       "      <td>Thought: The SQL query filtered the top 10 cyc...</td>\n",
       "      <td>which country had the most cyclists finish wit...</td>\n",
       "      <td>5077</td>\n",
       "      <td>Which country were the cyclists who finished w...</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Thought: Based on the SQL query provided, Ital...</td>\n",
       "      <td>which country had the most cyclists finish wit...</td>\n",
       "      <td>5077</td>\n",
       "      <td>which country had the most cyclists finish wi...</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Thought: The SQL query first extracts the last...</td>\n",
       "      <td>which country had the most cyclists finish wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nu-1</th>\n",
       "      <td>Thought: Based on the SQL query provided, 100,...</td>\n",
       "      <td>how many people were murdered in 1940/41?</td>\n",
       "      <td>6199</td>\n",
       "      <td>How many people were murdered in 1940/41?;how ...</td>\n",
       "      <td>100,000</td>\n",
       "      <td>Thought: The SQL query filtered the data to on...</td>\n",
       "      <td>how many people were murdered in 1940/41?</td>\n",
       "      <td>5864</td>\n",
       "      <td>how many people were murdered in 1940?;How man...</td>\n",
       "      <td>100000</td>\n",
       "      <td>Thought: Based on the SQL query provided, the ...</td>\n",
       "      <td>how many people were murdered in 1940/41?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nu-2</th>\n",
       "      <td>Thought: The SQL query filters the data to onl...</td>\n",
       "      <td>how long did it take for the new york american...</td>\n",
       "      <td>5223</td>\n",
       "      <td>When did the New York Americans win the Nation...</td>\n",
       "      <td>1953/54</td>\n",
       "      <td>Thought: The New York Americans won the Nation...</td>\n",
       "      <td>how long did it take for the new york american...</td>\n",
       "      <td>4971</td>\n",
       "      <td>When did the New York Americans win the Nation...</td>\n",
       "      <td>17 years</td>\n",
       "      <td>Thought: The SQL query filters the table to on...</td>\n",
       "      <td>how long did it take for the new york american...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nu-3</th>\n",
       "      <td>Thought: The episode \"Donnell's Birthday Party...</td>\n",
       "      <td>alfie's birthday party aired on january 19. wh...</td>\n",
       "      <td>8830</td>\n",
       "      <td>What was the airdate of the episode after Alfi...</td>\n",
       "      <td>January 20, 1995</td>\n",
       "      <td>Thought: The SQL query is filtering for the or...</td>\n",
       "      <td>alfie's birthday party aired on january 19. wh...</td>\n",
       "      <td>6850</td>\n",
       "      <td>what was the airdate of the episode that aire...</td>\n",
       "      <td>No data from database</td>\n",
       "      <td>Thought: The original air date of the episode ...</td>\n",
       "      <td>alfie's birthday party aired on january 19. wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nu-4</th>\n",
       "      <td>Thought: The SQL query is filtering the DataFr...</td>\n",
       "      <td>what is the number of 1st place finishes acros...</td>\n",
       "      <td>5209</td>\n",
       "      <td>How many first place finishes were achieved in...</td>\n",
       "      <td>17</td>\n",
       "      <td>Thought: The SQL query is counting the number ...</td>\n",
       "      <td>what is the number of 1st place finishes acros...</td>\n",
       "      <td>5218</td>\n",
       "      <td>How many first place finishes were achieved in...</td>\n",
       "      <td>17</td>\n",
       "      <td>Thought: The total number of 1st place finishe...</td>\n",
       "      <td>what is the number of 1st place finishes acros...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                preds_1  \\\n",
       "ids                                                       \n",
       "nu-0  Thought: The SQL query filtered the top 10 cyc...   \n",
       "nu-1  Thought: Based on the SQL query provided, 100,...   \n",
       "nu-2  Thought: The SQL query filters the data to onl...   \n",
       "nu-3  Thought: The episode \"Donnell's Birthday Party...   \n",
       "nu-4  Thought: The SQL query is filtering the DataFr...   \n",
       "\n",
       "                                           statements_1  tokens_1  \\\n",
       "ids                                                                 \n",
       "nu-0  which country had the most cyclists finish wit...      5077   \n",
       "nu-1          how many people were murdered in 1940/41?      6199   \n",
       "nu-2  how long did it take for the new york american...      5223   \n",
       "nu-3  alfie's birthday party aired on january 19. wh...      8830   \n",
       "nu-4  what is the number of 1st place finishes acros...      5209   \n",
       "\n",
       "                                                extra_1    final_answer_1  \\\n",
       "ids                                                                         \n",
       "nu-0  Which country were the cyclists who finished w...               ITA   \n",
       "nu-1  How many people were murdered in 1940/41?;how ...           100,000   \n",
       "nu-2  When did the New York Americans win the Nation...           1953/54   \n",
       "nu-3  What was the airdate of the episode after Alfi...  January 20, 1995   \n",
       "nu-4  How many first place finishes were achieved in...                17   \n",
       "\n",
       "                                                preds_2  \\\n",
       "ids                                                       \n",
       "nu-0  Thought: Based on the SQL query provided, Ital...   \n",
       "nu-1  Thought: The SQL query filtered the data to on...   \n",
       "nu-2  Thought: The New York Americans won the Nation...   \n",
       "nu-3  Thought: The SQL query is filtering for the or...   \n",
       "nu-4  Thought: The SQL query is counting the number ...   \n",
       "\n",
       "                                           statements_2  tokens_2  \\\n",
       "ids                                                                 \n",
       "nu-0  which country had the most cyclists finish wit...      5077   \n",
       "nu-1          how many people were murdered in 1940/41?      5864   \n",
       "nu-2  how long did it take for the new york american...      4971   \n",
       "nu-3  alfie's birthday party aired on january 19. wh...      6850   \n",
       "nu-4  what is the number of 1st place finishes acros...      5218   \n",
       "\n",
       "                                                extra_2  \\\n",
       "ids                                                       \n",
       "nu-0   which country had the most cyclists finish wi...   \n",
       "nu-1  how many people were murdered in 1940?;How man...   \n",
       "nu-2  When did the New York Americans win the Nation...   \n",
       "nu-3   what was the airdate of the episode that aire...   \n",
       "nu-4  How many first place finishes were achieved in...   \n",
       "\n",
       "             final_answer_2  \\\n",
       "ids                           \n",
       "nu-0                    ITA   \n",
       "nu-1                 100000   \n",
       "nu-2               17 years   \n",
       "nu-3  No data from database   \n",
       "nu-4                     17   \n",
       "\n",
       "                                                  preds  \\\n",
       "ids                                                       \n",
       "nu-0  Thought: The SQL query first extracts the last...   \n",
       "nu-1  Thought: Based on the SQL query provided, the ...   \n",
       "nu-2  Thought: The SQL query filters the table to on...   \n",
       "nu-3  Thought: The original air date of the episode ...   \n",
       "nu-4  Thought: The total number of 1st place finishe...   \n",
       "\n",
       "                                             statements  sample_n final_answer  \n",
       "ids                                                                             \n",
       "nu-0  which country had the most cyclists finish wit...       NaN          ITA  \n",
       "nu-1          how many people were murdered in 1940/41?       NaN       100000  \n",
       "nu-2  how long did it take for the new york american...       NaN     17 years  \n",
       "nu-3  alfie's birthday party aired on january 19. wh...       NaN   1995-01-26  \n",
       "nu-4  what is the number of 1st place finishes acros...       NaN           17  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e725269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6758445164275798\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "from collections import Counter\n",
    "for index, row in all_data.iterrows():\n",
    "    target = target_values_map[index]\n",
    "    answer = Counter([row['final_answer_1'], row['final_answer_2'], row['final_answer']]).most_common()[0][0]\n",
    "    \n",
    "    if len(target) > 1:\n",
    "        pred_answer_1 = to_value_list(answer.split(','))\n",
    "        # pred_answer_2 = to_value_list(row['final_answer_2'].split(','))\n",
    "        # pred_answer_3 = to_value_list(row['final_answer'].split(','))\n",
    "    else:\n",
    "        pred_answer_1 = to_value_list([answer])\n",
    "        # pred_answer_2 = to_value_list([row['final_answer_2']])\n",
    "        # pred_answer_3 = to_value_list([row['final_answer']])\n",
    "    if check_denotation(pred_answer_1, target):\n",
    "        acc += 1\n",
    "    else:\n",
    "        # print(index, row['final_answer_left'],row['final_answer_right'], target)\n",
    "        pass\n",
    "print(acc / len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6fd55",
   "metadata": {},
   "source": [
    "#### list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f419a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nu-0 ITA [S['italy']]\n",
      "3 nu-3 No data from database [D(1995,1,26)['january 26, 1995']]\n",
      "10 nu-10 1970, 1988, 1979 [N(2004.000000)['2004'], N(2005.000000)['2005'], N(2006.000000)['2006']]\n",
      "11 nu-11 Jamie Cureton [S['john']]\n",
      "12 nu-12 17 [N(440.000000)['440']]\n",
      "13 nu-13 0 [N(7.000000)['7']]\n",
      "14 nu-14 \\\\0 [S['space']]\n",
      "15 nu-15 305 [N(68.000000)['68']]\n",
      "19 nu-19 3 [N(492111.000000)['492,111']]\n",
      "23 nu-23 Sayonara [S['brindabella']]\n",
      "25 nu-25 8 [N(3.000000)['3']]\n",
      "26 nu-26 14 [N(20.000000)['20']]\n",
      "29 nu-29 Once [N(1.000000)['1']]\n",
      "34 nu-34 No other contestant(s) [S['patricia valiahmetova'], S['carmen jenockova'], S['mariesea mnesicu'], S['jahaira novgorodova'], S['anastasija larkova']]\n",
      "35 nu-35 7 [N(0.000000)['0']]\n",
      "36 nu-36 1 [N(4.000000)['4']]\n",
      "37 nu-37 0 [N(10.000000)['10']]\n",
      "42 nu-42 St Nikolai [S[\"st. mary's church\"]]\n",
      "44 nu-44 2014 [N(1992.000000)['1992']]\n",
      "46 nu-46 12 [N(20.000000)['20']]\n",
      "53 nu-53  [N(1935.000000)['1935']]\n",
      "58 nu-58 David Berger [S['esther shahamorov']]\n",
      "60 nu-60 Kranjska Gora Slovenia [S['giant slalom']]\n",
      "66 nu-66 2010-09-06 [D(2010,12,6)['december 6, 2010']]\n",
      "82 nu-82 0 [N(1.000000)['1']]\n",
      "90 nu-90 0 sizes have an inner diameter above 50 mm. [N(2.000000)['2']]\n",
      "91 nu-91 Westwood [S['usa']]\n",
      "92 nu-92 No [S['yes']]\n",
      "94 nu-94 7 [N(11.000000)['11']]\n",
      "103 nu-103 Sears Point [S['westwood']]\n",
      "105 nu-105 Maurice Bolwerk [S['henk van de lagemaat']]\n",
      "110 nu-110 1 [N(3.000000)['3']]\n",
      "112 nu-112 2 [N(1.000000)['1']]\n",
      "116 nu-116 No [S['yes']]\n",
      "117 nu-117 Joel [S['joel smith']]\n",
      "119 nu-119 2 [N(3.000000)['3']]\n",
      "123 nu-123 Spring [S['becket']]\n",
      "124 nu-124 9 [N(10.000000)['10']]\n",
      "126 nu-126 I cannot determine the nation that comes first from the sub-table. [S['united states']]\n",
      "127 nu-127 No data from database [S['2010-11']]\n",
      "129 nu-129 2 [N(7.000000)['7']]\n",
      "133 nu-133 No data from database [S['los angeles']]\n",
      "136 nu-136 G [S['e']]\n",
      "138 nu-138 2570 BC–1311 [N(3881.000000)['3881']]\n",
      "139 nu-139 0 [N(9.000000)['9']]\n",
      "140 nu-140 The country with the most competitors cannot be determined from the provided sub-table. [S['italy']]\n",
      "144 nu-144 Strafford Union Academy [S['samuel wyatt house']]\n",
      "150 nu-150 President [S['george washington']]\n",
      "153 nu-153 NAnastasiades: 38.2052%, GLillikas: 18.7143%, SMalas: 21.103%, Others: 2.27783% [N(48.400000)['48.4%'], N(25.290000)['25.29%'], N(3.790000)['3.79%'], N(22.520000)['22.52%']]\n",
      "158 nu-158 1 [N(6.000000)['6']]\n",
      "160 nu-160 5 [N(6.000000)['6']]\n",
      "173 nu-173 No data available [S['john mccain']]\n",
      "183 nu-183 76500 [N(76000.000000)['76,000']]\n",
      "194 nu-194 1 [N(2.000000)['2 years']]\n",
      "203 nu-203 5 [N(4.000000)['4']]\n",
      "206 nu-206 Boston and Maine Railroad Antelope [S['lner class a4 no. 4468 mallard']]\n",
      "209 nu-209 8 [N(6.000000)['6']]\n",
      "212 nu-212 Asian Games [S['asian indoor games']]\n",
      "213 nu-213 The previous name of Ajax is the name in the third row. [S['ajax the great']]\n",
      "214 nu-214 Seven, Out Here, It Ain't A Thang, Digging, Lady In The Jaguar, They Pray with Snakes, Rollin Hard, The Harvest, Sippin, Lake of Fire, Red Mist, Angel Like [S['intro']]\n",
      "215 nu-215 North Carolina [S['texas pan-american']]\n",
      "216 nu-216 12 [N(11.000000)['11']]\n",
      "221 nu-221 BAA Buffalo, BAA Indianapolis [S['baltimore bullets']]\n",
      "224 nu-224 Graham Moore [S['gerry poulson']]\n",
      "228 nu-228 Cannot be determined [S['nightrain']]\n",
      "236 nu-236 Austria [S['united states'], S['canada']]\n",
      "237 nu-237 Higgins [S['kevin higgins']]\n",
      "238 nu-238 3 [N(2.000000)['2']]\n",
      "239 nu-239 Troy Corser [S['carl fogarty']]\n",
      "240 nu-240 Train Station\\nBus Terminal [S['bus terminal']]\n",
      "245 nu-245 3 [N(18.000000)['18']]\n",
      "249 nu-249 Guillem Bauza [S['jamie cureton']]\n",
      "253 nu-253 0 [N(105.000000)['105']]\n",
      "265 nu-265 Seattle Seahawks [S['san francisco 49ers']]\n",
      "266 nu-266 Avi Elkabetz [S['elkabetz']]\n",
      "267 nu-267 9 [N(8.000000)['8']]\n",
      "268 nu-268 Tore Torgersen [S['paul moor']]\n",
      "269 nu-269 No data from database [S['jared nathan']]\n",
      "270 nu-270 3 days, 14 hours, 58 minutes, and 46 seconds [S['3:14:58:46']]\n",
      "272 nu-272 Klete Keller [S['ian thorpe']]\n",
      "273 nu-273 Touch the Sky [S['planet pop']]\n",
      "277 nu-277 1988 [N(1993.000000)['1993']]\n",
      "278 nu-278 284.143 [N(153.000000)['153']]\n",
      "279 nu-279 Republican [S['william kent']]\n",
      "284 nu-284 11 [N(1.000000)['1']]\n",
      "289 nu-289 7 [N(4.000000)['4']]\n",
      "290 nu-290 3 [N(20.000000)['20']]\n",
      "293 nu-293 2007 [N(2014.000000)['2014']]\n",
      "294 nu-294 Denny Hulme drove more laps. [S['denny hulme']]\n",
      "295 nu-295 7, 25 [S['1953/54']]\n",
      "299 nu-299 £1,031,660 [D(1998,6,28)['june 28, 1998']]\n",
      "310 nu-310  [N(70.000000)['70']]\n",
      "312 nu-312 May 25 [D(-1,12,21)['dec 21']]\n",
      "314 nu-314 2006 [N(1997.000000)['1997']]\n",
      "320 nu-320 Wimbledon [S['tsuruya open']]\n",
      "321 nu-321 184 [N(200.000000)['200']]\n",
      "328 nu-328 75 [N(112.000000)['112']]\n",
      "332 nu-332 2003 [N(2010.000000)['2010']]\n",
      "334 nu-334 Ben Cardin and Steny Hoyer were re-elected with at least 60% of the vote. [S['steny hoyer'], S['albert wynn'], S['roscoe bartlett'], S['wayne gilchrest'], S['elijah cummings'], S['ben cardin']]\n",
      "337 nu-337 13 [N(4.000000)['4']]\n",
      "338 nu-338 472.038 [N(525.260000)['525.26']]\n",
      "339 nu-339 1988-1989 [S['1982-1985']]\n",
      "340 nu-340 William C. Canby, Jr. [S['d. lawrence gunnels']]\n",
      "341 nu-341 Thaddeus Bell [S['klaus jurgen schneider']]\n",
      "344 nu-344 5 [N(4.000000)['4']]\n",
      "346 nu-346 Himalayan Elm, Indian Elm [S['tamarind']]\n",
      "349 nu-349 0 [N(3.000000)['3']]\n",
      "350 nu-350 Larisa Verbitskaya [S['larisa verbitskaya 43.the tv presenter']]\n",
      "351 nu-351 less than 10 [S['less']]\n",
      "356 nu-356 National Rugby League [S['super rugby']]\n",
      "359 nu-359 Denny Morrison, Mathieu Giroux, and Lucas Makowsky [S['canada']]\n",
      "364 nu-364 2 writers [N(3.000000)['3']]\n",
      "366 nu-366 132 miles [N(132.000000)['132 mi']]\n",
      "368 nu-368 2008 [N(2012.000000)['2012']]\n",
      "369 nu-369 0 [N(4.000000)['4']]\n",
      "370 nu-370 6 [N(8.000000)['8']]\n",
      "377 nu-377 PG16 [S['no']]\n",
      "379 nu-379 8 [N(6.000000)['6']]\n",
      "385 nu-385 John Byrne [S['francis forde']]\n",
      "391 nu-391 No data from database [N(70.000000)['070']]\n",
      "394 nu-394 5 [N(202.000000)['202']]\n",
      "403 nu-403 Not available [S['bansko, bulgaria']]\n",
      "412 nu-412 7 [N(14.000000)['14']]\n",
      "415 nu-415 8 [N(3.000000)['3']]\n",
      "420 nu-420 5 [N(3.000000)['3']]\n",
      "422 nu-422 Itumeleng Khune [S['moeneeb josephs']]\n",
      "427 nu-427 No data from database [S['keiko yoshida']]\n",
      "428 nu-428 Christian Tiboni [S['spas delev']]\n",
      "430 nu-430 18.3 [N(18.800000)['18.8']]\n",
      "432 nu-432 15 [N(16.000000)['16']]\n",
      "439 nu-439 Feb 1 2013 [D(2013,2,1)['1 february 2013']]\n",
      "442 nu-442 5 [N(4.000000)['4']]\n",
      "443 nu-443 2011-11-06 [D(1987,11,25)['25 november 1987']]\n",
      "448 nu-448 252,000 [N(352000.000000)['352,000']]\n",
      "457 nu-457 6 [N(3.000000)['3']]\n",
      "458 nu-458 With Eliel Saarinen; solo addition in 1962. Designated a National Historic Landmark in 2009. [S['cross']]\n",
      "463 nu-463 4 [N(3.000000)['3']]\n",
      "464 nu-464 0 [N(9.000000)['9']]\n",
      "467 nu-467 38 [N(19.000000)['19']]\n",
      "472 nu-472 Fullback [S['dick bielski']]\n",
      "474 nu-474 278 [N(845.000000)['845']]\n",
      "476 nu-476 1979 [N(1.000000)['1 year']]\n",
      "484 nu-484 2013, 2014 [N(2014.000000)['2014']]\n",
      "487 nu-487 0 [N(3.000000)['3']]\n",
      "488 nu-488 20 [N(2.000000)['2']]\n",
      "492 nu-492 1 in 2,000 [N(2000.000000)['2,000']]\n",
      "493 nu-493 No data from database [S['giant slalom']]\n",
      "495 nu-495 0 [N(3.000000)['3']]\n",
      "502 nu-502 Lord Privy Seal [S['below']]\n",
      "506 nu-506 5 [N(2.000000)['2']]\n",
      "508 nu-508 George Shaw, Max Boydston [S['max boydston']]\n",
      "509 nu-509 Yes, the Chennai Open tournament and the Swiss Open tournament have the same surface listed. [S['no']]\n",
      "512 nu-512 0 [N(4.000000)['4']]\n",
      "513 nu-513 4 [N(8.000000)['8']]\n",
      "522 nu-522 at Hamilton Tiger-Cats [S['hamilton tiger-cats']]\n",
      "523 nu-523 0 [N(11.000000)['11']]\n",
      "524 nu-524 South Asia [S['no']]\n",
      "526 nu-526 3 [N(71.000000)['71']]\n",
      "527 nu-527 Edgar D. Bush [S['oliver p. morton']]\n",
      "534 nu-534 1.5 [N(2.000000)['2']]\n",
      "538 nu-538 28 [N(1950.000000)['1950 hours']]\n",
      "540 nu-540 5 [N(2.000000)['2']]\n",
      "542 nu-542 2007 [N(2006.000000)['2006']]\n",
      "543 nu-543 18 [N(8.000000)['8']]\n",
      "548 nu-548 0 [N(6.000000)['6']]\n",
      "553 nu-553 Fiat 500 1.4 LOUNGE 3D\n",
      "Fiat 500 1.4 POP\n",
      "Fiat 500 1.4 SPORT [S['peugeot 207 xs 1.4 5dr 5spd m p'], S['suzuki swift glxh 1.5 5dr'], S['citroen c4 2.0 sx 5dr 6sp a d'], S['suzuki swift glxh2 1.5 5dr'], S['suzuki swift glx 1.5 5dr'], S['fiat 500 1.4 sport'], S['saab 9-3 linear convertible 1.9tid m'], S['fiat 500 1.4 lounge 3d'], S['volkswagen golf tdi 103kw 4motion']]\n",
      "554 nu-554 3.00 [S['£3.00']]\n",
      "561 nu-561 2 [N(3.000000)['3']]\n",
      "563 nu-563 New York Jets [S['seattle seahawks']]\n",
      "569 nu-569 53 [N(198.000000)['198']]\n",
      "571 nu-571 I cannot get an answer from the sub-table. [N(1.000000)['1']]\n",
      "576 nu-576 1 [N(2.000000)['2']]\n",
      "580 nu-580 Giulio Ciotti [S['tora harris']]\n",
      "586 nu-586 No [S['yes']]\n",
      "587 nu-587 Forbidden Fruit\n",
      "Need You [S['need you']]\n",
      "596 nu-596 0 [N(2.000000)['2']]\n",
      "597 nu-597 The match that was in the same month as the one in Atlanta, Georgia was the match on May 9, 1994 in Pinehurst, USA where the player was the runner-up against Jared Palmer. [S['pinehurst, usa']]\n",
      "598 nu-598 Milka Duno [S['danica patrick']]\n",
      "599 nu-599 6 [N(3.000000)['3']]\n",
      "601 nu-601 at Dallas Cowboys [S['dallas cowboys']]\n",
      "603 nu-603 Tsuruya Open [S['asia-pacific panasonic open']]\n",
      "605 nu-605 7 [N(5.000000)['5']]\n",
      "608 nu-608 3551 [N(710.200000)['710.2']]\n",
      "611 nu-611 Randy Savage [S['lanny poffo']]\n",
      "614 nu-614 No data from database [S['dig me out']]\n",
      "617 nu-617 Indiana [S['michigan']]\n",
      "619 nu-619 32 [N(4.000000)['4']]\n",
      "626 nu-626 1 [N(3.000000)['3']]\n",
      "627 nu-627 No data from database [S['male']]\n",
      "635 nu-635 Abraham to Isaac and Descendants of Esau [S['esau']]\n",
      "642 nu-643 Sound Movie film, S-8, Type A [S['kodachrome 40 film']]\n",
      "644 nu-645 0 [N(11.000000)['11']]\n",
      "646 nu-647 0 [N(20.000000)['20']]\n",
      "648 nu-649 Canada [S['andorra']]\n",
      "654 nu-655 4 [N(6.000000)['6']]\n",
      "658 nu-659 5 [N(3.000000)['3']]\n",
      "661 nu-662 372 [S['6:10.02']]\n",
      "662 nu-663 6 [N(4.000000)['4']]\n",
      "664 nu-665 58 [S['58-13']]\n",
      "666 nu-667 The first award Leona Lewis won was not specified in the provided sub-table. Therefore, I cannot provide an answer based on the sub-table. [S['cosmopolitan ultimate woman of the year']]\n",
      "669 nu-670 $12 [N(12000000000.000000)['$12 billion']]\n",
      "670 nu-671 Withdrew after 3 games [N(1.000000)['1st']]\n",
      "671 nu-672 8 [N(3.000000)['3']]\n",
      "673 nu-674 Aleksandar Krajišnik [S['srđan dincic']]\n",
      "677 nu-678 1 [N(6.000000)['6']]\n",
      "682 nu-683 4 [N(9.000000)['9']]\n",
      "685 nu-686 4 [N(5.000000)['5']]\n",
      "687 nu-688 13 [N(14.000000)['14']]\n",
      "688 nu-689 Feb. 8, 1964 against Ohio State with a score of 21-0. [S['denver'], D(1964,3,21)['march 21, 1964']]\n",
      "694 nu-695 4, 4, 0, 0, 0 [N(8.000000)['8 years']]\n",
      "696 nu-697 1 [N(40.000000)['40']]\n",
      "704 nu-705 11 [N(7.000000)['7']]\n",
      "706 nu-707 West Desert [S['el mabrouk']]\n",
      "709 nu-710 0 [N(9.000000)['9']]\n",
      "710 nu-711 N/A [N(2.000000)['2']]\n",
      "715 nu-716 4.60m [N(4.600000)['4.60 m']]\n",
      "726 nu-727 No data from database [S['rolf stommelen']]\n",
      "727 nu-728 13 [N(2.000000)['2']]\n",
      "730 nu-731 No data from database [S['dr salim mehmud']]\n",
      "738 nu-739 1998 [N(1.000000)['1']]\n",
      "740 nu-741 1 [N(2.000000)['2']]\n",
      "742 nu-743 Nagmamahal, Kapamilya: Songs for Global Pinoys [S['h.o.p.e']]\n",
      "748 nu-749 4220 meters or 13845 feet [N(4220.000000)['4220 m'], N(13845.000000)['13,845 ft']]\n",
      "750 nu-751 7136 [N(684.000000)['684']]\n",
      "753 nu-754 35 [N(34.000000)['34']]\n",
      "754 nu-755 11.7% [N(11.700000)['11.7']]\n",
      "756 nu-757 Jo Durie [S['judy chaloner']]\n",
      "758 nu-759 - [S['headquarters']]\n",
      "761 nu-762 Keflavík and Leiftur [S['leiftur'], S['keflavik']]\n",
      "762 nu-763 Not provided [S['giants stadium']]\n",
      "766 nu-767 Cannot be determined [S['cairo']]\n",
      "770 nu-771 2 [N(3.000000)['3']]\n",
      "773 nu-774 Marcellino Lucchi [S['henk van de lagemaat']]\n",
      "774 nu-775 1 [N(4.000000)['4']]\n",
      "775 nu-776 0 [N(2.000000)['2']]\n",
      "776 nu-777 Pacifier [S['bleeder']]\n",
      "779 nu-780 12 [N(2.000000)['2']]\n",
      "780 nu-781 0.5 seconds [N(4.670000)['4.67']]\n",
      "781 nu-782 6 [N(5.000000)['5']]\n",
      "785 nu-786 6 [N(3.000000)['3']]\n",
      "786 nu-787 3 [N(4.000000)['4']]\n",
      "787 nu-788 322 [N(3.000000)['3 days']]\n",
      "793 nu-794 No data from database [S['italy'], S['russia'], S['china']]\n",
      "794 nu-795 Diana DeGette [S['democratic']]\n",
      "796 nu-797 Total [S['netherlands']]\n",
      "800 nu-801 James Ford Cooper [S['dennis f. carter']]\n",
      "801 nu-802 Perfect Sting [S['check the label']]\n",
      "804 nu-805 1 [S['yes']]\n",
      "811 nu-812 less [S['more']]\n",
      "815 nu-816 4 [N(2.000000)['2']]\n",
      "817 nu-818 Mikac [S['des wall']]\n",
      "821 nu-822 2007-12-15 [D(2007,7,25)['july 25, 2007']]\n",
      "822 nu-823 Leo Penn [S['paul wendkos']]\n",
      "829 nu-830 Derrick Favors [S['terry furlow']]\n",
      "830 nu-831 3 [N(2.000000)['2']]\n",
      "842 nu-843 0 [N(9.000000)['9']]\n",
      "847 nu-848 10.3333 [N(17259.000000)['17,259']]\n",
      "853 nu-854 138.1 miles [N(138.100000)['138.1']]\n",
      "855 nu-856 2002, 2003 [N(2002.000000)['2002']]\n",
      "856 nu-857 16 [N(26.000000)['26']]\n",
      "859 nu-860 1.3672 [N(1.000000)['1 mph']]\n",
      "861 nu-862 Kushi [S['love guru']]\n",
      "864 nu-865 September, October, December [D(-1,9,-1)['september']]\n",
      "866 nu-867 Tennessee Titans [S['pittsburgh steelers']]\n",
      "867 nu-868 60 [N(51.000000)['51']]\n",
      "871 nu-872 Tennessee Titans [S['buffalo bills']]\n",
      "886 nu-887 1-1 [N(11.000000)['11']]\n",
      "891 nu-892 I cannot list the models with diesel fuel produced from 1998-2001 from the sub-table. [S['m57d30 turbocharged i6'], S['m67d40 turbocharged v8']]\n",
      "895 nu-896 63.50 meters [N(63.500000)['63.50 m']]\n",
      "897 nu-898 episode 11 and episode 18 [S['danger in the depths']]\n",
      "903 nu-904 6 [N(2.000000)['2']]\n",
      "906 nu-907 -1 [N(46.000000)['46']]\n",
      "907 nu-908 -2 [N(2.000000)['2']]\n",
      "908 nu-909 No data from database [S['real zaragoza']]\n",
      "910 nu-911 1978 [N(1979.000000)['1979']]\n",
      "911 nu-912 0.727273 [N(1.000000)['1']]\n",
      "918 nu-919 Pennsylvania Avenue Line [N(32.000000)['32']]\n",
      "921 nu-922 Brown [S['nixon']]\n",
      "927 nu-928 11 [N(13.000000)['13']]\n",
      "932 nu-933 0 [N(3.000000)['3']]\n",
      "951 nu-952 1 [N(2.000000)['2']]\n",
      "961 nu-962 1 [N(6.000000)['6']]\n",
      "962 nu-963 No data from database [S['cape lookout']]\n",
      "964 nu-965 16 [N(5.000000)['5']]\n",
      "967 nu-968 Unlimited [S['datacenter']]\n",
      "970 nu-971 50-44 [N(50.000000)['50']]\n",
      "973 nu-974 12 [N(2.000000)['2']]\n",
      "977 nu-978 Nagmamahal, Kapamilya: Songs for Global Pinoys, Hotsilog: The ASAP Hotdog Compilation [S['nagmamahal, kapamilya: songs for global pinoys']]\n",
      "988 nu-989 1986–present [N(28.000000)['28']]\n",
      "995 nu-996 0 [N(3.000000)['3']]\n",
      "997 nu-998 2003, 2006, 2007, 2008, 2009, 2010, 2011 [N(2004.000000)['2004'], N(2005.000000)['2005']]\n",
      "1000 nu-1001 Toronto Argonauts: 5 times, Hamilton Tiger-Cats: 4 times, Montreal Alouettes: 5 times [N(12.000000)['12']]\n",
      "1004 nu-1005 1.51407e+06 [N(1514069.000000)['1,514,069']]\n",
      "1005 nu-1006 less than 6 [S['less']]\n",
      "1007 nu-1008 better [S['worse']]\n",
      "1008 nu-1009 0 [N(4.000000)['£4.00']]\n",
      "1013 nu-1014 111 [N(110.000000)['110']]\n",
      "1029 nu-1030 1 [N(23.000000)['23']]\n",
      "1030 nu-1031 2.875 [N(2.500000)['2.5']]\n",
      "1031 nu-1032 Shani Davis, Joey Cheek, Erben Wennemars, Lee Kyou-hyuk, Jan Bos, Chad Hedrick, Yevgeny Lalenkov [S['yevgeny lalenkov']]\n",
      "1034 nu-1035 16 [N(17.000000)['17']]\n",
      "1035 nu-1036 Yelena Kondulaynen [S['yelena kondulaynen 44.the actress']]\n",
      "1036 nu-1037 1 [N(2.000000)['2']]\n",
      "1048 nu-1049 Remodel [S['charles eames']]\n",
      "1051 nu-1052 27.88 miles [N(27.880000)['27.88']]\n",
      "1054 nu-1055 Tim Tam [S['bally ache']]\n",
      "1055 nu-1056 NOT AWARDED [S['morgan freeman']]\n",
      "1056 nu-1057 2 [N(1.000000)['1']]\n",
      "1058 nu-1059 73.23 [N(24.720000)['24.72']]\n",
      "1065 nu-1066 1910-11, 1923-24, 1926-27, 1933-34, 1934-34 [S['1910-11']]\n",
      "1073 nu-1074 4 [N(12.000000)['12']]\n",
      "1077 nu-1078 5 [N(2.000000)['2']]\n",
      "1082 nu-1083 Launceston [S['ulverstone']]\n",
      "1087 nu-1088 Polly Umrigar [S['umrigar']]\n",
      "1088 nu-1089 The kit manufacturer that came next after Umbro is not available in the provided sub-table. [S['henson']]\n",
      "1089 nu-1090 No Canadian opponent mentioned. [S['milos raonic']]\n",
      "1091 nu-1092 Jack Brabham and Mike Parkes [S['jack brabham'], S['mike parkes']]\n",
      "1095 nu-1096 GameStorm 16 [N(1188.000000)['1188']]\n",
      "1097 nu-1098 1906-05-15 [N(1906.000000)['1906']]\n",
      "1098 nu-1099 56.70% [N(89.170000)['89.17']]\n",
      "1103 nu-1104 1 [N(2.000000)['2']]\n",
      "1104 nu-1105 3, 6, 8 [N(8.000000)['8']]\n",
      "1105 nu-1106 Say It Again [S['thin line']]\n",
      "1107 nu-1108 John F. Williams [S['william a. mann']]\n",
      "1109 nu-1110 381000 [S['1943/44']]\n",
      "1111 nu-1112 4 [N(7.000000)['7']]\n",
      "1113 nu-1114 -7.3 [N(7.300000)['7.3']]\n",
      "1115 nu-1116 November 1, 2009 [D(2009,11,1)['1 november 2009']]\n",
      "1120 nu-1121 Kenneth W. Dam, Alan C. Kohn [S['alan c. kohn']]\n",
      "1124 nu-1125 0 [N(7.000000)['7']]\n",
      "1131 nu-1132 September [D(-1,9,-1)['september'], D(-1,10,-1)['october']]\n",
      "1136 nu-1137 0 [N(17.000000)['17']]\n",
      "1138 nu-1139 0 [N(5.000000)['5']]\n",
      "1144 nu-1145 3 [S['lord high treasurer']]\n",
      "1146 nu-1147 at Denver Broncos [S['denver broncos']]\n",
      "1147 nu-1148 5 [N(4.000000)['4']]\n",
      "1148 nu-1149 1 [N(16.000000)['16']]\n",
      "1149 nu-1150 Alex Barron [S['alex zanardi']]\n",
      "1150 nu-1151 PE-12 [S['pe-60']]\n",
      "1153 nu-1154 1 [N(2.000000)['2']]\n",
      "1154 nu-1155 19 [N(3.000000)['3']]\n",
      "1155 nu-1156 1 [N(2.000000)['2']]\n",
      "1156 nu-1157 No data from database [S['tumon, guam']]\n",
      "1159 nu-1160 9 [N(7.000000)['7']]\n",
      "1161 nu-1162 4 TB [N(4.000000)['4']]\n",
      "1167 nu-1168 1 [N(5.000000)['5']]\n",
      "1168 nu-1169 Neymar, Cesc Fàbregas, Alexis Sánchez [S['alexis sanchez']]\n",
      "1169 nu-1170 #6 UCLA [S['ucla']]\n",
      "1176 nu-1177 The Harvest [S['seven']]\n",
      "1184 nu-1185 X9 [S['benning road-h street metro extra line']]\n",
      "1185 nu-1186 Port Douglas Crocs [S['north cairns tigers']]\n",
      "1187 nu-1188 United Kingdom [S['norway']]\n",
      "1188 nu-1189 42 [N(22.000000)['22']]\n",
      "1194 nu-1195 No data from database [N(3.000000)['3']]\n",
      "1201 nu-1202 56 [N(2.000000)['2 months']]\n",
      "1205 nu-1206 3,783,070 [S['3 783 069']]\n",
      "1207 nu-1208 15 [N(2.000000)['2 years']]\n",
      "1208 nu-1209 2 [N(7.000000)['7']]\n",
      "1214 nu-1215 365 [N(1.000000)['1 year']]\n",
      "1215 nu-1216 1 [S['sebastien bourdais']]\n",
      "1217 nu-1218 Queensland [S['tasmania']]\n",
      "1219 nu-1220 Dario Franchitti, Ryan Hunter-Reay, Hideki Mutoh, Marco Andretti, Paul Tracy, Graham Rahal, Raphael Matos (R), Tony Kanaan, Oriol Servià, Hélio Castroneves, Justin Wilson, Robert Doornbos (R), E. J. Viso, Dan Wheldon, Ed Carpenter, Richard Antinucci, Danica Patrick, Mike Conway (R), Milka Duno [S['dario franchitti']]\n",
      "1220 nu-1221 1960-08-24 [D(1960,8,31)['31 august 1960']]\n",
      "1221 nu-1222 7 [N(0.000000)['0']]\n",
      "1223 nu-1224 No data from database [S['canada']]\n",
      "1226 nu-1227 Aalborg [S['anderlecht']]\n",
      "1228 nu-1229 1 [N(17.000000)['17']]\n",
      "1229 nu-1230 1960-08-20 [N(54.000000)['54 years']]\n",
      "1232 nu-1233 91 [N(83.000000)['83']]\n",
      "1236 nu-1237 0 [N(3.000000)['3']]\n",
      "1244 nu-1245 1 [N(3.000000)['3']]\n",
      "1247 nu-1248 Clint Dempsey [S['earnie stewart']]\n",
      "1249 nu-1250 Career* [N(2003.000000)['2003']]\n",
      "1255 nu-1256 7th [N(1.000000)['1st']]\n",
      "1257 nu-1258 3 [N(8.000000)['8']]\n",
      "1261 nu-1262 We cannot determine if all symbols come before numbers based on the given sub-table. [S['no']]\n",
      "1262 nu-1263 1 [N(4.000000)['4']]\n",
      "1263 nu-1264 Peace Memorial Park\\n平和記念公園\\nHeiwa kinen kōen [S['unesco world heritage list']]\n",
      "1264 nu-1265 9 [N(8.000000)['8']]\n",
      "1265 nu-1266 12 [N(6.000000)['6']]\n",
      "1266 nu-1267 The last game of the season was on January 2, 1995, against #13 Ohio State, at the Citrus Bowl in Orlando, FL. The game was televised on ABC, and the result was a win for the team with a score of 24-17. [D(1995,1,2)['january 2, 1995']]\n",
      "1269 nu-1270 1 [N(3.000000)['3']]\n",
      "1270 nu-1271 Thiruvezhukkurrirukkai [S['peria thirumadal'], S['siriya thirumadal'], S['thiruvezhukkurrirukkai']]\n",
      "1272 nu-1273 1 [N(4.000000)['4']]\n",
      "1274 nu-1275 0 [N(9.000000)['9']]\n",
      "1279 nu-1280 Alan McManus [S['stephen hendry']]\n",
      "1280 nu-1281 1991, 2014 [N(23.000000)['23 years']]\n",
      "1282 nu-1283 I cannot get the answer from the sub-table. [N(118.000000)['118']]\n",
      "1283 nu-1284 8 [N(2.000000)['2']]\n",
      "1285 nu-1286 The game with a score gap less than the February 28th game is the October 14th game between SHELL and their opponent, with a score of 68-62. [D(-1,2,16)['february 16']]\n",
      "1288 nu-1289 1938, 1955, 1972 [N(1938.000000)['1938'], N(1972.000000)['1972']]\n",
      "1289 nu-1290 1987 [N(14.000000)['14']]\n",
      "1295 nu-1296 1044.21 [N(527.460000)['527.46']]\n",
      "1303 nu-1304 3 [N(4.000000)['4']]\n",
      "1304 nu-1305 Clyde [S['rangers']]\n",
      "1305 nu-1306 20081 [N(2008.000000)['2008']]\n",
      "1308 nu-1309 67 [N(8.000000)['8']]\n",
      "1310 nu-1311 1 [N(2.000000)['2']]\n",
      "1317 nu-1318 9 [N(1.000000)['1']]\n",
      "1320 nu-1321 Mighty Koadiak [S['invader i']]\n",
      "1322 nu-1323 Camelopardalis B [S['ngc 1569']]\n",
      "1324 nu-1325 Major General (MG) [S['mg']]\n",
      "1325 nu-1326 I cannot determine the race caller before Fred Capossela from the given sub-table. [S['bryan field']]\n",
      "1328 nu-1329 Major General Raza Hussain and Major General Ahmed Bilal [S['major general raza hussain'], S['major general ahmed bilal']]\n",
      "1332 nu-1333 3 periods have an IMR greater than 150. [N(8.000000)['8']]\n",
      "1333 nu-1334 1998–2001 [N(2001.000000)['2001']]\n",
      "1341 nu-1342 4 [N(3.000000)['3']]\n",
      "1343 nu-1344 96.6 km/h (60 mph) [S['185.07 km/h']]\n",
      "1345 nu-1346 3 [N(2.000000)['2']]\n",
      "1346 nu-1347 2008-05-15 [N(2008.000000)['2008']]\n",
      "1348 nu-1349 7 [N(6.000000)['6']]\n",
      "1350 nu-1352 Men's 50 km walk [S['20 km walk']]\n",
      "1352 nu-1354 0 [N(6.000000)['6']]\n",
      "1358 nu-1360 1 [N(13.000000)['13']]\n",
      "1368 nu-1370 Los Angeles Raiders [S['new york giants']]\n",
      "1369 nu-1371 348 [S['5:19.35']]\n",
      "1372 nu-1374 2012 [N(2011.000000)['2011']]\n",
      "1376 nu-1378 4 [N(9.000000)['9']]\n",
      "1379 nu-1381 Loris Capirossi [S['franco battaini']]\n",
      "1381 nu-1383 7 [N(3.000000)['3']]\n",
      "1383 nu-1385 at Las Vegas Legends [S['las vegas legends']]\n",
      "1385 nu-1387 1966-04-27 [S['april 27, 1966']]\n",
      "1386 nu-1388 Bryan Field [S['fred capossela']]\n",
      "1387 nu-1389 3 [N(450.000000)['450']]\n",
      "1392 nu-1394 W 49-0 [N(33.000000)['33']]\n",
      "1393 nu-1395 4 [N(3.000000)['3']]\n",
      "1394 nu-1396 Jan Heylen, Bruno Junqueira, Tristan Gommendy, Neel Jani, Simon Pagenaud, Sébastien Bourdais, Oriol Servià, Graham Rahal, Ryan Dalziel, Dan Clarke, Katherine Legge, Alex Tagliani, Alex Figge, Paul Tracy [S['paul tracy']]\n",
      "1397 nu-1399 Lake Louise, Canada [S['beaver creek, usa']]\n",
      "1404 nu-1406 1 [N(3.000000)['3']]\n",
      "1407 nu-1409 1992 [N(1998.000000)['1998']]\n",
      "1408 nu-1410 Germany [S['canada']]\n",
      "1412 nu-1414 35 [N(27.000000)['27 years']]\n",
      "1420 nu-1422 8 months and 7 days [N(6.000000)['6 years']]\n",
      "1421 nu-1423 Japan [S['china']]\n",
      "1426 nu-1428 0 [S['0:30.31']]\n",
      "1428 nu-1430 7 [N(8.000000)['8']]\n",
      "1434 nu-1436 at New Orleans Saints [S['new orleans saints']]\n",
      "1435 nu-1437 119 [N(82.000000)['82']]\n",
      "1436 nu-1438 11 [N(7.000000)['7']]\n",
      "1439 nu-1441 Mr B. Owen-Jones [S['mr b. owen- jones']]\n",
      "1440 nu-1442 24 [N(12.000000)['12']]\n",
      "1443 nu-1445 Wayne Gilchrest (R) 76.67%\\nAnn Tamlyn (D) 23.16% [S['steny hoyer']]\n",
      "1444 nu-1446 Michigan [S['new york']]\n",
      "1447 nu-1449 2065-08-02 [D(2069,5,20)['may 20, 2069']]\n",
      "1453 nu-1455 0 [N(3.000000)['3']]\n",
      "1459 nu-1461 202.6 [S['202.6 km/h']]\n",
      "1469 nu-1471 0 [N(7.000000)['7']]\n",
      "1470 nu-1472 -2,450,030 [N(9.000000)['9 years']]\n",
      "1472 nu-1474 1 [N(8.000000)['8']]\n",
      "1475 nu-1477 12 [N(6.000000)['6']]\n",
      "1478 nu-1480 Viscount Cranborne [S['alfred scott']]\n",
      "1479 nu-1481 No data from database [S['none']]\n",
      "1482 nu-1484 Less than 5 [S['less']]\n",
      "1485 nu-1487 The Remixes III: Mix Rice Plantation [S['the remixes']]\n",
      "1488 nu-1490 11 [N(10.000000)['10']]\n",
      "1492 nu-1494 05 [S['may']]\n",
      "1496 nu-1498 5 [N(9.000000)['9']]\n",
      "1497 nu-1499 2004, 2005, 2008, 2009 [N(2009.000000)['2009']]\n",
      "1498 nu-1500 We cannot determine which team had the best rushing attempts. [S['cincinnati bengals']]\n",
      "1511 nu-1513 4 [N(3.000000)['3']]\n",
      "1520 nu-1522 No data from database [S['yes']]\n",
      "1522 nu-1524 1961–1974, 1965–1974, 1961–1974, 1962–1978 [N(1936.000000)['1936']]\n",
      "1523 nu-1525 2010, 2012 [N(2010.000000)['2010']]\n",
      "1524 nu-1526 4 [N(6.000000)['6']]\n",
      "1533 nu-1535 3 [N(8.000000)['8']]\n",
      "1535 nu-1537 Tiger Stadium [S['metropolitan stadium']]\n",
      "1536 nu-1538 16 [N(21.000000)['21']]\n",
      "1538 nu-1540 37 [S['super g']]\n",
      "1542 nu-1544 $27.81 million [N(34700000000.000000)['$34.7 billion']]\n",
      "1543 nu-1545 3 [N(4.000000)['4']]\n",
      "1544 nu-1546 18 [N(2.000000)['2']]\n",
      "1546 nu-1548 No data from database [S['mrs e.myer']]\n",
      "1550 nu-1552 1 [N(2.000000)['2']]\n",
      "1551 nu-1553 1 [N(2.000000)['2']]\n",
      "1556 nu-1558 6 [N(2.000000)['2']]\n",
      "1557 nu-1559 Saracens (RU) [S['saracens(ru)']]\n",
      "1559 nu-1561 Forbidden Fruit, Need You [S['need you']]\n",
      "1560 nu-1562 1:07:23.333 [N(38.903000)['+38.903']]\n",
      "1564 nu-1566 3 [N(4.000000)['4']]\n",
      "1570 nu-1572 Duurly's [S['america managua']]\n",
      "1575 nu-1577 Klaws [S['galactus']]\n",
      "1576 nu-1578 No data from database [S['1941/42']]\n",
      "1577 nu-1579 Wake Forest Baptist Medical Center [S['duke']]\n",
      "1578 nu-1580 HSBC Arena [S['away']]\n",
      "1581 nu-1583 Malaysian Open, Malaysia [S['swiss open, switzerland']]\n",
      "1583 nu-1585 Belgium [S['hungary'], S['england'], S['portugal'], S['soviet union'], S['belgium'], S['bulgaria'], S['spain']]\n",
      "1584 nu-1586 4 [N(9.000000)['9']]\n",
      "1589 nu-1591 24.86 [N(24860000.000000)['24.86 million']]\n",
      "1590 nu-1592 Peace Lutheran School [S['christ lutheran school']]\n",
      "1592 nu-1594 Chhatisgarh Express, Jabalpur-Amravati SF, Amla-Nagpur Pass, Indore-Nag Tri. Exp, Indore-Yashwantpur Exp, Nizamuddin-Bhusaval Gondwana Exp, Nizamuddin-Raigarh Gondwana Exp [S['nagpur-agra pass']]\n",
      "1595 nu-1597 Newbury [S['newbury, ohio']]\n",
      "1597 nu-1599 Lokomotiv Moscow [S['spartak nizhny novgorod']]\n",
      "1598 nu-1600 China PR, Syria, Iran [S['syria']]\n",
      "1599 nu-1601 26 [N(25.000000)['25']]\n",
      "1603 nu-1605 Cannot be determined [S['leo burke']]\n",
      "1605 nu-1607 No [S['yes']]\n",
      "1607 nu-1609 2043.24 [N(1045.080000)['1045.08']]\n",
      "1608 nu-1610 1 [N(5.000000)['5']]\n",
      "1609 nu-1611 0 [N(25.000000)['25']]\n",
      "1615 nu-1617 30 [N(35.000000)['35']]\n",
      "1618 nu-1620 11 [S['china open super series']]\n",
      "1626 nu-1628 Henry Picard, Ed Dudley, Toney Penna [S['henry picard']]\n",
      "1632 nu-1634 1951-05-05, Brighton & Hove Albion [S['brighton & hove albion']]\n",
      "1633 nu-1635 Elvis Costello (Vanity Fair, Issue No. 483) [S['time out']]\n",
      "1634 nu-1636 No [S['yes']]\n",
      "1638 nu-1640 December 15, 1985 [D(1985,12,15)['15 december 1985']]\n",
      "1640 nu-1642 Alice Springs [S['alkupitja']]\n",
      "1642 nu-1644  [N(2.000000)['2']]\n",
      "1644 nu-1646 4 [N(6.000000)['6']]\n",
      "1646 nu-1648 2065-08-02 [D(2069,5,20)['may 20, 2069']]\n",
      "1647 nu-1649 12 [N(8.000000)['8']]\n",
      "1649 nu-1651 Northwest of Dover on County Farm Rd. [S['county farm bridge']]\n",
      "1650 nu-1652 1 [N(3.000000)['3']]\n",
      "1651 nu-1653 415 [S['the far reaching effects of broadband']]\n",
      "1652 nu-1654 4 [N(3.000000)['3']]\n",
      "1653 nu-1655 1981-10-18 [D(1981,10,11)['october 11, 1981']]\n",
      "1666 nu-1668 27 [N(36.000000)['36']]\n",
      "1667 nu-1669 0.159091 [N(7.000000)['7']]\n",
      "1669 nu-1671 Rome, Yocemento [S['rome'], S['yocemento'], S['smoky hill city']]\n",
      "1672 nu-1674 14 [N(16.000000)['16']]\n",
      "1676 nu-1678 2006 [N(2001.000000)['2001']]\n",
      "1681 nu-1683 20 [N(2.000000)['2']]\n",
      "1686 nu-1689 8 [N(17.000000)['17 years']]\n",
      "1687 nu-1690 91 [N(13.000000)['13']]\n",
      "1688 nu-1691 3 [N(4.000000)['4']]\n",
      "1689 nu-1692 4x100 m [S['pan arab games']]\n",
      "1694 nu-1697 Dallas Cowboys [S['san francisco 49ers']]\n",
      "1696 nu-1699 2 [N(9.000000)['9']]\n",
      "1698 nu-1701 Once Upon a Dream [S['part of your world']]\n",
      "1699 nu-1702 May 11, 1917 [S['11 may 1917 @ 1950 hours']]\n",
      "1703 nu-1706 Tunisia, Turkey [S['yugoslavia'], S['france']]\n",
      "1704 nu-1707 9830 [S['u+2666']]\n",
      "1705 nu-1708 Tommy Sandt [S['roy hartsfield']]\n",
      "1707 nu-1710 0 [N(5.000000)['5 years']]\n",
      "1709 nu-1712 Volume 1-Elloree [S['lord have mercy']]\n",
      "1710 nu-1713 1998 [N(1995.000000)['1995']]\n",
      "1719 nu-1722 Total formal votes [S['adrian pederick']]\n",
      "1722 nu-1725 Mr B.Melman [S['mr p.venter']]\n",
      "1727 nu-1730 6 [N(5.000000)['5']]\n",
      "1728 nu-1731 Cessna 421C Golden Eagle [S['piper pa-31 navajo']]\n",
      "1729 nu-1732 1903 [N(1905.000000)['1905']]\n",
      "1741 nu-1744 Anderlecht [S['anderlecht'], S['bayern munich']]\n",
      "1742 nu-1745 Manchester United [D(2006,4,14)['14 april 2006']]\n",
      "1744 nu-1747 2 [N(6.000000)['6']]\n",
      "1746 nu-1749 Igor' Livanov, the actor [S[\"igor' livanov\"]]\n",
      "1763 nu-1766 Jack Murphy Stadium [S['rfk stadium']]\n",
      "1765 nu-1768 1010 1100 [S['0011 0100']]\n",
      "1766 nu-1769 Li Yihua (CHN) [S['sylvie bernier']]\n",
      "1767 nu-1770 4 [N(3.000000)['3']]\n",
      "1772 nu-1775 World Youth Championships, World Junior Championships [S['world junior championships'], S['european junior championships'], S['world youth championships']]\n",
      "1777 nu-1780 1 [N(2.000000)['2']]\n",
      "1778 nu-1781 Dzejlana \"Lana\" Baltić [S['dzejlana \"lana\" baltic'], S['melisa popanicic']]\n",
      "1779 nu-1782 Val d'Isère France, Beaver Creek USA, Garmisch Germany, Kranjska Gora Slovenia [S['kranjska gora, slovenia'], S['garmisch, germany'], S[\"val d'isere, france\"], S['beaver creek, usa']]\n",
      "1782 nu-1785 Institution of Engineering & Technology [S['university of cambridge']]\n",
      "1783 nu-1786 1-1 [S['1990-1991 season']]\n",
      "1785 nu-1788 2 [N(6.000000)['6']]\n",
      "1786 nu-1789 66 [N(33.000000)['33']]\n",
      "1788 nu-1791 No data from database [D(1997,9,20)['september 20, 1997']]\n",
      "1791 nu-1794 0 [N(12.000000)['12']]\n",
      "1795 nu-1798 31 [N(15.000000)['15']]\n",
      "1797 nu-1800 10 [N(10727.000000)['10727']]\n",
      "1798 nu-1801 Mr. George Hartigan [S['jeff king']]\n",
      "1801 nu-1804 2003 [N(2008.000000)['2008']]\n",
      "1805 nu-1808 0 [N(1.000000)['1']]\n",
      "1806 nu-1809 1 [N(823.000000)['823']]\n",
      "1808 nu-1811 11 [N(10.000000)['10']]\n",
      "1809 nu-1812 4708, 4100, 5009 [N(4708.000000)['4708']]\n",
      "1813 nu-1816 Japan [S['canada']]\n",
      "1818 nu-1821 -103 [N(103.000000)['103']]\n",
      "1823 nu-1826 1 [N(7.000000)['7']]\n",
      "1825 nu-1828 Manunda Hawks [S['north cairns tigers']]\n",
      "1826 nu-1829 No data from database [S['volcan acatenango pb']]\n",
      "1827 nu-1830 .925 silver [N(0.900000)['.900 silver']]\n",
      "1829 nu-1832 Winner [S['clay']]\n",
      "1830 nu-1833 State_Territory_Womens_Division [S[\"state/territory women's division\"]]\n",
      "1832 nu-1835 G♯mM7 [S['cmm7']]\n",
      "1835 nu-1838 3 [N(2.000000)['2']]\n",
      "1836 nu-1839 0 [N(2.000000)['2']]\n",
      "1837 nu-1840 Garmisch, Germany [S['bansko, bulgaria']]\n",
      "1838 nu-1841 Dr Abdul Majid and Major General Raza Hussain [S['air commodore k. m. ahmad'], S['dr m. shafi ahmad']]\n",
      "1846 nu-1849 1 [N(10.000000)['10']]\n",
      "1850 nu-1853 Quarterback [S['halfback']]\n",
      "1857 nu-1860 8th Voted Out on Day 28 [N(28.000000)['28 days']]\n",
      "1859 nu-1862 No data from database [S['bernie fryer']]\n",
      "1862 nu-1865 Jaipur-Nagpur Exp [S['nagpur-indore tri. exp']]\n",
      "1864 nu-1867 22 [N(31.000000)['31']]\n",
      "1867 nu-1870 No data from database [S['five']]\n",
      "1870 nu-1873 246 [N(1.000000)['1']]\n",
      "1882 nu-1885 4 [N(29.000000)['29']]\n",
      "1883 nu-1886 2006 [N(2005.000000)['2005'], N(2006.000000)['2006']]\n",
      "1884 nu-1887 1 [N(172000.000000)['172,000']]\n",
      "1887 nu-1890 2 [N(0.000000)['0']]\n",
      "1894 nu-1897 6 [N(5.000000)['5']]\n",
      "1896 nu-1899 1 [N(89.000000)['89']]\n",
      "1900 nu-1903 Russia [S['canada']]\n",
      "1902 nu-1905 9 [N(7.000000)['7']]\n",
      "1903 nu-1906 1993-94 [N(1994.000000)['1994']]\n",
      "1906 nu-1909 3 [N(7.000000)['7']]\n",
      "1908 nu-1911 0 [N(7.000000)['7']]\n",
      "1911 nu-1914 No data from database [S['kevin \"buzz\" barrette']]\n",
      "1912 nu-1915 First Kiss [S['kiss']]\n",
      "1914 nu-1917 We cannot determine the place Shaul Ladani took in the Men's 50 km walk event from the information provided in the sub-table. [N(19.000000)['19']]\n",
      "1915 nu-1918 Weapons development [S['atarque']]\n",
      "1923 nu-1926 8 [N(9.000000)['9']]\n",
      "1924 nu-1927 1,484,900 [N(1484900.000000)['1484900']]\n",
      "1927 nu-1930 22 [N(7.000000)['7']]\n",
      "1928 nu-1931 0 [N(23.000000)['23']]\n",
      "1929 nu-1932 1 [S['once']]\n",
      "1933 nu-1936 3 [N(4.000000)['4']]\n",
      "1936 nu-1939 No data from database [S['mauro biello']]\n",
      "1939 nu-1942 No data from database [N(1964.000000)['1964']]\n",
      "1945 nu-1948 $108.9 billion [N(20.700000)['20.7']]\n",
      "1946 nu-1949 1991 [N(2001.000000)['2001']]\n",
      "1947 nu-1950 2 [N(4.000000)['4']]\n",
      "1950 nu-1953 1999-01-18 [N(1999.000000)['1999']]\n",
      "1954 nu-1957 0 [N(14.000000)['14']]\n",
      "1956 nu-1959 French Open [S['us open']]\n",
      "1958 nu-1961 Indy Five Hundred, Lucifer's Stone [S['pat day'], S['john velazquez']]\n",
      "1959 nu-1962 India won [S['won']]\n",
      "1962 nu-1965 Wayne Gilchrest [S['albert wynn']]\n",
      "1963 nu-1966 15:26.62 Q [S['gabriela szabo']]\n",
      "1964 nu-1967 27000 [S['above']]\n",
      "1966 nu-1969 Total wins range from 0 to 11. [N(473.000000)['473']]\n",
      "1968 nu-1971 5.75 [N(1.150000)['1.15m']]\n",
      "1969 nu-1972 16 [N(8.000000)['8']]\n",
      "1970 nu-1973 15 [N(6.000000)['6']]\n",
      "1972 nu-1975 70223.8 [N(70223.000000)['70223']]\n",
      "1974 nu-1977 8 [N(5.000000)['5']]\n",
      "1975 nu-1978 2001 [N(2010.000000)['2010']]\n",
      "1977 nu-1980 PacWest Racing Group [S['pacwest']]\n",
      "1979 nu-1982 Mr B. Owen-Jones [S['mr p.venter']]\n",
      "1982 nu-1985 Enemy of the State [S['u.s. marshals']]\n",
      "1984 nu-1987 Venezuela [S['canada']]\n",
      "1991 nu-1994 12 [N(9.000000)['9']]\n",
      "1992 nu-1995 7CAE [S['7the']]\n",
      "1994 nu-1997 7 [N(1.000000)['1']]\n",
      "1995 nu-1998 2.99 [N(1.000000)['1']]\n",
      "1996 nu-1999 Descendants of Ishmael 25:13 - 18 [S['ishmael']]\n",
      "2002 nu-2005 7552 [N(3776.000000)['3776']]\n",
      "2007 nu-2010 27,426,000 [N(27426028.000000)['27,426,028']]\n",
      "2010 nu-2013 NGC 1569 [S['kk 35']]\n",
      "2011 nu-2014 China, Japan [S['japan']]\n",
      "2012 nu-2015 Tunisia [S['russia']]\n",
      "2016 nu-2019 22 [N(12.000000)['12']]\n",
      "2020 nu-2023 16 [N(10.000000)['10']]\n",
      "2021 nu-2024 Clint Dempsey [S['eric wynalda']]\n",
      "2023 nu-2026 1 [N(6.000000)['6']]\n",
      "2032 nu-2035 Mark Tarbell [S['cat cora']]\n",
      "2033 nu-2036 31, 1, 2 [N(68.000000)['68']]\n",
      "2034 nu-2037 0 [N(10.000000)['10']]\n",
      "2036 nu-2039 Totaal [S['greece']]\n",
      "2037 nu-2040 12 [S['+68° 05′ 46′′']]\n",
      "2038 nu-2041 Season 8 [N(8.000000)['8']]\n",
      "2039 nu-2042 22 [N(21.000000)['21']]\n",
      "2040 nu-2043 2009 [S['clausura 2008']]\n",
      "2041 nu-2044 Adam Shunk [S['roman fricke']]\n",
      "2044 nu-2047 159,074 [S['no']]\n",
      "2045 nu-2048 RBMK-1000 [S['kursk-6']]\n",
      "2047 nu-2050 Italy (ITA) [S['great britain']]\n",
      "2049 nu-2052 Purdue [S['vs. #12 washington']]\n",
      "2056 nu-2059 1987 [S['1987-88']]\n",
      "2058 nu-2061 0 [N(2.000000)['2']]\n",
      "2059 nu-2062 3 [N(5.000000)['5']]\n",
      "2060 nu-2063 1992-10-24 [D(1992,8,15)['15 august 1992'], D(1993,4,13)['13 april 1993'], D(1992,8,19)['19 august 1992'], D(1993,4,7)['7 april 1993']]\n",
      "2061 nu-2064 0 [N(1.000000)['1']]\n",
      "2065 nu-2068 No [S['addhuri']]\n",
      "2070 nu-2073 No data from database [S['qu bo']]\n",
      "2071 nu-2074 0 [N(54.000000)['54']]\n",
      "2078 nu-2081 3 [N(5.000000)['5']]\n",
      "2082 nu-2085 Maze by Gordon Ramsay [S['maze']]\n",
      "2083 nu-2086 0 [N(6.000000)['6']]\n",
      "2091 nu-2094 29.133 [N(29133000.000000)['29.133 million']]\n",
      "2092 nu-2095 No data from database [N(2011.000000)['2011']]\n",
      "2094 nu-2097 -1 [N(0.000000)['0']]\n",
      "2102 nu-2105  [S['summertime']]\n",
      "2104 nu-2107 Friendlies [S['fifa confederations cup']]\n",
      "2108 nu-2111 52 [S['above']]\n",
      "2110 nu-2113 15 [N(30.000000)['30']]\n",
      "2114 nu-2117 10 [N(19.000000)['19']]\n",
      "2117 nu-2120 -11 [N(4.000000)['4']]\n",
      "2118 nu-2121 2 [N(4.000000)['4']]\n",
      "2120 nu-2123 No data from database [S['good shepherd early childhood']]\n",
      "2126 nu-2129 £5 [S['£5.00']]\n",
      "2127 nu-2130 1 [N(3.000000)['3']]\n",
      "2132 nu-2135 France [S['italy']]\n",
      "2133 nu-2136 There is no date available to determine when the first departure occurred. [D(2004,2,27)['2004-02-27']]\n",
      "2135 nu-2138 9th place [N(6.000000)['6th']]\n",
      "2136 nu-2139 No data from database [S['thin line']]\n",
      "2139 nu-2142 2 [N(1.000000)['1']]\n",
      "2144 nu-2147 Yankton/Vermillion [N(106.300000)['106.3 fm']]\n",
      "2145 nu-2148 August_1_2_n126 [N(154.000000)['154']]\n",
      "2147 nu-2150 R [S['republican']]\n",
      "2149 nu-2152 World Cross Country Championships [S['all-africa games']]\n",
      "2150 nu-2153 4.77778 [N(4.700000)['4.7']]\n",
      "2151 nu-2154 1 [N(5.000000)['5']]\n",
      "2152 nu-2155 No data from database [S['atlanta, ga']]\n",
      "2153 nu-2156 0 [N(1.000000)['1']]\n",
      "2154 nu-2157 2009, 2010, 2012, 2013, 2014 [N(2012.000000)['2012']]\n",
      "2156 nu-2159 Dan Wheldon [S['justin wilson']]\n",
      "2163 nu-2166 14 [N(13.000000)['13']]\n",
      "2164 nu-2167 -13 [N(13.000000)['13']]\n",
      "2170 nu-2173 25% [N(25.000000)['25']]\n",
      "2171 nu-2174 0 [N(2.000000)['2']]\n",
      "2179 nu-2182 Niñas mal (telenovela) [S['yo te estare cuidando']]\n",
      "2183 nu-2186 No data from database [S['antonio manuel reina']]\n",
      "2185 nu-2188 20 [N(1.000000)['1']]\n",
      "2188 nu-2191 Atarque has a higher elevation than Cebolla - 1. [S['atarque']]\n",
      "2191 nu-2194 Tommy Sandt [S['roy hartsfield']]\n",
      "2193 nu-2196 We cannot determine if Jamaica has at least a quantity of 5. [S['no']]\n",
      "2194 nu-2197 MG Creed C. Hammond [S['creed c. hammond']]\n",
      "2198 nu-2201 1938–1951 [N(1956.000000)['1956']]\n",
      "2199 nu-2202 Matthew Bryan-Amaning [S['justin holiday']]\n",
      "2200 nu-2203 16 [N(14.000000)['14']]\n",
      "2202 nu-2205 1 [N(42.000000)['42']]\n",
      "2203 nu-2206 European Championships [S['world indoor championships']]\n",
      "2204 nu-2207 at Seattle Seahawks [S['2004 rams']]\n",
      "2210 nu-2213 8 [N(4.000000)['4']]\n",
      "2216 nu-2219 ♦ [S['diams']]\n",
      "2218 nu-2221 John Moore-Brabazon [S['sir andrew duncan']]\n",
      "2227 nu-2230 5.4 [S['5.4l']]\n",
      "2228 nu-2231 96.6 km/h (60 mph) [N(202.600000)['202.6 km/h']]\n",
      "2231 nu-2234 6 [N(12.000000)['12']]\n",
      "2232 nu-2235 Mini Cooper COUPE 6M 3DR 1.6L [S['mini cooper coupe 6m 3dr 1.6l diesel']]\n",
      "2233 nu-2236 0 [N(6.000000)['6']]\n",
      "2239 nu-2242 November 11, 2007 [D(2007,11,11)['11 nov 2007']]\n",
      "2241 nu-2244 1 [N(6.000000)['6']]\n",
      "2247 nu-2250 4 [N(3.000000)['3']]\n",
      "2248 nu-2251 Oldsmobile [S['honda'], S['oldsmobile'], S['toyota']]\n",
      "2250 nu-2253 21 [N(5.000000)['5']]\n",
      "2251 nu-2254 Republican [S['democratic']]\n",
      "2254 nu-2257 1 [N(7.000000)['7']]\n",
      "2255 nu-2258 #9 (FCS) Northern Iowa [S['northern iowa']]\n",
      "2256 nu-2259 0 [N(179.000000)['179']]\n",
      "2262 nu-2265 6 [N(10.000000)['10']]\n",
      "2263 nu-2266 19 [N(18.000000)['18']]\n",
      "2265 nu-2268 Xiao Zhanbo [S['qu bo']]\n",
      "2267 nu-2270 85153 [S['giza']]\n",
      "2271 nu-2274 Zakarpattia [S['chornohora']]\n",
      "2279 nu-2282 Coefficient continuation field (bits) [S['exponent continuation field']]\n",
      "2280 nu-2283 110 [N(12.000000)['12']]\n",
      "2282 nu-2285 11 May 1917 @ 1950 hours [S['4 december 1916 @ 1100 hours']]\n",
      "2284 nu-2287 19 [N(93.000000)['93']]\n",
      "2285 nu-2288 Yes [S['no']]\n",
      "2286 nu-2289 1931 to 1967 [N(1967.000000)['1967']]\n",
      "2287 nu-2290 Reggie Johnson [S['johnson']]\n",
      "2292 nu-2295 0.0535714 [N(3.000000)['3']]\n",
      "2294 nu-2297 Harp [S['lang']]\n",
      "2296 nu-2299 1 [N(2.000000)['2']]\n",
      "2297 nu-2300 No data from database [S['cyprus']]\n",
      "2298 nu-2301 20 [N(11.000000)['11']]\n",
      "2302 nu-2305 3 [N(8.000000)['8']]\n",
      "2308 nu-2311 Not specified [S['fk radnicki nis']]\n",
      "2309 nu-2312 Cataraqui Town Centre or St. Lawrence College [S['cataraqui town centre st. lawrence college']]\n",
      "2310 nu-2313 Pakistan, South Africa, Ireland [S['pakistan']]\n",
      "2315 nu-2318 0 [N(11.000000)['11']]\n",
      "2316 nu-2319 2 [N(1.000000)['1']]\n",
      "2318 nu-2321 Dean Heller [S['orrin hatch']]\n",
      "2319 nu-2322 4 [N(6.000000)['6']]\n",
      "2320 nu-2323 Wyoming [S['california']]\n",
      "2326 nu-2329 10 [N(6.000000)['6']]\n",
      "2327 nu-2330 -1926 [N(13.000000)['13']]\n",
      "2328 nu-2331 D4500 [S['mci d4500']]\n",
      "2330 nu-2333 Cannot be determined [S['maghreb']]\n",
      "2333 nu-2336 Tokyo, Japan\n",
      "Osaka, Japan [S['japan']]\n",
      "2334 nu-2337 Men's 20 km walk [S['20 km walk']]\n",
      "2339 nu-2342 29 [N(25.000000)['25']]\n",
      "2343 nu-2346 Chad Hedrick [S['hedrick']]\n",
      "2345 nu-2348 1944-1945 [S['1943/44']]\n",
      "2348 nu-2351 10 [N(4.000000)['4']]\n",
      "2356 nu-2359 0 [S['less']]\n",
      "2357 nu-2360 Noah to Shem, Ham, and Japeth 6:9 - 10 [S['adam to noah 5:1 - 32']]\n",
      "2358 nu-2361 9.6 [N(3.500000)['3.5']]\n",
      "2359 nu-2362 3 [N(13.800000)['13.8'], N(13.500000)['13.5'], N(13.900000)['13.9']]\n",
      "2364 nu-2367 0 [N(1.000000)['1']]\n",
      "2365 nu-2368 9 [N(8.000000)['8']]\n",
      "2366 nu-2369 2003, 2002, 2008 [N(2001.000000)['2001'], N(2002.000000)['2002'], N(2003.000000)['2003']]\n",
      "2368 nu-2371 3 [N(11.000000)['11']]\n",
      "2370 nu-2373 100 m hurdles [S['grand prix final']]\n",
      "2373 nu-2376 Winner of the Nobel Peace Prize (1986) [S['professional writer winner of the nobel peace prize']]\n",
      "2376 nu-2379 0 [N(5.000000)['5']]\n",
      "2381 nu-2384 1461 [N(4.000000)['4 years']]\n",
      "2391 nu-2394 Renault [S['dams']]\n",
      "2394 nu-2397 Nagore Robles [S['ursula aguilar']]\n",
      "2398 nu-2401 Empire State Building [S['ostankino tower']]\n",
      "2399 nu-2402 Andrey Tereshin, Víctor Moya, Linus Thörnblad, Giulio Ciotti, Robert Wolski, Ramsay Carelse, Tora Harris, Nicola Ciotti, Wojciech Theiner, Tomáš Janku, Mustapha Raifak, Svatoslav Ton, Adam Shunk, Roman Fricke [S['andrey tereshin']]\n",
      "2403 nu-2406 Lick It Up [S['loose cannon']]\n",
      "2405 nu-2408 2 [N(0.366000)['.366 seconds']]\n",
      "2406 nu-2409 1 [N(2.000000)['2']]\n",
      "2409 nu-2412 1 [N(5.000000)['5']]\n",
      "2416 nu-2419 1988 [S['1991/92']]\n",
      "2420 nu-2423 0 [N(4.000000)['4']]\n",
      "2421 nu-2424 No data from database [S['milton town house'], S['jenness farm'], S['farmington town pound'], S['plummer homestead'], S['richard hayes house'], S['woodbury mill'], S['new durham meetinghouse and pound'], S['plumer-jones farm'], S['canaan chapel'], S['strafford county farm']]\n",
      "2422 nu-2425 2 [N(4.000000)['4']]\n",
      "2424 nu-2427 3 [N(2.000000)['2']]\n",
      "2425 nu-2428 19494 [N(73721.000000)['73721']]\n",
      "2436 nu-2439 More [S['usher']]\n",
      "2438 nu-2441 2 [S['no']]\n",
      "2440 nu-2443 No data from database [S['purple']]\n",
      "2442 nu-2445 10 [N(13.000000)['13']]\n",
      "2443 nu-2446 Herman Wouk [S['elie wiesel']]\n",
      "2447 nu-2450 0 [N(28.000000)['28']]\n",
      "2448 nu-2451 Gateway to the Open Mizuno Open [S['tsuruya open']]\n",
      "2450 nu-2453 Georgina Hale did not receive the BAFTA award for any film. [S['mahler']]\n",
      "2451 nu-2454 5 [N(4.000000)['4']]\n",
      "2454 nu-2457 Tunisia, Egypt [S['egypt']]\n",
      "2456 nu-2459 No data from database [S['guy ligier']]\n",
      "2462 nu-2465 49 [N(7.000000)['7']]\n",
      "2466 nu-2469 0 [S['8:43']]\n",
      "2468 nu-2471 Carolin Leonhardt, Silke Hörmann, Franziska Weber, Tina Dietze, Nicole Reinhardt, Conny Wassmuth [S['germany nicole reinhardt conny wassmuth tina dietze carolin leonhardt'], S['germany carolin leonhardt silke hormann franziska weber tina dietze']]\n",
      "2469 nu-2472 4 [N(3.000000)['3']]\n",
      "2471 nu-2474 Yes [S['no']]\n",
      "2474 nu-2477 60.45 meters [N(60.450000)['60.45 m']]\n",
      "2486 nu-2489 Buffalo Bills (1), Buffalo Bills (2), Buffalo Bills (4) [S['buffalo bills']]\n",
      "2489 nu-2492 4 [N(3.000000)['3']]\n",
      "2493 nu-2496 Yes, Pierre Karsmakers is listed above John Banks in the sub-table. [S['above']]\n",
      "2494 nu-2497 Do-Si-Do [N(8.000000)['8']]\n",
      "2496 nu-2499 6 [N(47.000000)['47']]\n",
      "2504 nu-2507 2 [N(3.000000)['3']]\n",
      "2506 nu-2509 7.78664e+06 [S['cairo']]\n",
      "2511 nu-2514 My Own Worst Enemy [S['army of me']]\n",
      "2515 nu-2519 Not Consecutive [S['yes']]\n",
      "2516 nu-2520 790.286 [N(922.000000)['922']]\n",
      "2518 nu-2522 -4006 [N(16.000000)['16']]\n",
      "2523 nu-2527 Justice Society of America vol. 3, #6 (July 2007) [S['legion membership first mentioned by starman in justice society of america vol. 3, #6 (july 2007) and confirmed in action comics #860 (february 2008)']]\n",
      "2525 nu-2529 Durham [S['charlotte']]\n",
      "2527 nu-2531 Yes, Arjun is located in Central India. [S['arjun']]\n",
      "2528 nu-2532 6 [N(10.000000)['10']]\n",
      "2530 nu-2534 European Open [S['world cup']]\n",
      "2533 nu-2537 6.17 miles [N(6.170000)['6.17']]\n",
      "2535 nu-2539 0 [N(5.000000)['5']]\n",
      "2541 nu-2545 Tiger Woods [S['hunter mahan']]\n",
      "2544 nu-2548 Cataraqui Town Centre\\nSt. Lawrence College [S['cataraqui town centre st. lawrence college']]\n",
      "2546 nu-2550 0 [N(27.000000)['27']]\n",
      "2548 nu-2552 Samdech Penn Nouth [S['sisowath monireth']]\n",
      "2549 nu-2553 1 [N(4.000000)['4']]\n",
      "2551 nu-2555 We cannot determine the year from the provided sub-table. [N(2010.000000)['2010']]\n",
      "2552 nu-2556 3 [N(2.000000)['2']]\n",
      "2554 nu-2558 3 [N(0.000000)['0']]\n",
      "2555 nu-2559 9 [N(14.000000)['14 days']]\n",
      "2556 nu-2560 December 18, 1948 [D(1931,10,3)['october 3, 1931']]\n",
      "2558 nu-2562 Regina Do Santos, Liberto López de la Franca, Mª Ángeles Delgado, Úrsula Aguilar, Álvaro Muñoz-Escassi, Pedro Reche, \"Reche\", Antonio David Flores, Raúl Hidalgo, Leticia Sabater, Brenda Cerdá, Sonia Baby, and Bárbara Rey. [S['regina do santos']]\n",
      "2559 nu-2563 Xiao Zhanbo [S['zhu ting']]\n",
      "2560 nu-2564 120 [N(4.000000)['4 months']]\n",
      "2564 nu-2568 0 [N(9.000000)['9']]\n",
      "2568 nu-2572 0 [N(17.000000)['17']]\n",
      "2571 nu-2575 Major General Ahmed Bilal [S['major general raza hussain']]\n",
      "2573 nu-2577 Toon, Red Cedar [S['simul']]\n",
      "2575 nu-2579 Moldova [S['canada']]\n",
      "2577 nu-2581 May 15, 1911 [N(1911.000000)['1911']]\n",
      "2579 nu-2583 17 [N(16.000000)['16']]\n",
      "2580 nu-2584 2014 [N(2012.000000)['2012']]\n",
      "2585 nu-2589 +39.092 [S['+ 39.092']]\n",
      "2586 nu-2590 0 [N(4.000000)['4']]\n",
      "2590 nu-2594 0 [N(2.000000)['2']]\n",
      "2592 nu-2596 6 [N(3.000000)['3']]\n",
      "2594 nu-2598  [S['denver']]\n",
      "2595 nu-2599 Class_3_eg_Car_with_trailer [S['class 5']]\n",
      "2601 nu-2605 1° Temporada [N(2.000000)['2 years']]\n",
      "2602 nu-2606 1, 9, 16, 17 [N(1.000000)['1'], N(9.000000)['9'], N(16.000000)['16'], N(17.000000)['17'], N(19.000000)['19'], N(20.000000)['20'], N(23.000000)['23'], N(24.000000)['24'], N(31.000000)['31'], N(34.000000)['34'], N(37.000000)['37'], N(38.000000)['38'], N(39.000000)['39'], N(40.000000)['40'], N(41.000000)['41'], N(42.000000)['42'], N(45.000000)['45'], N(46.000000)['46'], N(48.000000)['48'], N(55.000000)['55'], N(61.000000)['61'], N(69.000000)['69'], N(75.000000)['75'], N(82.000000)['82'], N(90.000000)['90'], N(91.000000)['91'], N(92.000000)['92']]\n",
      "2604 nu-2608 Dancer in the Dark [S['the five obstructions']]\n",
      "2611 nu-2615 French (St.-Jean)/English (Fauget) [S['english']]\n",
      "2613 nu-2617 KK93 and The Dam [S['the dam'], S['kk93']]\n",
      "2614 nu-2618 Millsaps [S['millspaps']]\n",
      "2615 nu-2619 Svydovets [S['uholka / wide meadow']]\n",
      "2622 nu-2626 Minnesota Vikings [D(1987,9,27)['september 27, 1987']]\n",
      "2625 nu-2629 San Francisco 49ers [S['denver broncos']]\n",
      "2626 nu-2630 No data from database [S['diamond sculls']]\n",
      "2627 nu-2631 ALASKA [D(-1,2,16)['february 16']]\n",
      "2629 nu-2633 below 100 [S['below']]\n",
      "2630 nu-2634 - [S['english']]\n",
      "2634 nu-2638 5 [N(3.000000)['3']]\n",
      "2635 nu-2639 0 [N(45.900000)['45.9']]\n",
      "2637 nu-2641 3 [N(4.000000)['4']]\n",
      "2639 nu-2643 11.8 square miles [N(11.800000)['11.8']]\n",
      "2642 nu-2646 Matti Hautamäki [S['andreas kofler']]\n",
      "2649 nu-2653 U+0000 [S['u']]\n",
      "2650 nu-2654 13 [N(80.000000)['80'], N(79.000000)['79']]\n",
      "2651 nu-2655 1880–1884 [N(4.000000)['4 years']]\n",
      "2653 nu-2657 less than 1.8m [S['less']]\n",
      "2658 nu-2662 more than a year [S['less']]\n",
      "2659 nu-2663 0 [N(5.000000)['5']]\n",
      "2660 nu-2664 0 [N(21.000000)['21 days']]\n",
      "2665 nu-2669 1 [N(10.000000)['10']]\n",
      "2667 nu-2671 0 [S['no']]\n",
      "2676 nu-2680 1 [N(5.000000)['5']]\n",
      "2679 nu-2683 0 [N(2.000000)['2']]\n",
      "2680 nu-2684 18 [N(19.000000)['19']]\n",
      "2686 nu-2690 Mera Juta Hai Japani, Ramaiya Vastavaiya [S['mera juta hai japani']]\n",
      "2697 nu-2701 1 [N(4.000000)['4']]\n",
      "2701 nu-2705 Conservative hold [S['patrick mcloughlin']]\n",
      "2706 nu-2710 6 [N(4.000000)['4']]\n",
      "2708 nu-2712 Veterinarian Dolittle [S['best supporting actress']]\n",
      "2712 nu-2716 36 [N(26.000000)['26 years']]\n",
      "2716 nu-2720 Sengkang Punggol [S['geylang united']]\n",
      "2726 nu-2730 Woodrow Wilson High School [S['santee education complex'], S['woodrow wilson high school']]\n",
      "2730 nu-2734 0 [N(4.000000)['4']]\n",
      "2737 nu-2741 0 [N(2.000000)['2']]\n",
      "2744 nu-2748 21.16mm (0.833 inches) [N(21.160000)['21.16']]\n",
      "2748 nu-2752 All-Africa Games [S['commonwealth games']]\n",
      "2749 nu-2753 14 [N(8.000000)['8']]\n",
      "2750 nu-2754 0 [N(15.000000)['15']]\n",
      "2751 nu-2755 Good Shepherd Early Childhood [S['bethlehem lutheran school']]\n",
      "2752 nu-2756 34 [N(7.000000)['7']]\n",
      "2754 nu-2758 September 8, 2001 [D(2008,5,10)['may 10, 2008']]\n",
      "2755 nu-2759 Neyland Stadium • Knoxville, TN (Third Saturday in October) [S['neyland stadium']]\n",
      "2758 nu-2762 Spain, Germany, France, Japan [S['japan'], S['germany'], S['france']]\n",
      "2760 nu-2764 3 [N(4.000000)['4']]\n",
      "2773 nu-2777 No data from database [S['sam']]\n",
      "2776 nu-2780 1 [N(2.000000)['2']]\n",
      "2777 nu-2781 46 [N(23.000000)['23']]\n",
      "2783 nu-2787 No data from database [S['longer']]\n",
      "2784 nu-2788 2008 [N(2012.000000)['2012']]\n",
      "2792 nu-2796 Florida [S['canaveral']]\n",
      "2793 nu-2797 Shamburg, Singersville [S['sackett']]\n",
      "2794 nu-2798 5-7, 6-2, 6-4 [N(12.000000)['12']]\n",
      "2795 nu-2799 22 [N(25.000000)['25']]\n",
      "2797 nu-2801 1919-03-15 [D(1918,7,11)['11 july 1918']]\n",
      "2802 nu-2806 Gillig [S['gillig'], S['new flyer']]\n",
      "2803 nu-2807 93259 [N(93505.000000)['93,505']]\n",
      "2807 nu-2811 61, 56 [N(7.000000)['7km']]\n",
      "2808 nu-2812 No data from database [N(4.670000)['4.67']]\n",
      "2810 nu-2814 30 [N(35.000000)['35']]\n",
      "2811 nu-2815 2003-01-25, 2003-02-04, 2003-02-05 [D(2003,1,25)['25 january 2003']]\n",
      "2812 nu-2816 H6 [S['e6']]\n",
      "2815 nu-2819 Andrew Davidson [S[\"caroline o'shea\"]]\n",
      "2816 nu-2820 -5 [N(5.000000)['5']]\n",
      "2822 nu-2827 1 [N(7.000000)['7 days']]\n",
      "2825 nu-2830 Jody Shelley, James Wisniewski, and Raffi Torres [S['jody shelley'], S['james wisniewski'], S['raffi torres']]\n",
      "2827 nu-2832 Norway [S['greece']]\n",
      "2828 nu-2833 Carroll, Humphries, J. Sharkey, McKay [S['carroll'], S['sharkey'], S['mckay'], S['humphries']]\n",
      "2829 nu-2834 582 [N(2.000000)['2 years']]\n",
      "2831 nu-2836 34°24′02″N 132°28′04″E﻿ / ﻿34.40050182°N 132.46770735°E [S['34°24′02′′n 132°28′04′′e / 34.40050182°n 132.46770735°e']]\n",
      "2833 nu-2838 18 [N(14.000000)['14']]\n",
      "2836 nu-2841 0 [N(0.200000)['.2']]\n",
      "2838 nu-2843 Light transport [S['piper pa-31 navajo']]\n",
      "2841 nu-2846 1 [N(2.000000)['2']]\n",
      "2842 nu-2847 28 [N(2010.000000)['2010']]\n",
      "2844 nu-2849 World [S['asia']]\n",
      "2846 nu-2851 24 [N(4.000000)['4']]\n",
      "2851 nu-2856 Cannot be determined [N(3.000000)['3']]\n",
      "2856 nu-2861 7 [N(6.000000)['6']]\n",
      "2862 nu-2867 19 [N(7.000000)['7']]\n",
      "2863 nu-2868 8th [N(2.000000)['2nd']]\n",
      "2864 nu-2869 Washington Redskins [S['dallas cowboys']]\n",
      "2866 nu-2871 2 [N(6.000000)['6']]\n",
      "2869 nu-2874 0 [N(15.000000)['15']]\n",
      "2871 nu-2876 BEL [S['belgium']]\n",
      "2873 nu-2878 No data from database [S['pe-1']]\n",
      "2878 nu-2883 24 [N(23.000000)['23']]\n",
      "2879 nu-2884 Valencia [S['real madrid']]\n",
      "2881 nu-2886 Phil Mickelson [S['geoff ogilvy']]\n",
      "2883 nu-2888 14 [N(16.000000)['16']]\n",
      "2885 nu-2890 WWE Raw [S['two and a half men']]\n",
      "2886 nu-2891 1 [N(2.000000)['2']]\n",
      "2888 nu-2893 20927 [N(41297.000000)['41297']]\n",
      "2891 nu-2896  [N(0.130000)['.13 seconds']]\n",
      "2895 nu-2900 Sumner City [S['ulysses']]\n",
      "2896 nu-2901 Maftir, Year 2 [S['year 2']]\n",
      "2897 nu-2902 24 [N(14.000000)['14']]\n",
      "2907 nu-2912 SOC [S['zueitina']]\n",
      "2908 nu-2913 Russia [S['brazil']]\n",
      "2911 nu-2916 Paris - Caen [S[\"les sables d'olonne - bordeaux\"]]\n",
      "2913 nu-2918 29-3 [S['31-3']]\n",
      "2915 nu-2920 0 [N(1.000000)['1']]\n",
      "2919 nu-2924 0 [N(2.000000)['2']]\n",
      "2932 nu-2937 Laramie [S['henry j. kaiser']]\n",
      "2935 nu-2940 6 [N(10.000000)['10']]\n",
      "2941 nu-2946 Nobel Peace Prize [S['professional writer winner of the nobel peace prize']]\n",
      "2947 nu-2952 Norway (NOR) [S['ole lilloe-olsen']]\n",
      "2958 nu-2963 0 [N(6.000000)['6']]\n",
      "2967 nu-2972 2006-2007 [N(1.000000)['1 year']]\n",
      "2968 nu-2973 more than 15 [S['more']]\n",
      "2969 nu-2974 475 [N(278.000000)['278']]\n",
      "2973 nu-2978 270 [N(295.000000)['295']]\n",
      "2977 nu-2982 America [S['south and central america']]\n",
      "2978 nu-2983 Danny Defrost-Bot [S['slide the heavy-metal robot']]\n",
      "2979 nu-2984 373 Spaces [N(373.000000)['373']]\n",
      "2987 nu-2992 12 [N(5.000000)['5 years']]\n",
      "2988 nu-2993 vs. Montreal Alouettes [S['montreal alouettes']]\n",
      "2989 nu-2994 0 [N(2.000000)['2']]\n",
      "2996 nu-3001 12 [N(13.000000)['13']]\n",
      "2998 nu-3003 Thou Shalt Not Steal, Callin' Dr. Casey, \"Bad News\" (b/w \"Guitar Player(Her and Him)\", Blue Train (Of the Heartbreak Line), Th' Wife, That Ain't All [S[\"callin' dr. casey\"], S[\"you're the guilty one\"], S[\"sittin' in the balcony\"], S[\"that ain't all\"], S['blue train'], S['\"bad news\" (b/w \"guitar player(her and him)\")'], S['odd folks of okracoke'], S['thou shalt not steal'], S[\"th' wife\"]]\n",
      "2999 nu-3004 0 [N(6.000000)['6']]\n",
      "3002 nu-3007 4 [N(2.000000)['2']]\n",
      "3003 nu-3008 28 [N(13129.000000)['13,129']]\n",
      "3010 nu-3015 I cannot provide an answer based on the sub-table. [S['a world called you']]\n",
      "3011 nu-3016 Dominican Republic [S['trinidad and tobago']]\n",
      "3013 nu-3018 6 [N(3.000000)['3']]\n",
      "3016 nu-3021 278 [N(31.000000)['31']]\n",
      "3017 nu-3022 Northern Mariana Islands [S['japan']]\n",
      "3018 nu-3023 Voodoo Dancer [S['samitar']]\n",
      "3019 nu-3024 5th [N(2.000000)['2nd']]\n",
      "3021 nu-3026 11 [N(5.000000)['5']]\n",
      "3024 nu-3029 1936/37 [S['1948/49']]\n",
      "3026 nu-3031 8.9692 [N(8.000000)['8']]\n",
      "3027 nu-3032 3 [N(2.000000)['2']]\n",
      "3028 nu-3033 Yes [S['true']]\n",
      "3030 nu-3035 500 [N(563.000000)['563']]\n",
      "3032 nu-3037 No data from database [S['netherlands']]\n",
      "3034 nu-3039 Clay (i) [S['hard']]\n",
      "3035 nu-3040 946 [S['total wins 473']]\n",
      "3036 nu-3041 4 [N(5.000000)['5']]\n",
      "3037 nu-3042 16 [N(14.000000)['14']]\n",
      "3038 nu-3043 1967 [N(1968.000000)['1968']]\n",
      "3041 nu-3046 below 10.59 [S['above']]\n",
      "3043 nu-3048 11 [N(10.000000)['10']]\n",
      "3048 nu-3053 U+0061 [S['u+0000']]\n",
      "3051 nu-3056 Mr B. Owen-Jones [S['mr b. owen- jones']]\n",
      "3052 nu-3057 1 [N(3.000000)['3']]\n",
      "3053 nu-3058 Libbie Hickman (USA) [S['annemari sandell']]\n",
      "3056 nu-3061 10 [S['argentina f8']]\n",
      "3058 nu-3063 962 [N(543.000000)['543']]\n",
      "3065 nu-3070 0 [N(1.000000)['1']]\n",
      "3068 nu-3073 10 [N(13.000000)['13']]\n",
      "3072 nu-3077 Narkhed-New Amravati Pass [S['chhatisgarh express']]\n",
      "3073 nu-3078 Being John Malkovich [S['bronze wrangler theatrical motion picture']]\n",
      "3076 nu-3081 3.7 [N(3.630000)['3.63']]\n",
      "3077 nu-3082 7 [N(9.000000)['9']]\n",
      "3081 nu-3086 Dates are not in consecutive order [S['no']]\n",
      "3083 nu-3088 L 8-14 [S['8-14']]\n",
      "3086 nu-3091 55316 [S['below']]\n",
      "3087 nu-3092 59 [N(0.000000)['0']]\n",
      "3088 nu-3093 Mr A. Ruffels [S['mr f.j.van heerden']]\n",
      "3089 nu-3094 It's My Time [S['blue train']]\n",
      "3090 nu-3095 14 [N(15.000000)['15 mm']]\n",
      "3093 nu-3098 3 [N(6.000000)['6']]\n",
      "3094 nu-3099 0 [N(3.000000)['3']]\n",
      "3096 nu-3101 1 [N(3.000000)['3']]\n",
      "3098 nu-3103 16 [N(19.000000)['19']]\n",
      "3099 nu-3104 John Rich [S['sheldon leonard']]\n",
      "3100 nu-3105  [S['eskender mustafaiev'], S['david smetanine']]\n",
      "3101 nu-3106 Yes [N(150.000000)['150']]\n",
      "3102 nu-3107 January 1 [D(-1,9,12)['september 12']]\n",
      "3103 nu-3108 10 [N(12.000000)['12']]\n",
      "3112 nu-3117 1999 [N(1986.000000)['1986']]\n",
      "3113 nu-3118 Volcán Tajumulco PB [S['volcan san cristobal pb']]\n",
      "3117 nu-3122 The country where Fantastic Fest was located is the USA. [S['usa']]\n",
      "3120 nu-3125 Formula 3 Euro Series [S['formula pilota china']]\n",
      "3122 nu-3127 No data from database [S['erben wennemars']]\n",
      "3125 nu-3130 4 [N(7.000000)['7']]\n",
      "3128 nu-3133 3 [N(5.000000)['5']]\n",
      "3137 nu-3142 Azteca 13 [S['tv 10 chiapas']]\n",
      "3143 nu-3148 1 [N(4.000000)['4']]\n",
      "3147 nu-3152 34 [N(7.000000)['7']]\n",
      "3148 nu-3153 Real Sociedad [S['levante']]\n",
      "3153 nu-3158 Doubledip [S['millie']]\n",
      "3154 nu-3159 0 [N(2.000000)['2']]\n",
      "3155 nu-3160 4 [N(5.000000)['5']]\n",
      "3156 nu-3161 7 [N(6.000000)['6']]\n",
      "3158 nu-3163 Valladolid Promesas [S['elche']]\n",
      "3165 nu-3170 1 song from the album \"Swingin'\" made it to the Billboard Hot 100. [N(2.000000)['2']]\n",
      "3166 nu-3171 1944-1945 [S['1944/45']]\n",
      "3168 nu-3173 52 [S['+ 53.3']]\n",
      "3178 nu-3183 Ernest Henry, Matthew Ryan, Kevin Nichols, Kevin Barry, Murray Rose, Dunc Gray, Ralph Doubell, Lionel Cox, John Devitt, Kevan Gosper, Neil Brooks/Peter Evans/Mark Kerry/Mark Tonelli, Michael Diamond, Peter Antonie/Stephen Hawkins, Duncan Armstrong, Herb Elliott, Andrew Cooper/Nicholas Green/Michael McKay/James Tomkins, John Konrads, Dean Lukin, Russell Mark, Ian O'Brien, Clint Robinson, Robert Windle, John Winter, Todd Woodbridge/Mark Woodforde, David Theile [S['ernest henry'], S['matthew ryan']]\n",
      "3180 nu-3185 RBMK-1000 [S['chernobyl-1']]\n",
      "3182 nu-3187 Der Heidenkönig [S['der friedensengel']]\n",
      "3184 nu-3189 Olympic Games [S['world junior championships']]\n",
      "3185 nu-3190 10 [N(4.000000)['4']]\n",
      "3186 nu-3191 -7 [N(31.000000)['31 minutes']]\n",
      "3190 nu-3195 Menace Of The Mole Men, Diablo [S['diablo']]\n",
      "3192 nu-3197 Chernobyl-2 [S['chernobyl-1']]\n",
      "3196 nu-3201 9 [N(5.000000)['5']]\n",
      "3200 nu-3205 No data from database [S['hotsilog: the asap hotdog compilation']]\n",
      "3202 nu-3207 2 [N(5.000000)['5 years']]\n",
      "3205 nu-3210 Vera Glagoleva, Larisa Verbitskaya, Aleksandr Lykov [S['yelena proklova 49.the tv presenter']]\n",
      "3206 nu-3211 0 [N(1.000000)['1']]\n",
      "3212 nu-3217 * [N(177.000000)['177']]\n",
      "3219 nu-3224 The Wolf 104.1 [S['wnax-fm']]\n",
      "3220 nu-3225 TBA [S['louis walsh']]\n",
      "3221 nu-3226 Partick Thistle [S['clyde']]\n",
      "3222 nu-3227 No [S['yes']]\n",
      "3229 nu-3234 Career* [N(2003.000000)['2003']]\n",
      "3239 nu-3244 21 [N(4.000000)['4']]\n",
      "3245 nu-3250 No data from database [S['air commodore k. m. ahmad']]\n",
      "3246 nu-3251 117 [N(12.000000)['12']]\n",
      "3248 nu-3253 Treece [S['irving']]\n",
      "3251 nu-3256 4 [N(5.000000)['5']]\n",
      "3252 nu-3257 No data from database [S['commonwealth games']]\n",
      "3254 nu-3259 Australia (AUS), Italy (ITA) [S['italy']]\n",
      "3256 nu-3261 24.8% [N(24.800000)['24.8']]\n",
      "3259 nu-3264 No data [N(30.310000)['30.31']]\n",
      "3265 nu-3270 62 [S['above']]\n",
      "3267 nu-3272 3 [N(17.000000)['17']]\n",
      "3270 nu-3275 5 [N(15.000000)['15']]\n",
      "3272 nu-3277 Not provided [S['roman fricke']]\n",
      "3273 nu-3278 Keith Newman [S['gale bennett']]\n",
      "3274 nu-3279 5 [N(3.000000)['3']]\n",
      "3276 nu-3281 29 [N(34.000000)['34']]\n",
      "3277 nu-3282 Spain, Greece [S['spain']]\n",
      "3280 nu-3285 38 [D(1972,11,11)['november 11, 1972']]\n",
      "3285 nu-3290 36 [N(17.000000)['17']]\n",
      "3288 nu-3293 119 episodes [N(119.000000)['119']]\n",
      "3290 nu-3295 60 feet (articulated) [N(60.000000)['60']]\n",
      "3291 nu-3296 below 15 [S['above']]\n",
      "3292 nu-3297 2 [N(3.000000)['3']]\n",
      "3293 nu-3298 5 [N(4.000000)['4']]\n",
      "3295 nu-3300 1 [N(40.000000)['40']]\n",
      "3299 nu-3304 1952\tSky Ship\t3\tRonnie Nash\tPreston M. Burch\tBrookmeade Stable\t1-1/8\t1:50.80\t-\t- [S['sky ship']]\n",
      "3312 nu-3317 15 [N(13.000000)['13']]\n",
      "3313 nu-3318 Quincy Pondexter [S['jon brockman']]\n",
      "3315 nu-3320 Esther Shahamorov, Shaul Ladani [S['yossef romano']]\n",
      "3316 nu-3321 2 [S['more']]\n",
      "3318 nu-3323 1 [N(3.000000)['3']]\n",
      "3320 nu-3325 Real Zaragoza [S['spain']]\n",
      "3323 nu-3328 Maryland 4 [S['albert wynn']]\n",
      "3325 nu-3330 Telugu [S['hindi']]\n",
      "3326 nu-3331 Anastasia Pozdniakova [S['hsu shi-han']]\n",
      "3327 nu-3332 Cairns Saints [S['port douglas crocs']]\n",
      "3329 nu-3334 K-1 500m [S['k-1 500 m']]\n",
      "3330 nu-3335 4 [N(3.000000)['3']]\n",
      "3335 nu-3340 3 [N(227000.000000)['227000']]\n",
      "3337 nu-3342 5 [N(3.000000)['3 weeks']]\n",
      "3338 nu-3343 5.2 [N(5.000000)['5']]\n",
      "3340 nu-3345 1 [N(3.000000)['3']]\n",
      "3345 nu-3350 2002 [N(1996.000000)['1996']]\n",
      "3347 nu-3352 2001 [S['season 3']]\n",
      "3352 nu-3357 Fabril [S['celta']]\n",
      "3354 nu-3359 735i [S['750i-il']]\n",
      "3356 nu-3361 18 [N(15.000000)['15']]\n",
      "3357 nu-3362 less than 15 [S['less']]\n",
      "3359 nu-3364 10 wins and 6 losses [S['10-6']]\n",
      "3365 nu-3370 6 [N(38.000000)['38']]\n",
      "3368 nu-3373 1.2 [N(1200000000.000000)['$1.2 billion']]\n",
      "3371 nu-3376 +1:40.635 [S['39:45.365']]\n",
      "3375 nu-3380 Ronnie O'Sullivan, Brian Morgan, Stephen Hendry [S['tony drago']]\n",
      "3379 nu-3384 12 [N(11.000000)['11']]\n",
      "3382 nu-3387 at Seattle Seahawks [S['chicago bears']]\n",
      "3386 nu-3391 Pan Arab Games, World Junior Championships [S['pan arab games']]\n",
      "3392 nu-3397 1 [N(5.000000)['5']]\n",
      "3393 nu-3398 2009-10 World Cup [D(2009,11,1)['1 november 2009']]\n",
      "3395 nu-3400 Major General Edgar C. Erickson [S['mg jesse mci. carter']]\n",
      "3397 nu-3402 3,345,250 [N(3345248.000000)['3,345,248']]\n",
      "3401 nu-3406 9 [N(4.000000)['4']]\n",
      "3402 nu-3407 October 7 [D(-1,10,13)['october 13']]\n",
      "3404 nu-3409 September 8, 4:10 PM [D(2013,1,1)['january 1, 2013'], S['4:10 pm']]\n",
      "3405 nu-3410 0 [N(2.000000)['2']]\n",
      "3410 nu-3415 RSA [S['chn']]\n",
      "3421 nu-3426 No data from database [N(2009.000000)['2009']]\n",
      "3423 nu-3428 2010-05-16 [N(2010.000000)['2010']]\n",
      "3425 nu-3430 20 [N(21.000000)['21']]\n",
      "3426 nu-3431 Calvin Coolidge [S['lyndon b. johnson']]\n",
      "3432 nu-3437 1, 3 [N(1.000000)['1']]\n",
      "3433 nu-3438 No data from database [S['mrs e.myer'], S['mr p.venter'], S['mr b.melman']]\n",
      "3435 nu-3440 33 years [N(34.000000)['34 years']]\n",
      "3438 nu-3443 6 [N(4.000000)['4']]\n",
      "3439 nu-3444 November 11, 1972 in Jacksonville, AL [N(38.000000)['38']]\n",
      "3445 nu-3450 0 [N(2.000000)['2']]\n",
      "3447 nu-3452 Sarah Burton for Alexander McQueen [S['sarah burton']]\n",
      "3448 nu-3453 No other race leader led more than 3 races besides Antonin Magne. [S['rafaele di paco']]\n",
      "3449 nu-3454 Thaddeus Bell, Gilles Echevin, George McNeill, Karl Heinz Schröder [S['thaddeus bell'], S['klaus jurgen schneider'], S['thane baker'], S['walt butler'], S['karl heinz schroder'], S['gilles echevin'], S['george mcneill']]\n",
      "3451 nu-3456 Welcome to the Club, Train In Vain, Grannies, Guns, Love Mints, Maybe, Baby [S['train in vain'], S['welcome to the club'], S['grannies, guns, love mints'], S['maybe, baby']]\n",
      "3460 nu-3465 Leander [S['ajax']]\n",
      "3461 nu-3466 1 [N(3.000000)['3']]\n",
      "3464 nu-3469 Cameron Stout [S['cameron stout'], S['brian dowling']]\n",
      "3470 nu-3475 2012, 2013, 2014 [N(2012.000000)['2012']]\n",
      "3472 nu-3477 Cook Islands [S['rarotonga, cook islands']]\n",
      "3473 nu-3478 0 [N(13.000000)['13 years']]\n",
      "3475 nu-3480 Hydroxypropyl methyl cellulose (HPMC) [S['hydroxyalkyl']]\n",
      "3481 nu-3486 Ethylene oxide [S['hydroxyalkyl']]\n",
      "3484 nu-3489 10 [N(8.000000)['8']]\n",
      "3485 nu-3490 2 [N(6.000000)['6']]\n",
      "3486 nu-3491 Jozy Altidore [S['bruce murray']]\n",
      "3487 nu-3492 46 [N(23.000000)['23']]\n",
      "3489 nu-3494 3 [N(5.000000)['5']]\n",
      "3499 nu-3504 all of them [S['stanford']]\n",
      "3500 nu-3505 2008 Beijing [N(2008.000000)['2008']]\n",
      "3501 nu-3506 17 [N(19.000000)['19']]\n",
      "3503 nu-3508 0 [N(3.000000)['3']]\n",
      "3505 nu-3510 No data from database [S['el salvador']]\n",
      "3506 nu-3511 Yes [S['datacenter']]\n",
      "3507 nu-3512 0 [N(2.000000)['2']]\n",
      "3508 nu-3513 in commission [S['lord high treasurer']]\n",
      "3511 nu-3516 1 [N(6.000000)['6 years']]\n",
      "3512 nu-3517 0 [N(3.000000)['3']]\n",
      "3515 nu-3520 Bay Area Rosal [S['monterrey flash']]\n",
      "3517 nu-3522 None [S['tiger woods']]\n",
      "3525 nu-3530 France [S['cuba']]\n",
      "3531 nu-3536 9 [N(5.000000)['5']]\n",
      "3532 nu-3537 2 [N(1.000000)['1']]\n",
      "3534 nu-3539 Trey Martinez Fischer, Philip Cortez, Joe Farias, Roland Gutierrez, Ruth McClendon, Joe Straus [S['joe straus']]\n",
      "3536 nu-3541 9 [N(10.000000)['10']]\n",
      "3537 nu-3542 Peter Radford [S['manfred germar']]\n",
      "3541 nu-3546 7 [N(3.000000)['3']]\n",
      "3543 nu-3548 Mr. R. Champion [S['mr issy kramer']]\n",
      "3547 nu-3552 Joel Smith, Venoy Overton, Tim Morris, Justin Dentmon, Matthew Bryan-Amaning, Ryan Appleby, Artem Wallace [S['artem wallace']]\n",
      "3551 nu-3556 Dmitry Pavlovich Tatishchev served the Russian Empire for the most amount of time. [S['dmitry mikhailovich golitsyn']]\n",
      "3552 nu-3557 No data from database [N(124.000000)['124']]\n",
      "3556 nu-3561 Himalayan Elm, Indian Elm [S['tamarind']]\n",
      "3557 nu-3562 I cannot determine the previous manager to George Case from the sub-table. [S['bob lemon']]\n",
      "3558 nu-3563 The region that comes after Zakarpattia is not provided in the sub-table. [S['presov']]\n",
      "3561 nu-3566 Alkupitja [S['cat tigers']]\n",
      "3563 nu-3568 1130 [N(565.000000)['565']]\n",
      "3565 nu-3570 0 [N(2.000000)['2']]\n",
      "3572 nu-3577 Cannot be determined [N(10.000000)['10 years']]\n",
      "3573 nu-3578 35 [N(34.000000)['34']]\n",
      "3576 nu-3581 5 [N(4.000000)['4']]\n",
      "3580 nu-3585 7 [N(6.000000)['6']]\n",
      "3582 nu-3587 2 [N(5.000000)['5']]\n",
      "3585 nu-3590 9 [N(12.000000)['12']]\n",
      "3591 nu-3596 $80/year [S['ixl']]\n",
      "3592 nu-3597 0 [N(8.000000)['8']]\n",
      "3593 nu-3598 Not possible to determine [N(2011.000000)['2011']]\n",
      "3601 nu-3606 October 3, 1981 [N(5.000000)['5 games']]\n",
      "3607 nu-3612 34 [N(4.000000)['4']]\n",
      "3615 nu-3620 7 [N(24.000000)['24']]\n",
      "3618 nu-3623 0 [N(3.000000)['3']]\n",
      "3619 nu-3624 72 [N(76.000000)['76']]\n",
      "3622 nu-3627 Greece [S['italy']]\n",
      "3627 nu-3632 1 [N(4.000000)['4']]\n",
      "3629 nu-3634 Ebbe Skovdahl [S['anders theil']]\n",
      "3632 nu-3637 5 [N(2.000000)['2']]\n",
      "3633 nu-3638 Strasbourg Cathedral [S['chrysler building']]\n",
      "3635 nu-3640 The total number of deaths outside of prisons and camps is not provided in the sub-table. [N(473000.000000)['473,000']]\n",
      "3636 nu-3641 4 [N(6.000000)['6']]\n",
      "3643 nu-3648 Total size (bytes) [S['coefficient size']]\n",
      "3644 nu-3649 8 years and 179 days [N(8.000000)['8 years']]\n",
      "3646 nu-3651 Nikkan Sports Grand Prix (Fall), 3rd TAMA Film Award, 35th Fumiko Yamaji Award Film Awards, 26th Nikkan Sport Film Awards, TV Navi, 70th The Television Drama Academy Awards, 35th Japan Academy Awards, Japan Film Festival Theater Staff, 16th Nikkan Sport Grand Prix [S['nikkan sports grand prix']]\n",
      "3648 nu-3653 2 [N(9.000000)['9']]\n",
      "3655 nu-3660 lower case letters [S['capital']]\n",
      "3658 nu-3663 Rebecca Shiner [S['anna nolan']]\n",
      "3664 nu-3669 3 [N(2.000000)['2']]\n",
      "3674 nu-3679 No data from database [S['diamond sculls']]\n",
      "3675 nu-3680 93 [N(3.000000)['3']]\n",
      "3681 nu-3686 Mr B. Owen-Jones [S['mr b. owen- jones']]\n",
      "3682 nu-3687 9 [N(10.000000)['10']]\n",
      "3684 nu-3689 René Heitmann [S[\"john 'tune' kristiansen\"]]\n",
      "3685 nu-3690 1 [N(2.000000)['2']]\n",
      "3687 nu-3692 1999, 2001, 2002, 2003, 2004, 2006, 2007, 2008, 2012 [N(1999.000000)['1999']]\n",
      "3689 nu-3694 Steve Schall [S['calvin roberts']]\n",
      "3697 nu-3702 11 [N(10.000000)['10']]\n",
      "3699 nu-3704 more than 8 [S['more']]\n",
      "3701 nu-3706 Solano - 3 (with Cebolla,Cuchillo [S['solano - 3']]\n",
      "3704 nu-3709 Shrink [S['doubledip']]\n",
      "3705 nu-3710 Farmer Picks a Wife [N(1.000000)['1']]\n",
      "3706 nu-3711 1922-2005 [N(83.000000)['83 years']]\n",
      "3707 nu-3712 Totaal [S['france']]\n",
      "3708 nu-3713 0 [N(2.000000)['2']]\n",
      "3712 nu-3717 8 [N(4.000000)['4']]\n",
      "3716 nu-3721 2004, 2005, 2006, 2008, 2010, 2011 [N(2011.000000)['2011']]\n",
      "3725 nu-3730 5 [N(7.000000)['7']]\n",
      "3726 nu-3731 14 [N(6.000000)['6']]\n",
      "3727 nu-3732 0 [N(1.000000)['1']]\n",
      "3732 nu-3737 30 [N(0.000000)['0']]\n",
      "3734 nu-3739 NASCAR Countdown in 2008 [N(2008.000000)['2008']]\n",
      "3736 nu-3741 12 [N(7.000000)['7']]\n",
      "3737 nu-3742 Liberto López de la Franca, Dionisio Rodríguez, \"Dioni\", Antonio David Flores [S['antonio david flores'], S['liberto lopez de la franca']]\n",
      "3742 nu-3747 USA [S['united states']]\n",
      "3744 nu-3749 Kevin Martin has more high rebounds. [S['brad miller']]\n",
      "3745 nu-3750 13 [N(14.000000)['14']]\n",
      "3750 nu-3755 9 [N(1.000000)['1']]\n",
      "3753 nu-3758 Michael Klim [S['michael phelps']]\n",
      "3754 nu-3759 Ether [N(2003.000000)['2003']]\n",
      "3759 nu-3764 Total number of pasurams [S['thiruvay mozhi']]\n",
      "3762 nu-3767 No specific information provided. [N(0.000000)['0']]\n",
      "3765 nu-3770 It is not possible to determine if George E. Leach or Kenneth F. Cramer was the chief. [S['mg george e. leach']]\n",
      "3769 nu-3774 Provident Stadium, The Wish Communications Stadium, Stade Gilbert Brutus, John Smith's Stadium, Kingston Communications Stadium, MS3 Craven Park, Headingley Carnegie Stadium, Twickenham Stoop, Salford City Stadium [S['salford city stadium']]\n",
      "3770 nu-3775 Episode 3 [N(3.000000)['3']]\n",
      "3772 nu-3777 Grand Trunk (GT) Express [S['grand trunk(gt) exp']]\n",
      "3775 nu-3780 South Cairns Cutters [S['port douglas crocs']]\n",
      "3779 nu-3784 John Lenthall [S['henry j. kaiser']]\n",
      "3781 nu-3786 9 [S['18-12']]\n",
      "3782 nu-3787 Sweden (SWE) [S['cyril mackworth-praed']]\n",
      "3785 nu-3790 6 [N(7.000000)['7']]\n",
      "3787 nu-3792 Nikolay Davydenko [S['argentina']]\n",
      "3791 nu-3796 5 [N(4.000000)['4']]\n",
      "3799 nu-3804 1 [N(2.000000)['2']]\n",
      "3800 nu-3805 Never 2 Much of U, Romeo, Gentle, Ooh Child, Endlessly [S['never 2 much of u']]\n",
      "3801 nu-3806 No data from database [S['grant hackett']]\n",
      "3803 nu-3808 0 [N(3.000000)['3']]\n",
      "3805 nu-3810 1961–1974 [N(1961.000000)['1961']]\n",
      "3807 nu-3812 8 [N(9.000000)['9']]\n",
      "3810 nu-3815 I cannot determine the player picked after Rich Yonakor from the sub-table. [S['calvin roberts']]\n",
      "3811 nu-3816 3 [N(4.500000)['4.5']]\n",
      "3812 nu-3817 20 [N(21.000000)['21']]\n",
      "3813 nu-3818 Denny Hulme [S['jack brabham']]\n",
      "3814 nu-3819 6 [N(5.000000)['5']]\n",
      "3817 nu-3822 Me-109 [S['me-110']]\n",
      "3818 nu-3823 1985 [S[\"it's raining men\"]]\n",
      "3820 nu-3825 11.63 [N(11630000.000000)['11.63 million']]\n",
      "3822 nu-3827 0 [N(3.000000)['3']]\n",
      "3824 nu-3829 Sean Morley [S['pulgarcito']]\n",
      "3827 nu-3832 Science, Social studies, English, Maths, Art & Music, Health, Technology [S['math']]\n",
      "3829 nu-3834 3 [N(9.000000)['9']]\n",
      "3835 nu-3840 March 22–25, 2012 [S['march 26-29, 2009']]\n",
      "3839 nu-3844 Francisco Bravo Medical Magnet High School in 2007 [S['francisco bravo medical magnet high school'], N(2007.000000)['2007']]\n",
      "3841 nu-3846 Scott Dixon [S['ryan hunter-reay']]\n",
      "3842 nu-3847 7LA [S['7exx']]\n",
      "3844 nu-3849 17 [N(1.000000)['1']]\n",
      "3851 nu-3856 National Society of Film Critics, 1972 [S['national society of film critics, best actor']]\n",
      "3852 nu-3857 Ivan Zourine [S['bruno brazil']]\n",
      "3854 nu-3859 10 [N(2.000000)['2']]\n",
      "3856 nu-3861 2 [N(1.000000)['1']]\n",
      "3860 nu-3865 Paul Christy [S['randy savage']]\n",
      "3861 nu-3866 Southend United [S['northampton town']]\n",
      "3868 nu-3873 £5.00 [S['class 4']]\n",
      "3870 nu-3875 Holy Roman Empire, Holy Roman Empire/Austrian Empire [S['russian empire']]\n",
      "3871 nu-3876 15 [N(4.000000)['4']]\n",
      "3872 nu-3877 6 [N(7.000000)['7']]\n",
      "3874 nu-3879 Career* [N(2003.000000)['2003']]\n",
      "3877 nu-3882 Bob Lemon [S['wayne terwilliger']]\n",
      "3878 nu-3883 16 [S['bay area rosal']]\n",
      "3882 nu-3887 -76 [N(76.000000)['76']]\n",
      "3884 nu-3889 7 [N(4.000000)['4']]\n",
      "3887 nu-3892 lost [S['lose']]\n",
      "3890 nu-3895 3 [N(6.000000)['6']]\n",
      "3893 nu-3898 Amherstview\\nCataraqui Town Centre [S['cataraqui town centre']]\n",
      "3894 nu-3899  [S['attorney general of new mexico']]\n",
      "3900 nu-3905 Ludwig Wolf from Germany (GER) [S['ludwig wolf']]\n",
      "3901 nu-3906 2 [N(10.000000)['10']]\n",
      "3905 nu-3910 8 [N(7.000000)['7']]\n",
      "3908 nu-3913 Survey USA [D(2007,12,17)['dec. 17, 2007']]\n",
      "3922 nu-3927 L 31-17 [S['l 29-21']]\n",
      "3924 nu-3929 Amphion, Apollo, Sydney (ex-Phaeton) [S['achilles']]\n",
      "3925 nu-3930 Die heilige Linde [S['walamund']]\n",
      "3926 nu-3931 No data from database [S['mr brough scott'], S['pat taaffe'], S['beltran osorio'], S['tommy carberry'], S['stan mellor']]\n",
      "3930 nu-3935 No data from database [S['preschool - 8th grade']]\n",
      "3931 nu-3936 0 [N(14.000000)['14 years']]\n",
      "3934 nu-3939 Total number of pasurams [S['thiruvay mozhi']]\n",
      "3936 nu-3941 11 [N(16.000000)['16']]\n",
      "3939 nu-3944 No data available [S['16:14.1']]\n",
      "3940 nu-3945 Cincinnati, Hamilton [S['cincinnati']]\n",
      "3942 nu-3947 Belarus [S['hungary']]\n",
      "3944 nu-3949 No data from database [S['ulverstone']]\n",
      "3945 nu-3950 1939 [N(1864.000000)['1864']]\n",
      "3946 nu-3951 September 29th at #20 Nebraska [D(-1,9,29)['september 29']]\n",
      "3948 nu-3953 Giuseppe Aquaro [S['rumen trifonov']]\n",
      "3950 nu-3955 Goodbye City...Hello Country [N(1.000000)['1']]\n",
      "3954 nu-3959 3 [N(5.000000)['5']]\n",
      "3956 nu-3961 6 [N(11.000000)['11']]\n",
      "3958 nu-3963 below 20 [S['below']]\n",
      "3964 nu-3969 128 [S['decimal128']]\n",
      "3970 nu-3975 8 [N(5.000000)['5']]\n",
      "3972 nu-3977 -18 [N(18.000000)['18']]\n",
      "3974 nu-3979 3 [N(4.000000)['4']]\n",
      "3979 nu-3984 38 [N(17.000000)['17']]\n",
      "3980 nu-3985 Bob Anderson, Chris Amon [S['dan gurney']]\n",
      "3984 nu-3989 File Services limits [S['essentials']]\n",
      "3986 nu-3991 6 [N(5.000000)['5']]\n",
      "3987 nu-3992 John Lenthall [S['laramie']]\n",
      "3996 nu-4001 Camelopardalis B [S['ugca 105']]\n",
      "3997 nu-4002 1 [N(2.000000)['2']]\n",
      "3998 nu-4003 0 [N(14.000000)['14']]\n",
      "3999 nu-4004 Devil Is A Lie [S['i know f rich homie quan']]\n",
      "4000 nu-4005 4 [N(3.000000)['3']]\n",
      "4002 nu-4007 Ayumi Hamasaki - Like a doll [S['ayumi hamasaki'], S['like a doll']]\n",
      "4005 nu-4010 31 Republicans and 23 Democrats [N(8.000000)['8']]\n",
      "4008 nu-4013 The differences between Justin Holiday and Darnell Gant are:\n",
      "1. Justin Holiday is 6'6\" tall and weighs 170 lbs, while Darnell Gant is 6'8\" tall and weighs 215 lbs.\n",
      "2. Justin Holiday is from Chatsworth, CA, U.S. and attended Campbell Hall School, while Darnell Gant is from Los Angeles, CA, U.S. and attended Crenshaw HS. [N(2.000000)['2 inches']]\n",
      "4012 nu-4017 Byalko [S['aleksandr byalko 50.the physicist']]\n",
      "4013 nu-4018 2 [N(9.000000)['9']]\n",
      "4015 nu-4020 MLW [S['alco']]\n",
      "4022 nu-4027 Zakirjan Asam [S['ravil mingazov']]\n",
      "4023 nu-4028 3 [N(2.000000)['2']]\n",
      "4024 nu-4029 Bob Jolly [S['john briggs']]\n",
      "4026 nu-4031 9 [N(13.000000)['13']]\n",
      "4027 nu-4032 No data available [N(6.000000)['6']]\n",
      "4037 nu-4042 0 [N(7.000000)['7']]\n",
      "4038 nu-4043 Piper PA-31 Navajo [S['partenvia p.68 observer']]\n",
      "4046 nu-4051 Iran [S['japan']]\n",
      "4049 nu-4054 0 [N(12.000000)['12']]\n",
      "4051 nu-4056 USS Wasp [S['benjamin isherwood']]\n",
      "4053 nu-4058 1 [N(64.000000)['64']]\n",
      "4055 nu-4060 Boston [S['grantham']]\n",
      "4057 nu-4062 18.9375 [N(18.000000)['18']]\n",
      "4061 nu-4066 5 [N(6.000000)['6']]\n",
      "4065 nu-4070 2004, 2005, 2006, 2007, 2012 [N(2006.000000)['2006']]\n",
      "4073 nu-4078 16 [N(15.000000)['15']]\n",
      "4078 nu-4083 Ligier JS2/Maserati 3.0L V6: 3 cars, McLaren F1 GTR/BMW S70 6.1L V12: 1 car, Mirage M9/Renault 2.0L Turbo V6: 1 car, Porsche 911 Carrera RSR/Porsche 3.8 L Flat-6: 1 car, Porsche 962C/Porsche Type-935 3.0L Turbo Flat-6: 1 car, Renault Alpine A442/Renault 2.0L Turbo V6: 1 car, Venturi 500LM/Renault PRV 3.0 L Turbo V6: 1 car. [N(13.000000)['13']]\n",
      "4080 nu-4085 Ray Shah [S['brian dowling']]\n",
      "4085 nu-4090  [S['elliot forbes-robinson']]\n",
      "4086 nu-4091 Queensbury Mill [S['back river farm']]\n",
      "4095 nu-4100  [N(1957.000000)['1957']]\n",
      "4096 nu-4101 Superboy [S['earth-man']]\n",
      "4097 nu-4102 No data from database [D(2011,2,13)['13 february 2011']]\n",
      "4106 nu-4111 John Briggs [S['kerry baily']]\n",
      "4108 nu-4113 3 [N(2.000000)['2']]\n",
      "4109 nu-4114 0 [N(2.000000)['2']]\n",
      "4114 nu-4119 7 [N(3.000000)['3']]\n",
      "4115 nu-4120 All-Africa Games, IAAF Grand Prix Final, IAAF Grand Prix Final, World Athletics Final, World Athletics Final [S['all-africa games']]\n",
      "4117 nu-4122 -3.6 [N(8.450000)['8.45']]\n",
      "4118 nu-4123 Kenneth \"Kenny\" Yates [S['caroline botelho']]\n",
      "4123 nu-4128 1 [N(2.000000)['2']]\n",
      "4126 nu-4131 14 [N(13.000000)['13']]\n",
      "4132 nu-4137 TBA [S['louis walsh']]\n",
      "4133 nu-4138 I cannot determine the names of the festivals that had at least 2 dates from the sub-table. [S['indonesia fantastic film festival'], S['fantasia festival'], S['icon tlv'], S['aff'], S['sitges film festival'], S['santa barbara international film festival'], S['seattle international film festival'], S['gwacheon international sf festival']]\n",
      "4135 nu-4140 38 [N(3.000000)['3']]\n",
      "4137 nu-4142 1 [N(7.000000)['7']]\n",
      "4138 nu-4143 1 [S['earl marshal']]\n",
      "4139 nu-4145 Totaal [S['tunisia']]\n",
      "4142 nu-4148 2 [N(1.000000)['1']]\n",
      "4145 nu-4151 I cannot determine the number of tablets in Genesis from the sub-table. [N(11.000000)['11']]\n",
      "4148 nu-4154 1 [N(6.000000)['6']]\n",
      "4151 nu-4157 0 [N(8.000000)['8']]\n",
      "4153 nu-4159 1.43178e+07 [N(12822406.000000)['12822406']]\n",
      "4156 nu-4162 No data from database [S['1986-87']]\n",
      "4157 nu-4163 Wang Han [S['han']]\n",
      "4159 nu-4165 smaller [S['larger']]\n",
      "4160 nu-4166 Pierluigi Martini and Maurício Gugelmin [S['pierluigi martini']]\n",
      "4161 nu-4167 Mauro Biello [S['canada']]\n",
      "4163 nu-4169 11 [N(10.000000)['10']]\n",
      "4168 nu-4174 46 minutes and 9.623 seconds [S['+1:01.4']]\n",
      "4169 nu-4175 13 [S['super series finals']]\n",
      "4173 nu-4179 300000 [S['korea open super series']]\n",
      "4174 nu-4180 1910-05-16 [N(1910.000000)['1910']]\n",
      "4177 nu-4183 2031 [N(2016.000000)['2016']]\n",
      "4181 nu-4187 Joe Clark and Peter MacKay [S['joe clark peter mackay']]\n",
      "4184 nu-4190 Unlimited [N(2.000000)['2']]\n",
      "4185 nu-4191 10 [N(20.000000)['20']]\n",
      "4194 nu-4200 1 [N(0.000000)['0']]\n",
      "4200 nu-4206 37 [N(13.000000)['13']]\n",
      "4202 nu-4208 No data from database [N(2007.000000)['2007']]\n",
      "4205 nu-4211 They lost [S['l 23-3']]\n",
      "4206 nu-4213 9th [N(4.000000)['4th']]\n",
      "4207 nu-4214 0 [N(12.000000)['12 days']]\n",
      "4211 nu-4218 No [S['yes']]\n",
      "4212 nu-4219 10 [N(6.000000)['6']]\n",
      "4214 nu-4221 0 [N(7.000000)['7']]\n",
      "4215 nu-4222 Yellowstone National Park [S['yellowstone']]\n",
      "4219 nu-4226 prologue and 3 acts [S['sternengebot'], S['der heidenkonig']]\n",
      "4226 nu-4233 0 [N(9.000000)['9']]\n",
      "4228 nu-4235 14 [N(13.000000)['13']]\n",
      "4229 nu-4236 1 [N(8.000000)['8']]\n",
      "4236 nu-4243 Sydney (ex-Phaeton) [S['orion']]\n",
      "4237 nu-4244 1919-07-22 [D(1918,7,11)['11 july 1918']]\n",
      "4242 nu-4249 12 [N(8.000000)['8']]\n",
      "4249 nu-4256 -4 [N(4.000000)['4 years']]\n",
      "4255 nu-4262 2006, 2005 [S['alice springs']]\n",
      "4257 nu-4264 The Little Mermaid [S['enchanted'], S['the little mermaid']]\n",
      "4265 nu-4272 Democratic Party, District 118 [S['d'], N(118.000000)['118']]\n",
      "4266 nu-4273 1998-02-22 [S['february 22, 1998']]\n",
      "4267 nu-4274 0 [N(0.320000)['.32']]\n",
      "4270 nu-4277 No data from database [S['eskender mustafaiev']]\n",
      "4271 nu-4278 5 [N(6.000000)['6']]\n",
      "4274 nu-4281 £6.20 [N(6.200000)['6.2']]\n",
      "4281 nu-4288 Community Baptist Christian School [S['nouvel catholic central high school']]\n",
      "4285 nu-4292 239 [N(138.200000)['138.2']]\n",
      "4288 nu-4295 Alex Song [S['neymar']]\n",
      "4289 nu-4296 2001-05-16 [N(2001.000000)['2001']]\n",
      "4293 nu-4300 7 [N(17.000000)['17']]\n",
      "4294 nu-4301 3 [N(2.000000)['2 games']]\n",
      "4295 nu-4302 Hanrapetakan Stadium, Yerevan, Armenia [S['tsirion stadium']]\n",
      "4297 nu-4304 more grades [S['less']]\n",
      "4300 nu-4307 DaMarcus Beasley has more caps than Eric Wynalda. [S['less']]\n",
      "4301 nu-4308 RBMK-1000 [S['chernobyl-4']]\n",
      "4304 nu-4311 26 [N(16.000000)['16']]\n",
      "4306 nu-4313 Cannot be determined [S['graham rahal']]\n",
      "4308 nu-4315 16 [N(24.000000)['24']]\n",
      "4316 nu-4323 9 [N(10.000000)['10']]\n",
      "4317 nu-4324 128-05-16 [D(2016,3,9)['march 9, 2016']]\n",
      "4324 nu-4331 0 [N(1.000000)['1']]\n",
      "4325 nu-4332 6 [N(5.000000)['5']]\n",
      "4330 nu-4337 Los Angeles [S['plumas']]\n",
      "4331 nu-4338 Cannot be determined [S['no']]\n",
      "0.6662812210915818\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for index, row in data3.iterrows():\n",
    "    id = row['ids']\n",
    "    target = target_values_map[id]\n",
    "    \n",
    "    preds = [row['final_answer']]\n",
    "    if len(target) > 1:\n",
    "        pred_answer = to_value_list(row['final_answer'].split(','))\n",
    "    else:\n",
    "        pred_answer = to_value_list(preds)\n",
    "    \n",
    "    if check_denotation(pred_answer, target):\n",
    "        acc += 1\n",
    "    else:\n",
    "        print(index,row['ids'], row['final_answer'], target)\n",
    "        pass\n",
    "print(acc / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5417371e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1974"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a7d5ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 nu-1001 4, 5, 5 [N(12.000000)['12']]\n",
      "5 nu-1005 -82 [N(1514069.000000)['1,514,069']]\n",
      "6 nu-1006 less than 6 goals [S['less']]\n",
      "8 nu-1008 The Bulldogs performed better in the 1906 season than the 1905 season. [S['worse']]\n",
      "10 nu-1010 1992-08-15 [D(1992,8,29)['29 august 1992']]\n",
      "14 nu-1014 111 [N(110.000000)['110']]\n",
      "24 nu-1024 16 [N(13.000000)['13 weeks']]\n",
      "31 nu-1031 2.875 [N(2.500000)['2.5']]\n",
      "32 nu-1032 Jan Bos [S['yevgeny lalenkov']]\n",
      "35 nu-1035 16 [N(17.000000)['17']]\n",
      "36 nu-1036 Yelena Kondulaynen [S['yelena kondulaynen 44.the actress']]\n",
      "37 nu-1037 0 [N(2.000000)['2']]\n",
      "41 nu-1041 Sidney Smith, Ralph Foster, Sam Costen, L. S. LeTellier, George C. Rogers, or Harvey O'Brien. [S['sidney smith']]\n",
      "43 nu-1043 Jack Brabham, Mike Parkes, Denny Hulme, Jochen Rindt, Dan Gurney [S['dan gurney'], S['denny hulme'], S['jochen rindt'], S['mike parkes'], S['jack brabham']]\n",
      "47 nu-1047 Who Do You Think You Are [S[\"everything you've done wrong\"]]\n",
      "49 nu-1049 Matthew Nowicki [S['charles eames']]\n",
      "52 nu-1052 27.88 miles [N(27.880000)['27.88']]\n",
      "55 nu-1055 Constitution, Orb, Take Charge Indy, Dialed In, Ice Box, Quality Road, Big Brown, Scat Daddy, Barbaro, High Fly, Friends Lake, Empire Maker, Harlan's Holiday, Monarchos, Hal's Hope, Vicar, Cape Town †, Captain Bodgit, Unbridled's Song, Thunder Gulch, Holy Bull, Bull In the Heather, Technology, Fly So Free, Unbridled, Mercedes Won, Brian's Time, Cryptoclearance, Snow Chief, Proud Truth, Swale, Croeso, Timely Writer, Lord Avie, Plugged Nickle, Spectacular Bid, Alydar, Ruthie's Native, Coined Silver, Honest Pleasure, Prince Thou Art, Judger, Royal and Regal, Upper Case, Eastern Fleet, My Dad George, Top Knight, Forward Pass, In Reality, Williamston Kid †, Native Charger, Northern Dancer, Candy Spots, Ridan, Carry Back, Bally Ache. [S['bally ache']]\n",
      "56 nu-1056 NOT AWARDED [S['morgan freeman']]\n",
      "57 nu-1057 2 [N(1.000000)['1']]\n",
      "59 nu-1059 54.49 [N(24.720000)['24.72']]\n",
      "63 nu-1063 12 [N(3.000000)['3']]\n",
      "66 nu-1066 1905-06 [S['1910-11']]\n",
      "68 nu-1068 Vira-Lata [S['voce decide']]\n",
      "69 nu-1069 −10\\n(14) and −8\\n(18) [D(-1,12,-1)['december']]\n",
      "74 nu-1074 1 [N(12.000000)['12']]\n",
      "75 nu-1075 The closest second to Alex Song in terms of transfer fee in the year 2012 cannot be determined from the sub-table. [S['jordi alba']]\n",
      "82 nu-1082 2 [N(1.000000)['1']]\n",
      "83 nu-1083 Hobart [S['ulverstone']]\n",
      "86 nu-1086 8, 9 [N(17.000000)['17']]\n",
      "88 nu-1088 Polly Umrigar [S['umrigar']]\n",
      "90 nu-1090 None [S['milos raonic']]\n",
      "92 nu-1092 Jack Brabham and Mike Parkes [S['mike parkes'], S['jack brabham']]\n",
      "96 nu-1096 March 20–23, 2014 [N(1188.000000)['1188']]\n",
      "99 nu-1099 40.3% [N(89.170000)['89.17']]\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for index, row in data3[:100].iterrows():\n",
    "    id = row['ids']\n",
    "    target = target_values_map[id]\n",
    "    \n",
    "    preds = [row['final_answer']]\n",
    "    pred_answer = to_value_list(preds)\n",
    "    if check_denotation(pred_answer, target):\n",
    "        acc += 1\n",
    "    else:\n",
    "        print(index,row['ids'], row['final_answer'], target)\n",
    "        pass\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "32f92385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc / 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dcc1fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "culture = Culture.English\n",
    "Recognizers.recognize_number('The total number of competitions is 20.', culture)[0].resolution['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about different games played by a football team. It includes details like the week number, date of the game, opponent team, game result, game site, NFL recap, and the attendance for each game.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f877301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The total number of competitions is 20.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize('The total number of competitions is 20.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d5083",
   "metadata": {},
   "source": [
    "### Experiement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c06a5",
   "metadata": {},
   "source": [
    "#### Large table analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2274d567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1609, 5963, 374, 2294, 758]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f4521f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e62e1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "small_tables  = []\n",
    "middle_tables  = []\n",
    "large_tables  = []\n",
    "for i in range(len(table_loader.dataset)):\n",
    "    sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "    sample_data = formatter.get_sample_data(sample_type='all')\n",
    "    table_length = len(encoding.encode(TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption'])))\n",
    "    if table_length < 2000:\n",
    "        small_tables.append(sample['id'])\n",
    "    elif table_length < 4000:\n",
    "        middle_tables.append(sample['id'])\n",
    "    else:\n",
    "        large_tables.append(sample['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "92bf11aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3466"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b76ec547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "acc_small = 0\n",
    "count  = 0\n",
    "for index, row in data3.iterrows():\n",
    "    id = row['ids']\n",
    "    if id not in large_tables:\n",
    "        continue\n",
    "    count += 1\n",
    "    target = target_values_map[id]\n",
    "    \n",
    "    if len(target) > 1:\n",
    "        pred_answer = to_value_list(row['final_answer'].split(','))\n",
    "    else:\n",
    "        pred_answer = to_value_list([row['final_answer']])\n",
    "    \n",
    "    if check_denotation(pred_answer, target):\n",
    "        acc_small += 1\n",
    "    else:\n",
    "        # print(index,row['ids'], row['final_answer'], target)\n",
    "        pass\n",
    "print(acc_small / count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
