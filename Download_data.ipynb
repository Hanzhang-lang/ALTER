{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b05908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "aug_information = pd.read_csv(f\"result/aug/wikitable_test_summary.csv\", index_col='table_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0081be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>column_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>csv/203-csv/840.tsv</th>\n",
       "      <td>List of Ambassadors of Russia to Austria</td>\n",
       "      <td>Name&lt;The name of the ambassador&gt;\\nTitle&lt;The ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv/204-csv/65.tsv</th>\n",
       "      <td>This table shows the results of the Men's 50 m...</td>\n",
       "      <td>Rank&lt;The ranking of the swimmer in the event&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv/203-csv/275.tsv</th>\n",
       "      <td>This table shows the results of the 1986 Austr...</td>\n",
       "      <td>Pos&lt;Position of the driver in the race&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv/204-csv/272.tsv</th>\n",
       "      <td>The table shows the results of Sky Track Cycli...</td>\n",
       "      <td>Date&lt;The date of the competition&gt;\\nCompetition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv/203-csv/328.tsv</th>\n",
       "      <td>This table provides information about episodes...</td>\n",
       "      <td>num&lt;The episode number&gt;\\nEpisode&lt;The title of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               summary  \\\n",
       "table_id                                                                 \n",
       "csv/203-csv/840.tsv           List of Ambassadors of Russia to Austria   \n",
       "csv/204-csv/65.tsv   This table shows the results of the Men's 50 m...   \n",
       "csv/203-csv/275.tsv  This table shows the results of the 1986 Austr...   \n",
       "csv/204-csv/272.tsv  The table shows the results of Sky Track Cycli...   \n",
       "csv/203-csv/328.tsv  This table provides information about episodes...   \n",
       "\n",
       "                                                    column_description  \n",
       "table_id                                                                \n",
       "csv/203-csv/840.tsv  Name<The name of the ambassador>\\nTitle<The ti...  \n",
       "csv/204-csv/65.tsv   Rank<The ranking of the swimmer in the event> ...  \n",
       "csv/203-csv/275.tsv            Pos<Position of the driver in the race>  \n",
       "csv/204-csv/272.tsv  Date<The date of the competition>\\nCompetition...  \n",
       "csv/203-csv/328.tsv  num<The episode number>\\nEpisode<The title of ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_information[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679c1edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1931, 4, 29, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "parser.parse('1931')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1c1feb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "composition_information = pd.read_csv(f\"result/aug/sqa_test_summary_alone.csv\", index_col='table_id')\n",
    "len(composition_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ccf00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year<The year the coin was released>', 'theme<The theme of the coin>', 'artist<The artist responsible for the design of the coin>', 'mintage<The number of coins minted>', 'issue_price<The price at which the coin was issued>']\n",
      "The year the coin was released\n",
      "The theme of the coin\n",
      "The artist responsible for the design of the coin\n",
      "The number of coins minted\n",
      "The price at which the coin was issued\n"
     ]
    }
   ],
   "source": [
    "test_string = 'year<The year the coin was released>\\ntheme<The theme of the coin>\\nartist<The artist responsible for the design of the coin>\\nmintage<The number of coins minted>\\nissue_price<The price at which the coin was issued>'\n",
    "import re \n",
    "test = test_string.split('\\n')\n",
    "print(test)\n",
    "pattern=r'([^<]*)<([^>]*)>'\n",
    "matches = re.finditer(pattern, test_string)\n",
    "for match in matches:\n",
    "   print(match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa6018",
   "metadata": {},
   "source": [
    "## Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1aebf6d-8a64-433c-84a0-d38e50c6f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into sqlite database\n",
    "from data_loader import TableLoader\n",
    "\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=True, small_test=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511cb4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465bf4dc-f2af-4456-b693-961ed623fc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31be66e69932488eb5608102ab74d390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6773b8eac4e94f1389d47511f6bf40d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649876b199ed47cea8cca330aaa54a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304a3b94808442428690fced3fa574af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "totto = load_dataset('./data_loader/totto_zh.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")\n",
    "tabfact = load_dataset('./data_loader/tabfact.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")\n",
    "sqa = load_dataset('./data_loader/sqa.py', verification_mode=\"no_checks\", cache_dir=\"/media/disk2/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db1b61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1000/1000 [00:00<00:00, 4669.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset = table_loader.dataset.filter(lambda example: example['small_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a91cae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'table', 'statement', 'label', 'hardness', 'small_test'],\n",
       "    num_rows: 147\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d9351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99838a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 996,\n",
       " 'table': {'id': '2-16369528-1.html.csv',\n",
       "  'header': ['year',\n",
       "   'best teenage / young adult',\n",
       "   \"reader 's vote\",\n",
       "   'best non - fiction',\n",
       "   'lifetime achievement'],\n",
       "  'rows': [['1996', 'na', 'na', 'na', 'jon cleary'],\n",
       "   ['1997',\n",
       "    'na',\n",
       "    'na',\n",
       "    'how to write crime edited by marele day',\n",
       "    'alan yates (aka carter brown )'],\n",
       "   ['1998', 'na', 'na', 'na', 'na'],\n",
       "   ['1999', 'na', 'na', 'na', 'peter corris'],\n",
       "   ['2000', 'na', 'na', 'na', 'na'],\n",
       "   ['2001',\n",
       "    'na',\n",
       "    'bleeding hearts by lindy cameron',\n",
       "    'na',\n",
       "    'professor stephen knight'],\n",
       "   ['2002',\n",
       "    'blue murder by ken catran',\n",
       "    'apartment 255 by bunty avieson',\n",
       "    'na',\n",
       "    'patrick gallagher'],\n",
       "   ['2003', 'na', 'na', 'na', 'kerry greenwood'],\n",
       "   ['2004', 'na', 'na', 'na', 'bob bottom'],\n",
       "   ['2005', 'na', 'na', 'na', 'stuart coupe'],\n",
       "   ['2006', 'na', 'na', 'na', 'andrew rule and john silvester'],\n",
       "   ['2007', 'na', 'na', 'na', 'sandra harvey and lindsay simpson'],\n",
       "   ['2008', 'na', 'na', 'na', 'marele day'],\n",
       "   ['2009', 'na', 'na', 'na', 'shane maloney'],\n",
       "   ['2010', 'na', 'na', 'na', 'peter doyle'],\n",
       "   ['2011', 'na', 'na', 'na', 'na']],\n",
       "  'caption': 'ned kelly awards'},\n",
       " 'statement': 'after 2005 , the winner of the lifetime achievement award be andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle',\n",
       " 'label': 1,\n",
       " 'hardness': 'simple',\n",
       " 'small_test': True}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = table_loader.dataset[2]\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188aeba",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入 schema(table measurement) statistical(numerical) enum string(char) date\n",
    "#引入 term explanation（table comment(RAG)）\n",
    "#引入 column summarization\n",
    "#是否需要search engine\n",
    "#table size, statistical features, header hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab5734d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema \n",
    "from data_loader import TableFormat\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.tech/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "# formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\"], template=\n",
    "\"\"\"\n",
    "Instruction: Given the following table, you will add Metadata about the columns in the table.\n",
    "Metadata includes:\n",
    "- Numerical: whether the column content is numeric type like int or float.\n",
    "- Char: whether the column content is a text or description.\n",
    "- Date: whether the column content is datetime.\n",
    "\n",
    "You need to output all the column names with metadata in angle brackets.\n",
    "Example: name<Char>, launched<Date>, count<Numerical>\n",
    "\n",
    "Table: {table}\n",
    "Output:\n",
    "\"\"\")\n",
    "# \n",
    "# output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "457207ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 1, 'prompt_tokens': 269, 'total_tokens': 270}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.response_metadata['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24ed8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarization\n",
    "pre_instruction_summary = PromptTemplate(input_variables=['table'], template=\n",
    "\"\"\"\n",
    "Instruction: Given the following table, you need to first summarize the contents of the table, then based on the summay, give a concluded description to each of the column.\n",
    "Table: {table}\n",
    "\n",
    "The output should use the following format: \n",
    "table summary: #summary for table contents\n",
    "column description: You need to output all the column names with description in angle brackets\n",
    "example: launched<The launched date for the competition> date<The date of the match>\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction_summary.format(table=formatter.format_html()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c92ad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table summary: The table shows the performance of a player in different tennis tournaments from 1986 to 1999.\n",
      "\n",
      "column description: \n",
      "tournament<The name of the tennis tournament>\n",
      "1986<The player's performance in the tournament in 1986>\n",
      "1988<The player's performance in the tournament in 1988>\n",
      "1989<The player's performance in the tournament in 1989>\n",
      "1990<The player's performance in the tournament in 1990>\n",
      "1991<The player's performance in the tournament in 1991>\n",
      "1992<The player's performance in the tournament in 1992>\n",
      "1993<The player's performance in the tournament in 1993>\n",
      "1994<The player's performance in the tournament in 1994>\n",
      "1995<The player's performance in the tournament in 1995>\n",
      "1996<The player's performance in the tournament in 1996>\n",
      "1997<The player's performance in the tournament in 1997>\n",
      "1998<The player's performance in the tournament in 1998>\n",
      "1999<The player's performance in the tournament in 1999>\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a1a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799366bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m table_loader\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m formatter \u001b[38;5;241m=\u001b[39m TableFormat(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43maug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_summary_aug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# batch_data = table_loader.dataset[:2]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print([formatter.load_data_from_dic({key: value[i] for key, value in batch_data.items()}).format_html() for i in range(len(batch_data.keys())) ])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print([formatter.load_data_from_dic({key: value[i] for key, value in table_loader.dataset[:2].items()}).format_html() for i in range(2)])\u001b[39;00m\n",
      "File \u001b[0;32m~/zh/tabular_data/data_loader/table_augmentation.py:61\u001b[0m, in \u001b[0;36mTableAug.batch_summary_aug\u001b[0;34m(self, formatter, batch_data, batch_size, output_token)\u001b[0m\n\u001b[1;32m     57\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     58\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mpre_instruction_summary, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# add             \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     batch_pred \u001b[38;5;241m=\u001b[39m llm_chain\u001b[38;5;241m.\u001b[39mbatch([formatter\u001b[38;5;241m.\u001b[39mload_data_from_dic(batch_data[i])\u001b[38;5;241m.\u001b[39mformat_html(batch_data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_pred)):\n\u001b[1;32m     64\u001b[0m     parts \u001b[38;5;241m=\u001b[39m batch_pred[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn description\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/zh/tabular_data/data_loader/table_augmentation.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     58\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mpre_instruction_summary, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# add             \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     batch_pred \u001b[38;5;241m=\u001b[39m llm_chain\u001b[38;5;241m.\u001b[39mbatch([formatter\u001b[38;5;241m.\u001b[39mload_data_from_dic(\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mformat_html(batch_data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_pred)):\n\u001b[1;32m     64\u001b[0m     parts \u001b[38;5;241m=\u001b[39m batch_pred[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn description\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#table_size\n",
    "def get_table_size():\n",
    "    return f'The table has {formatter.data.shape[0]} rows and {formatter.data.shape[1]} columns.'\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\", temperature=0.1)\n",
    "from data_loader import TableAug,TableFormat\n",
    "aug = TableAug(model)\n",
    "# aug.schema_aug(test_sample)\n",
    "test_sample = table_loader.dataset[0]\n",
    "formatter = TableFormat(format='none')\n",
    "output = aug.batch_summary_aug(formatter, table_loader.dataset[:2], batch_size=2, output_token=True)\n",
    "# batch_data = table_loader.dataset[:2]\n",
    "\n",
    "# print([formatter.load_data_from_dic({key: value[i] for key, value in batch_data.items()}).format_html() for i in range(len(batch_data.keys())) ])\n",
    "# print([formatter.load_data_from_dic({key: value[i] for key, value in table_loader.dataset[:2].items()}).format_html() for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d08d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'table summary: The table provides information about different wind farms including their names, scheduled dates, capacity in megawatts, number of turbines, types of turbines, and locations.\\n\\ncolumn description: \\nwind farm<The name of the wind farm>\\nscheduled<The scheduled date for the wind farm>\\ncapacity (mw)<The capacity of the wind farm in megawatts>\\nturbines<The number of turbines at the wind farm>\\ntype<The type of turbines used at the wind farm>\\nlocation<The location of the wind farm>'}\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffaeeba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Golf tournament winners' information\",\n",
       " \"player<The name of the player>\\ncountry<The country the player represents>\\nyear (s) won<The year(s) the player won the tournament>\\ntotal<The total score of the player>\\nto par<The score in relation to par (under par or over par)>\\nfinish<The player's finishing position in the tournament>\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatter = TableFormat(format='none',data=test_sample)\n",
    "aug.summary_aug(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999286c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed509fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10112f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe409023",
   "metadata": {},
   "source": [
    "### Few Shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6daf1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Given the following table and claim, let's first summarize the contents of the rows and columns of the table, and then select relevent rows/columns in the given table that support or oppose the statement.\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  wind farm</th><th>  scheduled</th><th>  capacity (mw)</th><th>  turbines</th><th>              type</th><th>      location</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>codling    </td><td>unknown    </td><td>1100           </td><td>220       </td><td>unknown           </td><td>county wicklow</td></tr>\n",
      "<tr><td>carrowleagh</td><td>2012       </td><td>36.8           </td><td>16        </td><td>enercon e - 70 2.3</td><td>county cork   </td></tr>\n",
      "<tr><td>gortahile  </td><td>2010 autumn</td><td>20             </td><td>8         </td><td>nordex n90        </td><td>county laois  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: the scheduled date for the farm with 17 turbine be 2012\n",
      "Summary: The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.\n",
      "Subtable: Columns(wind farm, scheduled, turbines), Rows(12)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  kanji</th><th>             name</th><th>                     builder</th><th>     laid down</th><th>     launched</th><th>      completed</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>望月   </td><td>mochizuki dd - 33</td><td>uraga dock company , japan  </td><td>23 march 1926 </td><td>28 april 1927</td><td>31 october 1927</td></tr>\n",
      "<tr><td>三日月 </td><td>mikazuki dd - 32 </td><td>sasebo naval arsenal , japan</td><td>21 august 1925</td><td>12 july 1926 </td><td>5 may 1927     </td></tr>\n",
      "<tr><td>睦月   </td><td>mutsuki dd - 19  </td><td>sasebo naval arsenal , japan</td><td>21 may 1924   </td><td>23 july 1925 </td><td>25 march 1926  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: uraga dock company produce the most destroyer on the list , at 3\n",
      "Summary: The table provides information about different destroyers, including their kanji (Japanese characters), names, builders, dates when they were laid down, launched, and completed.\n",
      "Subtable: Columns(kanji, builder), Rows(ALL)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>               event name</th><th>  established</th><th>  category</th><th>  sub category</th><th>           main venue</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>the frye festival        </td><td>2000         </td><td>arts      </td><td>literary      </td><td>university of moncton</td></tr>\n",
      "<tr><td>world wine &amp; food expo   </td><td>1990         </td><td>arts      </td><td>food &amp; drink  </td><td>moncton coliseum     </td></tr>\n",
      "<tr><td>dieppe kite international</td><td>2001         </td><td>sporting  </td><td>kite flying   </td><td>dover park           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "summary_examples = ['The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.',\n",
    "                    \"The table provides information about different destroyers, including their kanji (Japanese characters), names, builders, dates when they were laid down, launched, and completed.\"]\n",
    "subtable_examples = ['Columns(wind farm, scheduled, turbines), Rows(12)',\n",
    "                    'Columns(kanji, builder), Rows(ALL)']\n",
    "inds = [0, 100]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"summary\", \"subtable\"], template=\n",
    "\"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "Summary: {summary}\n",
    "Subtable: {subtable}\"\"\")\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "num_k = 2\n",
    "# examples = [examples_prompt.format(**{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]]).format_html(),\n",
    "#                                     \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "#                                     \"summary\": summary_examples[i],\n",
    "#                                     \"subtable\": subtable_examples[i]}) for i in range(num_k)]\n",
    "\n",
    "examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_html(),\n",
    "                                    \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                    \"summary\": summary_examples[i],\n",
    "                                    \"subtable\": subtable_examples[i]} for i in range(num_k)]\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"Instruction: Given the following table and claim, let's first summarize the contents of the rows and columns of the table, and then select relevent rows/columns in the given table that support or oppose the statement.\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "    \"\"\",\n",
    "    input_variables=[\"table\", \"claim\"],\n",
    ")\n",
    "print(prompt.format(table=formatter.format_html(), claim=test_sample['statement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d826faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(2)', response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 931, 'total_tokens': 972}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29768c0b",
   "metadata": {},
   "source": [
    "### Few-shot for operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d644a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
      "Instruction: Given the following table and claim, you will output the operations corresponding to each column which can help us judging the truth or falsity of claim.\n",
      "Operations: DELETE(delete column unrelevant to the claim), KEEP(keep column relevant to the claim), GROUP BY(combine aggregate functions and group the result set by one or more columns), COUNT(returns the number of rows in column), AVG(returns the average value of a numeric column), SUM(returns the sum of a numeric column), MAX(returns the max value of a numeric column), MIN(returns the min value of a numeric column), ORDER BY(sort the value in ascending order)\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>  wind farm</th><th>  scheduled</th><th>  capacity (mw)</th><th>  turbines</th><th>              type</th><th>      location</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>codling    </td><td>unknown    </td><td>1100           </td><td>220       </td><td>unknown           </td><td>county wicklow</td></tr>\n",
      "<tr><td>carrowleagh</td><td>2012       </td><td>36.8           </td><td>16        </td><td>enercon e - 70 2.3</td><td>county cork   </td></tr>\n",
      "<tr><td>gortahile  </td><td>2010 autumn</td><td>20             </td><td>8         </td><td>nordex n90        </td><td>county laois  </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: the scheduled date for the farm with 17 turbine be 2012\n",
      "Output: wind farm<DELETE>, scheduled<KEEP>, capacity (mw)<DELETE>, turbines<KEEP>, type<KEEP>, location<KEEP>\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>               event name</th><th>  established</th><th>  category</th><th>  sub category</th><th>           main venue</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>the frye festival        </td><td>2000         </td><td>arts      </td><td>literary      </td><td>university of moncton</td></tr>\n",
      "<tr><td>world wine &amp; food expo   </td><td>1990         </td><td>arts      </td><td>food &amp; drink  </td><td>moncton coliseum     </td></tr>\n",
      "<tr><td>dieppe kite international</td><td>2001         </td><td>sporting  </td><td>kite flying   </td><td>dover park           </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Claim: touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "Output: event name<KEEP> established<KEEP> category<KEEP> sub category<DELETE> main venue<DELETE>\n",
      "\n",
      "\n",
      "Table: <table>\n",
      "<thead>\n",
      "<tr><th>            date</th><th>        tournament</th><th>  surface</th><th>        partner</th><th>                                     opponents</th><th>                score</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>11 february 2008</td><td>mallorca 2 , spain</td><td>clay     </td><td>stephanie vogt </td><td>leticia costas - moreira maite gabarrus alonso</td><td>7 - 6 (7 - 2) , 6 - 3</td></tr>\n",
      "<tr><td>8 february 2010 </td><td>cali , colombia   </td><td>clay     </td><td>edina gallovits</td><td>estrella cabeza candella laura pous tió       </td><td>3 - 6 , 6 - 3 ,      </td></tr>\n",
      "<tr><td>28 april 2008   </td><td>makarska , croatia</td><td>clay     </td><td>stephanie vogt </td><td>tadeja majerić maša zec peškirič              </td><td>7 - 5 , 6 - 2        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Thought: your reason here\n",
      "Claim: polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "inds = [0,2]\n",
    "summary_examples = ['The columns in the table are \"wind farm, scheduled, capacity (mw), turbines, type, and location.\" The rows in the table represent different wind farms, with information about their scheduled dates, capacity, number of turbines, type, and location.',\n",
    "                    \"The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\"]\n",
    "Output_examples = ['wind farm<DELETE>, scheduled<KEEP>, capacity (mw)<DELETE>, turbines<KEEP>, type<KEEP>, location<KEEP>', 'event name<KEEP> established<KEEP> category<KEEP> sub category<DELETE> main venue<DELETE>']\n",
    "examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\"], template=\n",
    "\"\"\"\n",
    "Table: {table}\n",
    "Claim: {claim}\n",
    "Output: {output}\"\"\")\n",
    "num_k = 2\n",
    "examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_html(),\n",
    "                                    \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                    # \"summary\": summary_examples[i],\n",
    "                                    \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "Instruction: Given the following table and claim, you will output the operations corresponding to each column which can help us judging the truth or falsity of claim.\n",
    "Operations: DELETE(delete column unrelevant to the claim), KEEP(keep column relevant to the claim), GROUP BY(combine aggregate functions and group the result set by one or more columns), COUNT(returns the number of rows in column), AVG(returns the average value of a numeric column), SUM(returns the sum of a numeric column), MAX(returns the max value of a numeric column), MIN(returns the min value of a numeric column), ORDER BY(sort the value in ascending order)\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Table: {table}\n",
    "Thought: your reason here\n",
    "Claim: {claim}\n",
    "    \"\"\",\n",
    "    input_variables=[\"table\", \"claim\"],\n",
    ")\n",
    "print(prompt.format(table=formatter.format_html(), claim=test_sample['statement']))\n",
    "\n",
    "# output = model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03387f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Output: date<DELETE>, tournament<DELETE>, surface<DELETE>, partner<KEEP>, opponents<KEEP>, score<DELETE>' response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1037, 'total_tokens': 1063}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "output = model.invoke([HumanMessage(content=prompt.format(table=formatter.format_html(), claim=test_sample['statement']))])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "741b809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------+\n",
      "| date             | tournament                        | surface   | partner             | opponents                                      | score                 |\n",
      "|------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------|\n",
      "| 15 january 2007  | algiers 2 , algeria               | clay      | rushmi chakravarthi | barbora matusova anna savitskaya               | 6 - 2 , 6 - 0         |\n",
      "| 11 february 2008 | mallorca 2 , spain                | clay      | stephanie vogt      | leticia costas - moreira maite gabarrus alonso | 7 - 6 (7 - 2) , 6 - 3 |\n",
      "| 28 april 2008    | makarska , croatia                | clay      | stephanie vogt      | tadeja majerić maša zec peškirič               | 7 - 5 , 6 - 2         |\n",
      "| 8 september 2008 | sarajevo 2 , bosnia - herzegovina | clay      | alberta brianti     | çağla büyükakçay julia glushko                 | 6 - 4 , 7 - 5         |\n",
      "| 8 february 2010  | cali , colombia                   | clay      | edina gallovits     | estrella cabeza candella laura pous tió        | 3 - 6 , 6 - 3 ,       |\n",
      "+------------------+-----------------------------------+-----------+---------------------+------------------------------------------------+-----------------------+\n",
      "polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(formatter.format_psql())\n",
    "print(test_sample['statement'])\n",
    "print(test_sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e7d96",
   "metadata": {},
   "source": [
    "## Zero-shot learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fa5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uraga dock company produce the most destroyer on the list , at 3\n",
      "+----+---------+-------------------+--------------------------------+------------------+------------------+-------------------+\n",
      "|    | kanji   | name              | builder                        | laid down        | launched         | completed         |\n",
      "|----+---------+-------------------+--------------------------------+------------------+------------------+-------------------|\n",
      "|  0 | 睦月    | mutsuki dd - 19   | sasebo naval arsenal , japan   | 21 may 1924      | 23 july 1925     | 25 march 1926     |\n",
      "|  1 | 如月    | kisaragi dd - 21  | maizuru naval arsenal , japan  | 3 june 1924      | 5 june 1925      | 21 december 1925  |\n",
      "|  2 | 彌生    | yayoi dd - 23     | uraga dock company , japan     | 11 january 1924  | 11 july 1925     | 28 august 1926    |\n",
      "|  3 | 卯月    | uzuki dd - 25     | ishikawajima shipyards , japan | 11 january 1924  | 15 october 1925  | 14 september 1926 |\n",
      "|  4 | 皐月    | satsuki dd - 27   | fujinagata shipyards , japan   | 1 december 1924  | 25 march 1925    | 15 november 1925  |\n",
      "|  5 | 水無月  | minazuki dd - 28  | uraga dock company , japan     | 24 march 1924    | 25 march 1926    | 22 march 1927     |\n",
      "|  6 | 文月    | fumizuki dd - 29  | fujinagata shipyards , japan   | 20 october 1924  | 16 february 1926 | 3 july 1926       |\n",
      "|  7 | 長月    | nagatsuki dd - 30 | ishikawajima shipyards , japan | 16 april 1925    | 6 october 1926   | 30 april 1927     |\n",
      "|  8 | 菊月    | kikuzuki dd - 31  | maizuru naval arsenal , japan  | 15 june 1925     | 15 may 1926      | 20 november 1926  |\n",
      "|  9 | 三日月  | mikazuki dd - 32  | sasebo naval arsenal , japan   | 21 august 1925   | 12 july 1926     | 5 may 1927        |\n",
      "| 10 | 望月    | mochizuki dd - 33 | uraga dock company , japan     | 23 march 1926    | 28 april 1927    | 31 october 1927   |\n",
      "| 11 | 夕月    | yūzuki dd - 34    | fujinagata shipyards , japan   | 27 november 1926 | 4 march 1927     | 25 july 1927      |\n",
      "+----+---------+-------------------+--------------------------------+------------------+------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "formatter = TableFormat(format='none', data=test_sample)\n",
    "print(test_sample['statement'])\n",
    "print(tabulate(formatter.data, headers=formatter.data.columns, tablefmt='psql'))\n",
    "# print('Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e7abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=True, small_test=False)\n",
    "test_sample = table_loader.dataset[40]\n",
    "formatter = TableFormat(format='none', data=test_sample, use_sampling=True)\n",
    "pre_instruction_schema = PromptTemplate(input_variables=[\"table\"], template=\"\"\"\n",
    "Instruction: Given the following table, you need to summarize the contents of the table and tell what table is about.\n",
    "Table: {table}\n",
    "\n",
    "The output should use the following format: \n",
    "Summary: #summary for table contents\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction_schema.format(table=formatter.format_html(),))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0d8705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about different games played by a football team. It includes details like the week number, date of the game, opponent team, game result, game site, NFL recap, and the attendance for each game.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "650b53bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------------------+---------------+----------------+----------------+--------------------------+\n",
      "|    | event name                                 |   established | category       | sub category   | main venue               |\n",
      "|----+--------------------------------------------+---------------+----------------+----------------+--------------------------|\n",
      "|  0 | dieppe kite international                  |          2001 | sporting       | kite flying    | dover park               |\n",
      "|  1 | the frye festival                          |          2000 | arts           | literary       | university of moncton    |\n",
      "|  2 | hubcap comedy festival                     |          2000 | arts           | comedy         | various                  |\n",
      "|  3 | touchdown atlantic                         |          2010 | sporting       | football       | moncton stadium          |\n",
      "|  4 | atlantic nationals automotive extravaganza |          2000 | transportation | automotive     | moncton coliseum         |\n",
      "|  5 | world wine & food expo                     |          1990 | arts           | food & drink   | moncton coliseum         |\n",
      "|  6 | shediac lobster festival                   |          1950 | arts           | food & drink   | shediac festival grounds |\n",
      "|  7 | mosaã¯q multicultural festival             |          2004 | festival       | multicultural  | moncton city hall plaza  |\n",
      "+----+--------------------------------------------+---------------+----------------+----------------+--------------------------+\n",
      "Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\n",
      "Subtable: Columns(event name, established, category), Rows(touchdown atlantic)\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(formatter.data, headers=formatter.data.columns, tablefmt='psql'))\n",
    "print('Summary: The table provides information about different events, including their names, establishment years, categories, subcategories, and main venues.\\nSubtable: Columns(event name, established, category), Rows(touchdown atlantic)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe7ca0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "touchdown atlantic , in the category of sporting , be establish in 2010\n"
     ]
    }
   ],
   "source": [
    "print(test_sample['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0fc7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "class Config:\n",
    "    def __init__(self) -> None:\n",
    "        self.openai_api_key = \"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\"\n",
    "        self.base_url = \"https://api.chatanywhere.cn/v1\"\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "\n",
    "class CallLLM:\n",
    "    \"\"\"Class for calling the OpenAI Language Model API.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.client = OpenAI(api_key=config.openai_api_key,\n",
    "                             base_url=config.base_url)\n",
    "        self.model = config.model\n",
    "        \n",
    "    @retry(wait=wait_random_exponential(min=30, max=60), stop=stop_after_attempt(1000))\n",
    "    def generate_text(self, prompt: List[str]) -> List[str]:\n",
    "        \"\"\"Generate text based on the prompt and instruction.\"\"\"\n",
    "\n",
    "            # batched examples, with xx completions per request\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "            temperature=0,\n",
    "            max_tokens=96,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "        )\n",
    "        # match completions to prompts by index\n",
    "        return response.choices[0].message.content.strip()\n",
    "configs = Config()  \n",
    "llm = CallLLM(config=configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "957617c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_text = \"\\n\".join(input)\n",
    "llm.generate_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0fee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_input(sample, instruction):\n",
    "    df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "    for i, line in enumerate(sample['table']['rows']):\n",
    "        df.loc[i] = line\n",
    "        \n",
    "    texts = [instruction,\n",
    "          \"The database table DF is shown as follows: \\n\",\n",
    "          df.to_html(),\n",
    "          \"query:\",\n",
    "          sample['statement'],\n",
    "           \"Output the code braced by '```'. \\n SQL:\"]\n",
    "    \n",
    "    label = sample['label']\n",
    "    return \"\\n\".join(texts), label \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec355fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtable_instruction = \"\"\"\n",
    "You are a SQLite expert. Given an input query, identify critical values and ranges of the table, then create a syntactically correct SQLite query to create a VIEW. To create a syntactically correct SQL view, the selected data within this view must be helpful in answering the question. During the construction of the view, if column names are confusing, rename the columns accordingly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604321c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nYou are a SQLite expert. Given an input query, identify critical values and ranges of the table, then create a syntactically correct SQLite query to create a VIEW. To create a syntactically correct SQL view, the selected data within this view must be helpful in answering the question. During the construction of the view, if column names are confusing, rename the columns accordingly.\\n\\nThe database table DF is shown as follows: \\n\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>date</th>\\n      <th>result</th>\\n      <th>score</th>\\n      <th>brazil scorers</th>\\n      <th>competition</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>may 11 , 1919</td>\\n      <td>w</td>\\n      <td>6 - 0</td>\\n      <td>friedenreich (3) , neco (2) , haroldo</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>may 18 , 1919</td>\\n      <td>w</td>\\n      <td>3 - 1</td>\\n      <td>heitor , amílcar , millon</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>may 26 , 1919</td>\\n      <td>d</td>\\n      <td>2 - 2</td>\\n      <td>neco (2)</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>may 29 , 1919</td>\\n      <td>w</td>\\n      <td>1 - 0</td>\\n      <td>friedenreich</td>\\n      <td>south american championship</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>june 1 , 1919</td>\\n      <td>d</td>\\n      <td>3 - 3</td>\\n      <td>haroldo , arlindo (2)</td>\\n      <td>taça roberto cherry</td>\\n    </tr>\\n  </tbody>\\n</table>\\nquery:\\nharoldo be mention as a brazil scorer for 2 different game\\nOutput the code braced by \\'```\\'. \\n SQL:', 1)\n"
     ]
    }
   ],
   "source": [
    "print(process_input(test_sample, subtable_instruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c3210",
   "metadata": {},
   "source": [
    "### Simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4aa5027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db')\n",
    "normalized = table_loader.normalize_table(test_sample)\n",
    "df = pd.DataFrame(columns=normalized['table']['header'])\n",
    "for ind, r in enumerate(normalized['table']['rows']):\n",
    "    df.loc[ind] = r\n",
    "# print(' '.join(normalized['table']['header']) + '*************')\n",
    "df.to_sql(name='ind100', con=engine, if_exists='replace', index=False)\n",
    "# table_loader.table2db(engine, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b84b796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "structured_data_markdown = tabulate(\n",
    "            df, headers=df.columns, tablefmt=\"pipe\", showindex=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea32bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|    | date          | result   | score   | brazil scorers                        | competition                 |\\n|---:|:--------------|:---------|:--------|:--------------------------------------|:----------------------------|\\n|  0 | may 11 , 1919 | w        | 6 - 0   | friedenreich (3) , neco (2) , haroldo | south american championship |\\n|  1 | may 18 , 1919 | w        | 3 - 1   | heitor , amílcar , millon             | south american championship |\\n|  2 | may 26 , 1919 | d        | 2 - 2   | neco (2)                              | south american championship |\\n|  3 | may 29 , 1919 | w        | 1 - 0   | friedenreich                          | south american championship |\\n|  4 | june 1 , 1919 | d        | 3 - 3   | haroldo , arlindo (2)                 | taça roberto cherry         |'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_data_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd90b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "model = ChatOpenAI(model_name=\"gpt-4\", openai_api_base=\"https://api.chatanywhere.cn/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a95af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_yes_no_and_map(text):\n",
    "    # Convert the input text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "\n",
    "    # Define regular expressions for yes/no matching\n",
    "    yes_patterns = [r'\\byes\\b', r'\\btrue\\b']\n",
    "    no_patterns = [r'\\bno\\b', r'\\bfalse\\b']\n",
    "\n",
    "    # Check for \"0\"\n",
    "    if text == \"0\":\n",
    "        return \"0\"\n",
    "\n",
    "    # Check for \"1\"\n",
    "    if text == \"1\":\n",
    "        return \"1\"\n",
    "\n",
    "    # Check for yes\n",
    "    for pattern in yes_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"1\"\n",
    "\n",
    "    # Check for no\n",
    "    for pattern in no_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return \"0\"\n",
    "\n",
    "    # Return 2 if neither yes nor no is found\n",
    "    return \"2\"\n",
    "\n",
    "def eval_fv_match(pred_list, gold_list):\n",
    "        acc = 0.0\n",
    "        for pred, gold in zip(pred_list, gold_list):\n",
    "            pred, gold = extract_yes_no_and_map(pred), extract_yes_no_and_map(gold)\n",
    "            if pred == gold:\n",
    "                acc += 1\n",
    "        acc = acc / len(pred_list)\n",
    "        return acc\n",
    "    \n",
    "def process_input(sample, instruction):\n",
    "    df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "    for i, line in enumerate(sample['table']['rows']):\n",
    "        df.loc[i] = line\n",
    "    texts = [instruction,\n",
    "          \"the table needed to be answered: \\n\",\n",
    "          df.to_html(),\n",
    "          \"query:\",\n",
    "          sample['statement'],\n",
    "           \"answer is: \\n\"]\n",
    "    \n",
    "    label = sample['label']\n",
    "    return \"\\n\".join(texts), label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "367a8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "#简易版本的pipeline\n",
    "instruction = \"Read the table below to verify whether the provided claim/query are true or false. Return 0 if it's false, or 1 if it's true. Only return 0 or 1 without any other information. \\n\"\n",
    "num_samples = 32\n",
    "batch_size = 32\n",
    "num_batches = num_samples // batch_size\n",
    "batches = []\n",
    "for batch_num in range(num_batches):\n",
    "    batch_prompt, ground = [], []\n",
    "    start = batch_num * batch_size\n",
    "    batch_data = tabfact['validation'][start: start+batch_size]\n",
    "    for i in range(batch_size):\n",
    "        prompt, label = process_input(sample=dict({key: value[i] for key, value in batch_data.items()}), instruction=instruction)\n",
    "        batch_prompt.append(prompt)\n",
    "        ground.append(str(label))\n",
    "        # call llm\n",
    "    batch_pred = list(map(lambda x: x.content, model.batch(batch_prompt)))\n",
    "        \n",
    "        #do evaluation\n",
    "    accuracy = eval_fv_match(batch_pred, ground)\n",
    "    print(accuracy)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e917216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "süper lig be the most common league to win a round in the turkish cup 1\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "there be new entry for the 1st 4 round of the turkish cup 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "2 be the lowest number of new entry conclude a round in the turkish cup 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "from round 1 to the final round , there be 4 club remain to complete the round 0\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "|    | round         |   clubs remaining |   clubs involved | winners from previous round   | new entries this round   | leagues entering at this round                     |\n",
      "|----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------|\n",
      "|  0 | first round   |               156 |               86 | none                          | 86                       | tff third league & turkish regional amateur league |\n",
      "|  1 | second round  |               113 |              108 | 43                            | 65                       | süper lig & tff first league & tff second league   |\n",
      "|  2 | third round   |                59 |               54 | 54                            | none                     | none                                               |\n",
      "|  3 | fourth round  |                32 |               32 | 27                            | 5                        | süper lig                                          |\n",
      "|  4 | fifth round   |                16 |               16 | 16                            | none                     | none                                               |\n",
      "|  5 | group stage   |                 8 |                8 | 8                             | none                     | none                                               |\n",
      "|  6 | semi - finals |                 4 |                4 | 4                             | none                     | none                                               |\n",
      "|  7 | final         |                 2 |                2 | 2                             | none                     | none                                               |\n",
      "+----+---------------+-------------------+------------------+-------------------------------+--------------------------+----------------------------------------------------+\n",
      "5 of the cultural interest fraternity and sorority be 2 sorority while 3 be a fraternity 0\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "|    | letters   | organization             | nickname         | founding date   | founding university              | type       |\n",
      "|----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------|\n",
      "|  0 | αεπ       | alpha epsilon pi 1       | aepi             | 1913 - 11 - 07  | new york university              | fraternity |\n",
      "|  1 | αεφ       | alpha epsilon phi 2      | aephi            | 1909 - 10 - 24  | barnard college                  | sorority   |\n",
      "|  2 | σαεπ      | sigma alpha epsilon pi 3 | sigma            | 1998 - 10 - 01  | university of california , davis | sorority   |\n",
      "|  3 | σαμ       | sigma alpha mu 1         | sammy            | 1909 - 11 - 26  | city college of new york         | fraternity |\n",
      "|  4 | σδτ       | sigma delta tau 2        | sdt or sig delts | 1917 - 03 - 25  | cornell university               | sorority   |\n",
      "|  5 | τεφ       | tau epsilon phi 1        | tep , tau boys   | 1910 - 10 - 10  | columbia university              | fraternity |\n",
      "|  6 | ζβτ       | zeta beta tau 1          | zbt              | 1898 - 12 - 29  | city college of new york         | fraternity |\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "7 of the cultural interest fraternity and sorority be found before the year 1921 0\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "|    | letters   | organization             | nickname         | founding date   | founding university              | type       |\n",
      "|----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------|\n",
      "|  0 | αεπ       | alpha epsilon pi 1       | aepi             | 1913 - 11 - 07  | new york university              | fraternity |\n",
      "|  1 | αεφ       | alpha epsilon phi 2      | aephi            | 1909 - 10 - 24  | barnard college                  | sorority   |\n",
      "|  2 | σαεπ      | sigma alpha epsilon pi 3 | sigma            | 1998 - 10 - 01  | university of california , davis | sorority   |\n",
      "|  3 | σαμ       | sigma alpha mu 1         | sammy            | 1909 - 11 - 26  | city college of new york         | fraternity |\n",
      "|  4 | σδτ       | sigma delta tau 2        | sdt or sig delts | 1917 - 03 - 25  | cornell university               | sorority   |\n",
      "|  5 | τεφ       | tau epsilon phi 1        | tep , tau boys   | 1910 - 10 - 10  | columbia university              | fraternity |\n",
      "|  6 | ζβτ       | zeta beta tau 1          | zbt              | 1898 - 12 - 29  | city college of new york         | fraternity |\n",
      "+----+-----------+--------------------------+------------------+-----------------+----------------------------------+------------+\n",
      "goal 2 - 5 be all consider friendly competition 1\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "goal 2 be the first of 3 game with a score of 2 - 0 0\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "the game in pueblo nuevo be 1 of 6 game play in venezuela 0\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "|    |   goal | date               | venue                                         | score   | result   | competition                  |\n",
      "|----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------|\n",
      "|  0 |      1 | september 4 , 2001 | estadio nacional de chile , santiago , chile  | 0 - 1   | 0 - 2    | 2002 world cup qualification |\n",
      "|  1 |      2 | november 20 , 2002 | brígido iriarte , caracas , venezuela         | 1 - 0   | 1 - 0    | friendly                     |\n",
      "|  2 |      3 | april 2 , 2003     | brígido iriarte , caracas , venezuela         | 2 - 0   | 2 - 0    | friendly                     |\n",
      "|  3 |      4 | february 9 , 2005  | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 3 - 0    | friendly                     |\n",
      "|  4 |      5 | march 28 , 2007    | josé pachencho romero , maracaibo , venezuela | 1 - 0   | 5 - 0    | friendly                     |\n",
      "|  5 |      6 | june 26 , 2007     | pueblo nuevo , san cristóbal , venezuela      | 2 - 1   | 2 - 2    | 2007 copa américa            |\n",
      "+----+--------+--------------------+-----------------------------------------------+---------+----------+------------------------------+\n",
      "in the 2008 manx grand prix the same team do not have more than 1 rider 1\n",
      "+----+--------+----------------------+---------------------+-------------+------------+\n",
      "|    |   rank | rider                | team                | speed       | time       |\n",
      "|----+--------+----------------------+---------------------+-------------+------------|\n",
      "|  0 |      1 | ryan farquhar        | 498cc bic paton     | 102.385 mph | 1:06.19.90 |\n",
      "|  1 |      2 | alan oversby         | 500cc norton manx   | 101.863 mph | 1:06.40.30 |\n",
      "|  2 |      3 | alan brew            | seeley g50 496cc    | 99.367 mph  | 1:08.20.78 |\n",
      "|  3 |      4 | wattie brown         | 500cc petty manx    | 98.118 mph  | 1:09.12.98 |\n",
      "|  4 |      5 | andy reynolds        | 499cc bic paton     | 97.152 mph  | 1:09.54.28 |\n",
      "|  5 |      6 | bob price            | 500cc seeley g50    | 96.890 mph  | 1:10.05.64 |\n",
      "|  6 |      7 | ken davis            | 500cc norton manx   | 95.948 mph  | 1:10.46.92 |\n",
      "|  7 |      8 | chris swallow        | 476cc ducati        | 95.664 mph  | 1:10.59.52 |\n",
      "|  8 |      9 | mark herbertson      | 499cc matchless g50 | 95.272 mph  | 1:11.17.05 |\n",
      "|  9 |     10 | dave madsen - mygdal | 499cc honda         | 92.209 mph  | 1:11.19.89 |\n",
      "+----+--------+----------------------+---------------------+-------------+------------+\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def display_wrong_result(pred_list, gold_list, dataset):\n",
    "    for ind, (pred, gold) in enumerate(zip(pred_list, gold_list)):\n",
    "        pred, gold = extract_yes_no_and_map(pred), extract_yes_no_and_map(gold)\n",
    "        if pred != gold:\n",
    "            sample= dataset[ind]\n",
    "            df = pd.DataFrame(columns=sample[\"table\"][\"header\"])\n",
    "            for i, line in enumerate(sample['table']['rows']):\n",
    "                df.loc[i] = line\n",
    "            print(sample['statement'], sample['label'])\n",
    "            print(tabulate(df, headers=df.columns, tablefmt='psql'))\n",
    "        \n",
    "print(display_wrong_result(batch_pred, ground, tabfact['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40664801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('1', '1')\n",
      "1 ('1', '1')\n",
      "2 ('1', '1')\n",
      "3 ('1', '1')\n",
      "4 ('1', '1')\n",
      "5 ('1', '0')\n",
      "6 ('0', '0')\n",
      "7 ('0', '0')\n",
      "8 ('0', '0')\n",
      "9 ('0', '0')\n",
      "10 ('1', '1')\n",
      "11 ('0', '1')\n",
      "12 ('1', '1')\n",
      "13 ('1', '1')\n",
      "14 ('0', '1')\n",
      "15 ('0', '0')\n",
      "16 ('0', '0')\n",
      "17 ('0', '0')\n",
      "18 ('1', '0')\n",
      "19 ('1', '0')\n",
      "20 ('The answer is 1.', '1')\n",
      "21 ('0', '1')\n",
      "22 ('1', '1')\n",
      "23 ('0', '1')\n",
      "24 ('1', '1')\n",
      "25 ('0', '0')\n",
      "26 ('0', '0')\n",
      "27 ('1', '0')\n",
      "28 ('0', '0')\n",
      "29 ('0', '0')\n",
      "30 ('1', '1')\n",
      "31 ('1', '1')\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(zip(batch_pred, ground)):\n",
    "    print(ind, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadec37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9490d54f",
   "metadata": {},
   "source": [
    "## Answer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b300498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data_loader import TableFormat\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from data_loader import TableLoader\n",
    "\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "from utils import normalize_schema\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_base=\"https://api.chatanywhere.tech/v1\", openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\")\n",
    "normalized_sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[3])\n",
    "formatter = TableFormat(format='none', data=normalized_sample)\n",
    "# schema_information = pd.read_csv(f\"result/aug/tabfact_test_schema.csv\", index_col='table_id')\n",
    "# formatter.data = normalize_schema(formatter.data, schema_information.loc[normalized_sample['id']]['schema'])\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\"], template=\n",
    "\"\"\"\n",
    "Below is a subtable with rows sampled, you are required to infer the data distribution and format from the sample data.\n",
    "Refine commonalities about the structure within each table column.\n",
    "You need to output in the following format: \n",
    "number. Column_name: Commonalities\n",
    "#example format\n",
    "1. championship: Names of golf tournaments are listed with some additional information (e.g., 's open, classic)\n",
    "\n",
    "sub-table: {table}\n",
    "\"\"\")\n",
    "# \n",
    "output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html()) )])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf55a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. position: Integer values representing the team's position in the table\n",
      "2. team: Names of football teams\n",
      "3. played: Number of games played by each team\n",
      "4. drawn: Number of games drawn by each team\n",
      "5. lost: Number of games lost by each team\n",
      "6. goals_for: Number of goals scored by each team\n",
      "7. goals_against: Number of goals conceded by each team\n",
      "8. goal_difference: Goal difference calculated as goals_for - goals_against\n",
      "9. points_1: Total points earned by each team in the league\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f79c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. game column: It appears to represent the game number, with each entry being a numerical value.\n",
      "2. date column: It represents the date of the game, with each entry being in a specific date format (e.g., \"month day\").\n",
      "3. team column: It represents the name of the team, with each entry being a text string.\n",
      "4. score column: It represents the game score, with each entry showing the score in a specific format (e.g., \"l 90 - 115 (ot)\").\n",
      "5. high_points column: It represents the player with the highest points in the game, with each entry showing the player's name and the number of points.\n",
      "6. high_rebounds column: It represents the player with the highest rebounds in the game, with each entry showing the player's name and the number of rebounds.\n",
      "7. high_assists column: It represents the player with the highest assists in the game, with each entry showing the player's name and the number of assists.\n",
      "8. location_attendance column: It represents the location of the game and the attendance, with each entry showing the location and the number of attendees.\n",
      "9. record column: It represents the team's record, with each entry showing the number of wins and losses.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query.\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        # 'claim':\"who is the winner of the lifetime achievement award after 2005?\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a285a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that provide clues for query.\n",
    "sub-table: {table}\n",
    "Query: verify whether the provided claim/query are true or false. {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        # 'claim':\"who is the winner of the lifetime achievement award after 2005?\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))\n",
    "# verify whether the provided claim/query are true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c50a649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information and data in subtable, write 3 SELECT SQL statements using table DF that complete or related to query.\n",
    "The SQL may select different useful parts for the query.\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        'claim': normalized_sample['query'] + \". The query is about 2005 Milwaukee Brewers season red uniforms vs Padres schedule\",\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9224bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Our ultimate goal is to answer query based on the table. Below is a subtable with columns filtered, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query.\n",
      "sub-table: <table>\n",
      "<caption>1986 - 87 north west counties football league</caption>\n",
      "<thead>\n",
      "<tr><th>  position</th><th>               team</th><th>  played</th><th>  drawn</th><th>  lost</th><th>  goals_for</th><th>  goals_against</th><th>  goal_difference</th><th>  points_1</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>12        </td><td>ashton town        </td><td>24      </td><td>9      </td><td>11    </td><td>29         </td><td>39             </td><td>10               </td><td>15 2      </td></tr>\n",
      "<tr><td>10        </td><td>padiham            </td><td>24      </td><td>8      </td><td>12    </td><td>35         </td><td>39             </td><td>4                </td><td>16        </td></tr>\n",
      "<tr><td>1         </td><td>atherton collieries</td><td>24      </td><td>4      </td><td>4     </td><td>46         </td><td>22             </td><td>+ 24             </td><td>36        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "Extra information: 1. position: Integer values representing the team's position in the table\n",
      "2. team: Names of football teams\n",
      "3. played: Number of games played by each team\n",
      "4. drawn: Number of games drawn by each team\n",
      "5. lost: Number of games lost by each team\n",
      "6. goals_for: Number of goals scored by each team\n",
      "7. goals_against: Number of goals conceded by each team\n",
      "8. goal_difference: Goal difference calculated as goals_for - goals_against\n",
      "9. points_1: Total points earned by each team in the league\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.tech/v1\",\n",
    "                       openai_api_key=\"sk-kxgtm71G6zwC44lglIF5CfiEVVzjjc39TOtppkNAwrVA2fUW\", temperature=0.1)\n",
    "llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=True)\n",
    "batch_pred = llm_chain.batch(inputs, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c819dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT team\n",
      "FROM DF\n",
      "WHERE goals_for = (SELECT MAX(goals_for) FROM DF)\n",
      "AND caption = '1986 - 87 north west counties football league'\n",
      "AND team = 'flixton';\n"
     ]
    }
   ],
   "source": [
    "print(batch_pred[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d2022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is relevant information regrading the table stucture. Carefully analyze the query, based on the augmentation information you are required to infer the data distribution and format. Write an SELECT SQL statement using table DF that is most likely to provide useful information to the query.\n",
    "Query: {claim}\n",
    "Extra information: {aug}\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                                        'aug':  output.content\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3acaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import TableLoader, TableFormat\n",
    "inputs = []\n",
    "\n",
    "row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is an initial SQL statement about the query. Now you can see some smaple rows from the table, improve the sql statement so that the SQL can answer the query.\n",
    "initial SQL: {initial}\n",
    "sub-table: {table}\n",
    "Query: {claim}\n",
    "\n",
    "SQL: \"\"\")\n",
    "inputs.append(dict({\"initial\" : initial[0]['text'],\n",
    "                                        'claim': normalized_sample['query'],\n",
    "                'table': formatter.format_html(table_caption=normalized_sample['table']['caption']),\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ff859ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 31997 mintage be release in 2001\n",
      "<table>\n",
      "<thead>\n",
      "<tr><th>  year</th><th>                  mintage</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>2003  </td><td>included in hmcs bras dor</td></tr>\n",
      "<tr><td>2003  </td><td>31997                    </td></tr>\n",
      "<tr><td>2000  </td><td>44367                    </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "+--------+----------------------------+-------------------+-----------------------------+---------------+\n",
      "|   year | theme                      | artist            | mintage                     |   issue price |\n",
      "|--------+----------------------------+-------------------+-----------------------------+---------------|\n",
      "|   2000 | steam buggy                | john mardon       | 44367                       |         59.95 |\n",
      "|   2000 | the bluenose               | j franklin wright | included in steam buggy     |         59.95 |\n",
      "|   2000 | the toronto                | john mardon       | included in steam buggy     |         59.95 |\n",
      "|   2001 | the russell light four     | john mardon       | 41828                       |         59.95 |\n",
      "|   2001 | the marco polo             | j franklin wright | included in the russell     |         59.95 |\n",
      "|   2001 | the scotia                 | don curley        | included in the russell     |         59.95 |\n",
      "|   2002 | the gray - dort            | john mardon       | 35944                       |         59.95 |\n",
      "|   2002 | the william lawrence       | bonnie ross       | included in the gray - dort |         59.95 |\n",
      "|   2002 | d - 10 locomotive          | dan fell          | included in the gray - dort |         59.95 |\n",
      "|   2003 | hmcs bras dor              | don curley        | 31997                       |         59.95 |\n",
      "|   2003 | cnr fa - 1 diesel electric | john mardon       | included in hmcs bras dor   |         59.95 |\n",
      "|   2003 | bricklin sv - 1            | brian hughes      | included in hmcs bras dor   |         59.95 |\n",
      "+--------+----------------------------+-------------------+-----------------------------+---------------+\n",
      "0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from data_loader import TableFormat\n",
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "i = 0\n",
    "# SQL = manager.format_sql(preds[i]['pred'].split(':')[1])\n",
    "\n",
    "\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    columns = [c.strip() for c in preds[i]['pred'].split(',')]\n",
    "    print(data['statement'])\n",
    "    formatter.data = formatter.data.loc[:, columns]\n",
    "    \n",
    "    print(formatter.format_html())\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # data.columns = [manager.normalize_col_name(c) for c in formatter.all_data.columns]\n",
    "    # data.to_sql('DF', manager.engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # subtable = pd.read_sql(command, self.engine)\n",
    "    # test_df = manager.execute_from_df(SQL, formatter.all_data)\n",
    "    # return test_df\n",
    "test_df = show_table(table_loader.dataset[i])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b05ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer output\n",
    "pre_instruction = PromptTemplate(input_variables=[\"table\", \"claim\"], template=\n",
    "\"\"\"\n",
    "Our ultimate goal is to answer query based on the table. Below is a SQL statement which reports error or returns no result. You need to understand the logic behind the SQL filtering and rewrite SQL to guarantee the SQL return useful information. \n",
    "sub-table: {table}\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Query: {claim}\n",
    "\"\"\")\n",
    "output = model.invoke([HumanMessage(content=pre_instruction.format(table=formatter.format_html(), claim=test_sample['statement']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3084f1",
   "metadata": {},
   "source": [
    "## Evaluat from local result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e12f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from data_loader import TableLoader\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', small_test=True, use_sample=False)\n",
    "preds = []\n",
    "with open('./result/answer/tabfact_test_04-20_02-06-16.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        preds.append(json.loads(l)['pred'])\n",
    "\n",
    "print(len(preds))\n",
    "SQLs = []\n",
    "with open('./result/SQL/tabfact_test_04-20_02-04-20.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        SQLs.append(json.loads(l)['pred'])\n",
    "print(len(SQLs))\n",
    "# do evaluation\n",
    "# accuracy = eval_fv_match(pred_label, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0423d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0']\n",
      "['1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0']\n",
      "(array([  0,   1,  11,  14,  22,  24,  26,  31,  37,  38,  39,  40,  47,\n",
      "        49,  50,  59,  62,  63,  65,  66,  68,  69,  70,  75,  80,  81,\n",
      "        82,  90,  91,  93,  95,  99, 100, 105, 106, 108, 110, 116, 119,\n",
      "       124, 129, 136, 137, 145, 147, 148, 151, 153, 155, 158, 160, 164,\n",
      "       167, 169, 171, 173, 175, 179, 180, 181, 187, 188, 190, 192, 198,\n",
      "       200, 207, 209, 210, 211, 217, 225, 227, 230, 233, 236, 237, 241,\n",
      "       251]),)\n",
      "0.6901960784313725\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_tabfact\n",
    "import json\n",
    "from data_loader import TableLoader\n",
    "import numpy as np\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "labels = [table_loader.normalize_table(line)['label'] for line in table_loader.dataset][:255]\n",
    "answers = eval_tabfact('./result/answer/tabfact_test_04-20_02-06-16.json', labels, verbose=True)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c40a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0']\n",
      "(array([ 2,  3, 14, 21, 25, 27, 32, 35]),)\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_tabfact\n",
    "import json\n",
    "from data_loader import TableLoader\n",
    "import numpy as np\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=True, small_test=True)\n",
    "labels = [table_loader.normalize_table(line)['label'] for line in table_loader.dataset]\n",
    "answers = eval_tabfact('./result/answer/tabfact_test_04-18_15-20-27.json', labels, verbose=True)\n",
    "print(np.where(np.array(labels) != np.array(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1931fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = table_loader.dataset[i]\n",
    "df = pd.DataFrame(columns=data[\"table\"][\"header\"])\n",
    "for i, line in enumerate(data['table']['rows']):\n",
    "    df.loc[i] = line\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75469cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = TableFormat(format='none', data=table_loader.dataset[i])\n",
    "from functools import partial\n",
    "data_func = partial(pd.to_datetime, dayfirst=True, format='mixed')\n",
    "formatter.all_data['date'] = data_func(formatter.all_data['date'])\n",
    "formatter.all_data['date'] = pd.to_datetime(formatter.all_data['date'], format='%Y-%m')\n",
    "formatter.all_data['date'] = formatter.all_data['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b96e507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "formatter = TableFormat(format='none', data=table_loader.dataset[i])\n",
    "schema_information = pd.read_csv(f\"result/aug/tabfact_test_schema.csv\", index_col='table_id')\n",
    "formatter.normalize_schema(schema_information.loc[table_loader.dataset[i]['table']['id']]['schema'])\n",
    "formatter.all_data.to_sql('DF', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69292e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = [0,   1,  11,  14,  22,  24,  26,  31,  37,  38,  39,  40,  47,\n",
    "       49,  50,  59,  62,  63,  65,  66,  68,  69,  70,  75,  80,  81,\n",
    "       82,  90,  91,  93,  95,  99, 100, 105, 106, 108, 110, 116, 119,\n",
    "124, 129, 136, 137, 145, 147, 148, 151, 153, 155, 158, 160, 164,\n",
    "167, 169, 171, 173, 175, 179, 180, 181, 187, 188, 190, 192, 198,\n",
    "200, 207, 209, 210, 211, 217, 225, 227, 230, 233, 236, 237, 241,\n",
    "251]\n",
    "len(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695c61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 u.s. open (golf)\n",
      "2-17231086-6.html.csv\n",
      "3 of the people tie for fifth place be from the united state\n",
      "+---------+---------------------+---------------+-------------------------+----------+---------+\n",
      "| place   | player              | country       | score                   | to_par   |   money |\n",
      "|---------+---------------------+---------------+-------------------------+----------+---------|\n",
      "| 1       | curtis strange      | united states | 71 + 64 + 73 + 70 = 278 | - 2      |  200000 |\n",
      "| t2      | chip beck           | united states | 71 + 69 + 71 + 68 = 279 | - 1      |   67823 |\n",
      "| t2      | mark mccumber       | united states | 70 + 68 + 72 + 69 = 279 | - 1      |   67823 |\n",
      "| t2      | ian woosnam         | wales         | 70 + 68 + 73 + 68 = 279 | - 1      |   67823 |\n",
      "| 5       | brian claar         | united states | 71 + 72 + 68 + 69 = 280 | e        |   34345 |\n",
      "| t6      | masashi ozaki       | japan         | 70 + 71 + 68 + 72 = 281 | + 1      |   28220 |\n",
      "| t6      | scott simpson       | united states | 67 + 70 + 69 + 75 = 281 | + 1      |   28220 |\n",
      "| 8       | peter jacobsen      | united states | 71 + 70 + 71 + 70 = 282 | + 2      |   24307 |\n",
      "| t9      | paul azinger        | united states | 71 + 72 + 70 + 70 = 283 | + 3      |   19968 |\n",
      "| t9      | hubert green        | united states | 69 + 72 + 74 + 68 = 283 | + 3      |   19968 |\n",
      "| t9      | tom kite            | united states | 67 + 69 + 69 + 78 = 283 | + 3      |   19968 |\n",
      "| t9      | josé maría olazábal | spain         | 69 + 72 + 70 + 72 = 283 | + 3      |   19968 |\n",
      "+---------+---------------------+---------------+-------------------------+----------+---------+\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='tabfact', split='test', use_sample=False, small_test=True)\n",
    "# table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "i = 25\n",
    "\n",
    "def show_table(data, execute=False):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['table']['id'])\n",
    "    print(data['statement'])\n",
    "    print(formatter.format_psql())\n",
    "    # print(preds[i])\n",
    "    # print(SQLs[i])\n",
    "    # test_df = manager.execute_from_df(SQLs[i], formatter.all_data)\n",
    "    # print(test_df)\n",
    "    print(data['label'])\n",
    "print(table_loader.dataset[i]['table']['caption'])\n",
    "show_table(table_loader.dataset[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213ddfe",
   "metadata": {},
   "source": [
    "#### show wikitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e849345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt-11806\n",
      "what was the time difference between the first place finisher and the eighth place finisher?\n",
      "+--------+-----------------------+---------------+---------+\n",
      "| Rank   | Athlete               | Nationality   | Time    |\n",
      "|--------+-----------------------+---------------+---------|\n",
      "|        | Liliana Barbulescu    | Romania       | 2:00.06 |\n",
      "|        | Anna Zagórska         | Poland        | 2:00.11 |\n",
      "|        | Irina Vashentseva     | Russia        | 2:00.77 |\n",
      "| 4      | Laura Gerber          | Switzerland   | 2:01.39 |\n",
      "| 5      | Christiane dos Santos | Brazil        | 2:01.53 |\n",
      "| 6      | Tamara Volkova        | Ukraine       | 2:01.86 |\n",
      "| 7      | Tatyana Yegorova      | Russia        | 2:02.64 |\n",
      "| 8      | Sandra Teixeira       | Portugal      | 2:03.01 |\n",
      "+--------+-----------------------+---------------+---------+\n",
      "['2.95']\n"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "# table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "i = 1\n",
    "\n",
    "\n",
    "def show_table(data, execute=False):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['id'])\n",
    "    print(data['query'])\n",
    "    print(formatter.format_psql())\n",
    "    # print(preds[i])\n",
    "    # print(SQLs[i])\n",
    "    # test_df = manager.execute_from_df(SQLs[i], formatter.all_data)\n",
    "    # print(test_df)\n",
    "    print(data['label'])\n",
    "\n",
    "show_table(table_loader.normalize_table(table_loader.dataset[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0f19b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Dmitry Mikhailovich Golitsyn']\n",
      "1 ['Kyunghyun Kim', 'Christoffer Lindhe', 'Arnost Petracek', 'Ronystony Cordeiro da Silva', 'Grant Patterson', 'Arnulfo Castorena']\n",
      "2 ['Italy']\n",
      "3 ['20']\n",
      "4 ['\"Never Tell\"']\n",
      "5 ['2']\n",
      "6 ['Young Forever']\n",
      "7 ['4']\n",
      "8 ['2:07:02.8248']\n",
      "9 ['Zhu Ting']\n",
      "10 ['21']\n",
      "11 ['Canada']\n",
      "12 ['9']\n",
      "13 ['no']\n",
      "14 ['21']\n",
      "15 ['Burton Township, Ohio and Troy Township, Ohio']\n",
      "16 ['6']\n",
      "17 ['below']\n",
      "18 ['14']\n",
      "19 ['13']\n",
      "20 ['Allianz Riviera']\n",
      "21 ['10']\n",
      "22 ['2001']\n",
      "23 ['4']\n",
      "24 ['Sopwith Triplane s/n N5460']\n",
      "25 ['Mr B. Owen- Jones']\n",
      "26 ['9']\n",
      "27 ['7']\n",
      "28 ['Ryan Hunter-Reay']\n",
      "29 ['4']\n",
      "30 ['60.28 m']\n",
      "31 ['6']\n",
      "32 ['2007']\n",
      "33 ['170 cm (5 ft 7 in)']\n",
      "34 ['2']\n",
      "35 ['14']\n",
      "36 ['1982-1985']\n",
      "37 ['12']\n",
      "38 ['31']\n",
      "39 ['473,000']\n",
      "40 ['8']\n",
      "41 ['2012']\n",
      "42 ['Holon']\n",
      "43 ['Addis Ababa']\n",
      "44 ['.900 silver']\n",
      "45 ['Yugoslavia']\n",
      "46 ['7']\n",
      "47 ['Chris Van Hollen']\n",
      "48 ['Khaled Yousef Al-Obaidli']\n",
      "49 ['2']\n",
      "50 ['Kodachrome 40 film']\n",
      "51 ['Paul Christy']\n",
      "52 ['yes']\n",
      "53 ['6']\n",
      "54 ['Ramsay Carelse']\n",
      "55 ['1943/44']\n",
      "56 ['4']\n",
      "57 ['3']\n",
      "58 ['7']\n",
      "59 ['ALCO']\n",
      "60 ['Cahill', 'Colosimo', 'Culina', 'Elrich', 'Griffiths', 'Skoko', 'Zdrilic']\n",
      "61 ['4']\n",
      "62 ['7']\n",
      "63 ['Henry Picard']\n",
      "64 ['Cheng Lim']\n",
      "65 ['Yelena Proklova 49.the TV presenter']\n",
      "66 ['United States (USA)']\n",
      "67 ['2']\n",
      "68 ['6']\n",
      "69 ['12']\n",
      "70 ['Cross']\n",
      "71 ['2']\n",
      "72 ['3']\n",
      "73 ['6']\n",
      "74 ['January 19, 2013']\n",
      "75 ['October 6, 2000']\n",
      "76 ['Roy Hartsfield']\n",
      "77 ['8']\n",
      "78 ['3']\n",
      "79 ['5']\n",
      "80 ['yes']\n",
      "81 ['17']\n",
      "82 ['10']\n",
      "83 ['A World Called You']\n",
      "84 ['10']\n",
      "85 ['6']\n",
      "86 ['54']\n",
      "87 ['Ronald Reagan']\n",
      "88 ['Trinidad and Tobago']\n",
      "89 ['Bally Ache']\n",
      "90 ['Sheldon Leonard']\n",
      "91 ['10']\n",
      "92 ['Canada/United States']\n",
      "93 ['above']\n",
      "94 ['6:10.02']\n",
      "95 ['14']\n",
      "96 ['15']\n",
      "97 ['United States']\n",
      "98 ['Ravil Mingazov']\n",
      "99 ['diesel']\n",
      "100 ['5']\n",
      "101 ['6 November 1999']\n",
      "102 ['Sackett']\n",
      "103 ['NGC 1569']\n",
      "104 ['969']\n",
      "105 ['Sept 11']\n",
      "106 ['54 years']\n",
      "107 ['Julius Kahn']\n",
      "108 ['2', '6']\n",
      "109 ['2']\n",
      "110 ['10']\n",
      "111 ['U.S. Marshals']\n",
      "112 ['Tora Harris']\n",
      "113 ['252.6']\n",
      "114 ['2']\n",
      "115 ['1998']\n",
      "116 ['185']\n",
      "117 ['6']\n",
      "118 ['Chevrolet Corvette']\n",
      "119 ['Livio Berruti']\n",
      "120 ['8']\n",
      "121 ['North Korea']\n",
      "122 ['16']\n",
      "123 ['above']\n",
      "124 ['1']\n",
      "125 ['1']\n",
      "126 ['118']\n",
      "127 ['34000']\n",
      "128 ['5']\n",
      "129 ['Gabriela Szabo']\n",
      "130 ['9 years']\n",
      "131 ['2']\n",
      "132 ['2']\n",
      "133 ['245.10']\n",
      "134 ['3']\n",
      "135 ['February 22, 1998 (1998-02-22)']\n",
      "136 ['Final Crisis: Legion of 3 Worlds #2']\n",
      "137 ['less']\n",
      "138 ['Yossef Romano']\n",
      "139 ['8']\n",
      "140 ['Below']\n",
      "141 ['FmM7']\n",
      "142 ['Usher']\n",
      "143 ['14']\n",
      "144 ['Albert Wynn']\n",
      "145 ['8']\n",
      "146 ['4']\n",
      "147 ['Salford City Stadium']\n",
      "148 ['Malaysia']\n",
      "149 ['Paul Stirling']\n",
      "150 ['\"Thin Line\"']\n",
      "151 ['10']\n",
      "152 ['\"Carry Me Back to Old Tsing-Tao\"']\n",
      "153 ['Grand Prix Final']\n",
      "154 ['2010']\n",
      "155 ['3']\n",
      "156 ['7']\n",
      "157 ['295']\n",
      "158 ['3 783 069']\n",
      "159 ['33']\n",
      "160 ['Canada']\n",
      "161 ['Domenic Beninca']\n",
      "162 ['13']\n",
      "163 ['36']\n",
      "164 ['Canada']\n",
      "165 ['4']\n",
      "166 ['153P/Ikeya-Zhang']\n",
      "167 ['Yelena Kondulaynen']\n",
      "168 ['Francis Forde']\n",
      "169 ['Brazil']\n",
      "170 ['Alex Hofmann']\n",
      "171 ['October 23']\n",
      "172 ['4 years']\n",
      "173 ['1 year']\n",
      "174 ['5']\n",
      "175 ['Chevrolet']\n",
      "176 ['4']\n",
      "177 ['Half Tree Hollow']\n",
      "178 ['Jakub Janda']\n",
      "179 ['Garmisch, Germany']\n",
      "180 ['3']\n",
      "181 ['Stephen Hendry']\n",
      "182 ['3 weeks']\n",
      "183 ['63.50 m']\n",
      "184 ['R']\n",
      "185 ['Steny Hoyer']\n",
      "186 ['8']\n",
      "187 ['Indonesia']\n",
      "188 ['2009']\n",
      "189 ['Mudh Mudh Ke Na Dekh']\n",
      "190 ['1939/40']\n",
      "191 ['Joe Wolfinger']\n",
      "192 ['English']\n",
      "193 ['1992']\n",
      "194 ['Yes']\n",
      "195 ['no']\n",
      "196 ['Brașov']\n",
      "197 ['2']\n",
      "198 ['3']\n",
      "199 ['6']\n",
      "200 ['Hot Dog']\n",
      "201 ['F']\n",
      "202 ['951']\n",
      "203 ['112.93']\n",
      "204 ['Robert Lewin']\n",
      "205 ['1970']\n",
      "206 ['Rasmussen Reports']\n",
      "207 ['\"The Practical Joke War\"']\n",
      "208 ['7']\n",
      "209 ['2']\n",
      "210 ['13']\n",
      "211 ['5']\n",
      "212 ['Alina Charlin Espinal Luna']\n",
      "213 ['Kazuki Yoshino']\n",
      "214 ['4']\n",
      "215 ['Alison Fealey']\n",
      "216 ['Rachel Selway']\n",
      "217 ['2013']\n",
      "218 ['Air Commodore K. M. Ahmad']\n",
      "219 ['Brian Dowling', 'Cameron Stout']\n",
      "220 ['24']\n",
      "221 ['Philadelphia Eagles']\n",
      "222 ['9']\n",
      "223 ['6']\n",
      "224 ['Panama']\n",
      "225 ['United States']\n",
      "226 ['Ollie P. Anderson, Jr.']\n",
      "227 ['7']\n",
      "228 ['2']\n",
      "229 ['4']\n",
      "230 ['\"Lord Have Mercy\"']\n",
      "231 ['138.1']\n",
      "232 ['Maghreb']\n",
      "233 ['Oriya']\n",
      "234 ['11']\n",
      "235 ['Diana DeGette']\n",
      "236 ['2006']\n",
      "237 ['7CAE']\n",
      "238 ['Bryan Field']\n",
      "239 ['Esther']\n",
      "240 ['7']\n",
      "241 ['2012-13']\n",
      "242 ['Ishmael']\n",
      "243 ['Daytona']\n",
      "244 ['5']\n",
      "245 ['4']\n",
      "246 ['8']\n",
      "247 ['24']\n",
      "248 ['20 km walk']\n",
      "249 ['009']\n",
      "250 ['1:48:11.023']\n",
      "251 ['Foundation']\n",
      "252 ['Alex Soler-Roig']\n",
      "253 ['Paolo Bettini (ITA)']\n",
      "254 ['2']\n",
      "255 ['1']\n",
      "256 ['15']\n",
      "257 ['Port Douglas Crocs']\n",
      "258 ['5']\n",
      "259 ['8 August']\n",
      "260 ['3']\n",
      "261 ['2']\n",
      "262 ['3']\n",
      "263 ['2']\n",
      "264 ['Dr M. Shafi Ahmad']\n",
      "265 ['Sylvie Bernier (CAN)']\n",
      "266 ['more']\n",
      "267 ['1']\n",
      "268 ['John Galliano']\n",
      "269 ['UCLA']\n",
      "270 ['Jeremy McWilliams']\n",
      "271 ['15']\n",
      "272 ['4']\n",
      "273 ['7']\n",
      "274 ['no']\n",
      "275 ['16']\n",
      "276 ['1']\n",
      "277 ['Going Up!']\n",
      "278 ['4165']\n",
      "279 ['Venice, Italy']\n",
      "280 ['Rasul Kudayev']\n",
      "281 ['12']\n",
      "282 ['Yo Te Estaré Cuidando']\n",
      "283 ['Jahangir Khan']\n",
      "284 ['Partenvia P.68 Observer']\n",
      "285 ['Doug Shierson Racing']\n",
      "286 ['27.88']\n",
      "287 ['2007']\n",
      "288 ['Hotsilog: The ASAP Hotdog Compilation']\n",
      "289 ['New Orleans Saints']\n",
      "290 ['2']\n",
      "291 ['6']\n",
      "292 ['25']\n",
      "293 ['Cat Tigers']\n",
      "294 ['Left Wing']\n",
      "295 ['54,500']\n",
      "296 ['4']\n",
      "297 ['5']\n",
      "298 ['12']\n",
      "299 ['3']\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(table_loader.dataset['answers']):\n",
    "    print(ind, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1301213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu-108\n",
      "what are all of the years? what are their national cup notes?\n",
      "+---------+------------+----------+------------------------+-----------------------+----------------+\n",
      "| Year    |   Division | League   | Reg_Season             | Playoffs              | National_Cup   |\n",
      "|---------+------------+----------+------------------------+-----------------------+----------------|\n",
      "| 1934/35 |        nan | ASL      | 6th                    | No playoff            | ?              |\n",
      "| 1935/36 |        nan | ASL      | 2nd                    | No playoff            | ?              |\n",
      "| 1936/37 |        nan | ASL      | 2nd, American          | 1st Round             | ?              |\n",
      "| 1937/38 |        nan | ASL      | 4th, American          | Did not qualify       | ?              |\n",
      "| 1938/39 |        nan | ASL      | 5th, American          | Did not qualify       | ?              |\n",
      "| 1939/40 |        nan | ASL      | 2nd(t)                 | No playoff            | Co-champion    |\n",
      "| 1940/41 |        nan | ASL      | 3rd                    | No playoff            | ?              |\n",
      "| 1941/42 |        nan | ASL      | 5th                    | No playoff            | ?              |\n",
      "| 1942/43 |        nan | ASL      | 5th                    | No playoff            | ?              |\n",
      "| 1943/44 |        nan | ASL      | 3rd                    | No playoff            | ?              |\n",
      "| 1944/45 |        nan | ASL      | 4th                    | No playoff            | ?              |\n",
      "| 1945/46 |        nan | ASL      | 1st                    | Champion (no playoff) | ?              |\n",
      "| 1946/47 |        nan | ASL      | 4th                    | No playoff            | ?              |\n",
      "| 1947/48 |        nan | ASL      | 4th                    | No playoff            | ?              |\n",
      "| 1948/49 |        nan | ASL      | Withdrew after 3 games | nan                   | nan            |\n",
      "+---------+------------+----------+------------------------+-----------------------+----------------+\n",
      "['?', '?', '?', '?', '?', 'Co-champion', '?', '?', '?', '?', '?', '?', '?', '?', 'N/A']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# sum, ope = split_answer(data[ind]['predict'])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print(ope)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(manager.format_sql(ope, table_name='DF'))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m show_table(table_loader\u001b[38;5;241m.\u001b[39mnormalize_table(table_loader\u001b[38;5;241m.\u001b[39mdataset[i])) \n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_sql\u001b[49m[i])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_data[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_sql' is not defined"
     ]
    }
   ],
   "source": [
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "from data_loader import TableLoader, TableFormat\n",
    "table_loader = TableLoader(table_name='sqa', split='test', use_sample=True)\n",
    "i = 124\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['id'])\n",
    "    print(data['query'])\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # sum, ope = split_answer(data[ind]['predict'])\n",
    "    # print(ope)\n",
    "    # print(manager.format_sql(ope, table_name='DF'))\n",
    "show_table(table_loader.normalize_table(table_loader.dataset[i])) \n",
    "print(all_sql[i])\n",
    "print(all_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860f3ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7e1daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the country of ecuador be the only country that use the us dollar (usd) as its currency , and the central bank be the federal reserve\n",
      "economy of south america\n",
      "+-----------+---------------------------------+--------------+-------------+------------------------------+\n",
      "| country   | currency                        |   c_1_euro_= |   c_1_usd_= | central_bank                 |\n",
      "|-----------+---------------------------------+--------------+-------------+------------------------------|\n",
      "| argentina | argentine peso (ars)            |      5.65    |      4.2    | central bank of argentina    |\n",
      "| bolivia   | bolivian boliviano (bob)        |     11.0985  |      7.5708 | central bank of bolivia      |\n",
      "| brazil    | brazilian real (brl)            |      2.58963 |      1.7665 | central bank of brazil       |\n",
      "| chile     | chilean peso (clp)              |    701.02    |    507.58   | central bank of chile        |\n",
      "| colombia  | colombian peso (cop)            |   2593.2     |   1885.74   | bank of the republic         |\n",
      "| ecuador   | us dollar (usd)                 |      1.46611 |      1      | federal reserve              |\n",
      "| guyana    | guyanese dollar (gyd)           |    297.547   |    202.95   | bank of guyana               |\n",
      "| paraguay  | paraguayan guaraní (pyg)        |   6802.74    |   4640      | central bank of paraguay     |\n",
      "| peru      | peruvian nuevo sol (pen)        |      4.26966 |      2.7244 | central reserve bank of peru |\n",
      "| suriname  | surinamese dollar (srd)         |      4.10543 |      2.8    | central bank of suriname     |\n",
      "| uruguay   | uruguayan peso (uyu)            |     31.1529  |     21.247  | central bank of uruguay      |\n",
      "| venezuela | venezuelan bolívar fuerte (vef) |      6.16331 |      4.3    | central bank of venezuela    |\n",
      "+-----------+---------------------------------+--------------+-------------+------------------------------+\n",
      "1\n",
      "0 the scheduled date for the farm with 17 turbine be 2012\n",
      "1 all 12 club play a total of 22 game for the wru division one east\n",
      "2 touchdown atlantic , in the category of sporting , be establish in 2010\n",
      "3 the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "4 in 1980 , 1981 and 1985 pat bradley (golfer) not have the average of 278 win score\n",
      "5 polona hercog partner with alberta brianti after she have stephanie vogt as the partner\n",
      "6 a gamecube game loss the award in each of the first 3 year\n",
      "7 scotland be the country with the least point\n",
      "8 only 1 of the college list be public , and it be in new orleans\n",
      "9 19.30 million viewer watch the season finale on march 12 , 1979\n",
      "10 the player garrett sutherland who be in lb position have a pick of 22\n",
      "11 st joseph 's catholic school be a state integrated school in te kuiti for year 1 - 8\n",
      "12 when north melbourne be the home team , they face away team footscray who score 8.9 (57)\n",
      "13 gene donaldson from purdue be pick in the third round\n",
      "14 the away team at prince park have a score of 13.12 (90)\n",
      "15 during the 1926 - 27 new york ranger season , game 26 , 29 , 30 , and 34 be all score in overtime\n",
      "16 a show with airdate 2 january 2010 and 4 couple have 3.87 million viewer\n",
      "17 the most total point score by the knicks in a single game be 126\n",
      "18 the show , my thursday night movie , be on at 9:00 when it be also on at 8:30\n",
      "19 jean behra be not 1 of the driver who have ferrari as their constructor\n",
      "20 the most recent locomotive to be manufacture be make more 10 year after the first to be manufacture\n",
      "21 the largest attendance for a new jersey home game in december be against the ny ranger\n",
      "22 nova scotia and prince edward island have the earliest effective date with indiana have the second early effective date\n",
      "23 during the 1987 master tournament , both tommy aaron and billy casper have a total of 305\n",
      "24 during all competition they have at least 1 draw each time\n",
      "25 when there be 161 receiving yard , there be 22 reception\n",
      "26 gene hartley finish in the same position in 1952 and 1953\n",
      "27 argentinos junior be the home team for the 2nd leg of the match with an aggregate of 2 - 3\n",
      "28 kelly jones and david pate win the match they play\n",
      "29 kim fogh replace the previous manager on 1 january 2011\n",
      "30 on october 2 when the royal be the opponent the score be 5 - 1\n",
      "31 the lowest score reach be 109 score in both game 22 and 23\n",
      "32 the montreal maroon play in 9 overtime game during the 1925 - 26 season\n",
      "33 jason richardson be their leading scorer 4 time that month , with at least 23 point per game\n",
      "34 ghatge 's most recent film be in hindi\n",
      "35 katie taylor win 2 event in the same city between 2005 and 2013\n",
      "36 the xiao hong crater be 0 , 7 km larger in diameter than the ximena crater\n",
      "37 the garden of evil and mission to venus both do not have ibsn number list for the us\n",
      "38 the episdode , live and let doyle air on january 12 , 2011 , be the most viewed episode\n",
      "39 there be more than 2 driver with 23 lap\n",
      "40 on game 45 , jr smith have the most point with the score of 97 - 92\n",
      "41 michael j maker be the trainer in the year 2012\n",
      "42 the difference between the highest number of high point and the lowest number of high point be 22\n",
      "43 calgary unite fc never play any game in 2009\n",
      "44 the only south african player take the fifth position\n",
      "45 the most laps any driver complete during the race be 75\n",
      "46 chick harbert , who lead with 68 before round 1 , finish round 2 with 73 and go down to third with ted kroll\n",
      "47 during the 1996 men 's world ice hockey championship , there be 1 more 1 loss than 4 loss\n",
      "48 the original round 5 game against read have to be replay on february 27\n",
      "49 curtis galick be from harvard college\n",
      "50 raymond sommer be the winner on 4 occasion in the 1946 season\n",
      "51 on 2013 - 05 - 26 molina have the lowest total goal during the k league classic\n",
      "52 the difference in area between the province west cape and gauteng is129462\n",
      "53 8 different bird be feature on the loonie between 2002 and 2012\n",
      "54 the award that ronnie mitchell have be nominate for most often be sexy female\n",
      "55 danny webb be 1 of 2 people to have have an accident during the race\n",
      "56 when the double (aids related) number be 41000 , and the paternal (total) be larger than 442000 then there be 24.6% orphan\n",
      "57 division 2 did not qualify for playoff after year 1993\n",
      "58 the aggregate when the third leg be 1 - 3 be 4 - 2\n",
      "59 in 2008 , the school with the nickname eagle join the mac\n",
      "60 during the 1948 vfl season , lake oral venue record the lowest crowd participation\n",
      "61 : clyde be the opponent for 2 game\n",
      "62 sergey gorovoy be the second youngest player in the team\n",
      "63 ricky newman retire from aldershot town fc on before may of 2009\n",
      "64 the march 86c chassis be use by 2 different team in the same year\n",
      "65 monta elli and matt barnes be lead scorer the most time\n",
      "66 3 of the 8 be radio station cover news in fargo - moorhead\n",
      "67 woman from 5 different country take part in this round of the 2008 woman 's british open\n",
      "68 the highest car number in the 2008 nascar craftsman truck series be 74\n",
      "69 charles martin and brian noble have 3.0 sack each , but neither 1 have any yard or interception\n",
      "70 when she be a runner - up the score be 6 - 4 , 6 - 3\n",
      "71 randall zisk direct 2 episode in all of season 4 , the least of the season\n",
      "72 the number of career cap for a full back be 0 when tour apps be smaller than 29\n",
      "73 the lowest attendance figure for a game be 37230\n",
      "74 the most point score by a celtic player in a game be 35\n",
      "75 the name of the visiting team who play home team chicago black hawk on march 20 be the boston bruin\n",
      "76 marco ravaioli , michael ranseder , takaaki nakagami , and esteve rabat all have to end the race early due to accident\n",
      "77 best new actor be the least common category that he be nominate for\n",
      "78 western oval have carlton as the home team\n",
      "79 douglas vandor cameron sylvester finish before any other team of rower\n",
      "80 panther have only 2 location\n",
      "81 stirling moss win the xiii barc aintree 200 on 20 july 1958\n",
      "82 mexico win the highest number of medal with fifty 7\n",
      "83 april 20 , 2009 be when episode 3 air\n",
      "84 tich freeman be on the record list 3 time , while colin blythe be only on the list 1 time\n",
      "85 52500 be the prize money for texas\n",
      "86 frederick fane be feature as an away captain at more venue than arthur jones\n",
      "87 the trojan be the mascot for the team that join the conference immediately after south newton\n",
      "88 there be a low attendance of 14007 against the devil ray on may 13\n",
      "89 mike eruzione score 92 goal from 1973 - 77\n",
      "90 both the tiger and the ranger be the 2 team that they play 3 time each\n",
      "91 there be only 2 people name sara / sarah show as centerfold\n",
      "92 the washington redskins lose a total of 8 game during their 1952 season\n",
      "93 robert wickens accumulate 4 more point than johnathan bomarito\n",
      "94 the team that earn the highest number of point for and point against be the team that win the most game\n",
      "95 vitória play after river plate\n",
      "96 there be 1 more team classification of euskaltel - euskadi than there be of caisse d'epargne\n",
      "97 freddie jackson 's status be advanced\n",
      "98 the league conference north happen 3 time\n",
      "99 the label before 1969 be columbia\n",
      "100 uraga dock company produce the most destroyer on the list , at 3\n",
      "101 peter mikkelsen only win the men 's single 1 time in 2007\n",
      "102 Örgryte be have the fewest allsvenskan title among the club list in the chart\n",
      "103 gloria moon be on the 2002 and 1999 commission\n",
      "104 multiple volleyball club be establish in st petersburg prior to 1940\n",
      "105 the queen 's birthday clash with the lowest attendance be in 2007\n",
      "106 al bridge in maryland be in the washington county\n",
      "107 5 player end their career in 2009\n",
      "108 the 14th game be the first game play at the summit and result in a 110 - 100 score\n",
      "109 for konstantopoulos , the loan club be coventry city and the start source be cardiff city\n",
      "110 the player of united state nationality be draft after john westin\n",
      "111 phil mickelson and mike weir in 2003 and 2004 be able to interrupt tiger wood streak\n",
      "112 davíd garza pérez participate in more race during the 2006 season than any other year\n",
      "113 northern ireland do not score more than 1 goal in any of the match list\n",
      "114 there be 2 player with the last name of elli on the roster\n",
      "115 22210 attend the tie between sheffield united and middlesbrough\n",
      "116 luigi riva be 1 of 3 people in 18th place\n",
      "117 when the week 15 result be michigan (7 - 2) the week 10 result be washington (7 - 1)\n",
      "118 in 1989 , boris becker be champion with alexander volkov as runner - up , and in 1989 , boris becker be the champion with alexander volkov as runner - up\n",
      "119 0 total win be associate with event with 2 top - 5s\n",
      "120 the united state be home to the most player with 9\n",
      "121 alfa romeo flat - 12 engine race in 1974 by martini racing\n",
      "122 darren kotania be the director and the episode for episode 1 of be you afraid of the dark season 3 be 1\n",
      "123 cristina teuscher be 1 of 2 american swimmer in the 200 meter event medley\n",
      "124 from 1980 to 2011 , apoel bc lose more than 2 time as many game as it win\n",
      "125 of the 14 game play during the month of january , exactly half be home game for the cavalier\n",
      "126 only 4 of the fight go the full 12 round\n",
      "127 sorana cîrstea have a 1r in all the tournament in 2012\n",
      "128 there be 4 win as result , while there be only 2 loss\n",
      "129 chauncey billups (8) have the high assist on april 17 , but share the high assist with anthony carter on april 23\n",
      "130 the country of ecuador be the only country that use the us dollar (usd) as its currency , and the central bank be the federal reserve\n",
      "131 both paraguay and peru use the us dollar\n",
      "132 only 1 player be in the pg position\n",
      "133 on october 4 the record be 90 - 68 when the royal be the opponent\n",
      "134 the episode title hare - abian night be 1 of 10 episode in the mm series\n",
      "135 wesley person lead in rebound on may 1\n",
      "136 1 more season premièred on september 20 than on september 21\n",
      "137 3 player have a - 2 to par and they be jack nicklaus , arnold palmer , and lee trevino\n",
      "138 cartagena fc and real oviedo have a draw of 14 with 44 game play\n",
      "139 the stadium for both of the game of the host team baltimore raven be the m&t bank stadium\n",
      "140 the mcg venue home team be richmond\n",
      "141 the 2006 connecticut sun lose their first 5 game int he month of june\n",
      "142 tumble rfc have win 20 out of 22 of the game they have play\n",
      "143 the entire kawasaki racing team be able to race in all of the round\n",
      "144 carpet be the surface for 16 april 2007\n",
      "145 the only 3 right hand batter be bear within 21 month of each other\n",
      "146 in 2008 , the chunnam dragon beat chonburi 1 - 0\n",
      "147 mauna kea be the summit in the rank 1 , and have a col (m) of 0\n",
      "148 the highest score achieve be 109 score in both game 22 and 23\n",
      "149 the shortest time be 11:44 when jbl be eliminate by jericho\n",
      "150 4 of the segment c show feature foodstuff : plantain chip , soda cracker , sugar , and goat cheese\n",
      "151 all but 1 game in the season have 53 game\n",
      "152 the hmjs surrey have a length of 42.8 m , and its max speed be faster than the hmjs fort charles (p 7) max speed\n",
      "153 the hispanic sounding character mimi be primarily cast by dutch woman\n",
      "154 there be 2 event at donington park in 1994\n",
      "155 brazil 's gold and silver medal be down a total of 10\n",
      "156 jack nicklaus have less than double the win of the rank 2 player\n",
      "157 the least amount of point the fire score in a game be 1\n",
      "158 the match between cowdenbeath and the ranger have a higher attendance than the game between ross county and the ranger\n",
      "159 the senate have an election in 1977 , 1978 and 1979\n",
      "160 since 2000 , there have be 4 match rank in the top 42 for attendance\n",
      "161 the result of the election , in which the incumbent be denver s church , be re - elect\n",
      "162 happy howl - o - ween 4 episode after freaky day / dog tire\n",
      "163 at the weightlifting at the 2008 summer olympics - men 's 105 kg , dmitry berestov snatch more weigth than marcin dołęga\n",
      "164 7 of the 10 bike be manufacture by zabel\n",
      "165 2 team score exactly 139 point during round 20 of the 1978 vfl season\n",
      "166 in april 1992 , ryan stile be the performer 2 time\n",
      "167 craig miller be the youngest water polo player list\n",
      "168 mapiu school have the highest roll in the state authority\n",
      "169 heikki kovalainen earn one lose in his formula one racing career\n",
      "170 the central bank for guyana and argentina be call the federal reserve\n",
      "171 on the earliest date , the score be 6 - 4 , 6 - 4\n",
      "172 john waite won series 3 , while miranda gore browne be 1 runner - up in series 1\n",
      "173 like like a dog / cold fish be list as have the highest number of us viewer\n",
      "174 slovan bratislava be the opponent the year brfore the fight against eintracht frankfurt\n",
      "175 the record in the 100 m freestyle event be set in 2007\n",
      "176 the ireland in the eurovision song contest in 1989 have the real me place 1 rank higher than easy\n",
      "177 dean semmens be not 1 of the 3 player bear after 1981\n",
      "178 on entertainment tonight , diresta be on at 7:30 , follow by cosby at 8:00\n",
      "179 in 1983 , aberdeen win\n",
      "180 mark fellow write 3 big time rush episode\n",
      "181 nick faldo be 1 of 2 player that finish in first place\n",
      "182 the penrith panther have a score of 60 - 17 at sydney football stadium in 2006\n",
      "183 the lowest attendance be 13831\n",
      "184 the team rusport have a 1:25.361 in qual 2\n",
      "185 the new york jet score more point against the houston oiler than the new orleans saint\n",
      "186 catawba and oneota both have the name change 1 time the canonicus - class monitor\n",
      "187 all of the ship in the bolitho novel be classify as frigate\n",
      "188 sam mcgregor be the youngest water polo player list\n",
      "189 d a weibring have less to par point than seve ballesteros\n",
      "190 only 1 of the top 3 winner be a group act\n",
      "191 gracia baylor 's term of office end after that of the member for higinbotham\n",
      "192 the team pacific coast motorsports have a 1:26.582 best record\n",
      "193 the tarija department have 12755 small (100ha) and 17101 medium (500ha)\n",
      "194 incumbent del latta be from district ohio 5\n",
      "195 fm 100.5 , which the note state be license to hope , play child 's music\n",
      "196 jens hammer sørensen leave by mutual consent and be replace by jakob michelsen\n",
      "197 seve ballesteros finish ahead of mike reid by 1 shot , and make 4400 more than him\n",
      "198 singer elvis costello cover a song from the alum the hissing of summer lawn\n",
      "199 only 1 role be the leading role\n",
      "200 the september 17 1997 match against košice have the lowest attendance rate of the season\n",
      "201 the rating (kansai) for the original air date may 25 , 2010 be 15.5\n",
      "202 the maserati win the 1946 grand prix season on 9 occasion\n",
      "203 there be 7 unspecified specie and 5 unspecified strain\n",
      "204 cuba have the second highest number of total medal among all nation\n",
      "205 the railway with a loco name of the pyramus and a build of 1912 be smr\n",
      "206 ted kroll lead lew warsham by 3 stroke at the end of round 2 in the 1953 master tournament\n",
      "207 college / junior / club team kitchener ranger (omjhl) make the 22 pick for the centre position\n",
      "208 finland be the country with the least point\n",
      "209 there be a total of 10267578 gaelic speaker in all council area\n",
      "210 wang xiaoli yu yang win womens double after 2010\n",
      "211 the game on 12 october 2012 , 10 september 2013 , and 19 november 2008 have a result of 1 - 0\n",
      "212 kaitlyn lawes be the skip and liz peter be the lead for canada\n",
      "213 the general classification be silvano contini only 1 time and that be stage 18\n",
      "214 irving romaine have over 1 hundred run more than david hemp\n",
      "215 the only game in manchester , england have a record of 5 - 2\n",
      "216 the average attendance for the series be 52424.40 crowd\n",
      "217 6 driver complete 75 lap , while only 1 driver complete 74 lap\n",
      "218 the attendance for all of the home game be over 77000 at each game\n",
      "219 bagnères - de - bigorre be a leader in 1948 with a stage number 18.0\n",
      "220 kansa city lose all 7 game with attendance of 47310 or greater during the 1978 season\n",
      "221 the spelling of יְהוֹשָפָט in english would be jehoshaphat\n",
      "222 the festival of pacific art be hold at a different location in the pacific every time\n",
      "223 toronto win all 7 of their home game in december of their 2007 - 2008 season\n",
      "224 erkranas and hjk helsinki have the highest agg score during the qualifying round\n",
      "225 the total number of run for and against for april be 173\n",
      "226 the eagle have 2 game where they score 0 point total\n",
      "227 12 - 26 - 1 be the record for detroit and decision of denis on december 30\n",
      "228 the venue mcg be home to the melbourne team\n",
      "229 there be no school that aren't coed and not under the authority of state integrate in the hawke 's bay region\n",
      "230 there be 1 round hold in nevada , united state with a time of 1:55\n",
      "231 the attendance on december 16 at washington redskin be 49484\n",
      "232 opponent albert montañés santiago ventura score 1 - 6 , 2 - 6 in the final\n",
      "233 during the supplemental first round selection , more than 6 people be select in the position rhp\n",
      "234 at the world mind sport game , japan 1 more bronze than israel have\n",
      "235 in international friendly , england always score at least 2 goal\n",
      "236 trina feature more than 3 release on the kontor house of house vol 13 (compilation album)\n",
      "237 bernard mceveety be a director on season 3\n",
      "238 the sum roll of karaka area be 442\n",
      "239 there be 5 game with the goal against over 44 and a goal difference of 11\n",
      "240 on 6 may 1917 , the aircraft locate at s of avion be the sopwith 1 1 / 2 strutter (a1010)\n",
      "241 in the pga championship greg norman be 5 top 5 finish and 6 top 10 finish\n",
      "242 the lowest decile be 1\n",
      "243 limpopo have a population with fewer people than eastern cape\n",
      "244 lord 's be the venue when the result be eng by wkt and the date be 10 , 12 , 13 aug 1902 with joe darling as the home captain\n",
      "245 °56′52″ be the declination ( j2000 ) for constellation of ophiuchus and have an apparent magnitude less than 8.6 with a right ascension ( j2000 ) of 16h47 m14.5s\n",
      "246 the minardi team spa use the minardi m187 chassis 5 out of the 8 time they enter between 1985 and 1987\n",
      "247 tim duncan be the lead athlete when the spur play the king\n",
      "248 more game start at 1:00 pm than at any other time\n",
      "249 the original air date of the episode with a production code of 3x6316 be february 21 , 2011\n",
      "250 iran end up in the top 5 in 7 of the 13 year they participate in the game\n",
      "251 jimmy robertson have a higher number of a (not participating in a tournament) in 2003 / 04 than in 2010 / 11\n",
      "252 3 of the musical guest song have the word the in its name\n",
      "253 mike miller score the highest assist and highest rebound 1 time each in november , but never have the highest point\n",
      "254 dieter kindlmann play as a partner in the tournament in rimini , italy\n",
      "255 maria kirilenko nadia petrova win both 2012 and 2013 french open competition\n",
      "256 pick 27 have a name of jaimie thomas who have a round of 7\n",
      "257 the toronto blue jay do not win the first or last game of the season\n",
      "258 the match in australia on 5 september 1998 , the score be 4 - 1\n",
      "259 when the 1st round be 2 - 0 and when team 2 be stade brestois (d1) the score be 5 - 3\n",
      "260 alberta have a more population density even though it have 4257744 less people in 2011\n",
      "261 adriano buzaid have the fastest lap when dean stoneman be the winning driver and alexander sims have the pole position\n",
      "262 there be 8 country that win their first french open men 's double championship before the year 1950\n",
      "263 the ottawa senator boston bruins be the only 2 team the maroon play in back - to - back game against\n",
      "264 colin montgomerie finish with the same score as tom kite\n",
      "265 when the cycle be less than 2 , the premiere date be april 6 , 2008\n",
      "266 detroit red wing be the only team beat with the least record\n",
      "267 jarno trulli be 1 of 2 driver to retire due to collision damage , after only 2 lap\n",
      "268 the hornet start march with more loss than win on their record\n",
      "269 the hawthorn team score the lowest of any of the home team in 1982 while play at prince park\n",
      "270 tim duncan have the highest number of high assist with 12 , and michael finley alone have the lowest number of high assist with 4\n",
      "271 juan manuel fangio be the sole driver who have maserati as their constructor\n",
      "272 when the place be 9th the date be 28 feb 1987 with location furano , japan and when the place be 5th the location be kitzbühel , austria with a date of 17 jan 1986\n",
      "273 the lowest value of paraguayan guaraní issue be 100000\n",
      "274 tony parker have the highest high point (30) and the lowest number of high point (19)\n",
      "275 the most amount of bronze a team with more than 2 silver have be more than 6.0\n",
      "276 sol de américa have 5 loss and be in last place\n",
      "277 the charger end the regular season with a 4 - 12 record in 2003\n",
      "278 in 1981 the yamaha team have 20 point\n",
      "279 the tenth wicket partnership have more than 59 run in the list\n",
      "280 the highest attendance be 2973 on 29 march 2008 and the lowest be 545 on 19 april 2008\n",
      "281 the first leg list for river plate be 0 - 2\n",
      "282 there be 6 stadium that have a limited capacity of 1000 and 2 with a capacity over 10000\n",
      "283 the lowest attendance show in the 2008 afl season be 18875\n",
      "284 south melbourne and essendon tie for the highest score of all team\n",
      "285 the lowest roll in the list of school be the kotemaori school with 6 , follow by mohaka school with 36\n",
      "286 yang (9:43) be first in front of sato (8:32)\n",
      "287 dominik meffert win all of the match list\n",
      "288 3 player be from russia , 2 from czechoslovakia , 4 from canada , and 1 each from sweden and latvia\n",
      "289 most of the people who play for the 1987 master tournament be from united state\n",
      "290 out of 5 game that boston play in 1975 - 1976 , paul west paul score the highest number of point in 3 of the game\n",
      "291 round larger than 2 and a position of guard involve george college\n",
      "292 on september 13 , september 15 , and september 29 the attendance be exactly the same with 50315 crowd\n",
      "293 goal 2 - 5 be all consider 2007 copa américa competition\n",
      "294 the nomad miss the quarter - final in 2010 and 2011\n",
      "295 the shark be pick second for all 6 year\n",
      "296 in the best families be the title when the season be less than 1.8 and first broadcast be march 6 , 1981\n",
      "297 episode 2 , dennis get divorce , be direct by randall einhorn\n",
      "298 india 's rank be tie with england 's\n",
      "299 in the benin and morocco match the final score be 8 - 2\n"
     ]
    }
   ],
   "source": [
    "# show table query\n",
    "#debugger\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from executor import SQLManager\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///db/sqlite/tabfact.db', echo=False)\n",
    "manager = SQLManager(engine)\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True)\n",
    "def show_table(data):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['statement'])\n",
    "    print(data['table']['caption'])\n",
    "    # print(formatter.format_html())\n",
    "    print(formatter.format_psql())\n",
    "    print(data['label'])\n",
    "    # data.columns = [manager.normalize_col_name(c) for c in formatter.all_data.columns]\n",
    "    # data.to_sql('DF', manager.engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # subtable = pd.read_sql(command, self.engine)\n",
    "    # test_df = manager.execute_from_df(SQL, formatter.all_data)\n",
    "    # return test_df\n",
    "# test_df = show_table(table_loader.dataset[i])\n",
    "show_table(table_loader.dataset[130])\n",
    "for ind, i in enumerate(table_loader.dataset['statement']):\n",
    "    print(ind, i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769844d",
   "metadata": {},
   "source": [
    "### Evaluate SQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8af6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6bf99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "all_data = []\n",
    "all_sql = []\n",
    "with open('./result/answer/sqa_test_04-15_11-44-40.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        data = json.loads(l)\n",
    "        all_data.append(data)\n",
    "print(len(all_data))\n",
    "with open('./result/SQL/sqa_test_04-15_10-35-18.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        data = json.loads(l)\n",
    "        all_sql.append(data)\n",
    "print(len(all_sql))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9aa0e9",
   "metadata": {},
   "source": [
    "### Evaluate WikiTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c33ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import recognizers_suite\n",
    "import recognizers_suite as Recognizers\n",
    "from recognizers_text import Culture, ModelResult\n",
    "def str_normalize(user_input, recognition_types=None):\n",
    "    \"\"\"A string normalizer which recognize and normalize value based on recognizers_suite\"\"\"\n",
    "    user_input = str(user_input)\n",
    "    user_input = user_input.replace(\"\\\\n\", \"; \")\n",
    "\n",
    "    def replace_by_idx_pairs(orig_str, strs_to_replace, idx_pairs):\n",
    "        assert len(strs_to_replace) == len(idx_pairs)\n",
    "        last_end = 0\n",
    "        to_concat = []\n",
    "        for idx_pair, str_to_replace in zip(idx_pairs, strs_to_replace):\n",
    "            to_concat.append(orig_str[last_end : idx_pair[0]])\n",
    "            to_concat.append(str_to_replace)\n",
    "            last_end = idx_pair[1]\n",
    "        to_concat.append(orig_str[last_end:])\n",
    "        return ''.join(to_concat)\n",
    "\n",
    "    if recognition_types is None:\n",
    "        recognition_types = [\n",
    "            \"datetime\",\n",
    "            \"number\",\n",
    "            \"ordinal\",\n",
    "            \"percentage\",\n",
    "            \"age\",\n",
    "            \"currency\",\n",
    "            \"dimension\",\n",
    "            \"temperature\",\n",
    "        ]\n",
    "    culture = Culture.English\n",
    "    for recognition_type in recognition_types:\n",
    "        if re.match(\"\\d+/\\d+\", user_input):\n",
    "            # avoid calculating str as 1991/92\n",
    "            continue\n",
    "        recognized_list = getattr(\n",
    "            recognizers_suite, \"recognize_{}\".format(recognition_type)\n",
    "        )(\n",
    "            user_input, culture\n",
    "        )  # may match multiple parts\n",
    "        strs_to_replace = []\n",
    "        idx_pairs = []\n",
    "        for recognized in recognized_list:\n",
    "            if not recognition_type == 'datetime':\n",
    "                recognized_value = recognized.resolution['value']\n",
    "                if str(recognized_value).startswith(\"P\"):\n",
    "                    # if the datetime is a period:\n",
    "                    continue\n",
    "                else:\n",
    "                    strs_to_replace.append(recognized_value)\n",
    "                    idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "            else:\n",
    "                if recognized.resolution:  # in some cases, this variable could be none.\n",
    "                    if len(recognized.resolution['values']) == 1:\n",
    "                        strs_to_replace.append(\n",
    "                            recognized.resolution['values'][0]['timex']\n",
    "                        )  # We use timex as normalization\n",
    "                        idx_pairs.append((recognized.start, recognized.end + 1))\n",
    "\n",
    "        if len(strs_to_replace) > 0:\n",
    "            user_input = replace_by_idx_pairs(user_input, strs_to_replace, idx_pairs)\n",
    "\n",
    "    if re.match(\"(.*)-(.*)-(.*) 00:00:00\", user_input):\n",
    "        user_input = user_input[: -len(\"00:00:00\") - 1]\n",
    "        # '2008-04-13 00:00:00' -> '2008-04-13'\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE), \" \", text)\n",
    "\n",
    "    def whilt_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return whilt_space_fix(remove_articles(remove_punc(lower(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f55ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, re, argparse\n",
    "import unicodedata\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "################ String Normalization ################\n",
    "\n",
    "def normalize(x):\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "    while True:\n",
    "        old_x = x\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        if x == old_x:\n",
    "            break\n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "################ Value Types ################\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "################ Value Instantiation ################\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "################ Check the Predicted Denotations ################\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    return True\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b7d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from ./result/data/wikitable/tagged/data/training.tagged\n",
      "Reading dataset from ./result/data/wikitable/tagged/data/pristine-unseen-tables.tagged\n",
      "Reading dataset from ./result/data/wikitable/tagged/data/pristine-seen-tables.tagged\n"
     ]
    }
   ],
   "source": [
    "tagged_dataset_path = './result/data/wikitable/tagged/data'\n",
    "target_values_map = {}\n",
    "for filename in os.listdir(tagged_dataset_path):\n",
    "    if filename[0]=='.':\n",
    "        continue\n",
    "    filename = os.path.join(tagged_dataset_path, filename)\n",
    "    print('Reading dataset from', filename)\n",
    "    with open(filename, 'r', 'utf8') as fin:\n",
    "        header = fin.readline().rstrip('\\n').split('\\t')\n",
    "        for line in fin:\n",
    "            stuff = dict(zip(header, line.rstrip('\\n').split('\\t')))\n",
    "            ex_id = stuff['id']\n",
    "            original_strings = tsv_unescape_list(stuff['targetValue'])\n",
    "            canon_strings = tsv_unescape_list(stuff['targetCanon'])\n",
    "\n",
    "            target_values_map[ex_id] = to_value_list(\n",
    "                original_strings, canon_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb2ff2",
   "metadata": {},
   "source": [
    "##### read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b921332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./result/answer/wikitable_zh_05-01_15-49-08.csv', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b178d62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d1bfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final_answer'] = data['preds'].apply(lambda x: x.split('Answer:')[-1].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "661be5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>statements</th>\n",
       "      <th>ids</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thought: \\n1. The SQL query filters the DF tab...</td>\n",
       "      <td>did dmitry mikhailovich golitsyn or andrey kir...</td>\n",
       "      <td>nu-3365</td>\n",
       "      <td>Andrey Kirillovich Razumovsky served as ambass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thought: \\n1. Look at the sub-table and find t...</td>\n",
       "      <td>which person(s) had a time of at least 40 seco...</td>\n",
       "      <td>nu-3138</td>\n",
       "      <td>Kyunghyun Kim, Christoffer Lindhe, Arnost Petr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thought: \\n1. The query is counting the number...</td>\n",
       "      <td>what country had the largest number of drivers?</td>\n",
       "      <td>nu-2135</td>\n",
       "      <td>The country with the largest number of drivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thought: The SQL query is counting the total n...</td>\n",
       "      <td>what is the total number of competition?</td>\n",
       "      <td>nu-290</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought: The SQL query is selecting the \"Episo...</td>\n",
       "      <td>the title of the last show was...</td>\n",
       "      <td>nu-3940</td>\n",
       "      <td>\"Never Tell\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thought: The SQL query is selecting the count ...</td>\n",
       "      <td>what is the total number of games played again...</td>\n",
       "      <td>nu-4028</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering for t...</td>\n",
       "      <td>which episode came first, young forever or you...</td>\n",
       "      <td>nu-3762</td>\n",
       "      <td>There are no episodes with the titles \"Young F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thought: \\n- The SQL query selects the count o...</td>\n",
       "      <td>how many top goalscorers have 30 or more goals?</td>\n",
       "      <td>nu-1889</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thought: \\nTo determine how long it took Ryan ...</td>\n",
       "      <td>how long did it take ryan briscoe to finish th...</td>\n",
       "      <td>nu-336</td>\n",
       "      <td>To calculate how long it took Ryan Briscoe to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thought: \\nWe need to find the player who scor...</td>\n",
       "      <td>who is china's top scorer in friendly matches?</td>\n",
       "      <td>nu-2563</td>\n",
       "      <td>Cannot get answer from sub-table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the \"...</td>\n",
       "      <td>how many candidates are over 1.8 meters tall?</td>\n",
       "      <td>nu-3430</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the column...</td>\n",
       "      <td>who has the most quantity of all nations?</td>\n",
       "      <td>nu-174</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thought: \\n- The sub-table generated by the SQ...</td>\n",
       "      <td>what is the number of russian detainees at gua...</td>\n",
       "      <td>nu-1498</td>\n",
       "      <td>Cannot get answer from sub-table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the \"...</td>\n",
       "      <td>does st helen elementary school have a larger ...</td>\n",
       "      <td>nu-3746</td>\n",
       "      <td>No, St Helen Elementary School does not have a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the count ...</td>\n",
       "      <td>the number of floods in the 1900's?</td>\n",
       "      <td>nu-2042</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thought: First, I'll observe the SQL query to ...</td>\n",
       "      <td>where is agape christian academy located?</td>\n",
       "      <td>nu-4257</td>\n",
       "      <td>Agape Christian Academy is located in either B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thought: \\nThe SQL query is selecting the coun...</td>\n",
       "      <td>how many total derivatives are cold water solu...</td>\n",
       "      <td>nu-1646</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Thought: \\n1. The SQL query selects rows from ...</td>\n",
       "      <td>is earl marshal listed above or below lord pri...</td>\n",
       "      <td>nu-502</td>\n",
       "      <td>Earl Marshal is listed above Lord Privy Seal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thought: \\n- The SQL query is filtering the ta...</td>\n",
       "      <td>what is the number of elements with a transien...</td>\n",
       "      <td>nu-3519</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thought: \\nThe SQL query is counting the numbe...</td>\n",
       "      <td>what is the number of years tony gulotta race?</td>\n",
       "      <td>nu-2166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the maximu...</td>\n",
       "      <td>what was the last stadium opened?</td>\n",
       "      <td>nu-1716</td>\n",
       "      <td>The last stadium opened is located in Nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the \"...</td>\n",
       "      <td>what is the number of reactors that are still ...</td>\n",
       "      <td>nu-1490</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the minimu...</td>\n",
       "      <td>what was the date of the first vessel that was...</td>\n",
       "      <td>nu-4296</td>\n",
       "      <td>May 1, 1998.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thought: \\n- The SQL query selects the count o...</td>\n",
       "      <td>how many countries earned gold medals?</td>\n",
       "      <td>nu-2610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Thought: \\n- The SQL query is selecting the Ai...</td>\n",
       "      <td>what aircraft was used before the 7th aerial v...</td>\n",
       "      <td>nu-4319</td>\n",
       "      <td>Sopwith Triplane s/n N5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thought: \\n1. The sub-table shows the result o...</td>\n",
       "      <td>who is the first name listed in the table?</td>\n",
       "      <td>nu-3686</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thought: \\n1. The SQL query is selecting the c...</td>\n",
       "      <td>how many games did the rough riders play befor...</td>\n",
       "      <td>nu-1378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thought: \\n1. The SQL query filters the rows i...</td>\n",
       "      <td>what is the number of wins by jaguar xjs?</td>\n",
       "      <td>nu-47</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the \"Drive...</td>\n",
       "      <td>which driver only scored 1 point?</td>\n",
       "      <td>nu-3602</td>\n",
       "      <td>Ryan Hunter-Reay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the d...</td>\n",
       "      <td>how many competitors were from the united states?</td>\n",
       "      <td>nu-2172</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thought: \\n1. The SQL query is selecting the m...</td>\n",
       "      <td>what is the least entry listed under notes?</td>\n",
       "      <td>nu-4325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the \"...</td>\n",
       "      <td>how many imparja cup victories has queensland ...</td>\n",
       "      <td>nu-2198</td>\n",
       "      <td>Queensland has had 6 Imparja Cup victories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Thought: \\n1. The SQL selects the year and cou...</td>\n",
       "      <td>which year had more competitions, 2006 or 2007?</td>\n",
       "      <td>nu-3060</td>\n",
       "      <td>2006 had more competitions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Thought: \\n1. The SQL query selects all column...</td>\n",
       "      <td>how long in height is isabelle raisa?</td>\n",
       "      <td>nu-1935</td>\n",
       "      <td>Isabelle Raisa's height is 170 cm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Thought: \\n- The SQL query filters the rows in...</td>\n",
       "      <td>how many goalscorers were brazilian?</td>\n",
       "      <td>nu-2683</td>\n",
       "      <td>The number of goalscorers who were Brazilian i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thought: \\n- The SQL query filters the rows wh...</td>\n",
       "      <td>how many total times did they not qualify for ...</td>\n",
       "      <td>nu-3943</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Thought: \\nTo answer the question, we need to ...</td>\n",
       "      <td>what time period had no shirt sponsor?</td>\n",
       "      <td>nu-8</td>\n",
       "      <td>1982–1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Thought: \\n1. The SQL query is selecting the c...</td>\n",
       "      <td>how many runner-up titles are there?</td>\n",
       "      <td>nu-3938</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Thought: \\n- The query is asking for the maxim...</td>\n",
       "      <td>at most, how many games were played in one year?</td>\n",
       "      <td>nu-3021</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Thought: \\n1. The SQL query is selecting the s...</td>\n",
       "      <td>what is the total number of deaths outside of ...</td>\n",
       "      <td>nu-3640</td>\n",
       "      <td>There is no information available for the tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Thought: \\n1. The SQL query filters the rows w...</td>\n",
       "      <td>how many games were played at home?</td>\n",
       "      <td>nu-1359</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the \"Year\"...</td>\n",
       "      <td>what year had the least amount of viewers?</td>\n",
       "      <td>nu-2584</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Thought: \\n1. The sub-table shows the populati...</td>\n",
       "      <td>which city had the greater population, holon o...</td>\n",
       "      <td>nu-1225</td>\n",
       "      <td>Cannot determine from the sub-table alone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Thought: \\n1. Look at the sub-table and find t...</td>\n",
       "      <td>which region has the best physician to patient...</td>\n",
       "      <td>nu-2995</td>\n",
       "      <td>Addis Ababa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Thought: \\n- The subquery (SELECT MIN(Dimensio...</td>\n",
       "      <td>which metal composition has the least dimension?</td>\n",
       "      <td>nu-685</td>\n",
       "      <td>.900 silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Thought: \\n1. The SQL query selects the column...</td>\n",
       "      <td>what country in the top ten had the least numb...</td>\n",
       "      <td>nu-2865</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Thought: \\n1. The SQL query is selecting the c...</td>\n",
       "      <td>what is the number of drivers that drove a veh...</td>\n",
       "      <td>nu-4193</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the d...</td>\n",
       "      <td>connie morella ran for re-election, but lost t...</td>\n",
       "      <td>nu-935</td>\n",
       "      <td>Connie Morella lost to Chris Van Hollen in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Thought: \\n- The SQL query is selecting the \"N...</td>\n",
       "      <td>who is after hiroyasu tuchie?</td>\n",
       "      <td>nu-557</td>\n",
       "      <td>Khaled Yousef Al-Obaidli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Thought: \\n1. The SQL query is filtering the d...</td>\n",
       "      <td>what number of dino's singles reached the top ...</td>\n",
       "      <td>nu-1451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                preds  \\\n",
       "0   Thought: \\n1. The SQL query filters the DF tab...   \n",
       "1   Thought: \\n1. Look at the sub-table and find t...   \n",
       "2   Thought: \\n1. The query is counting the number...   \n",
       "3   Thought: The SQL query is counting the total n...   \n",
       "4   Thought: The SQL query is selecting the \"Episo...   \n",
       "5   Thought: The SQL query is selecting the count ...   \n",
       "6   Thought: \\n1. The SQL query is filtering for t...   \n",
       "7   Thought: \\n- The SQL query selects the count o...   \n",
       "8   Thought: \\nTo determine how long it took Ryan ...   \n",
       "9   Thought: \\nWe need to find the player who scor...   \n",
       "10  Thought: \\n1. The SQL query is filtering the \"...   \n",
       "11  Thought: \\n1. The SQL query selects the column...   \n",
       "12  Thought: \\n- The sub-table generated by the SQ...   \n",
       "13  Thought: \\n1. The SQL query is filtering the \"...   \n",
       "14  Thought: \\n1. The SQL query selects the count ...   \n",
       "15  Thought: First, I'll observe the SQL query to ...   \n",
       "16  Thought: \\nThe SQL query is selecting the coun...   \n",
       "17  Thought: \\n1. The SQL query selects rows from ...   \n",
       "18  Thought: \\n- The SQL query is filtering the ta...   \n",
       "19  Thought: \\nThe SQL query is counting the numbe...   \n",
       "20  Thought: \\n1. The SQL query selects the maximu...   \n",
       "21  Thought: \\n1. The SQL query is filtering the \"...   \n",
       "22  Thought: \\n1. The SQL query selects the minimu...   \n",
       "23  Thought: \\n- The SQL query selects the count o...   \n",
       "24  Thought: \\n- The SQL query is selecting the Ai...   \n",
       "25  Thought: \\n1. The sub-table shows the result o...   \n",
       "26  Thought: \\n1. The SQL query is selecting the c...   \n",
       "27  Thought: \\n1. The SQL query filters the rows i...   \n",
       "28  Thought: \\n1. The SQL query selects the \"Drive...   \n",
       "29  Thought: \\n1. The SQL query is filtering the d...   \n",
       "30  Thought: \\n1. The SQL query is selecting the m...   \n",
       "31  Thought: \\n1. The SQL query is filtering the \"...   \n",
       "32  Thought: \\n1. The SQL selects the year and cou...   \n",
       "33  Thought: \\n1. The SQL query selects all column...   \n",
       "34  Thought: \\n- The SQL query filters the rows in...   \n",
       "35  Thought: \\n- The SQL query filters the rows wh...   \n",
       "36  Thought: \\nTo answer the question, we need to ...   \n",
       "37  Thought: \\n1. The SQL query is selecting the c...   \n",
       "38  Thought: \\n- The query is asking for the maxim...   \n",
       "39  Thought: \\n1. The SQL query is selecting the s...   \n",
       "40  Thought: \\n1. The SQL query filters the rows w...   \n",
       "41  Thought: \\n1. The SQL query selects the \"Year\"...   \n",
       "42  Thought: \\n1. The sub-table shows the populati...   \n",
       "43  Thought: \\n1. Look at the sub-table and find t...   \n",
       "44  Thought: \\n- The subquery (SELECT MIN(Dimensio...   \n",
       "45  Thought: \\n1. The SQL query selects the column...   \n",
       "46  Thought: \\n1. The SQL query is selecting the c...   \n",
       "47  Thought: \\n1. The SQL query is filtering the d...   \n",
       "48  Thought: \\n- The SQL query is selecting the \"N...   \n",
       "49  Thought: \\n1. The SQL query is filtering the d...   \n",
       "\n",
       "                                           statements      ids  \\\n",
       "0   did dmitry mikhailovich golitsyn or andrey kir...  nu-3365   \n",
       "1   which person(s) had a time of at least 40 seco...  nu-3138   \n",
       "2     what country had the largest number of drivers?  nu-2135   \n",
       "3            what is the total number of competition?   nu-290   \n",
       "4                   the title of the last show was...  nu-3940   \n",
       "5   what is the total number of games played again...  nu-4028   \n",
       "6   which episode came first, young forever or you...  nu-3762   \n",
       "7     how many top goalscorers have 30 or more goals?  nu-1889   \n",
       "8   how long did it take ryan briscoe to finish th...   nu-336   \n",
       "9      who is china's top scorer in friendly matches?  nu-2563   \n",
       "10      how many candidates are over 1.8 meters tall?  nu-3430   \n",
       "11          who has the most quantity of all nations?   nu-174   \n",
       "12  what is the number of russian detainees at gua...  nu-1498   \n",
       "13  does st helen elementary school have a larger ...  nu-3746   \n",
       "14                the number of floods in the 1900's?  nu-2042   \n",
       "15          where is agape christian academy located?  nu-4257   \n",
       "16  how many total derivatives are cold water solu...  nu-1646   \n",
       "17  is earl marshal listed above or below lord pri...   nu-502   \n",
       "18  what is the number of elements with a transien...  nu-3519   \n",
       "19     what is the number of years tony gulotta race?  nu-2166   \n",
       "20                  what was the last stadium opened?  nu-1716   \n",
       "21  what is the number of reactors that are still ...  nu-1490   \n",
       "22  what was the date of the first vessel that was...  nu-4296   \n",
       "23             how many countries earned gold medals?  nu-2610   \n",
       "24  what aircraft was used before the 7th aerial v...  nu-4319   \n",
       "25         who is the first name listed in the table?  nu-3686   \n",
       "26  how many games did the rough riders play befor...  nu-1378   \n",
       "27          what is the number of wins by jaguar xjs?    nu-47   \n",
       "28                  which driver only scored 1 point?  nu-3602   \n",
       "29  how many competitors were from the united states?  nu-2172   \n",
       "30        what is the least entry listed under notes?  nu-4325   \n",
       "31  how many imparja cup victories has queensland ...  nu-2198   \n",
       "32    which year had more competitions, 2006 or 2007?  nu-3060   \n",
       "33              how long in height is isabelle raisa?  nu-1935   \n",
       "34               how many goalscorers were brazilian?  nu-2683   \n",
       "35  how many total times did they not qualify for ...  nu-3943   \n",
       "36             what time period had no shirt sponsor?     nu-8   \n",
       "37               how many runner-up titles are there?  nu-3938   \n",
       "38   at most, how many games were played in one year?  nu-3021   \n",
       "39  what is the total number of deaths outside of ...  nu-3640   \n",
       "40                how many games were played at home?  nu-1359   \n",
       "41         what year had the least amount of viewers?  nu-2584   \n",
       "42  which city had the greater population, holon o...  nu-1225   \n",
       "43  which region has the best physician to patient...  nu-2995   \n",
       "44   which metal composition has the least dimension?   nu-685   \n",
       "45  what country in the top ten had the least numb...  nu-2865   \n",
       "46  what is the number of drivers that drove a veh...  nu-4193   \n",
       "47  connie morella ran for re-election, but lost t...   nu-935   \n",
       "48                      who is after hiroyasu tuchie?   nu-557   \n",
       "49  what number of dino's singles reached the top ...  nu-1451   \n",
       "\n",
       "                                         final_answer  \n",
       "0   Andrey Kirillovich Razumovsky served as ambass...  \n",
       "1   Kyunghyun Kim, Christoffer Lindhe, Arnost Petr...  \n",
       "2   The country with the largest number of drivers...  \n",
       "3                                                  18  \n",
       "4                                        \"Never Tell\"  \n",
       "5                                                   3  \n",
       "6   There are no episodes with the titles \"Young F...  \n",
       "7                                                   4  \n",
       "8   To calculate how long it took Ryan Briscoe to ...  \n",
       "9                   Cannot get answer from sub-table.  \n",
       "10                                                 20  \n",
       "11                                             Canada  \n",
       "12                  Cannot get answer from sub-table.  \n",
       "13  No, St Helen Elementary School does not have a...  \n",
       "14                                                 22  \n",
       "15  Agape Christian Academy is located in either B...  \n",
       "16                                                  4  \n",
       "17      Earl Marshal is listed above Lord Privy Seal.  \n",
       "18                                                 14  \n",
       "19                                                  0  \n",
       "20        The last stadium opened is located in Nice.  \n",
       "21                                                 13  \n",
       "22                                       May 1, 1998.  \n",
       "23                                                  4  \n",
       "24                         Sopwith Triplane s/n N5460  \n",
       "25                                                     \n",
       "26                                                  4  \n",
       "27                                                  7  \n",
       "28                                   Ryan Hunter-Reay  \n",
       "29                                                  4  \n",
       "30                                                  0  \n",
       "31        Queensland has had 6 Imparja Cup victories.  \n",
       "32                        2006 had more competitions.  \n",
       "33                 Isabelle Raisa's height is 170 cm.  \n",
       "34  The number of goalscorers who were Brazilian i...  \n",
       "35                                                 14  \n",
       "36                                          1982–1985  \n",
       "37                                                 11  \n",
       "38                                                278  \n",
       "39  There is no information available for the tota...  \n",
       "40                                                  8  \n",
       "41                                               2014  \n",
       "42         Cannot determine from the sub-table alone.  \n",
       "43                                        Addis Ababa  \n",
       "44                                        .900 silver  \n",
       "45                                         Yugoslavia  \n",
       "46                                                  7  \n",
       "47  Connie Morella lost to Chris Van Hollen in the...  \n",
       "48                           Khaled Yousef Al-Obaidli  \n",
       "49                                                  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7d5ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "25\n",
      "26\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "37\n",
      "38\n",
      "39\n",
      "41\n",
      "42\n",
      "47\n",
      "49\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for index, row in data.iterrows():\n",
    "    id = row['ids']\n",
    "    target = target_values_map[id]\n",
    "     \n",
    "    preds = [row['final_answer']]\n",
    "    pred_answer = to_value_list(preds)\n",
    "    if check_denotation(pred_answer, target):\n",
    "        acc += 1\n",
    "    else:\n",
    "        print(index)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dcc1fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "culture = Culture.English\n",
    "Recognizers.recognize_number('The total number of competitions is 20.', culture)[0].resolution['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about different games played by a football team. It includes details like the week number, date of the game, opponent team, game result, game site, NFL recap, and the attendance for each game.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f877301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The total number of competitions is 20.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize('The total number of competitions is 20.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d5083",
   "metadata": {},
   "source": [
    "#### decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eff14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class AugType(Enum):\n",
    "    augmentation_aug = 'aug'\n",
    "    schema_aug = 'schema'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "223b3f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapper func\n",
      "subwrapper\n",
      "This is the summary method.\n",
      "This is the summary method.\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(type):\n",
    "    def wrapper(func):\n",
    "        print('wrapper func')\n",
    "        def subwrapper(self, *args, **kwargs):\n",
    "            print('subwrapper')\n",
    "            self.function_mapping[type] = func\n",
    "            return func(self, *args, **kwargs)\n",
    "        return subwrapper\n",
    "    return wrapper\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.function_mapping = {}\n",
    "    def execute_method(self, type):\n",
    "       method = self.function_mapping.get(type, None)\n",
    "       if method:\n",
    "           method(self)\n",
    "       else:\n",
    "           print(f\"Method {type} not found.\")\n",
    "\n",
    "    @my_decorator(type='sum')\n",
    "    def summary(self):\n",
    "        print(\"This is the summary method.\")\n",
    "\n",
    "a = MyClass()\n",
    "a.summary()\n",
    "a.execute_method('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bb5655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary method.\n",
      "This is the augmentation method.\n",
      "This is the schema method.\n",
      "Method nonexistent not found.\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "   def __init__(self):\n",
    "       self.function_mapping = {}\n",
    " \n",
    "   def execute_method(self, type):\n",
    "       method = self.function_mapping.get(type, None)\n",
    "       if method:\n",
    "           method()\n",
    "       else:\n",
    "           print(f\"Method {type} not found.\")\n",
    " \n",
    "   def register_function(self, type):\n",
    "       def decorator(func):\n",
    "           self.function_mapping[type] = func\n",
    "           return func\n",
    "       return decorator\n",
    " \n",
    "# 使用装饰器来注册函数\n",
    "my_instance = MyClass()\n",
    "@my_instance.register_function('sum')\n",
    "def summary():\n",
    "   print(\"This is the summary method.\")\n",
    " \n",
    "@my_instance.register_function('aug')\n",
    "def augmentation():\n",
    "   print(\"This is the augmentation method.\")\n",
    " \n",
    "@my_instance.register_function('schema')\n",
    "def schema():\n",
    "   print(\"This is the schema method.\")\n",
    " \n",
    "# 根据type参数调用对应的方法\n",
    "my_instance.execute_method('sum')  # 输出: This is the summary method.\n",
    "my_instance.execute_method('aug')  # 输出: This is the augmentation method.\n",
    "my_instance.execute_method('schema')  # 输出: This is the schema method.\n",
    "my_instance.execute_method('nonexistent')  # 输出: Method nonexistent not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ea9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClass():\n",
    "    def answer(self):\n",
    "        return \"i am baseclass\"\n",
    "\n",
    "class MetaClass(type):\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "\n",
    "# 什么是元类， 元类是创建类的类。\n",
    "# 创建过程：type --> class(对象) --> 对象 \n",
    "class User(BaseClass, metaclass=MetaClass):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def __str__(self):\n",
    "        return \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47f3cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nihao\n"
     ]
    }
   ],
   "source": [
    "def repeat(number=3):\n",
    "   def decorator(func):\n",
    "       def wrapper(self, *args, **kwargs):\n",
    "           print('nihao')\n",
    "           for _ in range(number):\n",
    "               value = func(self, *args, **kwargs)\n",
    "           return value\n",
    "       return wrapper\n",
    "   return decorator\n",
    " \n",
    "class MyClass:\n",
    "   @repeat(number=5)\n",
    "   def say_hello(self):\n",
    "    #    print(\"Hello!\")\n",
    "        pass\n",
    " \n",
    "# 创建 MyClass 的实例并调用 say_hello 方法\n",
    "my_instance = MyClass()\n",
    "my_instance.say_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd3ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am baseclass'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1544737e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_decorator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m                 attrs[key] \u001b[38;5;241m=\u001b[39m my_decorator(value)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Meta, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, bases, attrs)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyClass\u001b[39;00m(metaclass\u001b[38;5;241m=\u001b[39mMeta):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mMeta.__new__\u001b[0;34m(cls, name, bases, attrs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m         attrs[key] \u001b[38;5;241m=\u001b[39m \u001b[43mmy_decorator\u001b[49m(value)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Meta, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, bases, attrs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_decorator' is not defined"
     ]
    }
   ],
   "source": [
    "class Meta(type):\n",
    "    def __new__(cls, name, bases, attrs):\n",
    "        for key, value in attrs.items():\n",
    "            if callable(value) and not key.startswith(\"__\"):\n",
    "                attrs[key] = my_decorator(value)\n",
    "        return super(Meta, cls).__new__(cls, name, bases, attrs)\n",
    "\n",
    "class MyClass(metaclass=Meta):\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "\n",
    "    def my_decorator(func):\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            print(\"Before function call\")\n",
    "            result = func(self, *args, **kwargs)\n",
    "            print(\"After function call\")\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    def my_method(self, x):\n",
    "        self.value += x\n",
    "        print(f\"Value is now {self.value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
