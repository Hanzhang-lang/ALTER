{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/disk1/chatgpt/zh/tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_manager import get_k_shot_with_answer, view_instruction, row_instruction\n",
    "import pandas as pd\n",
    "from utils import parse_specific_composition, add_row_number\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from data_loader import TableFormat, TableLoader\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sqlalchemy import create_engine\n",
    "from executor import SQLManager\n",
    "import sqlparse\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "            model_name='BAAI/bge-large-en',\n",
    "            model_kwargs={'device': 'cuda:2', 'trust_remote_code': True},\n",
    "            encode_kwargs={'normalize_embeddings': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "                  \"what was the time difference between the first place finisher and the eighth place finisher?\",\n",
    "                  # \"compare the chart positions between the us and the uk for the science of selling yourself short, where did it do better?\",\n",
    "                  \"other than william stuart price, which other businessman was born in tulsa?\",\n",
    "                  \"which canadian city had the most passengers traveling from manzanillo international airport in 2013?\"\n",
    "                # \"what is the next most populous district after haridwar?\",(70)\n",
    "                  ]\n",
    "new_query_examples = [\n",
    "  # \"what was the chart position of 'The Science of Selling Yourself Short' in the US?; what was the chart position of 'The Science of Selling Yourself Short' in the UK?;\",\n",
    "                      \"what was the time for the first place finisher?; what was the time for the eighth place finisher?\",\n",
    "                      \"was william stuart price born in tulsa?; who was born in tulsa?\",\n",
    "                      \"how many passengers from each airline from canadian city? which canadian city had the most passengers?\"\n",
    "                    # \"what are the districts after haridwar?; what is the next most populous district after haridwar?\",\n",
    "                    #   \"When did polona hercog partner with alberta brianti?; When did polona hercog partner with stephanie vogt?\",\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 11, 86, 70, 42]\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=True, embeddings=embeddings).get_sample_data(sample_type='embedding', query=normalised_data[i]['query']) for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub queries. Based on the table, decompose original query into at most 2 complete sub queries which can solve original query. Output new query directly.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Sub-Table: {table}\n",
    "Query: {query}\n",
    "Decompose query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "query_examples = [\n",
    "    # \"after 2005 , the winner of the lifetime achievement award be andrew rule john silvester , sandra harvey lindsay simpson , marele day , shane maloney , and peter doyle\",\n",
    "                  \"all 12 club play a total of 22 game for the wru division one east\",\n",
    "                #   \"a gamecube game loss the award in each of the first 3 year\",\n",
    "                \"from 1980 to 2011 , apoel bc lose more than 2 time as many game as it win\",\n",
    "                  \"polona hercog 1890partner with alberta brianti after she have stephanie vogt as the partner\",\n",
    "                  ]\n",
    "task_examples = [\"query rewrite\", \"query decompose\", \"query ambiguity resolve\"]\n",
    "new_query_examples = [\n",
    "    # \"Who were the winners of the lifetime achievement award after 2005?;\",\n",
    "                      \"How many clubs play for the wru division one east in total?; How many clubs play 22 game for the wru division one east?;\",\n",
    "                    #   \"a gamecube game loss the award in each of the first 3 year\",\n",
    "                    \"from 1980 to 2011 , how many games did apoel bc lose?; from 1980 to 2011 , how many games did apoel bc win?;\",\n",
    "                      \"When did polona hercog partner with alberta brianti?; When did polona hercog partner with stephanie vogt?\",\n",
    "                      ]\n",
    "num_k = 3\n",
    "inds = [1, 124, 5]\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"table\", \"new_query\"], template=\n",
    "\"\"\"Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": query_examples[i],\n",
    "                                    \"table\": examples[i],\n",
    "                                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "decompose_prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"You are capable of converting complex query into sub-queries. Based on the table, provide at most 2 sub-queries for knowledge that you need. Output new query directly.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"Query: {query}\n",
    "Table: {table}\n",
    "New query: \"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")\n",
    "\n",
    "# Sub-questions are separated by semicolons.\n",
    "# answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "#                                     template=\"\"\"\n",
    "# Below is a sub-table generated by excuting the SQL. You need to understand the logic behind the SQL filtering and complete task using the final sub-table. \n",
    "# SQL Excuted: \n",
    "# ```{SQL}```\n",
    "# Sub-table: {table}\n",
    "# Query: {claim}\n",
    "# answer the question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "# \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'wikitable'\n",
    "split = 'test'\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "                       openai_api_key=\"sk-Kfk2WiZcPgajLVtdGPGmfahxCmWqJSbMeRck5sXujlMS4Nai\", temperature=0.7).bind(logprobs=True)\n",
    "schema_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_schema.csv\", index_col='table_id')\n",
    "aug_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_summary.csv\", index_col='table_id')\n",
    "composition_information = pd.read_csv(f\"../result/aug/{task_name}_{split}_composition.csv\", index_col='table_id')\n",
    "engine = create_engine('sqlite:///db/sqlite/test.db', echo=False)\n",
    "manager = SQLManager(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loader = TableLoader(table_name=task_name, split='test', use_sample=False, small_test=False)\n",
    "sample = table_loader.normalize_table(table_loader.dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [11,]\n",
    "num_k = 1\n",
    "table_loader = TableLoader(table_name='wikitable', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which business man was born in tulsa?\",\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['question'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt_wiki = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Based on the table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query:\"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from data_loader import TableFormat\n",
    "inds = [8, 173,]\n",
    "num_k = 2\n",
    "table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "examples = [TableFormat.format_nl_sep(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "new_query_examples = [\n",
    "    # \"Which country uses the US dollar as its currency and has the Federal Reserve as its central bank?\",\n",
    "    \"which college list be public?\",\n",
    "    \"what was the works number used in 1883?\"\n",
    "    ]\n",
    "examples_prompt = PromptTemplate(input_variables=[\"query\", \"new_query\"], template=\n",
    "\"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query: {new_query}\"\"\")\n",
    "\n",
    "examples_dict = [{\"query\": table_loader.dataset[inds[i]]['statement'],\n",
    "                  \"table\": examples[i],\n",
    "                    \"new_query\": new_query_examples[i]} for i in range(num_k)]\n",
    "step_back_prompt = FewShotPromptTemplate(\n",
    "    examples=examples_dict,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"\"\"Based on the table, your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"\"\",\n",
    "    suffix=\n",
    "    \"\"\"\n",
    "Query: {query}\n",
    "Table: {table}\n",
    "New query:\"\"\",\n",
    "    input_variables=[\"query\", \"table\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_with_answer(k: int=1):\n",
    "    sqls = [\"SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';\"\n",
    "            ]\n",
    "    thoughts = [\"Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \"]\n",
    "    tables = [\"<table>\\n<caption>1972 isle of man tt</caption>\\n<thead>\\n<tr><th>  MIN(points)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>3            </td></tr>\\n</tbody>\\n</table>\"]\n",
    "    claims = [\"was 2 be the fewest point that roger dutton / tony wright receive?\"]\n",
    "    # inds from test split\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], template=\n",
    "    \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Query: {claim}\n",
    "Thought: {thought}\n",
    "Answer: {output}\n",
    "    \"\"\")\n",
    "    examples_dict = dict(zip([\"SQL\", \"table\", \"claim\", \"thought\", \"output\"], [sqls[0], tables[0], claims[0], thoughts[0], '3']))\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=[examples_dict],\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\"\"\"Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the last question given in the query.\n",
    "You should output in the following format:\n",
    "Thought: your step by step thought\n",
    "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
    "Below is an example.\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: {table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\"\"\",\n",
    "        input_variables=[\"table\", \"query\", \"SQL\", \"information\"],\n",
    ")\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_k_shot_with_aug(k: int=2):\n",
    "#     table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "\n",
    "#     inds = [3, 6, 260, 33]\n",
    "#     Output_examples = [\n",
    "#                        'team, goals_for',\n",
    "#                        'year, game, platform_s',\n",
    "#                        'name, population_density_km_2_, population_2011_census_'\n",
    "#                        'leading_scorer, score, date']\n",
    "#     linking_examples = ['the team -> team; the most goal for -> goals_for',\n",
    "#                         'gamecube -> platform_s; gamecube game -> game; the first 3 year -> year;',\n",
    "#                         'alberta -> name; population density -> population_density_km_2_; 4257744 less people -> population_2011_census_; 2011 -> population_2011_census_'\n",
    "#                         'jason richardson -> leading_scorer; leading scorer -> score; month -> date; 23 point per game -> leading_scorer'\n",
    "#     ]\n",
    "#     examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "#     \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking: {linking}\n",
    "#     Columns: {output}\"\"\")\n",
    "#     num_k = 3\n",
    "#     examples_dict = [{\"table\": TableFormat(format='none', data=table_loader.dataset[inds[i]], use_sampling=True).format_nl_sep(table_loader.dataset[inds[i]]['table']['caption']),\n",
    "#                                         \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "#                                         \"linking\": linking_examples[i],\n",
    "#                                         # \"summary\": summary_examples[i],\n",
    "#                                         \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "#     prompt_template = FewShotPromptTemplate(\n",
    "#         examples=examples_dict,\n",
    "#         example_prompt=examples_prompt,\n",
    "#         prefix=\n",
    "#         \"\"\"\n",
    "#     Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
    "#     Approach this task as follows:\n",
    "#     Read the question thoroughly and list every possible link from query term to column in Table.\n",
    "#     Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "#     # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "#     # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "#     # Here are some examples:\"\"\",\n",
    "#         suffix=\n",
    "#         \"\"\"\n",
    "#     Table: {table}\n",
    "#     Query: {claim}\n",
    "#     Column linking:\n",
    "#     \"\"\",\n",
    "#         input_variables=[\"table\", \"claim\"],\n",
    "# )\n",
    "#     return prompt_template\n",
    "\n",
    "def get_k_shot_with_aug(k: int=2):\n",
    "    table_loader = TableLoader(table_name='tabfact', split='validation', use_sample=True, small_test=False)\n",
    "    table_loader_wiki = TableLoader(table_name='wikitable', split='train', use_sample=True, small_test=False)\n",
    "    inds = [3, 6, 260, 33]\n",
    "    Output_examples = [\n",
    "                       'team, goals_for',\n",
    "                       'year, game, platform_s',\n",
    "                       'name, population_density_km_2_, population_2011_census_'\n",
    "                       'leading_scorer, score, date']\n",
    "    linking_examples = ['the team -> team, the most goal for -> goals_for',\n",
    "                        'gamecube -> platform_s, gamecube game -> game, the first 3 year -> year',\n",
    "                        'alberta -> name, population density -> population_density_km_2_, 4257744 less people -> population_2011_census_, 2011 -> population_2011_census_'\n",
    "                        'jason richardson -> leading_scorer, month -> date, 23 point per game -> score'\n",
    "    ]\n",
    "    examples_prompt = PromptTemplate(input_variables=[\"table\", \"claim\", \"output\", \"linking\"], template=\n",
    "    \"\"\"\n",
    "    Table: {table}\n",
    "    Query: {claim}\n",
    "    Column linking: {linking}\n",
    "    Columns: {output}\"\"\")\n",
    "    num_k = 2\n",
    "    normalised_data = [table_loader.normalize_table(table_loader.dataset[inds[i]]) for i in range(num_k)]\n",
    "    example_samples = [TableFormat(format='none', data=normalised_data[i], save_embedding=False).get_sample_data(sample_type='random') for i in range(num_k)]\n",
    "    examples = [TableFormat.format_html(example_samples[i], normalised_data[i]['table']['caption']) for i in range(num_k)]\n",
    "    examples_dict = [{\"table\": examples[i],\n",
    "                                        \"claim\": table_loader.dataset[inds[i]]['statement'],\n",
    "                                        \"linking\": linking_examples[i],\n",
    "                                        # \"summary\": summary_examples[i],\n",
    "                                        \"output\": Output_examples[i]} for i in range(num_k)]\n",
    "    examples_dict.extend([{\"table\": '<table>\\n<caption>Hoot Kloot</caption>\\n<thead>\\n<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>1  </td><td>\"Kloot\\'s Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\\n<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\\n</tbody>\\n</table>',\n",
    "                                        \"claim\": table_loader_wiki.dataset[95]['question'],\n",
    "                                        \"linking\": \"the last title -> Released_, the last title-> Number, title -> Title\",\n",
    "                                        # \"summary\": summary_examples[i],\n",
    "                                        \"output\": \"Title, Released_, Number\"}])\n",
    "#     examples_dict.extend([{\"table\": \"\"\"<table>\n",
    "# <thead>\n",
    "# <tr><th>  Pick</th><th>       Player</th><th>              Team</th><th>  Position</th><th>                    School</th></tr>\n",
    "# </thead>\n",
    "# <tbody>\n",
    "# <tr><td>24    </td><td>Alan Zinter  </td><td>New York Mets     </td><td>C         </td><td>University of Arizona     </td></tr>\n",
    "# <tr><td>18    </td><td>Willie Greene</td><td>Pittsburgh Pirates</td><td>SS        </td><td>Jones County HS (Gray, GA)</td></tr>\n",
    "# <tr><td>23    </td><td>Mo Vaughn    </td><td>Boston Red Sox    </td><td>1B        </td><td>Seton Hall University     </td></tr>\n",
    "# </tbody>\n",
    "# </table>\"\"\",\n",
    "#                                     \"claim\": \"was kiki jones picked before or after greg gohr?\",\n",
    "#                                     \"linking\": \"kiki jones -> Player, picked before -> Pick, after -> Pick, greg gohr -> Player\",\n",
    "#                                     # \"summary\": summary_examples[i],\n",
    "#                                     \"output\": \"Player, Pick\"}])\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples_dict,\n",
    "        example_prompt=examples_prompt,\n",
    "        prefix=\n",
    "        \"\"\"\n",
    "    Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
    "    Approach this task as follows，read the claim thoroughly and list every possible link from query term to column in Table. Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\"\"\",\n",
    "    # You are a brilliant table executor with the capabilities information retrieval, table parsing, table partition and semantic understanding who can understand the structural information of the table.\n",
    "    # Given the following table and query, you should output columns related to the query or contain useful information about the query. \n",
    "    # Here are some examples:\"\"\",\n",
    "        suffix=\n",
    "        \"\"\"\n",
    "    Table: {table}\n",
    "    Extra information: {aug}\n",
    "    Query: {claim}\"\"\",\n",
    "        input_variables=[\"table\", \"claim\", \"aug\"],\n",
    ")\n",
    "    return prompt_template\n",
    "\n",
    "pre_instruction_schema = PromptTemplate(input_variables=[\"table\"], template=\"\"\"\n",
    "Instruction: Given the following table, you will add Metadata about the columns in the table.\n",
    "Metadata includes:\n",
    "- Numerical: consist digits and numerical symbols like decimal points or signs.\n",
    "- Char: whether column content is a text or description.\n",
    "- Date: whether the column content is datetime.\n",
    "\n",
    "You need to output all the column names with metadata in angle brackets.\n",
    "Example: name<Char> launched<Date> count<Numerical>\n",
    "\n",
    "Table: {table}\n",
    "Output:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "def scene_A(query, sample, verbose=True):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    sample_data = formatter.get_sample_data(sample_type='embedding', query=query)\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        # if pd.isna(summary_aug):\n",
    "        #     summary_aug = ''\n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        \n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        if verbose:\n",
    "            print(stage_1_batch_pred)\n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        \n",
    "        try: \n",
    "            # formatter.all_data = formatter.all_data.loc[:, columns]\n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            pass\n",
    "        extra_information = parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns)\n",
    "        extra_information.append('row_number: row number in the original table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data = sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\nColumn information:\\n' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "        if verbose:\n",
    "            print(stage_2_batch_pred)\n",
    "    # stage 3: SQL Excution\n",
    "    try: \n",
    "        execute_data = manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "    except:\n",
    "        execute_data = formatter.all_data\n",
    "        stage_2_batch_pred = 'SELECT * from DF;'\n",
    "    if len(execute_data) == 0:\n",
    "        return query, stage_2_batch_pred, 'No data from database', cb.total_tokens\n",
    "    return query, stage_2_batch_pred, TableFormat.format_html(data=execute_data), cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_blury_string(pred_list):\n",
    "    pred_label = []\n",
    "    for pred in pred_list:\n",
    "        predict_ans = pred.split('\\n')[-1]\n",
    "        if '0' in predict_ans:\n",
    "            predict_ans = '0'\n",
    "        elif '1' in predict_ans:\n",
    "            predict_ans = '1'\n",
    "        else:\n",
    "            predict_ans = '2'\n",
    "        pred_label.append(predict_ans)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "def parallel_run(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = [executor.submit(func, arg) for arg in args_list]\n",
    "        return [future.result() for future in concurrent.futures.as_completed(results)]\n",
    "\n",
    "def parallel_run_kwargs(func, args_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda kwargs: func(**kwargs), args_list)\n",
    "        return list(results)\n",
    "\n",
    "def save_csv(input_list: List[List], label_list: List, file_path):\n",
    "    import pandas as pd\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    assert len(input_list) == len(label_list)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(label_list)):\n",
    "        df[label_list[i]] = pd.Series(input_list[i])\n",
    "    if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "        df_origin = pd.read_csv(file_path)\n",
    "        df = pd.concat([df_origin, df], axis=0)\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整extrainformation的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_output\n",
    "answer_instruction = PromptTemplate(input_variables=[\"SQL\", \"table\", \"claim\"], \n",
    "                                    template=\"\"\"\n",
    "Below is a sub-table generated by excuting the SQL. You need to understand the logic behind the SQL filtering and complete task using the final sub-table. \n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table: \n",
    "{table}\n",
    "Query: {claim}\n",
    "Please provide a clear, concise statement in response to the question. If you cannot answer the question based on the sub-table, just say 'Cannot get answer from sub-table'\n",
    "\"\"\" )\n",
    "def scene_B(query, sample, verbose=False):\n",
    "    row_instruction = PromptTemplate(input_variables=[\"table\", \"claim\", \"aug\"], \n",
    "                                 template=\"\"\"Our ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
    "sub-table: {table}\n",
    "Extra information: {aug}\n",
    "\n",
    "Query: {claim}\n",
    "SQL: \"\"\")\n",
    "    formatter = TableFormat(format='none', data=sample, save_embedding=True, embeddings=embeddings)\n",
    "    formatter.normalize_schema(schema_information.loc[sample['table']['id']]['schema'])\n",
    "    sample_data = formatter.get_sample_data(sample_type='embedding', query=query)\n",
    "    # get columns\n",
    "    k_shot_prompt = get_k_shot_with_aug()\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_chain = LLMChain(llm=model, prompt=k_shot_prompt, verbose=verbose)\n",
    "        summary_aug, column_aug = aug_information.loc[sample['table']['id']]['summary'], aug_information.loc[sample['table']['id']]['column_description'] \n",
    "        # if pd.isna(summary_aug):\n",
    "        #     summary_aug = ''\n",
    "        col_names, col_infos = parse_output(column_aug, pattern=r'([^<]*)<([^>]*)>')\n",
    "        extra_col_info = []\n",
    "        for i_c in range(len(col_names)):\n",
    "            extra_col_info.append(f'{i_c + 1}. {col_names[i_c]}: {col_infos[i_c]}')\n",
    "        stage_1_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  '\\n'.join(extra_col_info)\n",
    "                                            })], return_only_outputs=True)[0]['text']\n",
    "        stage_1_batch_pred = stage_1_batch_pred.split(':')[-1]\n",
    "        \n",
    "        extra_cols = formatter.get_sample_column(embeddings, column_aug)\n",
    "        # stage 2: SQL generation\n",
    "        llm_chain = LLMChain(llm=model, prompt=row_instruction, verbose=verbose)\n",
    "        columns = list(set([c.strip() for c in stage_1_batch_pred.split(',')] + extra_cols))\n",
    "        \n",
    "        try: \n",
    "            sample_data = add_row_number(sample_data.loc[:, columns])\n",
    "        except:\n",
    "            pass\n",
    "        extra_information = (parse_specific_composition(composition_information.loc[sample['table']['id']]['composition'], sample_data.columns))\n",
    "        extra_information.append('row_number: row number in the table')\n",
    "        stage_2_batch_pred = llm_chain.batch([dict({'table': TableFormat.format_html(data=sample_data, table_caption=sample['table']['caption']),\n",
    "                                            'claim': query,\n",
    "                                            'aug':  summary_aug + '\\n Column information:' + '\\n'.join(extra_information)\n",
    "                                            })], return_only_outputs=True)[0]['text'].replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"―\", \"-\").replace(\"−\", \"-\")\n",
    "    \n",
    "        \n",
    "        # stage 3: SQL Excution\n",
    "        try: \n",
    "            execute_data= manager.execute_from_df(stage_2_batch_pred, add_row_number(formatter.all_data), table_name='DF')\n",
    "        except:\n",
    "            execute_data = formatter.all_data\n",
    "            stage_2_batch_pred = 'SELECT * from DF;'\n",
    "        llm_chain = LLMChain(llm=model, prompt=answer_instruction, verbose=verbose)\n",
    "        response = llm_chain.batch([dict({'table': TableFormat.format_html(execute_data),\n",
    "                                                'claim': query,\n",
    "                                                'SQL':  stage_2_batch_pred\n",
    "                                                })], return_only_outputs=True)[0]['text']\n",
    "    # print(\"total_tokens:\", cb.total_tokens)\n",
    "    return response, cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0c75de50975e4f278b882fe90da47f2f\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ces.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "\n",
    "model = ChatOpenAI(model_name=model_name, openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "                       openai_api_key=\"sk-Kfk2WiZcPgajLVtdGPGmfahxCmWqJSbMeRck5sXujlMS4Nai\", temperature=0.7).bind(logprobs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 4*GPUs----------\n",
      "['Who was the first mayor to be inaugurated in Witswaterand?', 'who was the mayor in 1931-32? who was the mayor in 1919-20?']\n",
      "Unknown Date format 0    1903-04\n",
      "1    1904-05\n",
      "2    1905-06\n",
      "3    1907-08\n",
      "4    1908-09\n",
      "Name: Year, dtype: object\n",
      "Unknown Date format 0     1935-36\n",
      "1     1936-37\n",
      "2    1937 -38\n",
      "3    1939 -40\n",
      "4     1940-41\n",
      "Name: Year_1, dtype: object\n",
      "Unknown Date format 0    1967-68\n",
      "1    1968-69\n",
      "2    1969-70\n",
      "3    1971-72\n",
      "4    1972-73\n",
      "Name: Year_2, dtype: object\n",
      "Unknown Date format 0    1903-04\n",
      "1    1904-05\n",
      "2    1905-06\n",
      "3    1907-08\n",
      "4    1908-09\n",
      "Name: Year, dtype: object\n",
      "Unknown Date format 0     1935-36\n",
      "1     1936-37\n",
      "2    1937 -38\n",
      "3    1939 -40\n",
      "4     1940-41\n",
      "Name: Year_1, dtype: object\n",
      "Unknown Date format 0    1967-68\n",
      "1    1968-69\n",
      "2    1969-70\n",
      "3    1971-72\n",
      "4    1972-73\n",
      "Name: Year_2, dtype: object\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Your task is accurately output columns related to the query or contain useful information about the query. This process involves linking similar words or semantically similar terms to columns in the table.\n",
      "    Approach this task as follows，read the claim thoroughly and list every possible link from query term to column in Table. Then Based on the column linking, output all useful columns at last. Make sure all columns in the link step are included and every column is in the Table.\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>1986 - 87 north west counties football league</caption>\n",
      "<thead>\n",
      "<tr><th>  position</th><th>               team</th><th>  played</th><th>  drawn</th><th>  lost</th><th>  goals_for</th><th>  goals_against</th><th>  goal_difference</th><th>  points_1</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>12        </td><td>ashton town        </td><td>24      </td><td>9      </td><td>11    </td><td>29         </td><td>39             </td><td>10               </td><td>15 2      </td></tr>\n",
      "<tr><td>10        </td><td>padiham            </td><td>24      </td><td>8      </td><td>12    </td><td>35         </td><td>39             </td><td>4                </td><td>16        </td></tr>\n",
      "<tr><td>1         </td><td>atherton collieries</td><td>24      </td><td>4      </td><td>4     </td><td>46         </td><td>22             </td><td>+ 24             </td><td>36        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: the team with the most goal for in the 1986 - 87 north west county football league be flixton\n",
      "    Column linking: the team -> team, the most goal for -> goals_for\n",
      "    Columns: team, goals_for\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>list of game of the year awards</caption>\n",
      "<thead>\n",
      "<tr><th>  year</th><th>                               game</th><th>                                  genre</th><th>                        platform_s</th><th>                 developer_s</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>2011  </td><td>the legend of zelda : skyward sword</td><td>action - adventure                     </td><td>wii                               </td><td>nintendo ead , monolith soft</td></tr>\n",
      "<tr><td>2010  </td><td>mass effect 2                      </td><td>action rpg : ( third - person ) shooter</td><td>xbox 360 , windows , playstation 3</td><td>bioware                     </td></tr>\n",
      "<tr><td>2001  </td><td>super smash bros melee             </td><td>fighting                               </td><td>gamecube                          </td><td>hal laboratory , inc        </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: a gamecube game loss the award in each of the first 3 year\n",
      "    Column linking: gamecube -> platform_s, gamecube game -> game, the first 3 year -> year\n",
      "    Columns: year, game, platform_s\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>Hoot Kloot</caption>\n",
      "<thead>\n",
      "<tr><th> Number</th><th> Title</th><th> Directed_by_</th><th> Released_</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1  </td><td>\"Kloot's Kounty\"           </td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>2  </td><td>\"Apache on the County Seat\"</td><td>Hawley Pratt  </td><td>1973       </td></tr>\n",
      "<tr><td>6  </td><td>\"Stirrups and Hiccups\"     </td><td>Gerry Chiniquy</td><td>1973       </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Query: what was the last title that sid marcus directed?\n",
      "    Column linking: the last title -> Released_, the last title-> Number, title -> Title\n",
      "    Columns: Title, Released_, Number\n",
      "\n",
      "\n",
      "    Table: <table>\n",
      "<caption>Boksburg</caption>\n",
      "<thead>\n",
      "<tr><th>   Year</th><th>             Name</th><th>  Year_1</th><th>        Name_1</th><th>  Year_2</th><th>            Name_2</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1923-24</td><td>                 </td><td>1954-56 </td><td>Mr J.H.A.Roets</td><td>1988-89 </td><td>Mr Beyers De Klerk</td></tr>\n",
      "<tr><td>1904-05</td><td>Mr B. Owen- Jones</td><td>1936-37 </td><td>Mr W.Pearce   </td><td>1968-69 </td><td>Mr Ben Steyn      </td></tr>\n",
      "<tr><td>1908-09</td><td>Mr T.R.Ziervogel </td><td>1940-41 </td><td>Mr P.Venter   </td><td>1972-73 </td><td>Mr Ben Steyn      </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "    Extra information: The table contains information about individuals associated with Boksburg over different years.1. Year: The year in which the individual was associated with Boksburg\n",
      "2. Name: The name of the individual associated with Boksburg\n",
      "    Query: who was the first mayor to be inaugurated in witswaterand?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Year, Name\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOur ultimate goal is to answer query based on the original table. Now we have a sub-table with rows sampled from the original table, you are required to infer the data distribution and format from the sample data of the sub-table. Carefully analyze the query, based on the augmentation information, write a SQLITE3 SELECT SQL statement using table DF that complete query. Directly Output SQL, do not add other string.\n",
      "sub-table: <table>\n",
      "<caption>Boksburg</caption>\n",
      "<thead>\n",
      "<tr><th>  row_number</th><th>             Name</th><th>   Year</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>20          </td><td>                 </td><td>1923-24</td></tr>\n",
      "<tr><td>2           </td><td>Mr B. Owen- Jones</td><td>1904-05</td></tr>\n",
      "<tr><td>5           </td><td>Mr T.R.Ziervogel </td><td>1908-09</td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information: The table contains information about individuals associated with Boksburg over different years.\n",
      "Column information:\n",
      "Year:Each entry consists of a range of years indicating a specific time period.\n",
      "Name:Each entry is left blank, suggesting that there may be missing information or the data is not applicable for this column.\n",
      "row_number: row number in the original table\n",
      "\n",
      "Query: who was the first mayor to be inaugurated in witswaterand?\n",
      "SQL: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "SELECT Name\n",
      "FROM DF\n",
      "WHERE Name IS NOT NULL\n",
      "ORDER BY row_number\n",
      "LIMIT 1\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Think step by step and answer the last question given in the query.\n",
      "You should output in the following format:\n",
      "Thought: your step by step thought\n",
      "Answer: Only return the concise string instead of other format information. Do not repeat the question.\n",
      "Below is an example.\n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT MIN(points) FROM DF WHERE rider = 'roger dutton / tony wright';```\n",
      "Sub-table: <table>\n",
      "<caption>1972 isle of man tt</caption>\n",
      "<thead>\n",
      "<tr><th>  MIN(points)</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>3            </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Query: was 2 be the fewest point that roger dutton / tony wright receive?\n",
      "Thought: Based on the SQL query provided, the minimum number of points that Roger Dutton / Tony Wright received in the 1972 Isle of Man TT event was 3. 3 is the fewest points they received. \n",
      "Answer: 3\n",
      "    \n",
      "\n",
      "\n",
      "SQL Excuted: \n",
      "```SELECT * from DF;```\n",
      "Sub-table: <table>\n",
      "<thead>\n",
      "<tr><th>   Year</th><th>             Name</th><th>  Year_1</th><th>            Name_1</th><th>  Year_2</th><th>             Name_2</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>1903-04</td><td>Mr B. Owen- Jones</td><td>1935-36 </td><td>Mr W.Pearce       </td><td>1967-68 </td><td>Mr J.F.Serfontein  </td></tr>\n",
      "<tr><td>1904-05</td><td>Mr B. Owen- Jones</td><td>1936-37 </td><td>Mr W.Pearce       </td><td>1968-69 </td><td>Mr Ben Steyn       </td></tr>\n",
      "<tr><td>1905-06</td><td>Mr G. Constable  </td><td>1937 -38</td><td>                  </td><td>1969-70 </td><td>                   </td></tr>\n",
      "<tr><td>1907-08</td><td>Mr T.R.Ziervogel </td><td>1939 -40</td><td>Mr W.E.Vickers    </td><td>1971-72 </td><td>Mr Chris Smith     </td></tr>\n",
      "<tr><td>1908-09</td><td>Mr T.R.Ziervogel </td><td>1940-41 </td><td>Mr P.Venter       </td><td>1972-73 </td><td>Mr Ben Steyn       </td></tr>\n",
      "<tr><td>1909-10</td><td>Mr J.Morris      </td><td>1941-42 </td><td>Mr P.Venter       </td><td>1973-74 </td><td>Mr Issy Kramer     </td></tr>\n",
      "<tr><td>1910-11</td><td>                 </td><td>1942-43 </td><td>Mr P.Venter       </td><td>1974-75 </td><td>                   </td></tr>\n",
      "<tr><td>1911-12</td><td>Mr B.Owen- Jones </td><td>1943-44 </td><td>Mr P.Venter       </td><td>1975-76 </td><td>Mr Sakkie Blanche  </td></tr>\n",
      "<tr><td>1912-13</td><td>Mr J.Johnston    </td><td>1944-45 </td><td>Mrs E.Myer        </td><td>1977-78 </td><td>Mr Sakkie Blanche  </td></tr>\n",
      "<tr><td>1913-14</td><td>Mr J.Cook        </td><td>1945-46 </td><td>Mrs E.Myer        </td><td>1978-79 </td><td>                   </td></tr>\n",
      "<tr><td>1914-15</td><td>Mr J.Cook        </td><td>1946-47 </td><td>Mrs E.Myer        </td><td>1979 -80</td><td>Mr Kobus Durand    </td></tr>\n",
      "<tr><td>1915-16</td><td>Mr R.Champion    </td><td>1947-48 </td><td>Mr C.Chambers     </td><td>1980-81 </td><td>Mr Meyer           </td></tr>\n",
      "<tr><td>1916-17</td><td>Mr R.Champion    </td><td>1948-49 </td><td>Mrs S.Von Wielligh</td><td>1981-82 </td><td>Mr Wiek Steyn      </td></tr>\n",
      "<tr><td>1917-18</td><td>Mr A.Ruffels     </td><td>1949-50 </td><td>Mr A.J.Law        </td><td>1982-83 </td><td>Mr Andrew Wheeler  </td></tr>\n",
      "<tr><td>1918-19</td><td>Mr J.Campbell    </td><td>1950-51 </td><td>Mr P.Venter       </td><td>1983-84 </td><td>                   </td></tr>\n",
      "<tr><td>1919-20</td><td>Mr B.Melman      </td><td>1951-52 </td><td>Mr P.Venter       </td><td>1984-85 </td><td>                   </td></tr>\n",
      "<tr><td>1920-21</td><td>Mr B.Melman      </td><td>1952-53 </td><td>Mr Vic Pretorius  </td><td>1985-86 </td><td>Mr J.Prins         </td></tr>\n",
      "<tr><td>1921-21</td><td>Mr B.Melman      </td><td>1953-54 </td><td>Mr Vic Pretorius  </td><td>1986-87 </td><td>                   </td></tr>\n",
      "<tr><td>1922-23</td><td>Mr J.Campbell    </td><td>1954-55 </td><td>                  </td><td>1987-88 </td><td>                   </td></tr>\n",
      "<tr><td>1923-24</td><td>                 </td><td>1954-56 </td><td>Mr J.H.A.Roets    </td><td>1988-89 </td><td>Mr Beyers De Klerk </td></tr>\n",
      "<tr><td>1924-25</td><td>Mr E.Murton      </td><td>1956-57 </td><td>Mr P.H.Tredoux    </td><td>1989-90 </td><td>Mr Gerrie Wolmarans</td></tr>\n",
      "<tr><td>1925-26</td><td>Mr S.Steenberg   </td><td>1957- 58</td><td>                  </td><td>1990-91 </td><td>Mr Gerrie Wolmarans</td></tr>\n",
      "<tr><td>1926-27</td><td>                 </td><td>1958-59 </td><td>Mr J.M.Cawood     </td><td>1991-92 </td><td>Mr TJ Ferreira     </td></tr>\n",
      "<tr><td>1927-28</td><td>Mr J.Stanbury    </td><td>1959-60 </td><td>Mr A.P.Scribante  </td><td>1992-93 </td><td>Mr Gerrie Wolmarans</td></tr>\n",
      "<tr><td>1928-29</td><td>Mr E.Murton      </td><td>1960-61 </td><td>Mr J.L.Viljoen    </td><td>1993-94 </td><td>Mr TJ Ferreira     </td></tr>\n",
      "<tr><td>1929-30</td><td>Mr K.Turner      </td><td>1961-62 </td><td>Mr J.L.Viljoen    </td><td>        </td><td>                   </td></tr>\n",
      "<tr><td>1930-31</td><td>Mr J.E.Bigwood   </td><td>1962-63 </td><td>Mrs S.Von Wielligh</td><td>        </td><td>                   </td></tr>\n",
      "<tr><td>1931-32</td><td>Mr A.Zaretsky    </td><td>1963-64 </td><td>Mr F.J.Van Heerden</td><td>        </td><td>                   </td></tr>\n",
      "<tr><td>1932-33</td><td>Mr G.J.Malan     </td><td>1964-65 </td><td>                  </td><td>        </td><td>                   </td></tr>\n",
      "<tr><td>1933-34</td><td>                 </td><td>1965-66 </td><td>                  </td><td>        </td><td>                   </td></tr>\n",
      "<tr><td>1934-34</td><td>                 </td><td>1966-67 </td><td>Mr H.McLennan     </td><td>        </td><td>                   </td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "Extra information:\n",
      "The mayor in 1931-32 was Mr A.Zaretsky. The mayor in 1919-20 was Mr B.Melman.\n",
      "\n",
      "Query: who was the first mayor to be inaugurated in witswaterand?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import datetime\n",
    "from FlagEmbedding import FlagReranker\n",
    "from openai import BadRequestError\n",
    "from tqdm.notebook import tqdm\n",
    "table_loader = TableLoader(table_name='wikitable', split='test', use_sample=False, small_test=False)\n",
    "# model = ChatOpenAI(model_name='gpt-3.5-turbo-0125', openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "#                        openai_api_key=\"sk-WZtqZEeuE0Xb6syVghDgAxdwe0ASWLkQRGxl61UI7B9RqNC4\", temperature=0.01)\n",
    "# save_path = f\"result/answer/wikitable_{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.csv\"\n",
    "save_path = f\"result/answer/wikitable_05-09_07-12-21.csv\"\n",
    "\n",
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "muilti_answer_instruction = PromptTemplate(input_variables=[\"information\", \"claim\"], \n",
    "# no cot prompt, not used\n",
    "template = \"\"\"\n",
    "Below is a sub-table generated by excuting the corresponding SQL. You need to understand the logic behind the SQL filtering. Complete task with the help of extra information below.\n",
    "\n",
    "SQL Excuted: \n",
    "```{SQL}```\n",
    "Sub-table:\n",
    "{table}\n",
    "Extra information:\n",
    "{information}\n",
    "\n",
    "Query: {query}\n",
    "Think step by step and answer the last question given in the query. Only return the string instead of other format information. Do not repeat the question.\n",
    "\"\"\" )\n",
    "\n",
    "tokens = []\n",
    "outputs = []\n",
    "labels = []\n",
    "ids = []\n",
    "samplings = []\n",
    "i = 1441\n",
    "\n",
    "\n",
    "\n",
    "# with tqdm(total=len(table_loader.dataset)-1980, desc=f\"Processing\",ncols=150) as pbar:\n",
    "#     while i < len(table_loader.dataset):\n",
    "#         try:\n",
    "sample = table_loader.normalize_table(\n",
    "                    table_loader.dataset[i])\n",
    "all_tokens = 0\n",
    "all_queries = []\n",
    "formatter = TableFormat(format='none', data=sample, save_embedding=False)\n",
    "sample_data = formatter.get_sample_data(sample_type='random', query=sample['query'])\n",
    "with get_openai_callback() as cb:\n",
    "    llm_chain = LLMChain(llm=model, prompt=step_back_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    all_queries.append(batch_pred[0]['text'].strip())\n",
    "    llm_chain = LLMChain(llm=model, prompt=decompose_prompt_wiki, verbose=False)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'], \"table\": TableFormat.format_html(sample_data)}], return_only_outputs=True)\n",
    "    all_queries.extend(batch_pred[0]['text'].split(';'))\n",
    "    print(all_queries)\n",
    "all_tokens += cb.total_tokens\n",
    "args_list = [{\"query\": q, \"sample\": sample} for q in all_queries if reranker.compute_score([(q, sample['query'])], normalize=True) < 0.95]\n",
    "# print(len(args_list))\n",
    "ans_from_B = parallel_run_kwargs(scene_B, args_list)\n",
    "results = [res[0] for res in ans_from_B if res[0] != 'Cannot get answer from sub-table']\n",
    "all_tokens += sum([res[1] for res in ans_from_B])\n",
    "#With answer\n",
    "# results= []\n",
    "with get_openai_callback() as cb:\n",
    "    imp_input = scene_A(sample['query'], sample, True)\n",
    "    llm_chain = LLMChain(llm=model, prompt=get_k_shot_with_answer(), verbose=True)\n",
    "    batch_pred = llm_chain.batch([{\"query\": sample['query'],\"SQL\": imp_input[1], \"table\": imp_input[2], \"information\": '\\n'.join(results)}], return_only_outputs=True)\n",
    "# print(batch_pred[0])\n",
    "all_tokens += cb.total_tokens\n",
    "# print('ALL TOKENS', all_tokens)\n",
    "ids.append(sample['id'])\n",
    "labels.append(sample['query'])\n",
    "outputs.append(batch_pred[0]['text'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu-1441\n",
      "who was the first mayor to be inaugurated in witswaterand?\n",
      "+---------+-------------------+----------+--------------------+----------+---------------------+\n",
      "| Year    | Name              | Year_1   | Name_1             | Year_2   | Name_2              |\n",
      "|---------+-------------------+----------+--------------------+----------+---------------------|\n",
      "| 1903-04 | Mr B. Owen- Jones | 1935-36  | Mr W.Pearce        | 1967-68  | Mr J.F.Serfontein   |\n",
      "| 1904-05 | Mr B. Owen- Jones | 1936-37  | Mr W.Pearce        | 1968-69  | Mr Ben Steyn        |\n",
      "| 1905-06 | Mr G. Constable   | 1937 -38 |                    | 1969-70  |                     |\n",
      "| 1907-08 | Mr T.R.Ziervogel  | 1939 -40 | Mr W.E.Vickers     | 1971-72  | Mr Chris Smith      |\n",
      "| 1908-09 | Mr T.R.Ziervogel  | 1940-41  | Mr P.Venter        | 1972-73  | Mr Ben Steyn        |\n",
      "| 1909-10 | Mr J.Morris       | 1941-42  | Mr P.Venter        | 1973-74  | Mr Issy Kramer      |\n",
      "| 1910-11 |                   | 1942-43  | Mr P.Venter        | 1974-75  |                     |\n",
      "| 1911-12 | Mr B.Owen- Jones  | 1943-44  | Mr P.Venter        | 1975-76  | Mr Sakkie Blanche   |\n",
      "| 1912-13 | Mr J.Johnston     | 1944-45  | Mrs E.Myer         | 1977-78  | Mr Sakkie Blanche   |\n",
      "| 1913-14 | Mr J.Cook         | 1945-46  | Mrs E.Myer         | 1978-79  |                     |\n",
      "| 1914-15 | Mr J.Cook         | 1946-47  | Mrs E.Myer         | 1979 -80 | Mr Kobus Durand     |\n",
      "| 1915-16 | Mr R.Champion     | 1947-48  | Mr C.Chambers      | 1980-81  | Mr Meyer            |\n",
      "| 1916-17 | Mr R.Champion     | 1948-49  | Mrs S.Von Wielligh | 1981-82  | Mr Wiek Steyn       |\n",
      "| 1917-18 | Mr A.Ruffels      | 1949-50  | Mr A.J.Law         | 1982-83  | Mr Andrew Wheeler   |\n",
      "| 1918-19 | Mr J.Campbell     | 1950-51  | Mr P.Venter        | 1983-84  |                     |\n",
      "| 1919-20 | Mr B.Melman       | 1951-52  | Mr P.Venter        | 1984-85  |                     |\n",
      "| 1920-21 | Mr B.Melman       | 1952-53  | Mr Vic Pretorius   | 1985-86  | Mr J.Prins          |\n",
      "| 1921-21 | Mr B.Melman       | 1953-54  | Mr Vic Pretorius   | 1986-87  |                     |\n",
      "| 1922-23 | Mr J.Campbell     | 1954-55  |                    | 1987-88  |                     |\n",
      "| 1923-24 |                   | 1954-56  | Mr J.H.A.Roets     | 1988-89  | Mr Beyers De Klerk  |\n",
      "| 1924-25 | Mr E.Murton       | 1956-57  | Mr P.H.Tredoux     | 1989-90  | Mr Gerrie Wolmarans |\n",
      "| 1925-26 | Mr S.Steenberg    | 1957- 58 |                    | 1990-91  | Mr Gerrie Wolmarans |\n",
      "| 1926-27 |                   | 1958-59  | Mr J.M.Cawood      | 1991-92  | Mr TJ Ferreira      |\n",
      "| 1927-28 | Mr J.Stanbury     | 1959-60  | Mr A.P.Scribante   | 1992-93  | Mr Gerrie Wolmarans |\n",
      "| 1928-29 | Mr E.Murton       | 1960-61  | Mr J.L.Viljoen     | 1993-94  | Mr TJ Ferreira      |\n",
      "| 1929-30 | Mr K.Turner       | 1961-62  | Mr J.L.Viljoen     |          |                     |\n",
      "| 1930-31 | Mr J.E.Bigwood    | 1962-63  | Mrs S.Von Wielligh |          |                     |\n",
      "| 1931-32 | Mr A.Zaretsky     | 1963-64  | Mr F.J.Van Heerden |          |                     |\n",
      "| 1932-33 | Mr G.J.Malan      | 1964-65  |                    |          |                     |\n",
      "| 1933-34 |                   | 1965-66  |                    |          |                     |\n",
      "| 1934-34 |                   | 1966-67  | Mr H.McLennan      |          |                     |\n",
      "+---------+-------------------+----------+--------------------+----------+---------------------+\n",
      "['Mr B. Owen- Jones']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_table(data, execute=False):\n",
    "    formatter = TableFormat(format='none', data=data)\n",
    "    print(data['id'])\n",
    "    print(data['query'])\n",
    "    print(formatter.format_psql())\n",
    "    # print(preds[i])\n",
    "    # print(SQLs[i])\n",
    "    # test_df = manager.execute_from_df(SQLs[i], formatter.all_data)\n",
    "    # print(test_df)\n",
    "    print(data['label'])\n",
    "\n",
    "show_table(table_loader.normalize_table(table_loader.dataset[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlboy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
